{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bb2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_Thesis.nn_classes import *\n",
    "from NN_Thesis.trainer import *\n",
    "from NN_Thesis.adapters import *\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c5ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_Thesis.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb6e4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "random.seed(123)\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "from NN_Thesis.dataset import cifar_n_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_path = 'data/cifar_5/cifar_04/train/data'\n",
    "test_path ='data/cifar_5/cifar_04/test/data'\n",
    "\n",
    "train_data = cifar_n_dataset(train_path)\n",
    "test_data = cifar_n_dataset(train_path)\n",
    "print(train_data.data.shape)\n",
    "\n",
    "def normalize_channels(data):\n",
    "    #We have a nxCxWxH array\n",
    "    d = data\n",
    "    d = torch.flatten(data,2,-1).to(dtype = torch.float32)/255\n",
    "    mean= torch.mean(d,dim = [0,2])\n",
    "    std = torch.std(d,dim = [0,2])\n",
    "    return mean,std\n",
    "\n",
    "mean,std = normalize_channels(train_data.data)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_data.transform = train_transform\n",
    "test_data.transform = test_transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa0941e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_data,batch_size =64,shuffle = True)\n",
    "\n",
    "x = train_data[0]\n",
    "img,label = next(iter(train_dataloader))\n",
    "\n",
    "img.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf0c4b0",
   "metadata": {},
   "source": [
    "# Code For Initial Cifar5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d540a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight 2160\n",
      "bn1.weight 80\n",
      "bn1.bias 80\n",
      "layer1.0.conv1.weight 57600\n",
      "layer1.0.bn1.weight 80\n",
      "layer1.0.bn1.bias 80\n",
      "layer1.0.conv2.weight 57600\n",
      "layer1.0.bn2.weight 80\n",
      "layer1.0.bn2.bias 80\n",
      "layer1.1.conv1.weight 57600\n",
      "layer1.1.bn1.weight 80\n",
      "layer1.1.bn1.bias 80\n",
      "layer1.1.conv2.weight 57600\n",
      "layer1.1.bn2.weight 80\n",
      "layer1.1.bn2.bias 80\n",
      "layer2.0.conv1.weight 115200\n",
      "layer2.0.bn1.weight 160\n",
      "layer2.0.bn1.bias 160\n",
      "layer2.0.conv2.weight 230400\n",
      "layer2.0.bn2.weight 160\n",
      "layer2.0.bn2.bias 160\n",
      "layer2.0.downsample.0.weight 12800\n",
      "layer2.0.downsample.1.weight 160\n",
      "layer2.0.downsample.1.bias 160\n",
      "layer2.1.conv1.weight 230400\n",
      "layer2.1.bn1.weight 160\n",
      "layer2.1.bn1.bias 160\n",
      "layer2.1.conv2.weight 230400\n",
      "layer2.1.bn2.weight 160\n",
      "layer2.1.bn2.bias 160\n",
      "layer3.0.conv1.weight 460800\n",
      "layer3.0.bn1.weight 320\n",
      "layer3.0.bn1.bias 320\n",
      "layer3.0.conv2.weight 921600\n",
      "layer3.0.bn2.weight 320\n",
      "layer3.0.bn2.bias 320\n",
      "layer3.0.downsample.0.weight 51200\n",
      "layer3.0.downsample.1.weight 320\n",
      "layer3.0.downsample.1.bias 320\n",
      "layer3.1.conv1.weight 921600\n",
      "layer3.1.bn1.weight 320\n",
      "layer3.1.bn1.bias 320\n",
      "layer3.1.conv2.weight 921600\n",
      "layer3.1.bn2.weight 320\n",
      "layer3.1.bn2.bias 320\n",
      "bn2.weight 320\n",
      "bn2.bias 320\n",
      "bn3.weight 5\n",
      "bn3.bias 5\n",
      "fc.weight 1600\n",
      "fc.bias 5\n",
      "\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "\n",
      "conv1.weight 432\n",
      "bn1.weight 16\n",
      "bn1.bias 16\n",
      "layer1.0.conv1.weight 2304\n",
      "layer1.0.bn1.weight 16\n",
      "layer1.0.bn1.bias 16\n",
      "layer1.0.conv2.weight 2304\n",
      "layer1.0.bn2.weight 16\n",
      "layer1.0.bn2.bias 16\n",
      "layer1.1.conv1.weight 2304\n",
      "layer1.1.bn1.weight 16\n",
      "layer1.1.bn1.bias 16\n",
      "layer1.1.conv2.weight 2304\n",
      "layer1.1.bn2.weight 16\n",
      "layer1.1.bn2.bias 16\n",
      "layer2.0.conv1.weight 4608\n",
      "layer2.0.bn1.weight 32\n",
      "layer2.0.bn1.bias 32\n",
      "layer2.0.conv2.weight 9216\n",
      "layer2.0.bn2.weight 32\n",
      "layer2.0.bn2.bias 32\n",
      "layer2.0.downsample.0.weight 512\n",
      "layer2.0.downsample.1.weight 32\n",
      "layer2.0.downsample.1.bias 32\n",
      "layer2.1.conv1.weight 9216\n",
      "layer2.1.bn1.weight 32\n",
      "layer2.1.bn1.bias 32\n",
      "layer2.1.conv2.weight 9216\n",
      "layer2.1.bn2.weight 32\n",
      "layer2.1.bn2.bias 32\n",
      "layer3.0.conv1.weight 18432\n",
      "layer3.0.bn1.weight 64\n",
      "layer3.0.bn1.bias 64\n",
      "layer3.0.conv2.weight 36864\n",
      "layer3.0.bn2.weight 64\n",
      "layer3.0.bn2.bias 64\n",
      "layer3.0.downsample.0.weight 2048\n",
      "layer3.0.downsample.1.weight 64\n",
      "layer3.0.downsample.1.bias 64\n",
      "layer3.1.conv1.weight 36864\n",
      "layer3.1.bn1.weight 64\n",
      "layer3.1.bn1.bias 64\n",
      "layer3.1.conv2.weight 36864\n",
      "layer3.1.bn2.weight 64\n",
      "layer3.1.bn2.bias 64\n",
      "fc.weight 320\n",
      "fc.bias 5\n",
      "\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "\n",
      "conv1.weight 9408\n",
      "bn1.weight 64\n",
      "bn1.bias 64\n",
      "layer1.0.conv1.weight 36864\n",
      "layer1.0.bn1.weight 64\n",
      "layer1.0.bn1.bias 64\n",
      "layer1.0.conv2.weight 36864\n",
      "layer1.0.bn2.weight 64\n",
      "layer1.0.bn2.bias 64\n",
      "layer1.1.conv1.weight 36864\n",
      "layer1.1.bn1.weight 64\n",
      "layer1.1.bn1.bias 64\n",
      "layer1.1.conv2.weight 36864\n",
      "layer1.1.bn2.weight 64\n",
      "layer1.1.bn2.bias 64\n",
      "layer2.0.conv1.weight 73728\n",
      "layer2.0.bn1.weight 128\n",
      "layer2.0.bn1.bias 128\n",
      "layer2.0.conv2.weight 147456\n",
      "layer2.0.bn2.weight 128\n",
      "layer2.0.bn2.bias 128\n",
      "layer2.0.downsample.0.weight 8192\n",
      "layer2.0.downsample.1.weight 128\n",
      "layer2.0.downsample.1.bias 128\n",
      "layer2.1.conv1.weight 147456\n",
      "layer2.1.bn1.weight 128\n",
      "layer2.1.bn1.bias 128\n",
      "layer2.1.conv2.weight 147456\n",
      "layer2.1.bn2.weight 128\n",
      "layer2.1.bn2.bias 128\n",
      "layer3.0.conv1.weight 294912\n",
      "layer3.0.bn1.weight 256\n",
      "layer3.0.bn1.bias 256\n",
      "layer3.0.conv2.weight 589824\n",
      "layer3.0.bn2.weight 256\n",
      "layer3.0.bn2.bias 256\n",
      "layer3.0.downsample.0.weight 32768\n",
      "layer3.0.downsample.1.weight 256\n",
      "layer3.0.downsample.1.bias 256\n",
      "layer3.1.conv1.weight 589824\n",
      "layer3.1.bn1.weight 256\n",
      "layer3.1.bn1.bias 256\n",
      "layer3.1.conv2.weight 589824\n",
      "layer3.1.bn2.weight 256\n",
      "layer3.1.bn2.bias 256\n",
      "layer4.0.conv1.weight 1179648\n",
      "layer4.0.bn1.weight 512\n",
      "layer4.0.bn1.bias 512\n",
      "layer4.0.conv2.weight 2359296\n",
      "layer4.0.bn2.weight 512\n",
      "layer4.0.bn2.bias 512\n",
      "layer4.0.downsample.0.weight 131072\n",
      "layer4.0.downsample.1.weight 512\n",
      "layer4.0.downsample.1.bias 512\n",
      "layer4.1.conv1.weight 2359296\n",
      "layer4.1.bn1.weight 512\n",
      "layer4.1.bn1.bias 512\n",
      "layer4.1.conv2.weight 2359296\n",
      "layer4.1.bn2.weight 512\n",
      "layer4.1.bn2.bias 512\n",
      "fc.weight 2560\n",
      "fc.bias 5\n"
     ]
    }
   ],
   "source": [
    "# train_dataloader = DataLoader(train_data,batch_size =32,shuffle = True)\n",
    "# test_dataloader = DataLoader(test_data,batch_size =32)\n",
    "\n",
    "# classes = tuple(train_data.label_names)\n",
    "\n",
    "BNN_resnet18 = resnet_binary(num_classes = 5 , depth = 18, dataset = 'cifar10')\n",
    "resnet18 = resnet(num_classes = 5 , depth = 18, dataset = 'cifar10')\n",
    "\n",
    "\n",
    "ImageNet_resnet18 = resnet_binary(num_classes = 5 , depth = 18, dataset = 'imagenet')\n",
    "\n",
    "for name,p in BNN_resnet18.named_parameters():\n",
    "    print(name,p.numel())\n",
    "\n",
    "print('\\n\\n','*'*100,'\\n\\n')\n",
    "\n",
    "for name,p in resnet18.named_parameters():\n",
    "    print(name,p.numel())\n",
    "\n",
    "print('\\n\\n','*'*100,'\\n\\n')\n",
    "\n",
    "for name,p in ImageNet_resnet18.named_parameters():\n",
    "    print(name,p.numel())\n",
    "\n",
    "\n",
    "# BNN_trainer = Trainer(BNN_resnet18,model_name = 'Baseline_BNN_Resnet18',project_name = 'Cifar5',classes = classes,seed = 123,binarise = True)\n",
    "# resnet_trainer =Trainer(resnet18,model_name = 'Baseline_Resnet18',project_name='Cifar5',classes = classes,seed = 123)\n",
    "\n",
    "# #Set Training Params\n",
    "# for trainer in [resnet_trainer,BNN_trainer]:\n",
    "#     trainer.lr = 0.1\n",
    "#     trainer.epochs = 200\n",
    "#     trainer.train(train_dataloader,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93934118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3dd87e4",
   "metadata": {},
   "source": [
    "# Code For Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dog', 'frog', 'horse', 'ship', 'truck')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'data/cifar_5/cifar_59/train/data'\n",
    "test_path ='data/cifar_5/cifar_59/test/data'\n",
    "\n",
    "train59_data = cifar_n_dataset(train_path)\n",
    "test59_data = cifar_n_dataset(train_path)\n",
    "# print(train_data.data.shape)\n",
    "\n",
    "def normalize_channels(data):\n",
    "    #We have a nxCxWxH array\n",
    "    d = data\n",
    "    d = torch.flatten(data,2,-1).to(dtype = torch.float32)/255\n",
    "    mean= torch.mean(d,dim = [0,2])\n",
    "    std = torch.std(d,dim = [0,2])\n",
    "    return mean,std\n",
    "\n",
    "mean,std = normalize_channels(train59_data.data)\n",
    "\n",
    "train59_transform = transforms.Compose([\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "\n",
    "test59_transform = transforms.Compose([\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train59_data.transform = train_transform\n",
    "test59_data.transform = test_transform\n",
    "train59_loader = DataLoader(train59_data,batch_size=64,shuffle=True)\n",
    "test59_loader = DataLoader(test59_data,batch_size=64,shuffle=True)\n",
    "classes = tuple(train59_data.label_names)\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7738f11",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "630f80ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler Set {'T_max': 2, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnny_suu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221021_151642-uatt55lu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/uatt55lu\" target=\"_blank\">colorful-donkey-14</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name feat_extract_2022_10_21_15_16_40 \n",
      "\n",
      "\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 16\n",
      "epochs : 20\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Initial accuracy:\n",
      "Test Accuracy : 16.2%, Test Loss: 2.1748023987426173\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 16.3%, Test Loss: 2.1617062100973885\n",
      "best_acc.pth saved!\n",
      "epoch: 1 average loss: 1.018\n",
      "Test Accuracy : 71.7%, Test Loss: 0.778345244086307\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.59 seconds\n",
      "epoch: 2 average loss: 0.789\n",
      "Test Accuracy : 72.5%, Test Loss: 0.7703028683314848\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.49 seconds\n",
      "epoch: 3 average loss: 0.818\n",
      "Test Accuracy : 72.7%, Test Loss: 0.7590659085442039\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.45 seconds\n",
      "epoch: 4 average loss: 0.792\n",
      "Test Accuracy : 73.4%, Test Loss: 0.7154592788585311\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.60 seconds\n",
      "epoch: 5 average loss: 0.801\n",
      "Test Accuracy : 72.8%, Test Loss: 0.7554373843285739\n",
      "Epoch Time (Training + Test) = 15.40 seconds\n",
      "epoch: 6 average loss: 0.792\n",
      "Test Accuracy : 73.6%, Test Loss: 0.7205842814939406\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.51 seconds\n",
      "epoch: 7 average loss: 0.799\n",
      "Test Accuracy : 74.1%, Test Loss: 0.7146569101706796\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.88 seconds\n",
      "epoch: 8 average loss: 0.798\n",
      "Test Accuracy : 73.6%, Test Loss: 0.7300539442035548\n",
      "Epoch Time (Training + Test) = 15.77 seconds\n",
      "epoch: 9 average loss: 0.800\n",
      "Test Accuracy : 73.0%, Test Loss: 0.7385583724969488\n",
      "Epoch Time (Training + Test) = 15.42 seconds\n",
      "epoch: 10 average loss: 0.794\n",
      "Test Accuracy : 74.3%, Test Loss: 0.7084959781993075\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.29 seconds\n",
      "epoch: 11 average loss: 0.794\n",
      "Test Accuracy : 73.7%, Test Loss: 0.7179938634033398\n",
      "Epoch Time (Training + Test) = 15.52 seconds\n",
      "epoch: 12 average loss: 0.798\n",
      "Test Accuracy : 73.9%, Test Loss: 0.7187207472293883\n",
      "Epoch Time (Training + Test) = 15.76 seconds\n",
      "epoch: 13 average loss: 0.816\n",
      "Test Accuracy : 72.8%, Test Loss: 0.765395883251639\n",
      "Epoch Time (Training + Test) = 15.72 seconds\n",
      "epoch: 14 average loss: 0.790\n",
      "Test Accuracy : 70.9%, Test Loss: 0.7782728137719966\n",
      "Epoch Time (Training + Test) = 15.64 seconds\n",
      "epoch: 15 average loss: 0.844\n",
      "Test Accuracy : 72.1%, Test Loss: 0.7617558147138952\n",
      "Epoch Time (Training + Test) = 15.51 seconds\n",
      "epoch: 16 average loss: 0.802\n",
      "Test Accuracy : 74.3%, Test Loss: 0.7096615912359389\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.68 seconds\n",
      "epoch: 17 average loss: 0.823\n",
      "Test Accuracy : 72.6%, Test Loss: 0.777892378285108\n",
      "Epoch Time (Training + Test) = 15.86 seconds\n",
      "epoch: 18 average loss: 0.779\n",
      "Test Accuracy : 74.0%, Test Loss: 0.7066040064215355\n",
      "Epoch Time (Training + Test) = 15.82 seconds\n",
      "epoch: 19 average loss: 0.781\n",
      "Test Accuracy : 74.2%, Test Loss: 0.7078248743358475\n",
      "Epoch Time (Training + Test) = 15.88 seconds\n",
      "epoch: 20 average loss: 0.791\n",
      "Test Accuracy : 72.2%, Test Loss: 0.7408325191958786\n",
      "Epoch Time (Training + Test) = 15.89 seconds\n",
      "Data Saved to feat_extract.csv\n",
      "Finished Training: \n",
      "Total Time 0.173696 hours\n",
      " Average Time Per Epoch 31.27 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "PATH = '.\\SavedModels\\Cifar5\\Baseline_BNN_Resnet18_2022_10_21_10_47_20\\Baseline_BNN_Resnet18_best_acc.pth'\n",
    "BinCifar5_state_dict = torch.load(PATH,map_location= device)\n",
    "\n",
    "feat_extr_model = resnet18_adapt(num_classes= 5)\n",
    "feat_extr_model.load_state_dict(BinCifar5_state_dict)\n",
    "feat_extr_model.freeze()\n",
    "feat_extr_model.fc = BinarizeLinear(64*5,5)\n",
    "\n",
    "feat_ex = Trainer(feat_extr_model,model_name = 'feat_extract',project_name = 'Cifar5',classes = classes,seed = 123,binarise = True)\n",
    "feat_ex.lr = 0.01\n",
    "feat_ex.epochs = 20\n",
    "feat_ex.tags =['finetune']\n",
    "feat_ex.train(train59_loader,test59_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38177ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler Set {'T_max': 10, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnny_suu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221021_210406-349v7z76</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/349v7z76\" target=\"_blank\">devoted-oath-20</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name Regular_finetune \n",
      "\n",
      "\n",
      "Run Start : 2022-10-21 21-04-04\n",
      "start_epoch : 0\n",
      "initial_lr : 0.1\n",
      "batch_size : 32\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4336415\n",
      "Initial accuracy:\n",
      "Test Accuracy : 16.2%, Test Loss: 2.1748023987426173\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 16.3%, Test Loss: 2.1617062100973885\n",
      "best_acc.pth saved!\n",
      "epoch: 1 average loss: 0.809\n",
      "Test Accuracy : 76.2%, Test Loss: 0.6314606831201812\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.36 seconds\n",
      "epoch: 2 average loss: 0.646\n",
      "Test Accuracy : 77.6%, Test Loss: 0.6018474381750502\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.99 seconds\n",
      "epoch: 3 average loss: 0.625\n",
      "Test Accuracy : 78.5%, Test Loss: 0.5747368917288378\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 4 average loss: 0.598\n",
      "Test Accuracy : 79.9%, Test Loss: 0.5379818796806628\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.90 seconds\n",
      "epoch: 5 average loss: 0.574\n",
      "Test Accuracy : 79.9%, Test Loss: 0.5400047667724702\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 6 average loss: 0.574\n",
      "Test Accuracy : 80.5%, Test Loss: 0.5227721972233804\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.93 seconds\n",
      "epoch: 7 average loss: 0.570\n",
      "Test Accuracy : 80.8%, Test Loss: 0.5236607568953043\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.95 seconds\n",
      "epoch: 8 average loss: 0.564\n",
      "Test Accuracy : 80.9%, Test Loss: 0.5181642953697068\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.95 seconds\n",
      "epoch: 9 average loss: 0.548\n",
      "Test Accuracy : 80.8%, Test Loss: 0.5160978469244965\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 10 average loss: 0.557\n",
      "Test Accuracy : 81.2%, Test Loss: 0.5076424869734918\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.21 seconds\n",
      "epoch: 11 average loss: 0.557\n",
      "Test Accuracy : 81.2%, Test Loss: 0.5082084624206319\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.12 seconds\n",
      "epoch: 12 average loss: 0.556\n",
      "Test Accuracy : 81.0%, Test Loss: 0.5157267136875626\n",
      "Epoch Time (Training + Test) = 26.94 seconds\n",
      "epoch: 13 average loss: 0.553\n",
      "Test Accuracy : 81.2%, Test Loss: 0.5119158646182331\n",
      "Epoch Time (Training + Test) = 27.13 seconds\n",
      "epoch: 14 average loss: 0.555\n",
      "Test Accuracy : 80.8%, Test Loss: 0.5225867840944959\n",
      "Epoch Time (Training + Test) = 27.55 seconds\n",
      "epoch: 15 average loss: 0.561\n",
      "Test Accuracy : 81.2%, Test Loss: 0.5111305489945595\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.66 seconds\n",
      "epoch: 16 average loss: 0.562\n",
      "Test Accuracy : 81.4%, Test Loss: 0.5028243501625402\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.43 seconds\n",
      "epoch: 17 average loss: 0.546\n",
      "Test Accuracy : 81.0%, Test Loss: 0.511865431390455\n",
      "Epoch Time (Training + Test) = 27.46 seconds\n",
      "epoch: 18 average loss: 0.547\n",
      "Test Accuracy : 82.0%, Test Loss: 0.4951822767629648\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.65 seconds\n",
      "epoch: 19 average loss: 0.541\n",
      "Test Accuracy : 82.4%, Test Loss: 0.48058604965429474\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.56 seconds\n",
      "epoch: 20 average loss: 0.533\n",
      "Test Accuracy : 82.5%, Test Loss: 0.4749075391560869\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.51 seconds\n",
      "epoch: 21 average loss: 0.528\n",
      "Test Accuracy : 82.2%, Test Loss: 0.4884799463517221\n",
      "Epoch Time (Training + Test) = 27.38 seconds\n",
      "epoch: 22 average loss: 0.525\n",
      "Test Accuracy : 82.8%, Test Loss: 0.4730875197502658\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.69 seconds\n",
      "epoch: 23 average loss: 0.520\n",
      "Test Accuracy : 82.1%, Test Loss: 0.4864568556361186\n",
      "Epoch Time (Training + Test) = 27.55 seconds\n",
      "epoch: 24 average loss: 0.515\n",
      "Test Accuracy : 82.8%, Test Loss: 0.46865775335170423\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.65 seconds\n",
      "epoch: 25 average loss: 0.515\n",
      "Test Accuracy : 83.5%, Test Loss: 0.4530936503959129\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.63 seconds\n",
      "epoch: 26 average loss: 0.511\n",
      "Test Accuracy : 83.6%, Test Loss: 0.4497453364188714\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.60 seconds\n",
      "epoch: 27 average loss: 0.503\n",
      "Test Accuracy : 83.5%, Test Loss: 0.4564616567719623\n",
      "Epoch Time (Training + Test) = 27.53 seconds\n",
      "epoch: 28 average loss: 0.504\n",
      "Test Accuracy : 83.2%, Test Loss: 0.4580954407410853\n",
      "Epoch Time (Training + Test) = 27.67 seconds\n",
      "epoch: 29 average loss: 0.497\n",
      "Test Accuracy : 83.8%, Test Loss: 0.44265276197429815\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.74 seconds\n",
      "epoch: 30 average loss: 0.499\n",
      "Test Accuracy : 83.5%, Test Loss: 0.4503801838135171\n",
      "Epoch Time (Training + Test) = 27.73 seconds\n",
      "epoch: 31 average loss: 0.500\n",
      "Test Accuracy : 83.3%, Test Loss: 0.4518094546044879\n",
      "Epoch Time (Training + Test) = 27.53 seconds\n",
      "epoch: 32 average loss: 0.491\n",
      "Test Accuracy : 83.6%, Test Loss: 0.45272155563392297\n",
      "Epoch Time (Training + Test) = 27.08 seconds\n",
      "epoch: 33 average loss: 0.501\n",
      "Test Accuracy : 83.5%, Test Loss: 0.451506230646692\n",
      "Epoch Time (Training + Test) = 27.67 seconds\n",
      "epoch: 34 average loss: 0.500\n",
      "Test Accuracy : 83.6%, Test Loss: 0.4515785156079875\n",
      "Epoch Time (Training + Test) = 27.55 seconds\n",
      "epoch: 35 average loss: 0.504\n",
      "Test Accuracy : 83.3%, Test Loss: 0.45772131286618656\n",
      "Epoch Time (Training + Test) = 27.58 seconds\n",
      "epoch: 36 average loss: 0.506\n",
      "Test Accuracy : 83.5%, Test Loss: 0.45447048476285035\n",
      "Epoch Time (Training + Test) = 27.49 seconds\n",
      "epoch: 37 average loss: 0.509\n",
      "Test Accuracy : 83.7%, Test Loss: 0.4444017124069316\n",
      "Epoch Time (Training + Test) = 27.38 seconds\n",
      "epoch: 38 average loss: 0.506\n",
      "Test Accuracy : 82.4%, Test Loss: 0.48212053937375393\n",
      "Epoch Time (Training + Test) = 27.64 seconds\n",
      "epoch: 39 average loss: 0.501\n",
      "Test Accuracy : 84.0%, Test Loss: 0.4401417546488745\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.80 seconds\n",
      "epoch: 40 average loss: 0.501\n",
      "Test Accuracy : 83.6%, Test Loss: 0.4440670875103577\n",
      "Epoch Time (Training + Test) = 26.76 seconds\n",
      "epoch: 41 average loss: 0.495\n",
      "Test Accuracy : 83.9%, Test Loss: 0.4426970369446918\n",
      "Epoch Time (Training + Test) = 27.14 seconds\n",
      "epoch: 42 average loss: 0.504\n",
      "Test Accuracy : 83.7%, Test Loss: 0.4397051885457295\n",
      "Epoch Time (Training + Test) = 27.44 seconds\n",
      "epoch: 43 average loss: 0.497\n",
      "Test Accuracy : 83.9%, Test Loss: 0.4404875903635684\n",
      "Epoch Time (Training + Test) = 27.55 seconds\n",
      "epoch: 44 average loss: 0.496\n",
      "Test Accuracy : 83.4%, Test Loss: 0.4525612859088746\n",
      "Epoch Time (Training + Test) = 27.49 seconds\n",
      "epoch: 45 average loss: 0.488\n",
      "Test Accuracy : 83.9%, Test Loss: 0.4387443722666377\n",
      "Epoch Time (Training + Test) = 27.97 seconds\n",
      "epoch: 46 average loss: 0.491\n",
      "Test Accuracy : 83.7%, Test Loss: 0.4479389174667466\n",
      "Epoch Time (Training + Test) = 27.48 seconds\n",
      "epoch: 47 average loss: 0.485\n",
      "Test Accuracy : 84.5%, Test Loss: 0.43011901701045463\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.64 seconds\n",
      "epoch: 48 average loss: 0.482\n",
      "Test Accuracy : 83.8%, Test Loss: 0.44021604192988645\n",
      "Epoch Time (Training + Test) = 27.52 seconds\n",
      "epoch: 49 average loss: 0.477\n",
      "Test Accuracy : 84.0%, Test Loss: 0.43423418250992474\n",
      "Epoch Time (Training + Test) = 27.52 seconds\n",
      "epoch: 50 average loss: 0.482\n",
      "Test Accuracy : 84.1%, Test Loss: 0.4350248547771093\n",
      "Epoch Time (Training + Test) = 27.53 seconds\n",
      "epoch: 51 average loss: 0.477\n",
      "Test Accuracy : 84.3%, Test Loss: 0.43002912337365357\n",
      "Epoch Time (Training + Test) = 27.73 seconds\n",
      "epoch: 52 average loss: 0.479\n",
      "Test Accuracy : 84.1%, Test Loss: 0.43274524487802746\n",
      "Epoch Time (Training + Test) = 27.66 seconds\n",
      "epoch: 53 average loss: 0.480\n",
      "Test Accuracy : 84.3%, Test Loss: 0.4359709666208233\n",
      "Epoch Time (Training + Test) = 27.86 seconds\n",
      "epoch: 54 average loss: 0.478\n",
      "Test Accuracy : 84.3%, Test Loss: 0.4288838753462448\n",
      "Epoch Time (Training + Test) = 28.27 seconds\n",
      "epoch: 55 average loss: 0.482\n",
      "Test Accuracy : 84.3%, Test Loss: 0.42671543573174636\n",
      "Epoch Time (Training + Test) = 28.25 seconds\n",
      "epoch: 56 average loss: 0.486\n",
      "Test Accuracy : 84.3%, Test Loss: 0.4303775728129975\n",
      "Epoch Time (Training + Test) = 28.51 seconds\n",
      "epoch: 57 average loss: 0.485\n",
      "Test Accuracy : 84.2%, Test Loss: 0.4278896622112035\n",
      "Epoch Time (Training + Test) = 28.31 seconds\n",
      "epoch: 58 average loss: 0.488\n",
      "Test Accuracy : 84.3%, Test Loss: 0.42595900842905654\n",
      "Epoch Time (Training + Test) = 28.13 seconds\n",
      "epoch: 59 average loss: 0.480\n",
      "Test Accuracy : 84.3%, Test Loss: 0.4312249313839866\n",
      "Epoch Time (Training + Test) = 28.10 seconds\n",
      "epoch: 60 average loss: 0.486\n",
      "Test Accuracy : 84.4%, Test Loss: 0.4267700456292428\n",
      "Epoch Time (Training + Test) = 28.21 seconds\n",
      "epoch: 61 average loss: 0.480\n",
      "Test Accuracy : 84.7%, Test Loss: 0.4211365668212666\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.18 seconds\n",
      "epoch: 62 average loss: 0.481\n",
      "Test Accuracy : 84.9%, Test Loss: 0.42073236470637115\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.18 seconds\n",
      "epoch: 63 average loss: 0.488\n",
      "Test Accuracy : 83.8%, Test Loss: 0.43789463172026\n",
      "Epoch Time (Training + Test) = 28.17 seconds\n",
      "epoch: 64 average loss: 0.480\n",
      "Test Accuracy : 84.7%, Test Loss: 0.420209461275269\n",
      "Epoch Time (Training + Test) = 28.21 seconds\n",
      "epoch: 65 average loss: 0.477\n",
      "Test Accuracy : 84.2%, Test Loss: 0.43152309973221603\n",
      "Epoch Time (Training + Test) = 28.18 seconds\n",
      "epoch: 66 average loss: 0.474\n",
      "Test Accuracy : 84.8%, Test Loss: 0.4168698810174337\n",
      "Epoch Time (Training + Test) = 28.71 seconds\n",
      "epoch: 67 average loss: 0.475\n",
      "Test Accuracy : 85.1%, Test Loss: 0.4117960314768964\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.18 seconds\n",
      "epoch: 68 average loss: 0.473\n",
      "Test Accuracy : 84.8%, Test Loss: 0.4190367724736938\n",
      "Epoch Time (Training + Test) = 28.37 seconds\n",
      "epoch: 69 average loss: 0.469\n",
      "Test Accuracy : 85.0%, Test Loss: 0.41777058147713353\n",
      "Epoch Time (Training + Test) = 28.16 seconds\n",
      "epoch: 70 average loss: 0.463\n",
      "Test Accuracy : 84.6%, Test Loss: 0.42325294863842333\n",
      "Epoch Time (Training + Test) = 28.13 seconds\n",
      "epoch: 71 average loss: 0.465\n",
      "Test Accuracy : 84.9%, Test Loss: 0.41221995998526473\n",
      "Epoch Time (Training + Test) = 28.15 seconds\n",
      "epoch: 72 average loss: 0.470\n",
      "Test Accuracy : 84.9%, Test Loss: 0.41138043751954423\n",
      "Epoch Time (Training + Test) = 28.06 seconds\n",
      "epoch: 73 average loss: 0.470\n",
      "Test Accuracy : 84.5%, Test Loss: 0.4239797291472135\n",
      "Epoch Time (Training + Test) = 28.17 seconds\n",
      "epoch: 74 average loss: 0.471\n",
      "Test Accuracy : 84.9%, Test Loss: 0.414707266956644\n",
      "Epoch Time (Training + Test) = 28.07 seconds\n",
      "epoch: 75 average loss: 0.473\n",
      "Test Accuracy : 84.6%, Test Loss: 0.41420182703858444\n",
      "Epoch Time (Training + Test) = 28.16 seconds\n",
      "epoch: 76 average loss: 0.471\n",
      "Test Accuracy : 84.3%, Test Loss: 0.4235412971976468\n",
      "Epoch Time (Training + Test) = 28.09 seconds\n",
      "epoch: 77 average loss: 0.478\n",
      "Test Accuracy : 84.4%, Test Loss: 0.4270097863719896\n",
      "Epoch Time (Training + Test) = 28.11 seconds\n",
      "epoch: 78 average loss: 0.473\n",
      "Test Accuracy : 84.9%, Test Loss: 0.4147106885071606\n",
      "Epoch Time (Training + Test) = 28.14 seconds\n",
      "epoch: 79 average loss: 0.480\n",
      "Test Accuracy : 84.6%, Test Loss: 0.42240109422322736\n",
      "Epoch Time (Training + Test) = 28.21 seconds\n",
      "epoch: 80 average loss: 0.478\n",
      "Test Accuracy : 84.5%, Test Loss: 0.41692108613298373\n",
      "Epoch Time (Training + Test) = 28.10 seconds\n",
      "epoch: 81 average loss: 0.476\n",
      "Test Accuracy : 84.0%, Test Loss: 0.4341806997271145\n",
      "Epoch Time (Training + Test) = 28.23 seconds\n",
      "epoch: 82 average loss: 0.476\n",
      "Test Accuracy : 84.9%, Test Loss: 0.41508550377910397\n",
      "Epoch Time (Training + Test) = 28.16 seconds\n",
      "epoch: 83 average loss: 0.471\n",
      "Test Accuracy : 82.9%, Test Loss: 0.459553888920323\n",
      "Epoch Time (Training + Test) = 28.09 seconds\n",
      "epoch: 84 average loss: 0.476\n",
      "Test Accuracy : 84.8%, Test Loss: 0.42000195932815143\n",
      "Epoch Time (Training + Test) = 28.12 seconds\n",
      "epoch: 85 average loss: 0.472\n",
      "Test Accuracy : 84.9%, Test Loss: 0.4144811697323304\n",
      "Epoch Time (Training + Test) = 28.13 seconds\n",
      "epoch: 86 average loss: 0.472\n",
      "Test Accuracy : 83.3%, Test Loss: 0.45229088898052644\n",
      "Epoch Time (Training + Test) = 28.26 seconds\n",
      "epoch: 87 average loss: 0.468\n",
      "Test Accuracy : 85.2%, Test Loss: 0.40704356328300806\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.52 seconds\n",
      "epoch: 88 average loss: 0.464\n",
      "Test Accuracy : 84.9%, Test Loss: 0.41356489957903353\n",
      "Epoch Time (Training + Test) = 27.58 seconds\n",
      "epoch: 89 average loss: 0.462\n",
      "Test Accuracy : 85.2%, Test Loss: 0.4114698624748098\n",
      "Epoch Time (Training + Test) = 27.06 seconds\n",
      "epoch: 90 average loss: 0.461\n",
      "Test Accuracy : 85.2%, Test Loss: 0.4058718917238743\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 91 average loss: 0.461\n",
      "Test Accuracy : 85.3%, Test Loss: 0.40330688083720634\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.21 seconds\n",
      "epoch: 92 average loss: 0.468\n",
      "Test Accuracy : 83.9%, Test Loss: 0.4324714906151642\n",
      "Epoch Time (Training + Test) = 27.15 seconds\n",
      "epoch: 93 average loss: 0.458\n",
      "Test Accuracy : 85.2%, Test Loss: 0.405216664228293\n",
      "Epoch Time (Training + Test) = 27.34 seconds\n",
      "epoch: 94 average loss: 0.475\n",
      "Test Accuracy : 85.2%, Test Loss: 0.4076776786914567\n",
      "Epoch Time (Training + Test) = 27.21 seconds\n",
      "epoch: 95 average loss: 0.466\n",
      "Test Accuracy : 84.8%, Test Loss: 0.41412569060350013\n",
      "Epoch Time (Training + Test) = 27.14 seconds\n",
      "epoch: 96 average loss: 0.465\n",
      "Test Accuracy : 85.3%, Test Loss: 0.4031306342853\n",
      "Epoch Time (Training + Test) = 27.29 seconds\n",
      "epoch: 97 average loss: 0.465\n",
      "Test Accuracy : 84.7%, Test Loss: 0.41745723490519904\n",
      "Epoch Time (Training + Test) = 27.16 seconds\n",
      "epoch: 98 average loss: 0.470\n",
      "Test Accuracy : 85.0%, Test Loss: 0.41314037967368467\n",
      "Epoch Time (Training + Test) = 27.14 seconds\n",
      "epoch: 99 average loss: 0.471\n",
      "Test Accuracy : 84.5%, Test Loss: 0.42643165855151616\n",
      "Epoch Time (Training + Test) = 27.12 seconds\n",
      "epoch: 100 average loss: 0.477\n",
      "Test Accuracy : 79.7%, Test Loss: 0.5422209664378934\n",
      "Epoch Time (Training + Test) = 27.22 seconds\n",
      "Data Saved to Regular_finetune.csv\n",
      "Finished Training: \n",
      "Total Time 1.535879 hours\n",
      " Average Time Per Epoch 55.29 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "PATH = '.\\SavedModels\\Cifar5\\Baseline_BNN_Resnet18_2022_10_21_10_47_20\\Baseline_BNN_Resnet18_best_acc.pth'\n",
    "BinCifar5_state_dict = torch.load(PATH,map_location= device)\n",
    "\n",
    "\n",
    "finetune_model = resnet18_adapt(num_classes= 5)\n",
    "finetune_model.load_state_dict(BinCifar5_state_dict)\n",
    "finetune_model.freeze()\n",
    "finetune_model.fc = BinarizeLinear(64*5,5)\n",
    "\n",
    "finetune = Trainer(finetune_model,model_name = 'Regular_finetune',project_name='Cifar5',classes = classes,seed = 123,binarise = True)\n",
    "finetune.lr = 0.01\n",
    "finetune.epochs = 20\n",
    "finetune.tags = ['finetune']\n",
    "m = finetune.model\n",
    "# m.to(finetune.device)\n",
    "# for layer in [m.fc,m.bn3,m.bn3]:\n",
    "#     for p in layer.parameters():\n",
    "#         p.requires_grad = True\n",
    "#     layer.train()\n",
    "# finetune.train(train59_loader,test59_loader)\n",
    "\n",
    "\n",
    "#FineTune\n",
    "finetune.epochs = 100\n",
    "finetune.lr = 0.1\n",
    "finetune.optimizer = optim.SGD(finetune.model.parameters(), lr=finetune.lr, momentum=0.9)\n",
    "finetune.scheduler = optim.lr_scheduler.CosineAnnealingLR(finetune.optimizer,finetune.epochs)\n",
    "m.unfreeze()\n",
    "finetune.train(train59_loader,test59_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab91d0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4336415"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = finetune.get_param_info()\n",
    "\n",
    "z = finetune.model\n",
    "element_info = dict()\n",
    "for layer in z.parameters():\n",
    "    if str(layer.dtype) not in element_info.keys():\n",
    "        element_info[str(layer.dtype)] = layer.numel()\n",
    "    else:\n",
    "        element_info[str(layer.dtype)] += layer.numel()\n",
    "\n",
    "element_info[str(layer.dtype)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76552806",
   "metadata": {},
   "source": [
    "# Adapter FineTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5909160e",
   "metadata": {},
   "source": [
    "## Single Autoencoder After bn2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e6b460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start_epoch : 0\n",
      "lr : 0.01\n",
      "batch_size : 128\n",
      "epochs : 70\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "epoch: 1 average loss: 1.388 Epoch Time 0.14 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 44.1%\n",
      "best_acc.pth saved!\n",
      "epoch: 2 average loss: 1.144 Epoch Time 0.28 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 52.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 3 average loss: 1.068 Epoch Time 0.42 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 57.9%\n",
      "best_acc.pth saved!\n",
      "epoch: 4 average loss: 1.011 Epoch Time 0.56 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 60.9%\n",
      "best_acc.pth saved!\n",
      "epoch: 5 average loss: 0.980 Epoch Time 0.69 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 65.1%\n",
      "best_acc.pth saved!\n",
      "epoch: 6 average loss: 0.940 Epoch Time 0.83 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 65.2%\n",
      "best_acc.pth saved!\n",
      "epoch: 7 average loss: 0.910 Epoch Time 0.97 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 67.1%\n",
      "best_acc.pth saved!\n",
      "epoch: 8 average loss: 0.888 Epoch Time 1.10 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 69.2%\n",
      "best_acc.pth saved!\n",
      "epoch: 9 average loss: 0.867 Epoch Time 1.24 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 69.8%\n",
      "best_acc.pth saved!\n",
      "epoch: 10 average loss: 0.847 Epoch Time 1.37 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 69.3%\n",
      "epoch: 11 average loss: 0.840 Epoch Time 1.50 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 71.1%\n",
      "best_acc.pth saved!\n",
      "epoch: 12 average loss: 0.832 Epoch Time 1.64 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 71.1%\n",
      "epoch: 13 average loss: 0.819 Epoch Time 1.77 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 71.6%\n",
      "best_acc.pth saved!\n",
      "epoch: 14 average loss: 0.803 Epoch Time 1.91 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.2%\n",
      "best_acc.pth saved!\n",
      "epoch: 15 average loss: 0.792 Epoch Time 2.04 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 16 average loss: 0.790 Epoch Time 2.18 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.2%\n",
      "epoch: 17 average loss: 0.780 Epoch Time 2.31 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.0%\n",
      "best_acc.pth saved!\n",
      "epoch: 18 average loss: 0.765 Epoch Time 2.45 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.1%\n",
      "epoch: 19 average loss: 0.762 Epoch Time 2.58 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 20 average loss: 0.757 Epoch Time 2.71 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.5%\n",
      "best_acc.pth saved!\n",
      "epoch: 21 average loss: 0.752 Epoch Time 2.85 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.3%\n",
      "epoch: 22 average loss: 0.750 Epoch Time 2.98 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.1%\n",
      "epoch: 23 average loss: 0.750 Epoch Time 3.12 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.6%\n",
      "best_acc.pth saved!\n",
      "epoch: 24 average loss: 0.749 Epoch Time 3.25 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.2%\n",
      "epoch: 25 average loss: 0.752 Epoch Time 3.38 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.6%\n",
      "epoch: 26 average loss: 0.748 Epoch Time 3.52 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.9%\n",
      "best_acc.pth saved!\n",
      "epoch: 27 average loss: 0.744 Epoch Time 3.65 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.5%\n",
      "epoch: 28 average loss: 0.747 Epoch Time 3.79 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.8%\n",
      "epoch: 29 average loss: 0.749 Epoch Time 3.92 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.8%\n",
      "epoch: 30 average loss: 0.745 Epoch Time 4.06 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.8%\n",
      "epoch: 31 average loss: 0.745 Epoch Time 4.19 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 32 average loss: 0.742 Epoch Time 4.32 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.0%\n",
      "epoch: 33 average loss: 0.745 Epoch Time 4.46 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.7%\n",
      "epoch: 34 average loss: 0.745 Epoch Time 4.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.8%\n",
      "epoch: 35 average loss: 0.746 Epoch Time 4.73 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.4%\n",
      "epoch: 36 average loss: 0.744 Epoch Time 4.86 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.8%\n",
      "epoch: 37 average loss: 0.746 Epoch Time 4.99 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 70.4%\n",
      "epoch: 38 average loss: 0.744 Epoch Time 5.13 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.2%\n",
      "epoch: 39 average loss: 0.744 Epoch Time 5.26 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.5%\n",
      "epoch: 40 average loss: 0.745 Epoch Time 5.40 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.8%\n",
      "epoch: 41 average loss: 0.742 Epoch Time 5.53 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.4%\n",
      "epoch: 42 average loss: 0.746 Epoch Time 5.67 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.7%\n",
      "epoch: 43 average loss: 0.746 Epoch Time 5.81 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.3%\n",
      "epoch: 44 average loss: 0.740 Epoch Time 5.95 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.2%\n",
      "epoch: 45 average loss: 0.741 Epoch Time 6.09 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.7%\n",
      "epoch: 46 average loss: 0.743 Epoch Time 6.22 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.2%\n",
      "epoch: 47 average loss: 0.740 Epoch Time 6.36 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.4%\n",
      "epoch: 48 average loss: 0.742 Epoch Time 6.49 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.6%\n",
      "epoch: 49 average loss: 0.739 Epoch Time 6.63 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.0%\n",
      "epoch: 50 average loss: 0.740 Epoch Time 6.77 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.5%\n",
      "epoch: 51 average loss: 0.741 Epoch Time 6.90 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.9%\n",
      "epoch: 52 average loss: 0.740 Epoch Time 7.04 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.0%\n",
      "epoch: 53 average loss: 0.740 Epoch Time 7.18 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.0%\n",
      "epoch: 54 average loss: 0.738 Epoch Time 7.32 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.9%\n",
      "epoch: 55 average loss: 0.737 Epoch Time 7.46 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.4%\n",
      "epoch: 56 average loss: 0.739 Epoch Time 7.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.2%\n",
      "epoch: 57 average loss: 0.741 Epoch Time 7.73 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 58 average loss: 0.739 Epoch Time 7.87 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.9%\n",
      "epoch: 59 average loss: 0.740 Epoch Time 8.02 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.4%\n",
      "epoch: 60 average loss: 0.735 Epoch Time 8.16 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.2%\n",
      "epoch: 61 average loss: 0.741 Epoch Time 8.30 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.0%\n",
      "epoch: 62 average loss: 0.738 Epoch Time 8.45 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.0%\n",
      "epoch: 63 average loss: 0.732 Epoch Time 8.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.1%\n",
      "epoch: 64 average loss: 0.736 Epoch Time 8.73 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.4%\n",
      "epoch: 65 average loss: 0.737 Epoch Time 8.87 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.6%\n",
      "epoch: 66 average loss: 0.738 Epoch Time 9.01 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.2%\n",
      "epoch: 67 average loss: 0.733 Epoch Time 9.15 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.9%\n",
      "epoch: 68 average loss: 0.736 Epoch Time 9.29 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.2%\n",
      "epoch: 69 average loss: 0.732 Epoch Time 9.44 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.1%\n",
      "epoch: 70 average loss: 0.729 Epoch Time 9.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.0%\n",
      "Data Saved to adapt_fine.csv\n",
      "Finished Training: \n",
      "Total Time 0.159884 hours\n",
      " Average Time Per Epoch 8.22 seconds\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Bin_state_dict = torch.load('BinaryCifar5_best_acc.pth',map_location= device)\n",
    "\n",
    "bottleneck = autoencoder_adapter(320,200)\n",
    "adapt_fine = resnet18_adapt(num_classes=5)\n",
    "adapt_fine.load_state_dict(Bin_state_dict)\n",
    "adapt_fine.freeze()\n",
    "adapt_fine.add_adapter(after = 'bn2',adapter = bottleneck)\n",
    "\n",
    "adapt_fine_trainer = adapter_Trainer(model = adapt_fine,seed = 123,model_name = 'adapt_fine',project_name='Cifar5',classes = classes,binarise= True)\n",
    "for trainer in [adapt_fine_trainer]:\n",
    "    m = trainer.model\n",
    "    m.to(trainer.device)\n",
    "    for layer in [m.fc,m.bn3,m.bn3]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = True\n",
    "        layer.train()\n",
    "    trainer.lr = 0.01\n",
    "    trainer.batch_size = 128\n",
    "    trainer.epochs =70\n",
    "    trainer.epoch_chkpts = []\n",
    "    trainer.start_epoch = 0\n",
    "    trainer.T_max = 70\n",
    "    # trainer.scheduler.T_max= trainer.T_max\n",
    "    # trainer.optimizer = optim.Adam(trainer.model.parameters(), lr=trainer.lr)\n",
    "    trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max= trainer.epochs)\n",
    "    trainer.train(train59_loader,test59_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b10f70d",
   "metadata": {},
   "source": [
    "## 2 Adapters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "080e9358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start_epoch : 0\n",
      "lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 50\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Cifar_n.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Su/Downloads/SydneyUni/thesis/Thesis/Cifar_n.ipynb#X21sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m trainer\u001b[39m.\u001b[39mT_max \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Su/Downloads/SydneyUni/thesis/Thesis/Cifar_n.ipynb#X21sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m trainer\u001b[39m.\u001b[39mscheduler \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mCosineAnnealingLR(trainer\u001b[39m.\u001b[39moptimizer, T_max\u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mepochs)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/John%20Su/Downloads/SydneyUni/thesis/Thesis/Cifar_n.ipynb#X21sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(train59_loader,test59_loader)\n",
      "File \u001b[1;32mc:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\NN_Thesis\\trainer.py:93\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, trainloader, testloader)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39m#Add chkpt saving\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_epoch,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs):   \n\u001b[1;32m---> 93\u001b[0m     loss,acc\u001b[39m=\u001b[39m  (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_epoch(epoch,trainloader),\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest(testloader))\n\u001b[0;32m     94\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_losses\u001b[39m.\u001b[39mappend((loss,acc))\n\u001b[0;32m     95\u001b[0m     \u001b[39m#Save at checkpoint\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\NN_Thesis\\trainer.py:142\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[1;34m(self, epoch, trainloader)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m--> 142\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m    143\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    145\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39mtime\u001b[39m.\u001b[39mperf_counter()\u001b[39m-\u001b[39m  time_start\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Bin_state_dict = torch.load('BinaryCifar5_best_acc.pth',map_location= device)\n",
    "\n",
    "# bottleneck = autoencoder_adapter(320,200)\n",
    "conv_bn = conv_adapter(80,kernel = 1, padding= 0)\n",
    "\n",
    "adapt_fine2 = resnet18_adapt(num_classes=5)\n",
    "adapt_fine2.load_state_dict(Bin_state_dict)\n",
    "adapt_fine2.freeze()\n",
    "\n",
    "# adapt_fine2.add_adapter(after = 'bn2',adapter = bottleneck)\n",
    "adapt_fine2.add_adapter(after = 'layer1',adapter = conv_bn)\n",
    "\n",
    "adapt_fine2_trainer = adapter_Trainer(model = adapt_fine2,seed = 123,name = 'adapt_fine2',classes = classes,binarise= True)\n",
    "for trainer in [adapt_fine2_trainer]:\n",
    "    m = trainer.model\n",
    "    m.to(trainer.device)\n",
    "    for layer in [m.fc,m.bn3,m.bn3]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = True\n",
    "        layer.train()\n",
    "    trainer.lr = 0.01\n",
    "    trainer.batch_size = 32\n",
    "    trainer.epochs =50\n",
    "    trainer.epoch_chkpts = []\n",
    "    trainer.start_epoch = 0\n",
    "    trainer.T_max = 50\n",
    "    trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max= trainer.epochs)\n",
    "    trainer.train(train59_loader,test59_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df2c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ea3499b",
   "metadata": {},
   "source": [
    "# Weight Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "770e923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_weights(main_model:nn.Module,*models:nn.Module):\n",
    "\n",
    "    main_weights = dict()\n",
    "    for (name, param) in main_model.named_parameters():\n",
    "        main_weights[name] = param\n",
    "\n",
    "    n = len( list(main_model.named_parameters()))\n",
    "    print(n)\n",
    "    \n",
    "    for model in models:\n",
    "        i = 0\n",
    "        for name, param in model.named_parameters():\n",
    "            if name in main_weights.keys():\n",
    "                main_weight = main_weights[name]\n",
    "                if not (torch.all(main_weight == param)):\n",
    "                    print(f'parameters {name} in main_model and other model do not match')\n",
    "            else:\n",
    "                print(f'name {name} does not exist in original model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab905d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "name layer1.2.conv1.weight does not exist in original model\n",
      "name layer1.2.bn1.weight does not exist in original model\n",
      "name layer1.2.bn1.bias does not exist in original model\n",
      "name layer1.2.deconv1.weight does not exist in original model\n",
      "name layer1.2.bn2.weight does not exist in original model\n",
      "name layer1.2.bn2.bias does not exist in original model\n",
      "parameters bn3.weight in main_model and other model do not match\n",
      "parameters bn3.bias in main_model and other model do not match\n",
      "parameters fc.weight in main_model and other model do not match\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.l_in.weight does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.l_in.bias does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.bn1.weight does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.bn1.bias does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.l_out.weight does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.l_out.bias does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.bn2.weight does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.bn2.bias does not exist in original model\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Bin_state_dict = torch.load('BinaryCifar5_best_acc.pth',map_location= device)\n",
    "fineTune_dict = torch.load('adapt_fine2_best_acc.pth',map_location= device)\n",
    "\n",
    "og_model =  resnet18_adapt(num_classes=5)\n",
    "og_model.load_state_dict(Bin_state_dict)\n",
    "og_model.to(device = 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "finetune = resnet18_adapt(num_classes=5)\n",
    "\n",
    "finetune.to(device = 'cpu')\n",
    "bottleneck = autoencoder_adapter(320,200)\n",
    "conv_bn = conv_bottleneck_adapter(80,40,kernel = 3, padding= 1)\n",
    "finetune.add_adapter(after = 'bn2',adapter = bottleneck)\n",
    "finetune.add_adapter(after = 'layer1',adapter = conv_bn)\n",
    "\n",
    "finetune.load_state_dict(fineTune_dict)\n",
    "\n",
    "# h = resnet18_adapt(num_classes=5)\n",
    "# x = resnet18_adapt(num_classes=5)\n",
    "compare_weights(og_model,finetune)\n",
    "\n",
    "\n",
    "# h = resnet18_adapt(num_classes=5)\n",
    "# x = resnet18_adapt(num_classes=5)\n",
    "\n",
    "# print(torch.all(h.weight == x.weight))\n",
    "\n",
    "# compare_weights(h,x)\n",
    "# print(h.weight)\n",
    "# adapt_fine2.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d27190a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start_epoch : 0\n",
      "lr : 0.01\n",
      "batch_size : 128\n",
      "epochs : 80\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "epoch: 1 average loss: 2.592 Epoch Time 0.89 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 29.9%\n",
      "best_acc.pth saved!\n",
      "epoch: 2 average loss: 1.996 Epoch Time 1.77 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 26.5%\n",
      "epoch: 3 average loss: 1.882 Epoch Time 2.64 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.5%\n",
      "best_acc.pth saved!\n",
      "epoch: 4 average loss: 1.860 Epoch Time 3.52 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 21.6%\n",
      "epoch: 5 average loss: 1.925 Epoch Time 4.40 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 29.8%\n",
      "epoch: 6 average loss: 1.910 Epoch Time 5.28 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 31.1%\n",
      "epoch: 7 average loss: 1.868 Epoch Time 6.16 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 28.4%\n",
      "epoch: 8 average loss: 1.945 Epoch Time 7.04 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 27.6%\n",
      "epoch: 9 average loss: 1.944 Epoch Time 7.92 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 24.7%\n",
      "epoch: 10 average loss: 1.942 Epoch Time 8.80 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 21.9%\n",
      "epoch: 11 average loss: 1.920 Epoch Time 9.68 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 28.0%\n",
      "epoch: 12 average loss: 1.971 Epoch Time 10.56 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 13 average loss: 1.929 Epoch Time 11.44 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.4%\n",
      "best_acc.pth saved!\n",
      "epoch: 14 average loss: 1.915 Epoch Time 12.32 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 31.6%\n",
      "epoch: 15 average loss: 1.915 Epoch Time 13.20 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.5%\n",
      "best_acc.pth saved!\n",
      "epoch: 16 average loss: 1.957 Epoch Time 14.07 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.4%\n",
      "epoch: 17 average loss: 1.851 Epoch Time 14.94 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 18 average loss: 1.826 Epoch Time 15.82 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 19 average loss: 1.834 Epoch Time 16.69 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 31.5%\n",
      "epoch: 20 average loss: 1.870 Epoch Time 17.56 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.8%\n",
      "epoch: 21 average loss: 1.883 Epoch Time 18.43 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.7%\n",
      "epoch: 22 average loss: 1.877 Epoch Time 19.31 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.6%\n",
      "epoch: 23 average loss: 1.884 Epoch Time 20.18 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.9%\n",
      "best_acc.pth saved!\n",
      "epoch: 24 average loss: 1.887 Epoch Time 21.05 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.4%\n",
      "best_acc.pth saved!\n",
      "epoch: 25 average loss: 1.896 Epoch Time 21.92 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.7%\n",
      "epoch: 26 average loss: 1.907 Epoch Time 22.80 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.9%\n",
      "epoch: 27 average loss: 1.880 Epoch Time 23.67 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "best_acc.pth saved!\n",
      "epoch: 28 average loss: 1.895 Epoch Time 24.54 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.6%\n",
      "epoch: 29 average loss: 1.903 Epoch Time 25.41 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 30 average loss: 1.920 Epoch Time 26.28 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.8%\n",
      "epoch: 31 average loss: 1.895 Epoch Time 27.15 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 18.9%\n",
      "epoch: 32 average loss: 1.887 Epoch Time 28.03 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.7%\n",
      "epoch: 33 average loss: 1.907 Epoch Time 28.90 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "best_acc.pth saved!\n",
      "epoch: 34 average loss: 1.873 Epoch Time 29.77 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.1%\n",
      "best_acc.pth saved!\n",
      "epoch: 35 average loss: 1.882 Epoch Time 30.64 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.4%\n",
      "epoch: 36 average loss: 1.868 Epoch Time 31.51 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.9%\n",
      "epoch: 37 average loss: 1.857 Epoch Time 32.38 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.0%\n",
      "epoch: 38 average loss: 1.850 Epoch Time 33.25 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.3%\n",
      "epoch: 39 average loss: 1.849 Epoch Time 34.12 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 40 average loss: 1.878 Epoch Time 34.99 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.5%\n",
      "epoch: 41 average loss: 1.897 Epoch Time 35.86 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.6%\n",
      "epoch: 42 average loss: 1.870 Epoch Time 36.74 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 43 average loss: 1.877 Epoch Time 37.61 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.4%\n",
      "epoch: 44 average loss: 1.880 Epoch Time 38.48 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.2%\n",
      "best_acc.pth saved!\n",
      "epoch: 45 average loss: 1.839 Epoch Time 39.35 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.9%\n",
      "epoch: 46 average loss: 1.836 Epoch Time 40.22 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 23.0%\n",
      "epoch: 47 average loss: 1.909 Epoch Time 41.09 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.3%\n",
      "epoch: 48 average loss: 1.878 Epoch Time 41.96 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 49 average loss: 1.924 Epoch Time 42.83 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.8%\n",
      "epoch: 50 average loss: 1.914 Epoch Time 43.70 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 21.2%\n",
      "epoch: 51 average loss: 1.898 Epoch Time 44.57 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.9%\n",
      "epoch: 52 average loss: 1.885 Epoch Time 45.44 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.3%\n",
      "epoch: 53 average loss: 1.888 Epoch Time 46.31 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.7%\n",
      "epoch: 54 average loss: 1.884 Epoch Time 47.18 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.9%\n",
      "epoch: 55 average loss: 1.901 Epoch Time 48.05 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.3%\n",
      "epoch: 56 average loss: 1.904 Epoch Time 48.92 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.5%\n",
      "epoch: 57 average loss: 1.897 Epoch Time 49.79 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.8%\n",
      "epoch: 58 average loss: 1.940 Epoch Time 50.66 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.5%\n",
      "epoch: 59 average loss: 1.880 Epoch Time 51.53 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.3%\n",
      "epoch: 60 average loss: 1.861 Epoch Time 52.40 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.6%\n",
      "epoch: 61 average loss: 1.859 Epoch Time 53.27 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.5%\n",
      "epoch: 62 average loss: 1.855 Epoch Time 54.14 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 63 average loss: 1.856 Epoch Time 55.02 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 64 average loss: 1.855 Epoch Time 55.88 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.4%\n",
      "best_acc.pth saved!\n",
      "epoch: 65 average loss: 1.855 Epoch Time 56.76 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.4%\n",
      "epoch: 66 average loss: 1.839 Epoch Time 57.63 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.2%\n",
      "epoch: 67 average loss: 1.842 Epoch Time 58.50 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.6%\n",
      "best_acc.pth saved!\n",
      "epoch: 68 average loss: 1.839 Epoch Time 59.37 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.0%\n",
      "epoch: 69 average loss: 1.841 Epoch Time 60.24 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.6%\n",
      "epoch: 70 average loss: 1.831 Epoch Time 61.11 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.0%\n",
      "epoch: 71 average loss: 1.831 Epoch Time 61.98 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.3%\n",
      "epoch: 72 average loss: 1.846 Epoch Time 62.85 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.8%\n",
      "epoch: 73 average loss: 1.831 Epoch Time 63.72 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.2%\n",
      "epoch: 74 average loss: 1.829 Epoch Time 64.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.2%\n",
      "epoch: 75 average loss: 1.838 Epoch Time 65.46 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.0%\n",
      "epoch: 76 average loss: 1.862 Epoch Time 66.33 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 17.6%\n",
      "epoch: 77 average loss: 1.992 Epoch Time 67.20 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 29.2%\n",
      "epoch: 78 average loss: 2.011 Epoch Time 68.07 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 29.9%\n",
      "epoch: 79 average loss: 1.915 Epoch Time 68.94 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.7%\n",
      "epoch: 80 average loss: 1.908 Epoch Time 69.81 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.5%\n",
      "0,8099.940979242325,0.2989\n",
      "\n",
      "1,6237.196184396744,0.265\n",
      "\n",
      "2,5879.953437805176,0.3246\n",
      "\n",
      "3,5813.886066913605,0.216\n",
      "\n",
      "4,6017.045122385025,0.2976\n",
      "\n",
      "5,5969.3530440330505,0.311\n",
      "\n",
      "6,5836.442450881004,0.2836\n",
      "\n",
      "7,6077.181616067886,0.2759\n",
      "\n",
      "8,6076.482693910599,0.2471\n",
      "\n",
      "9,6069.883714199066,0.2193\n",
      "\n",
      "10,5999.171329975128,0.2801\n",
      "\n",
      "11,6158.684487938881,0.1\n",
      "\n",
      "12,6029.4378073215485,0.334\n",
      "\n",
      "13,5984.127944946289,0.3162\n",
      "\n",
      "14,5983.590229034424,0.3348\n",
      "\n",
      "15,6117.186181783676,0.3244\n",
      "\n",
      "16,5783.250534415245,0.3532\n",
      "\n",
      "17,5707.166515469551,0.1\n",
      "\n",
      "18,5731.650639533997,0.3154\n",
      "\n",
      "19,5845.213054299355,0.3478\n",
      "\n",
      "20,5885.716653347015,0.3373\n",
      "\n",
      "21,5864.85775744915,0.3464\n",
      "\n",
      "22,5888.944297671318,0.3595\n",
      "\n",
      "23,5897.626473665237,0.3637\n",
      "\n",
      "24,5924.192006111145,0.3268\n",
      "\n",
      "25,5959.27901995182,0.3586\n",
      "\n",
      "26,5876.152055263519,0.3646\n",
      "\n",
      "27,5921.497925400734,0.356\n",
      "\n",
      "28,5946.001384496689,0.1\n",
      "\n",
      "29,6000.746152162552,0.3379\n",
      "\n",
      "30,5923.365646481514,0.1891\n",
      "\n",
      "31,5896.231310606003,0.3469\n",
      "\n",
      "32,5959.00818836689,0.3649\n",
      "\n",
      "33,5852.973301410675,0.371\n",
      "\n",
      "34,5882.13953769207,0.3541\n",
      "\n",
      "35,5837.738756775856,0.3589\n",
      "\n",
      "36,5803.401345491409,0.32\n",
      "\n",
      "37,5780.3156661987305,0.3629\n",
      "\n",
      "38,5779.354523777962,0.1\n",
      "\n",
      "39,5868.924768090248,0.3053\n",
      "\n",
      "40,5926.852863669395,0.3656\n",
      "\n",
      "41,5845.198913693428,0.1\n",
      "\n",
      "42,5864.073205471039,0.3239\n",
      "\n",
      "43,5874.591424465179,0.3722\n",
      "\n",
      "44,5746.118590831757,0.3389\n",
      "\n",
      "45,5736.706527233124,0.2297\n",
      "\n",
      "46,5965.842227220535,0.3035\n",
      "\n",
      "47,5869.5217707157135,0.1\n",
      "\n",
      "48,6010.998265504837,0.3277\n",
      "\n",
      "49,5979.784052729607,0.2125\n",
      "\n",
      "50,5930.023477315903,0.3489\n",
      "\n",
      "51,5889.915028214455,0.343\n",
      "\n",
      "52,5900.942342400551,0.3468\n",
      "\n",
      "53,5887.088482737541,0.3289\n",
      "\n",
      "54,5940.074189782143,0.3528\n",
      "\n",
      "55,5948.972398400307,0.3453\n",
      "\n",
      "56,5928.912617087364,0.348\n",
      "\n",
      "57,6063.025860071182,0.3548\n",
      "\n",
      "58,5874.237913131714,0.3333\n",
      "\n",
      "59,5816.52621281147,0.3664\n",
      "\n",
      "60,5808.114767551422,0.3248\n",
      "\n",
      "61,5797.466562390327,0.3729\n",
      "\n",
      "62,5801.06084215641,0.3732\n",
      "\n",
      "63,5796.374711990356,0.3738\n",
      "\n",
      "64,5798.34011900425,0.3735\n",
      "\n",
      "65,5748.099517226219,0.3724\n",
      "\n",
      "66,5755.917871117592,0.3762\n",
      "\n",
      "67,5747.28307557106,0.3697\n",
      "\n",
      "68,5753.993115663528,0.3759\n",
      "\n",
      "69,5722.7913945913315,0.3002\n",
      "\n",
      "70,5721.40315079689,0.3734\n",
      "\n",
      "71,5769.376770377159,0.3481\n",
      "\n",
      "72,5721.977698922157,0.3723\n",
      "\n",
      "73,5714.555166721344,0.3724\n",
      "\n",
      "74,5742.844411492348,0.3398\n",
      "\n",
      "75,5818.116864085197,0.1762\n",
      "\n",
      "76,6226.110817313194,0.2924\n",
      "\n",
      "77,6282.881877183914,0.2994\n",
      "\n",
      "78,5985.552012562752,0.3368\n",
      "\n",
      "79,5962.420366883278,0.3051\n",
      "\n",
      "Data Saved to Conv_BNN2.csv\n",
      "Finished Training: \n",
      "Total Time 1.163545 hours\n",
      " Average Time Per Epoch 52.36 seconds\n",
      "start\n",
      "start_epoch : 0\n",
      "lr : 0.01\n",
      "batch_size : 128\n",
      "epochs : 80\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "epoch: 1 average loss: 2.589 Epoch Time 0.94 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.1%\n",
      "best_acc.pth saved!\n",
      "epoch: 2 average loss: 1.838 Epoch Time 1.89 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 3 average loss: 1.857 Epoch Time 2.83 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.6%\n",
      "best_acc.pth saved!\n",
      "epoch: 4 average loss: 1.896 Epoch Time 3.78 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 5 average loss: 1.828 Epoch Time 4.72 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "best_acc.pth saved!\n",
      "epoch: 6 average loss: 1.825 Epoch Time 5.67 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 7 average loss: 1.856 Epoch Time 6.62 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.1%\n",
      "epoch: 8 average loss: 1.870 Epoch Time 7.56 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.9%\n",
      "epoch: 9 average loss: 1.893 Epoch Time 8.51 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.7%\n",
      "epoch: 10 average loss: 1.796 Epoch Time 9.46 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.8%\n",
      "epoch: 11 average loss: 1.813 Epoch Time 10.41 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.0%\n",
      "best_acc.pth saved!\n",
      "epoch: 12 average loss: 1.805 Epoch Time 11.35 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 13 average loss: 1.781 Epoch Time 12.31 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 14 average loss: 1.769 Epoch Time 13.25 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.1%\n",
      "epoch: 15 average loss: 1.834 Epoch Time 14.20 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.3%\n",
      "epoch: 16 average loss: 1.767 Epoch Time 15.15 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 27.6%\n",
      "epoch: 17 average loss: 1.741 Epoch Time 16.10 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.9%\n",
      "epoch: 18 average loss: 1.747 Epoch Time 17.04 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.6%\n",
      "epoch: 19 average loss: 1.803 Epoch Time 17.99 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "epoch: 20 average loss: 1.809 Epoch Time 18.94 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 21.4%\n",
      "epoch: 21 average loss: 1.800 Epoch Time 19.89 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 22 average loss: 1.804 Epoch Time 20.84 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.5%\n",
      "epoch: 23 average loss: 1.790 Epoch Time 21.78 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.1%\n",
      "epoch: 24 average loss: 1.826 Epoch Time 22.73 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 25 average loss: 1.807 Epoch Time 23.68 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.1%\n",
      "epoch: 26 average loss: 1.821 Epoch Time 24.63 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.2%\n",
      "epoch: 27 average loss: 1.804 Epoch Time 25.58 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.9%\n",
      "epoch: 28 average loss: 1.764 Epoch Time 26.52 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.4%\n",
      "epoch: 29 average loss: 1.776 Epoch Time 27.47 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.6%\n",
      "epoch: 30 average loss: 1.749 Epoch Time 28.42 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 31 average loss: 1.751 Epoch Time 29.37 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 29.2%\n",
      "epoch: 32 average loss: 1.771 Epoch Time 30.32 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 33 average loss: 1.790 Epoch Time 31.27 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.2%\n",
      "epoch: 34 average loss: 1.747 Epoch Time 32.21 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 35 average loss: 1.770 Epoch Time 33.16 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 28.9%\n",
      "epoch: 36 average loss: 1.747 Epoch Time 34.11 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 37 average loss: 1.752 Epoch Time 35.06 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.1%\n",
      "epoch: 38 average loss: 1.761 Epoch Time 36.00 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.2%\n",
      "epoch: 39 average loss: 1.762 Epoch Time 36.95 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 40 average loss: 1.758 Epoch Time 37.90 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.8%\n",
      "epoch: 41 average loss: 1.756 Epoch Time 38.85 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 23.5%\n",
      "epoch: 42 average loss: 1.783 Epoch Time 39.80 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.6%\n",
      "epoch: 43 average loss: 1.777 Epoch Time 40.74 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.8%\n",
      "epoch: 44 average loss: 1.772 Epoch Time 41.69 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 45 average loss: 1.772 Epoch Time 42.64 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.0%\n",
      "epoch: 46 average loss: 1.769 Epoch Time 43.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.2%\n",
      "epoch: 47 average loss: 1.732 Epoch Time 44.53 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.8%\n",
      "epoch: 48 average loss: 1.774 Epoch Time 45.48 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.7%\n",
      "epoch: 49 average loss: 1.789 Epoch Time 46.43 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.5%\n",
      "epoch: 50 average loss: 1.783 Epoch Time 47.38 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.3%\n",
      "epoch: 51 average loss: 1.771 Epoch Time 48.33 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.7%\n",
      "epoch: 52 average loss: 1.758 Epoch Time 49.27 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.5%\n",
      "epoch: 53 average loss: 1.736 Epoch Time 50.22 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.1%\n",
      "epoch: 54 average loss: 1.750 Epoch Time 51.17 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.7%\n",
      "epoch: 55 average loss: 1.752 Epoch Time 52.12 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.0%\n",
      "epoch: 56 average loss: 1.746 Epoch Time 53.07 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.2%\n",
      "epoch: 57 average loss: 1.735 Epoch Time 54.01 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.4%\n",
      "epoch: 58 average loss: 1.757 Epoch Time 54.96 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.5%\n",
      "epoch: 59 average loss: 1.725 Epoch Time 55.91 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.4%\n",
      "epoch: 60 average loss: 1.708 Epoch Time 56.86 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 27.7%\n",
      "epoch: 61 average loss: 1.717 Epoch Time 57.80 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "epoch: 62 average loss: 1.719 Epoch Time 58.75 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 63 average loss: 1.722 Epoch Time 59.70 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 64 average loss: 1.727 Epoch Time 60.65 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.4%\n",
      "epoch: 65 average loss: 1.739 Epoch Time 61.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 66 average loss: 1.740 Epoch Time 62.54 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.3%\n",
      "epoch: 67 average loss: 1.717 Epoch Time 63.49 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "epoch: 68 average loss: 1.722 Epoch Time 64.44 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.6%\n",
      "epoch: 69 average loss: 1.733 Epoch Time 65.38 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.0%\n",
      "best_acc.pth saved!\n",
      "epoch: 70 average loss: 1.717 Epoch Time 66.33 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.1%\n",
      "epoch: 71 average loss: 1.702 Epoch Time 67.28 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.3%\n",
      "epoch: 72 average loss: 1.707 Epoch Time 68.23 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.4%\n",
      "epoch: 73 average loss: 1.718 Epoch Time 69.18 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.4%\n",
      "epoch: 74 average loss: 1.741 Epoch Time 70.12 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.0%\n",
      "epoch: 75 average loss: 1.767 Epoch Time 71.07 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.6%\n",
      "epoch: 76 average loss: 1.716 Epoch Time 72.02 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.3%\n",
      "epoch: 77 average loss: 1.761 Epoch Time 72.97 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "epoch: 78 average loss: 1.738 Epoch Time 73.92 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.1%\n",
      "epoch: 79 average loss: 1.755 Epoch Time 74.86 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.6%\n",
      "epoch: 80 average loss: 1.724 Epoch Time 75.81 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "0,8090.045108914375,0.3406\n",
      "\n",
      "1,5744.079199790955,0.1\n",
      "\n",
      "2,5803.732268214226,0.356\n",
      "\n",
      "3,5924.422278046608,0.1\n",
      "\n",
      "4,5712.627169132233,0.3646\n",
      "\n",
      "5,5703.643463611603,0.1\n",
      "\n",
      "6,5800.083121538162,0.3314\n",
      "\n",
      "7,5843.463107466698,0.3488\n",
      "\n",
      "8,5916.790301680565,0.3473\n",
      "\n",
      "9,5611.466279864311,0.3576\n",
      "\n",
      "10,5665.3035036325455,0.3696\n",
      "\n",
      "11,5639.972053408623,0.1\n",
      "\n",
      "12,5565.110634684563,0.1\n",
      "\n",
      "13,5529.023782968521,0.3014\n",
      "\n",
      "14,5729.736257195473,0.3333\n",
      "\n",
      "15,5523.338476061821,0.2756\n",
      "\n",
      "16,5439.97814977169,0.3689\n",
      "\n",
      "17,5460.107109308243,0.3662\n",
      "\n",
      "18,5634.898241281509,0.3653\n",
      "\n",
      "19,5651.863823533058,0.2136\n",
      "\n",
      "20,5624.1750375032425,0.1\n",
      "\n",
      "21,5637.9680832624435,0.3447\n",
      "\n",
      "22,5594.580346941948,0.3506\n",
      "\n",
      "23,5707.296412944794,0.1\n",
      "\n",
      "24,5648.300881147385,0.3607\n",
      "\n",
      "25,5690.181461453438,0.3516\n",
      "\n",
      "26,5637.855673789978,0.3689\n",
      "\n",
      "27,5513.164198517799,0.3544\n",
      "\n",
      "28,5549.68645632267,0.3263\n",
      "\n",
      "29,5466.688217997551,0.1\n",
      "\n",
      "30,5471.597128510475,0.2925\n",
      "\n",
      "31,5532.820133924484,0.1\n",
      "\n",
      "32,5592.819152832031,0.3616\n",
      "\n",
      "33,5458.608039140701,0.1\n",
      "\n",
      "34,5529.745078325272,0.2893\n",
      "\n",
      "35,5458.006286859512,0.1\n",
      "\n",
      "36,5473.929146409035,0.3305\n",
      "\n",
      "37,5503.10265994072,0.352\n",
      "\n",
      "38,5507.019405007362,0.1\n",
      "\n",
      "39,5493.107804059982,0.308\n",
      "\n",
      "40,5487.285251617432,0.2348\n",
      "\n",
      "41,5571.946670532227,0.3357\n",
      "\n",
      "42,5552.931448936462,0.3484\n",
      "\n",
      "43,5536.606554508209,0.1\n",
      "\n",
      "44,5538.198343634605,0.3598\n",
      "\n",
      "45,5529.61530995369,0.3423\n",
      "\n",
      "46,5412.885029435158,0.3583\n",
      "\n",
      "47,5543.503016471863,0.347\n",
      "\n",
      "48,5590.957150816917,0.3555\n",
      "\n",
      "49,5573.319034337997,0.3534\n",
      "\n",
      "50,5533.50147151947,0.357\n",
      "\n",
      "51,5494.279057621956,0.3347\n",
      "\n",
      "52,5425.19837141037,0.3009\n",
      "\n",
      "53,5470.206729650497,0.3572\n",
      "\n",
      "54,5475.071274995804,0.3602\n",
      "\n",
      "55,5455.507556080818,0.3519\n",
      "\n",
      "56,5422.673845171928,0.3545\n",
      "\n",
      "57,5490.635876297951,0.3549\n",
      "\n",
      "58,5390.933984160423,0.3644\n",
      "\n",
      "59,5337.682922840118,0.2774\n",
      "\n",
      "60,5364.75077188015,0.3655\n",
      "\n",
      "61,5372.103421330452,0.1\n",
      "\n",
      "62,5381.836247205734,0.1\n",
      "\n",
      "63,5397.231115102768,0.3038\n",
      "\n",
      "64,5434.606628894806,0.1\n",
      "\n",
      "65,5438.863090991974,0.3632\n",
      "\n",
      "66,5365.0239174366,0.3655\n",
      "\n",
      "67,5381.173480629921,0.3658\n",
      "\n",
      "68,5415.449820995331,0.37\n",
      "\n",
      "69,5366.66263127327,0.3615\n",
      "\n",
      "70,5318.368523001671,0.3628\n",
      "\n",
      "71,5333.096682906151,0.3645\n",
      "\n",
      "72,5370.250630021095,0.3643\n",
      "\n",
      "73,5439.1297389268875,0.3502\n",
      "\n",
      "74,5522.361746668816,0.3659\n",
      "\n",
      "75,5361.294143199921,0.3633\n",
      "\n",
      "76,5503.716962218285,0.3654\n",
      "\n",
      "77,5431.796422958374,0.3606\n",
      "\n",
      "78,5485.211228251457,0.3564\n",
      "\n",
      "79,5388.070419073105,0.3648\n",
      "\n",
      "Data Saved to ConvBN_BNN2.csv\n",
      "Finished Training: \n",
      "Total Time 1.263516 hours\n",
      " Average Time Per Epoch 56.86 seconds\n"
     ]
    }
   ],
   "source": [
    "# from NN_Thesis.models.binarized_modules import BinarizeConv2d\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Bin_state_dict = torch.load('test_best_acc.pth',map_location= device)\n",
    "\n",
    "bt_model = resnet18_adapt()\n",
    "bt_model.load_state_dict(Bin_state_dict)\n",
    "\n",
    "conv_model = resnet18_adapt()\n",
    "conv_model.load_state_dict(Bin_state_dict)\n",
    "\n",
    "conv_bt_model = resnet18_adapt()\n",
    "conv_bt_model.load_state_dict(Bin_state_dict)\n",
    "\n",
    "\n",
    "\n",
    "adapters = [\n",
    "    (bottleneck_adapter((80,32,32),5),bottleneck_adapter((160,16,16),5),bottleneck_adapter((320,8,8),5)),\n",
    "    (conv_adapter(80,kernel= 3,padding = 1),conv_adapter(160,kernel= 3,padding = 1),conv_adapter(320,kernel=1)),\n",
    "    (conv_bottleneck_adapter(80,80,kernel=3,padding=1),conv_bottleneck_adapter(160,80,kernel=3,padding=1),conv_bottleneck_adapter(320,160,kernel=3,padding=1))\n",
    "]\n",
    "\n",
    "\n",
    "#Set all layer requires grad to false and set to eval mode()\n",
    "for m,adpts in zip([bt_model,conv_model,conv_bt_model],adapters):\n",
    "    m.freeze()\n",
    "    m.add_adapter(after = 'layer1',adapter =adpts[0])\n",
    "    m.add_adapter(after = 'layer2',adapter =adpts[1])\n",
    "    m.add_adapter(after = 'layer3',adapter =adpts[2])\n",
    "\n",
    "\n",
    "# bottle_trainer = adapter_Trainer(model = bt_model,seed = 123,name = 'Bottleneck_BNN2',classes = classes,binarise= True)\n",
    "conv_trainer = adapter_Trainer(model = conv_model,seed = 123,name = 'Conv_BNN2',classes = classes,binarise= True)\n",
    "conv_bt_trainer = adapter_Trainer(model = conv_bt_model,seed = 123,name = 'ConvBN_BNN2',classes = classes,binarise= True)\n",
    "# trainer.load('test_150.pth',map_location= device,load_model= True)\n",
    "for trainer in [conv_trainer,conv_bt_trainer]:\n",
    "    m = trainer.model\n",
    "    m.to(trainer.device)\n",
    "    for layer in [m.fc,m.bn3,m.bn3]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = True\n",
    "        layer.train()\n",
    "    trainer.lr = 0.01\n",
    "    trainer.batch_size = 128\n",
    "    trainer.epochs =80\n",
    "    trainer.epoch_chkpts = []\n",
    "    trainer.start_epoch = 0\n",
    "    trainer.T_max = 80\n",
    "    # trainer.scheduler.T_max= trainer.T_max\n",
    "    trainer.optimizer = optim.Adam(trainer.model.parameters(), lr=trainer.lr)\n",
    "    trainer.scheduler = optim.lr_scheduler.ExponentialLR(trainer.optimizer, gamma=0.95)\n",
    "    trainer.train(trainloader,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f6c44",
   "metadata": {},
   "source": [
    "# DEBUGGING TIME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e50802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start_epoch : 0\n",
      "lr : 0.01\n",
      "batch_size : 128\n",
      "epochs : 10\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "epoch: 1 average loss: 0.448 Epoch Time 0.49 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.7%\n",
      "best_acc.pth saved!\n",
      "epoch: 2 average loss: 0.447 Epoch Time 0.98 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.7%\n",
      "best_acc.pth saved!\n",
      "epoch: 3 average loss: 0.445 Epoch Time 1.47 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 4 average loss: 0.448 Epoch Time 1.97 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 5 average loss: 0.450 Epoch Time 2.46 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 6 average loss: 0.445 Epoch Time 2.96 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.8%\n",
      "best_acc.pth saved!\n",
      "epoch: 7 average loss: 0.453 Epoch Time 3.46 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 8 average loss: 0.446 Epoch Time 3.96 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.9%\n",
      "best_acc.pth saved!\n",
      "epoch: 9 average loss: 0.448 Epoch Time 4.45 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.7%\n",
      "epoch: 10 average loss: 0.445 Epoch Time 4.94 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.8%\n",
      "0,1399.2995592085645,0.8365\n",
      "\n",
      "1,1397.314375732094,0.8372\n",
      "\n",
      "2,1389.4603708926588,0.836\n",
      "\n",
      "3,1399.6776360534132,0.836\n",
      "\n",
      "4,1404.7952956985682,0.8361\n",
      "\n",
      "5,1391.060079159215,0.8377\n",
      "\n",
      "6,1415.2307629678398,0.8357\n",
      "\n",
      "7,1393.2362602110952,0.8392\n",
      "\n",
      "8,1400.529228085652,0.8371\n",
      "\n",
      "9,1389.1054652705789,0.8381\n",
      "\n",
      "Data Saved to debug.csv\n",
      "Finished Training: \n",
      "Total Time 0.082292 hours\n",
      " Average Time Per Epoch 29.63 seconds\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Bin_state_dict = torch.load('test_best_acc.pth',map_location= device)\n",
    "\n",
    "debug = resnet18_adapt()\n",
    "debug.load_state_dict(Bin_state_dict)\n",
    "debug.freeze()\n",
    "debug.add_adapter(after = 'layer3',adapter = identity_adapter())\n",
    "\n",
    "debug_trainer = adapter_Trainer(model = debug,seed = 123,name = 'debug',classes = classes,binarise= True)\n",
    "for trainer in [debug_trainer]:\n",
    "    m = trainer.model\n",
    "    m.to(trainer.device)\n",
    "    for layer in [m.fc,m.bn3,m.bn3]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = True\n",
    "        layer.train()\n",
    "    trainer.lr = 0.01\n",
    "    trainer.batch_size = 128\n",
    "    trainer.epochs =10\n",
    "    trainer.epoch_chkpts = []\n",
    "    trainer.start_epoch = 0\n",
    "    trainer.T_max = 80\n",
    "    # trainer.scheduler.T_max= trainer.T_max\n",
    "    trainer.optimizer = optim.Adam(trainer.model.parameters(), lr=trainer.lr)\n",
    "    trainer.scheduler = optim.lr_scheduler.ExponentialLR(trainer.optimizer, gamma=0.95)\n",
    "    trainer.train(trainloader,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9f9eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start_epoch : 0\n",
      "lr : 0.01\n",
      "batch_size : 128\n",
      "epochs : 10\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "epoch: 1 average loss: 0.447 Epoch Time 0.56 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "best_acc.pth saved!\n",
      "epoch: 2 average loss: 0.447 Epoch Time 1.12 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.7%\n",
      "best_acc.pth saved!\n",
      "epoch: 3 average loss: 0.444 Epoch Time 1.69 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 4 average loss: 0.448 Epoch Time 2.25 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.3%\n",
      "epoch: 5 average loss: 0.449 Epoch Time 2.81 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 6 average loss: 0.445 Epoch Time 3.37 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 7 average loss: 0.453 Epoch Time 3.93 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.5%\n",
      "epoch: 8 average loss: 0.446 Epoch Time 4.49 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 84.0%\n",
      "best_acc.pth saved!\n",
      "epoch: 9 average loss: 0.448 Epoch Time 5.06 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 10 average loss: 0.444 Epoch Time 5.65 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.8%\n",
      "0,1398.4110385291278,0.8363\n",
      "\n",
      "1,1396.523651432246,0.837\n",
      "\n",
      "2,1387.8463219068944,0.8363\n",
      "\n",
      "3,1398.9699801634997,0.8331\n",
      "\n",
      "4,1404.590050060302,0.8364\n",
      "\n",
      "5,1391.5139812212437,0.8361\n",
      "\n",
      "6,1416.2695680838078,0.8347\n",
      "\n",
      "7,1392.584654616192,0.8401\n",
      "\n",
      "8,1401.0626330338418,0.8356\n",
      "\n",
      "9,1387.0222478583455,0.8377\n",
      "\n",
      "Data Saved to mini_adapt.csv\n",
      "Finished Training: \n",
      "Total Time 0.094159 hours\n",
      " Average Time Per Epoch 33.90 seconds\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Bin_state_dict = torch.load('test_best_acc.pth',map_location= device)\n",
    "\n",
    "adapter = mini_bottleneck_adapter()\n",
    "\n",
    "mini_adapt_model = resnet18_adapt()\n",
    "mini_adapt_model.load_state_dict(Bin_state_dict)\n",
    "mini_adapt_model.freeze()\n",
    "mini_adapt_model.add_adapter(after = 'layer3',adapter = adapter)\n",
    "\n",
    "mini_adapt_trainer = adapter_Trainer(model = mini_adapt_model,seed = 123,name = 'mini_adapt',classes = classes,binarise= True)\n",
    "for trainer in [mini_adapt_trainer]:\n",
    "    m = trainer.model\n",
    "    m.to(trainer.device)\n",
    "    for layer in [m.fc,m.bn3,m.bn3]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = True\n",
    "        layer.train()\n",
    "    trainer.lr = 0.01\n",
    "    trainer.batch_size = 128\n",
    "    trainer.epochs =10\n",
    "    trainer.epoch_chkpts = []\n",
    "    trainer.start_epoch = 0\n",
    "    trainer.T_max = 80\n",
    "    # trainer.scheduler.T_max= trainer.T_max\n",
    "    trainer.optimizer = optim.Adam(trainer.model.parameters(), lr=trainer.lr)\n",
    "    trainer.scheduler = optim.lr_scheduler.ExponentialLR(trainer.optimizer, gamma=0.95)\n",
    "    trainer.train(trainloader,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0dd6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe717efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5daaeb58",
   "metadata": {},
   "source": [
    "# Adapter Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c84ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adp_only layer1 80\n",
      "Scheduler Set {'T_max': 10, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnny_suu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221021_220335-13kj1oac</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/13kj1oac\" target=\"_blank\">visionary-darkness-22</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name adp_layer1_adp_only \n",
      "\n",
      "\n",
      "Run Start : 2022-10-21 22-03-33\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4343135\n",
      "Initial accuracy:\n",
      "Test Accuracy : 8.8%, Test Loss: 4.613198432776019\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 8.4%, Test Loss: 4.8334173107391125\n",
      "epoch: 1 average loss: 1.031\n",
      "Test Accuracy : 72.9%, Test Loss: 0.7262849130136583\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.24 seconds\n",
      "epoch: 2 average loss: 0.720\n",
      "Test Accuracy : 76.9%, Test Loss: 0.6304557144336993\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.17 seconds\n",
      "epoch: 3 average loss: 0.676\n",
      "Test Accuracy : 78.0%, Test Loss: 0.619110785100771\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 20.88 seconds\n",
      "epoch: 4 average loss: 0.647\n",
      "Test Accuracy : 79.0%, Test Loss: 0.5816041288320976\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 20.68 seconds\n",
      "epoch: 5 average loss: 0.623\n",
      "Test Accuracy : 80.0%, Test Loss: 0.5519972227113631\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 20.70 seconds\n",
      "epoch: 6 average loss: 0.606\n",
      "Test Accuracy : 80.3%, Test Loss: 0.5418400766751955\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.24 seconds\n",
      "epoch: 7 average loss: 0.603\n",
      "Test Accuracy : 80.1%, Test Loss: 0.5451022622073093\n",
      "Epoch Time (Training + Test) = 21.29 seconds\n",
      "epoch: 8 average loss: 0.586\n",
      "Test Accuracy : 80.8%, Test Loss: 0.5343324207436398\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.34 seconds\n",
      "epoch: 9 average loss: 0.585\n",
      "Test Accuracy : 80.8%, Test Loss: 0.5302456634123917\n",
      "Epoch Time (Training + Test) = 20.58 seconds\n",
      "epoch: 10 average loss: 0.580\n",
      "Test Accuracy : 80.8%, Test Loss: 0.5292068922230045\n",
      "Epoch Time (Training + Test) = 20.16 seconds\n",
      "epoch: 11 average loss: 0.579\n",
      "Test Accuracy : 81.0%, Test Loss: 0.5236006560532943\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 20.60 seconds\n",
      "epoch: 12 average loss: 0.579\n",
      "Test Accuracy : 80.8%, Test Loss: 0.5339869590061704\n",
      "Epoch Time (Training + Test) = 20.58 seconds\n",
      "epoch: 13 average loss: 0.578\n",
      "Test Accuracy : 81.4%, Test Loss: 0.519434367909151\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 20.48 seconds\n",
      "epoch: 14 average loss: 0.586\n",
      "Test Accuracy : 80.7%, Test Loss: 0.5299209874609242\n",
      "Epoch Time (Training + Test) = 20.69 seconds\n",
      "epoch: 15 average loss: 0.587\n",
      "Test Accuracy : 80.7%, Test Loss: 0.5303986020710157\n",
      "Epoch Time (Training + Test) = 20.64 seconds\n",
      "epoch: 16 average loss: 0.588\n",
      "Test Accuracy : 81.3%, Test Loss: 0.5242446772277812\n",
      "Epoch Time (Training + Test) = 20.37 seconds\n",
      "epoch: 17 average loss: 0.586\n",
      "Test Accuracy : 80.3%, Test Loss: 0.5382902099348396\n",
      "Epoch Time (Training + Test) = 20.64 seconds\n",
      "epoch: 18 average loss: 0.586\n",
      "Test Accuracy : 79.7%, Test Loss: 0.5493999367479778\n",
      "Epoch Time (Training + Test) = 20.09 seconds\n",
      "epoch: 19 average loss: 0.578\n",
      "Test Accuracy : 80.4%, Test Loss: 0.5388599735544161\n",
      "Epoch Time (Training + Test) = 20.90 seconds\n",
      "epoch: 20 average loss: 0.579\n",
      "Test Accuracy : 81.5%, Test Loss: 0.5141339105032289\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.16 seconds\n",
      "epoch: 21 average loss: 0.570\n",
      "Test Accuracy : 80.8%, Test Loss: 0.5239783523942504\n",
      "Epoch Time (Training + Test) = 21.50 seconds\n",
      "epoch: 22 average loss: 0.569\n",
      "Test Accuracy : 82.2%, Test Loss: 0.4933351683799568\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.42 seconds\n",
      "epoch: 23 average loss: 0.560\n",
      "Test Accuracy : 81.9%, Test Loss: 0.4925904532756342\n",
      "Epoch Time (Training + Test) = 21.19 seconds\n",
      "epoch: 24 average loss: 0.555\n",
      "Test Accuracy : 82.1%, Test Loss: 0.4950359120698231\n",
      "Epoch Time (Training + Test) = 21.10 seconds\n",
      "epoch: 25 average loss: 0.542\n",
      "Test Accuracy : 82.5%, Test Loss: 0.4884601456429952\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.12 seconds\n",
      "epoch: 26 average loss: 0.533\n",
      "Test Accuracy : 82.1%, Test Loss: 0.4905333047937554\n",
      "Epoch Time (Training + Test) = 21.50 seconds\n",
      "epoch: 27 average loss: 0.529\n",
      "Test Accuracy : 82.7%, Test Loss: 0.4727154109255432\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.49 seconds\n",
      "epoch: 28 average loss: 0.530\n",
      "Test Accuracy : 82.7%, Test Loss: 0.47310941832144854\n",
      "Epoch Time (Training + Test) = 21.46 seconds\n",
      "epoch: 29 average loss: 0.519\n",
      "Test Accuracy : 83.4%, Test Loss: 0.462224434480033\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.40 seconds\n",
      "epoch: 30 average loss: 0.518\n",
      "Test Accuracy : 83.0%, Test Loss: 0.47037377530504065\n",
      "Epoch Time (Training + Test) = 20.92 seconds\n",
      "epoch: 31 average loss: 0.523\n",
      "Test Accuracy : 83.0%, Test Loss: 0.4689950960523942\n",
      "Epoch Time (Training + Test) = 20.92 seconds\n",
      "epoch: 32 average loss: 0.516\n",
      "Test Accuracy : 82.8%, Test Loss: 0.47102256546087584\n",
      "Epoch Time (Training + Test) = 20.57 seconds\n",
      "epoch: 33 average loss: 0.522\n",
      "Test Accuracy : 82.7%, Test Loss: 0.47316618092224727\n",
      "Epoch Time (Training + Test) = 20.82 seconds\n",
      "epoch: 34 average loss: 0.526\n",
      "Test Accuracy : 82.8%, Test Loss: 0.4728899454826589\n",
      "Epoch Time (Training + Test) = 20.68 seconds\n",
      "epoch: 35 average loss: 0.532\n",
      "Test Accuracy : 82.3%, Test Loss: 0.48632920558190407\n",
      "Epoch Time (Training + Test) = 21.13 seconds\n",
      "epoch: 36 average loss: 0.530\n",
      "Test Accuracy : 82.3%, Test Loss: 0.4764457777561739\n",
      "Epoch Time (Training + Test) = 20.95 seconds\n",
      "epoch: 37 average loss: 0.536\n",
      "Test Accuracy : 82.3%, Test Loss: 0.4802187655283057\n",
      "Epoch Time (Training + Test) = 21.12 seconds\n",
      "epoch: 38 average loss: 0.538\n",
      "Test Accuracy : 81.8%, Test Loss: 0.49786974775516774\n",
      "Epoch Time (Training + Test) = 20.84 seconds\n",
      "epoch: 39 average loss: 0.534\n",
      "Test Accuracy : 82.7%, Test Loss: 0.4754237178570169\n",
      "Epoch Time (Training + Test) = 21.34 seconds\n",
      "epoch: 40 average loss: 0.540\n",
      "Test Accuracy : 82.8%, Test Loss: 0.47348086604529327\n",
      "Epoch Time (Training + Test) = 21.47 seconds\n",
      "epoch: 41 average loss: 0.536\n",
      "Test Accuracy : 82.7%, Test Loss: 0.47522306468938014\n",
      "Epoch Time (Training + Test) = 21.43 seconds\n",
      "epoch: 42 average loss: 0.527\n",
      "Test Accuracy : 83.0%, Test Loss: 0.47406103448642184\n",
      "Epoch Time (Training + Test) = 21.52 seconds\n",
      "epoch: 43 average loss: 0.523\n",
      "Test Accuracy : 82.8%, Test Loss: 0.47856008152827584\n",
      "Epoch Time (Training + Test) = 21.29 seconds\n",
      "epoch: 44 average loss: 0.532\n",
      "Test Accuracy : 83.0%, Test Loss: 0.4691493454034371\n",
      "Epoch Time (Training + Test) = 21.23 seconds\n",
      "epoch: 45 average loss: 0.517\n",
      "Test Accuracy : 83.1%, Test Loss: 0.46320364024023264\n",
      "Epoch Time (Training + Test) = 21.41 seconds\n",
      "epoch: 46 average loss: 0.515\n",
      "Test Accuracy : 83.2%, Test Loss: 0.46013779027382734\n",
      "Epoch Time (Training + Test) = 21.32 seconds\n",
      "epoch: 47 average loss: 0.508\n",
      "Test Accuracy : 83.4%, Test Loss: 0.4567295640630795\n",
      "Epoch Time (Training + Test) = 21.47 seconds\n",
      "epoch: 48 average loss: 0.507\n",
      "Test Accuracy : 83.7%, Test Loss: 0.4505970569522789\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.48 seconds\n",
      "epoch: 49 average loss: 0.498\n",
      "Test Accuracy : 83.6%, Test Loss: 0.45163465224568494\n",
      "Epoch Time (Training + Test) = 21.03 seconds\n",
      "epoch: 50 average loss: 0.496\n",
      "Test Accuracy : 83.5%, Test Loss: 0.4527155927303807\n",
      "Epoch Time (Training + Test) = 20.74 seconds\n",
      "epoch: 51 average loss: 0.496\n",
      "Test Accuracy : 83.4%, Test Loss: 0.44986648613687064\n",
      "Epoch Time (Training + Test) = 21.02 seconds\n",
      "epoch: 52 average loss: 0.497\n",
      "Test Accuracy : 83.5%, Test Loss: 0.4529734753891635\n",
      "Epoch Time (Training + Test) = 20.63 seconds\n",
      "epoch: 53 average loss: 0.503\n",
      "Test Accuracy : 83.6%, Test Loss: 0.44809424675181697\n",
      "Epoch Time (Training + Test) = 20.80 seconds\n",
      "epoch: 54 average loss: 0.503\n",
      "Test Accuracy : 83.8%, Test Loss: 0.4432603867767412\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 20.87 seconds\n",
      "epoch: 55 average loss: 0.503\n",
      "Test Accuracy : 83.3%, Test Loss: 0.45532065294587704\n",
      "Epoch Time (Training + Test) = 21.20 seconds\n",
      "epoch: 56 average loss: 0.513\n",
      "Test Accuracy : 83.3%, Test Loss: 0.45621199730564566\n",
      "Epoch Time (Training + Test) = 21.08 seconds\n",
      "epoch: 57 average loss: 0.512\n",
      "Test Accuracy : 83.6%, Test Loss: 0.4544488327277591\n",
      "Epoch Time (Training + Test) = 21.46 seconds\n",
      "epoch: 58 average loss: 0.519\n",
      "Test Accuracy : 83.3%, Test Loss: 0.4561468535829383\n",
      "Epoch Time (Training + Test) = 21.36 seconds\n",
      "epoch: 59 average loss: 0.519\n",
      "Test Accuracy : 82.7%, Test Loss: 0.47695636246210477\n",
      "Epoch Time (Training + Test) = 21.16 seconds\n",
      "epoch: 60 average loss: 0.513\n",
      "Test Accuracy : 83.6%, Test Loss: 0.45528120438918435\n",
      "Epoch Time (Training + Test) = 21.04 seconds\n",
      "epoch: 61 average loss: 0.512\n",
      "Test Accuracy : 83.6%, Test Loss: 0.45179551119542183\n",
      "Epoch Time (Training + Test) = 21.40 seconds\n",
      "epoch: 62 average loss: 0.513\n",
      "Test Accuracy : 83.3%, Test Loss: 0.4532456921646967\n",
      "Epoch Time (Training + Test) = 21.69 seconds\n",
      "epoch: 63 average loss: 0.512\n",
      "Test Accuracy : 82.9%, Test Loss: 0.4706226352154446\n",
      "Epoch Time (Training + Test) = 21.48 seconds\n",
      "epoch: 64 average loss: 0.503\n",
      "Test Accuracy : 83.2%, Test Loss: 0.46032325161235105\n",
      "Epoch Time (Training + Test) = 21.33 seconds\n",
      "epoch: 65 average loss: 0.504\n",
      "Test Accuracy : 83.7%, Test Loss: 0.4461547860023006\n",
      "Epoch Time (Training + Test) = 21.16 seconds\n",
      "epoch: 66 average loss: 0.495\n",
      "Test Accuracy : 83.9%, Test Loss: 0.4409442981490699\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.66 seconds\n",
      "epoch: 67 average loss: 0.495\n",
      "Test Accuracy : 83.8%, Test Loss: 0.4387150746019905\n",
      "Epoch Time (Training + Test) = 20.77 seconds\n",
      "epoch: 68 average loss: 0.491\n",
      "Test Accuracy : 83.8%, Test Loss: 0.44336943557042907\n",
      "Epoch Time (Training + Test) = 20.51 seconds\n",
      "epoch: 69 average loss: 0.492\n",
      "Test Accuracy : 84.1%, Test Loss: 0.43412353879655413\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 20.48 seconds\n",
      "epoch: 70 average loss: 0.484\n",
      "Test Accuracy : 84.0%, Test Loss: 0.44096946262794995\n",
      "Epoch Time (Training + Test) = 20.97 seconds\n",
      "epoch: 71 average loss: 0.482\n",
      "Test Accuracy : 84.2%, Test Loss: 0.43164868831939407\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.19 seconds\n",
      "epoch: 72 average loss: 0.487\n",
      "Test Accuracy : 84.3%, Test Loss: 0.4325302306114865\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 20.61 seconds\n",
      "epoch: 73 average loss: 0.484\n",
      "Test Accuracy : 84.3%, Test Loss: 0.43248705352511246\n",
      "Epoch Time (Training + Test) = 20.58 seconds\n",
      "epoch: 74 average loss: 0.486\n",
      "Test Accuracy : 84.0%, Test Loss: 0.43707666559444974\n",
      "Epoch Time (Training + Test) = 20.33 seconds\n",
      "epoch: 75 average loss: 0.492\n",
      "Test Accuracy : 83.9%, Test Loss: 0.442739181963684\n",
      "Epoch Time (Training + Test) = 20.47 seconds\n",
      "epoch: 76 average loss: 0.498\n",
      "Test Accuracy : 83.9%, Test Loss: 0.4428496840207473\n",
      "Epoch Time (Training + Test) = 20.48 seconds\n",
      "epoch: 77 average loss: 0.502\n",
      "Test Accuracy : 83.1%, Test Loss: 0.4593578823234724\n",
      "Epoch Time (Training + Test) = 20.46 seconds\n",
      "epoch: 78 average loss: 0.504\n",
      "Test Accuracy : 83.4%, Test Loss: 0.4546683435626042\n",
      "Epoch Time (Training + Test) = 20.48 seconds\n",
      "epoch: 79 average loss: 0.506\n",
      "Test Accuracy : 82.9%, Test Loss: 0.4622687326215417\n",
      "Epoch Time (Training + Test) = 20.89 seconds\n",
      "epoch: 80 average loss: 0.504\n",
      "Test Accuracy : 83.6%, Test Loss: 0.4544317909823659\n",
      "Epoch Time (Training + Test) = 21.32 seconds\n",
      "epoch: 81 average loss: 0.505\n",
      "Test Accuracy : 83.7%, Test Loss: 0.4453795596080668\n",
      "Epoch Time (Training + Test) = 20.90 seconds\n",
      "epoch: 82 average loss: 0.501\n",
      "Test Accuracy : 83.4%, Test Loss: 0.45461479877419486\n",
      "Epoch Time (Training + Test) = 21.18 seconds\n",
      "epoch: 83 average loss: 0.496\n",
      "Test Accuracy : 83.9%, Test Loss: 0.436947737927632\n",
      "Epoch Time (Training + Test) = 21.71 seconds\n",
      "epoch: 84 average loss: 0.500\n",
      "Test Accuracy : 83.9%, Test Loss: 0.44826902414831665\n",
      "Epoch Time (Training + Test) = 21.03 seconds\n",
      "epoch: 85 average loss: 0.495\n",
      "Test Accuracy : 83.8%, Test Loss: 0.44438788725439543\n",
      "Epoch Time (Training + Test) = 20.84 seconds\n",
      "epoch: 86 average loss: 0.489\n",
      "Test Accuracy : 84.1%, Test Loss: 0.4385951829840765\n",
      "Epoch Time (Training + Test) = 21.33 seconds\n",
      "epoch: 87 average loss: 0.481\n",
      "Test Accuracy : 84.0%, Test Loss: 0.4395780532103975\n",
      "Epoch Time (Training + Test) = 21.53 seconds\n",
      "epoch: 88 average loss: 0.483\n",
      "Test Accuracy : 84.2%, Test Loss: 0.434935329820189\n",
      "Epoch Time (Training + Test) = 21.43 seconds\n",
      "epoch: 89 average loss: 0.474\n",
      "Test Accuracy : 84.6%, Test Loss: 0.42105518292892924\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.31 seconds\n",
      "epoch: 90 average loss: 0.472\n",
      "Test Accuracy : 84.7%, Test Loss: 0.42227056180424705\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.33 seconds\n",
      "epoch: 91 average loss: 0.481\n",
      "Test Accuracy : 84.6%, Test Loss: 0.42552950783916144\n",
      "Epoch Time (Training + Test) = 21.31 seconds\n",
      "epoch: 92 average loss: 0.483\n",
      "Test Accuracy : 84.7%, Test Loss: 0.4235066830197259\n",
      "Epoch Time (Training + Test) = 20.97 seconds\n",
      "epoch: 93 average loss: 0.473\n",
      "Test Accuracy : 84.4%, Test Loss: 0.42374454034716275\n",
      "Epoch Time (Training + Test) = 21.30 seconds\n",
      "epoch: 94 average loss: 0.485\n",
      "Test Accuracy : 84.5%, Test Loss: 0.4241004589268619\n",
      "Epoch Time (Training + Test) = 21.64 seconds\n",
      "epoch: 95 average loss: 0.476\n",
      "Test Accuracy : 84.6%, Test Loss: 0.4284883321779768\n",
      "Epoch Time (Training + Test) = 21.24 seconds\n",
      "epoch: 96 average loss: 0.479\n",
      "Test Accuracy : 84.3%, Test Loss: 0.431465951149421\n",
      "Epoch Time (Training + Test) = 21.32 seconds\n",
      "epoch: 97 average loss: 0.487\n",
      "Test Accuracy : 84.4%, Test Loss: 0.43104195693874603\n",
      "Epoch Time (Training + Test) = 21.31 seconds\n",
      "epoch: 98 average loss: 0.493\n",
      "Test Accuracy : 83.9%, Test Loss: 0.44258106326508095\n",
      "Epoch Time (Training + Test) = 21.09 seconds\n",
      "epoch: 99 average loss: 0.495\n",
      "Test Accuracy : 83.4%, Test Loss: 0.4600654214315707\n",
      "Epoch Time (Training + Test) = 21.36 seconds\n",
      "epoch: 100 average loss: 0.495\n",
      "Test Accuracy : 83.6%, Test Loss: 0.4578166165010399\n",
      "Epoch Time (Training + Test) = 22.59 seconds\n",
      "Data Saved to adp_layer1_adp_only.csv\n",
      "Finished Training: \n",
      "Total Time 1.170485 hours\n",
      " Average Time Per Epoch 42.14 seconds\n",
      "full_ft layer1 80\n",
      "Scheduler Set {'T_max': 10, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:13kj1oac) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch time (s)</td><td>▁▆▅▆▄▅▅▅▆▆▆▆▆▅▆▅▆▆▆▆▆▅▆▆▆▆▇▅▆▅▅▅▆▆▆▆▆▇▆█</td></tr><tr><td>lr</td><td>█▇▅▂▁▂▅▇█▇▅▂▁▂▅▇█▇▃▂▁▂▆▇█▆▃▁▁▃▆█▇▆▂▁▂▃▇█</td></tr><tr><td>test_accuracy</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>test_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.84712</td></tr><tr><td>Total Time (hours)</td><td>1.17049</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>22.58553</td></tr><tr><td>lr</td><td>0.1</td></tr><tr><td>test_accuracy</td><td>0.83644</td></tr><tr><td>test_loss</td><td>0.45782</td></tr><tr><td>training_loss</td><td>0.49542</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">visionary-darkness-22</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/13kj1oac\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar5/runs/13kj1oac</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221021_220335-13kj1oac\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:13kj1oac). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88804205026f4661aebd3fa7d0bddc03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221021_223902-9xuel8wc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/9xuel8wc\" target=\"_blank\">fallen-haze-23</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name adp_layer1_full_ft \n",
      "\n",
      "\n",
      "Run Start : 2022-10-21 22-39-02\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4343135\n",
      "Initial accuracy:\n",
      "Test Accuracy : 8.8%, Test Loss: 4.613198432776019\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 8.4%, Test Loss: 4.8334173107391125\n",
      "epoch: 1 average loss: 0.961\n",
      "Test Accuracy : 73.8%, Test Loss: 0.7023793851475582\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 30.91 seconds\n",
      "epoch: 2 average loss: 0.694\n",
      "Test Accuracy : 77.2%, Test Loss: 0.6077157112643542\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 30.88 seconds\n",
      "epoch: 3 average loss: 0.642\n",
      "Test Accuracy : 77.4%, Test Loss: 0.6059497943162309\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 30.88 seconds\n",
      "epoch: 4 average loss: 0.595\n",
      "Test Accuracy : 80.6%, Test Loss: 0.5242338600518454\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 30.87 seconds\n",
      "epoch: 5 average loss: 0.575\n",
      "Test Accuracy : 81.0%, Test Loss: 0.5073400906589635\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 30.88 seconds\n",
      "epoch: 6 average loss: 0.558\n",
      "Test Accuracy : 81.9%, Test Loss: 0.4957340949255487\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.51 seconds\n",
      "epoch: 7 average loss: 0.546\n",
      "Test Accuracy : 81.7%, Test Loss: 0.49697680538877503\n",
      "Epoch Time (Training + Test) = 28.61 seconds\n",
      "epoch: 8 average loss: 0.535\n",
      "Test Accuracy : 82.6%, Test Loss: 0.48079357995554006\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.38 seconds\n",
      "epoch: 9 average loss: 0.532\n",
      "Test Accuracy : 82.6%, Test Loss: 0.4790660699691309\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.37 seconds\n",
      "epoch: 10 average loss: 0.529\n",
      "Test Accuracy : 82.2%, Test Loss: 0.4846745078139903\n",
      "Epoch Time (Training + Test) = 28.44 seconds\n",
      "epoch: 11 average loss: 0.525\n",
      "Test Accuracy : 82.7%, Test Loss: 0.47963652311993377\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.58 seconds\n",
      "epoch: 12 average loss: 0.526\n",
      "Test Accuracy : 82.4%, Test Loss: 0.48511345391078375\n",
      "Epoch Time (Training + Test) = 28.49 seconds\n",
      "epoch: 13 average loss: 0.519\n",
      "Test Accuracy : 82.5%, Test Loss: 0.47656422167482887\n",
      "Epoch Time (Training + Test) = 28.44 seconds\n",
      "epoch: 14 average loss: 0.527\n",
      "Test Accuracy : 82.3%, Test Loss: 0.48870517778427097\n",
      "Epoch Time (Training + Test) = 28.60 seconds\n",
      "epoch: 15 average loss: 0.530\n",
      "Test Accuracy : 82.8%, Test Loss: 0.4696978024204674\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.35 seconds\n",
      "epoch: 16 average loss: 0.534\n",
      "Test Accuracy : 82.7%, Test Loss: 0.4769109156354309\n",
      "Epoch Time (Training + Test) = 28.15 seconds\n",
      "epoch: 17 average loss: 0.528\n",
      "Test Accuracy : 81.2%, Test Loss: 0.5179835823185913\n",
      "Epoch Time (Training + Test) = 28.43 seconds\n",
      "epoch: 18 average loss: 0.524\n",
      "Test Accuracy : 82.6%, Test Loss: 0.4750627368459921\n",
      "Epoch Time (Training + Test) = 28.58 seconds\n",
      "epoch: 19 average loss: 0.517\n",
      "Test Accuracy : 81.2%, Test Loss: 0.5032428828499201\n",
      "Epoch Time (Training + Test) = 28.05 seconds\n",
      "epoch: 20 average loss: 0.520\n",
      "Test Accuracy : 83.1%, Test Loss: 0.4597416326899053\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.39 seconds\n",
      "epoch: 21 average loss: 0.509\n",
      "Test Accuracy : 82.9%, Test Loss: 0.46359678870424287\n",
      "Epoch Time (Training + Test) = 28.13 seconds\n",
      "epoch: 22 average loss: 0.507\n",
      "Test Accuracy : 83.3%, Test Loss: 0.4592583681768773\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.90 seconds\n",
      "epoch: 23 average loss: 0.498\n",
      "Test Accuracy : 83.0%, Test Loss: 0.4747325275712611\n",
      "Epoch Time (Training + Test) = 28.53 seconds\n",
      "epoch: 24 average loss: 0.492\n",
      "Test Accuracy : 82.7%, Test Loss: 0.4673127706550881\n",
      "Epoch Time (Training + Test) = 28.19 seconds\n",
      "epoch: 25 average loss: 0.487\n",
      "Test Accuracy : 82.8%, Test Loss: 0.47025387774190636\n",
      "Epoch Time (Training + Test) = 29.51 seconds\n",
      "epoch: 26 average loss: 0.472\n",
      "Test Accuracy : 84.4%, Test Loss: 0.43115848718244404\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.71 seconds\n",
      "epoch: 27 average loss: 0.465\n",
      "Test Accuracy : 84.0%, Test Loss: 0.43551255370040076\n",
      "Epoch Time (Training + Test) = 28.31 seconds\n",
      "epoch: 28 average loss: 0.473\n",
      "Test Accuracy : 84.5%, Test Loss: 0.42357661904733807\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.85 seconds\n",
      "epoch: 29 average loss: 0.458\n",
      "Test Accuracy : 84.9%, Test Loss: 0.41085656840935386\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.56 seconds\n",
      "epoch: 30 average loss: 0.457\n",
      "Test Accuracy : 84.8%, Test Loss: 0.42051014174585755\n",
      "Epoch Time (Training + Test) = 28.27 seconds\n",
      "epoch: 31 average loss: 0.461\n",
      "Test Accuracy : 84.7%, Test Loss: 0.4178362718552275\n",
      "Epoch Time (Training + Test) = 28.88 seconds\n",
      "epoch: 32 average loss: 0.455\n",
      "Test Accuracy : 85.0%, Test Loss: 0.41221465593408746\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.83 seconds\n",
      "epoch: 33 average loss: 0.462\n",
      "Test Accuracy : 84.8%, Test Loss: 0.4180045238769878\n",
      "Epoch Time (Training + Test) = 28.25 seconds\n",
      "epoch: 34 average loss: 0.469\n",
      "Test Accuracy : 84.5%, Test Loss: 0.42057102240259997\n",
      "Epoch Time (Training + Test) = 28.30 seconds\n",
      "epoch: 35 average loss: 0.467\n",
      "Test Accuracy : 84.3%, Test Loss: 0.4282258965475175\n",
      "Epoch Time (Training + Test) = 28.27 seconds\n",
      "epoch: 36 average loss: 0.470\n",
      "Test Accuracy : 83.9%, Test Loss: 0.4426703159613987\n",
      "Epoch Time (Training + Test) = 28.37 seconds\n",
      "epoch: 37 average loss: 0.473\n",
      "Test Accuracy : 83.9%, Test Loss: 0.4455950837153608\n",
      "Epoch Time (Training + Test) = 28.31 seconds\n",
      "epoch: 38 average loss: 0.478\n",
      "Test Accuracy : 83.5%, Test Loss: 0.451522692961766\n",
      "Epoch Time (Training + Test) = 28.29 seconds\n",
      "epoch: 39 average loss: 0.479\n",
      "Test Accuracy : 84.6%, Test Loss: 0.4195239594601609\n",
      "Epoch Time (Training + Test) = 28.24 seconds\n",
      "epoch: 40 average loss: 0.478\n",
      "Test Accuracy : 83.8%, Test Loss: 0.44073994404367167\n",
      "Epoch Time (Training + Test) = 29.10 seconds\n",
      "epoch: 41 average loss: 0.470\n",
      "Test Accuracy : 84.5%, Test Loss: 0.4232385530877296\n",
      "Epoch Time (Training + Test) = 28.70 seconds\n",
      "epoch: 42 average loss: 0.469\n",
      "Test Accuracy : 83.5%, Test Loss: 0.4490681444592488\n",
      "Epoch Time (Training + Test) = 28.68 seconds\n",
      "epoch: 43 average loss: 0.470\n",
      "Test Accuracy : 83.8%, Test Loss: 0.4428171122546696\n",
      "Epoch Time (Training + Test) = 29.17 seconds\n",
      "epoch: 44 average loss: 0.465\n",
      "Test Accuracy : 84.7%, Test Loss: 0.4166265099935824\n",
      "Epoch Time (Training + Test) = 28.42 seconds\n",
      "epoch: 45 average loss: 0.454\n",
      "Test Accuracy : 84.3%, Test Loss: 0.4236497086713381\n",
      "Epoch Time (Training + Test) = 28.50 seconds\n",
      "epoch: 46 average loss: 0.451\n",
      "Test Accuracy : 83.9%, Test Loss: 0.4349301598413521\n",
      "Epoch Time (Training + Test) = 28.95 seconds\n",
      "epoch: 47 average loss: 0.447\n",
      "Test Accuracy : 85.5%, Test Loss: 0.3971481778280205\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.88 seconds\n",
      "epoch: 48 average loss: 0.442\n",
      "Test Accuracy : 85.6%, Test Loss: 0.3959193063514007\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 29.01 seconds\n",
      "epoch: 49 average loss: 0.437\n",
      "Test Accuracy : 85.4%, Test Loss: 0.39789811710414985\n",
      "Epoch Time (Training + Test) = 28.76 seconds\n",
      "epoch: 50 average loss: 0.432\n",
      "Test Accuracy : 85.3%, Test Loss: 0.39897935039094645\n",
      "Epoch Time (Training + Test) = 28.71 seconds\n",
      "epoch: 51 average loss: 0.432\n",
      "Test Accuracy : 85.4%, Test Loss: 0.3934513942131301\n",
      "Epoch Time (Training + Test) = 28.85 seconds\n",
      "epoch: 52 average loss: 0.438\n",
      "Test Accuracy : 85.7%, Test Loss: 0.3965667907310569\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.74 seconds\n",
      "epoch: 53 average loss: 0.437\n",
      "Test Accuracy : 85.7%, Test Loss: 0.3916452795343326\n",
      "Epoch Time (Training + Test) = 28.65 seconds\n",
      "epoch: 54 average loss: 0.438\n",
      "Test Accuracy : 85.2%, Test Loss: 0.40223380934704295\n",
      "Epoch Time (Training + Test) = 28.84 seconds\n",
      "epoch: 55 average loss: 0.448\n",
      "Test Accuracy : 84.7%, Test Loss: 0.4166256811688928\n",
      "Epoch Time (Training + Test) = 28.74 seconds\n",
      "epoch: 56 average loss: 0.447\n",
      "Test Accuracy : 85.1%, Test Loss: 0.4098065248916826\n",
      "Epoch Time (Training + Test) = 28.35 seconds\n",
      "epoch: 57 average loss: 0.454\n",
      "Test Accuracy : 85.2%, Test Loss: 0.40806820607551225\n",
      "Epoch Time (Training + Test) = 28.14 seconds\n",
      "epoch: 58 average loss: 0.450\n",
      "Test Accuracy : 85.6%, Test Loss: 0.3979901554029616\n",
      "Epoch Time (Training + Test) = 28.47 seconds\n",
      "epoch: 59 average loss: 0.455\n",
      "Test Accuracy : 84.9%, Test Loss: 0.416839655784085\n",
      "Epoch Time (Training + Test) = 28.54 seconds\n",
      "epoch: 60 average loss: 0.454\n",
      "Test Accuracy : 83.2%, Test Loss: 0.46453001397802396\n",
      "Epoch Time (Training + Test) = 28.46 seconds\n",
      "epoch: 61 average loss: 0.457\n",
      "Test Accuracy : 81.3%, Test Loss: 0.4948580593556699\n",
      "Epoch Time (Training + Test) = 28.51 seconds\n",
      "epoch: 62 average loss: 0.449\n",
      "Test Accuracy : 84.8%, Test Loss: 0.41214955824872723\n",
      "Epoch Time (Training + Test) = 28.48 seconds\n",
      "epoch: 63 average loss: 0.457\n",
      "Test Accuracy : 85.6%, Test Loss: 0.3979489634485196\n",
      "Epoch Time (Training + Test) = 28.53 seconds\n",
      "epoch: 64 average loss: 0.448\n",
      "Test Accuracy : 83.3%, Test Loss: 0.46011721843953635\n",
      "Epoch Time (Training + Test) = 28.57 seconds\n",
      "epoch: 65 average loss: 0.447\n",
      "Test Accuracy : 83.4%, Test Loss: 0.4610827958873471\n",
      "Epoch Time (Training + Test) = 28.50 seconds\n",
      "epoch: 66 average loss: 0.439\n",
      "Test Accuracy : 84.6%, Test Loss: 0.41989886486316885\n",
      "Epoch Time (Training + Test) = 28.52 seconds\n",
      "epoch: 67 average loss: 0.438\n",
      "Test Accuracy : 86.0%, Test Loss: 0.387365354944373\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.51 seconds\n",
      "epoch: 68 average loss: 0.435\n",
      "Test Accuracy : 84.3%, Test Loss: 0.42983149906710894\n",
      "Epoch Time (Training + Test) = 28.54 seconds\n",
      "epoch: 69 average loss: 0.429\n",
      "Test Accuracy : 86.0%, Test Loss: 0.3858218644662281\n",
      "Epoch Time (Training + Test) = 27.99 seconds\n",
      "epoch: 70 average loss: 0.426\n",
      "Test Accuracy : 85.8%, Test Loss: 0.3871219500022776\n",
      "Epoch Time (Training + Test) = 27.41 seconds\n",
      "epoch: 71 average loss: 0.427\n",
      "Test Accuracy : 86.2%, Test Loss: 0.37900846201897886\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.37 seconds\n",
      "epoch: 72 average loss: 0.427\n",
      "Test Accuracy : 85.9%, Test Loss: 0.38488471530892354\n",
      "Epoch Time (Training + Test) = 27.32 seconds\n",
      "epoch: 73 average loss: 0.432\n",
      "Test Accuracy : 85.9%, Test Loss: 0.37920855347762633\n",
      "Epoch Time (Training + Test) = 27.34 seconds\n",
      "epoch: 74 average loss: 0.435\n",
      "Test Accuracy : 84.9%, Test Loss: 0.4126873610879454\n",
      "Epoch Time (Training + Test) = 27.32 seconds\n",
      "epoch: 75 average loss: 0.438\n",
      "Test Accuracy : 85.4%, Test Loss: 0.40302971523741016\n",
      "Epoch Time (Training + Test) = 27.34 seconds\n",
      "epoch: 76 average loss: 0.439\n",
      "Test Accuracy : 85.0%, Test Loss: 0.4102576183312384\n",
      "Epoch Time (Training + Test) = 27.31 seconds\n",
      "epoch: 77 average loss: 0.445\n",
      "Test Accuracy : 84.8%, Test Loss: 0.40997385109781914\n",
      "Epoch Time (Training + Test) = 27.34 seconds\n",
      "epoch: 78 average loss: 0.442\n",
      "Test Accuracy : 84.2%, Test Loss: 0.43908543899998337\n",
      "Epoch Time (Training + Test) = 27.32 seconds\n",
      "epoch: 79 average loss: 0.450\n",
      "Test Accuracy : 85.5%, Test Loss: 0.4041608522462723\n",
      "Epoch Time (Training + Test) = 27.37 seconds\n",
      "epoch: 80 average loss: 0.448\n",
      "Test Accuracy : 83.4%, Test Loss: 0.44851204154588986\n",
      "Epoch Time (Training + Test) = 27.35 seconds\n",
      "epoch: 81 average loss: 0.447\n",
      "Test Accuracy : 82.7%, Test Loss: 0.4695247813411381\n",
      "Epoch Time (Training + Test) = 27.34 seconds\n",
      "epoch: 82 average loss: 0.442\n",
      "Test Accuracy : 84.8%, Test Loss: 0.4138622366635086\n",
      "Epoch Time (Training + Test) = 27.35 seconds\n",
      "epoch: 83 average loss: 0.442\n",
      "Test Accuracy : 86.2%, Test Loss: 0.37913025645038967\n",
      "Epoch Time (Training + Test) = 27.31 seconds\n",
      "epoch: 84 average loss: 0.438\n",
      "Test Accuracy : 84.0%, Test Loss: 0.4403098184815453\n",
      "Epoch Time (Training + Test) = 27.35 seconds\n",
      "epoch: 85 average loss: 0.433\n",
      "Test Accuracy : 84.7%, Test Loss: 0.42403476233677484\n",
      "Epoch Time (Training + Test) = 27.31 seconds\n",
      "epoch: 86 average loss: 0.430\n",
      "Test Accuracy : 86.1%, Test Loss: 0.38282759156068574\n",
      "Epoch Time (Training + Test) = 27.37 seconds\n",
      "epoch: 87 average loss: 0.425\n",
      "Test Accuracy : 85.9%, Test Loss: 0.3833501921666553\n",
      "Epoch Time (Training + Test) = 27.40 seconds\n",
      "epoch: 88 average loss: 0.419\n",
      "Test Accuracy : 85.9%, Test Loss: 0.38501984403109\n",
      "Epoch Time (Training + Test) = 27.59 seconds\n",
      "epoch: 89 average loss: 0.419\n",
      "Test Accuracy : 85.0%, Test Loss: 0.41030273527440514\n",
      "Epoch Time (Training + Test) = 27.36 seconds\n",
      "epoch: 90 average loss: 0.419\n",
      "Test Accuracy : 86.4%, Test Loss: 0.3726894682478112\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.89 seconds\n",
      "epoch: 91 average loss: 0.413\n",
      "Test Accuracy : 86.6%, Test Loss: 0.36761462837076553\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.82 seconds\n",
      "epoch: 92 average loss: 0.424\n",
      "Test Accuracy : 85.5%, Test Loss: 0.39763421388080966\n",
      "Epoch Time (Training + Test) = 28.27 seconds\n",
      "epoch: 93 average loss: 0.418\n",
      "Test Accuracy : 86.0%, Test Loss: 0.38388191769495034\n",
      "Epoch Time (Training + Test) = 28.13 seconds\n",
      "epoch: 94 average loss: 0.430\n",
      "Test Accuracy : 86.0%, Test Loss: 0.3829908945676311\n",
      "Epoch Time (Training + Test) = 27.54 seconds\n",
      "epoch: 95 average loss: 0.422\n",
      "Test Accuracy : 85.4%, Test Loss: 0.4074724718280461\n",
      "Epoch Time (Training + Test) = 27.47 seconds\n",
      "epoch: 96 average loss: 0.430\n",
      "Test Accuracy : 85.6%, Test Loss: 0.39810012498170216\n",
      "Epoch Time (Training + Test) = 27.52 seconds\n",
      "epoch: 97 average loss: 0.435\n",
      "Test Accuracy : 85.4%, Test Loss: 0.4007816036872547\n",
      "Epoch Time (Training + Test) = 27.49 seconds\n",
      "epoch: 98 average loss: 0.433\n",
      "Test Accuracy : 84.9%, Test Loss: 0.4127607234679829\n",
      "Epoch Time (Training + Test) = 27.51 seconds\n",
      "epoch: 99 average loss: 0.439\n",
      "Test Accuracy : 85.7%, Test Loss: 0.39102524015909573\n",
      "Epoch Time (Training + Test) = 27.49 seconds\n",
      "epoch: 100 average loss: 0.444\n",
      "Test Accuracy : 85.1%, Test Loss: 0.4050438601113951\n",
      "Epoch Time (Training + Test) = 27.53 seconds\n",
      "Data Saved to adp_layer1_full_ft.csv\n",
      "Finished Training: \n",
      "Total Time 1.573407 hours\n",
      " Average Time Per Epoch 56.64 seconds\n",
      "adp_only layer2 160\n",
      "Scheduler Set {'T_max': 10, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:9xuel8wc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch time (s)</td><td>▁██▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▇▆▆▆</td></tr><tr><td>lr</td><td>█▇▅▂▁▂▅▇█▇▅▂▁▂▅▇█▇▃▂▁▂▆▇█▆▃▁▁▃▆█▇▆▂▁▂▃▇█</td></tr><tr><td>test_accuracy</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>test_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.86628</td></tr><tr><td>Total Time (hours)</td><td>1.57341</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>27.52569</td></tr><tr><td>lr</td><td>0.1</td></tr><tr><td>test_accuracy</td><td>0.85088</td></tr><tr><td>test_loss</td><td>0.40504</td></tr><tr><td>training_loss</td><td>0.44411</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fallen-haze-23</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/9xuel8wc\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar5/runs/9xuel8wc</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221021_223902-9xuel8wc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:9xuel8wc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8157facb0d408b8716c72d0fac7b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221021_232645-fx5aexwk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/fx5aexwk\" target=\"_blank\">polar-snowflake-24</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name adp_layer2_adp_only \n",
      "\n",
      "\n",
      "Run Start : 2022-10-21 23-26-45\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4362655\n",
      "Initial accuracy:\n",
      "Test Accuracy : 7.1%, Test Loss: 4.672063447630314\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 6.3%, Test Loss: 4.930686494578486\n",
      "epoch: 1 average loss: 0.767\n",
      "Test Accuracy : 78.2%, Test Loss: 0.5941561580923818\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.50 seconds\n",
      "epoch: 2 average loss: 0.594\n",
      "Test Accuracy : 80.0%, Test Loss: 0.545416933496285\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.56 seconds\n",
      "epoch: 3 average loss: 0.555\n",
      "Test Accuracy : 82.3%, Test Loss: 0.493122919136301\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.55 seconds\n",
      "epoch: 4 average loss: 0.525\n",
      "Test Accuracy : 83.2%, Test Loss: 0.46219612227376466\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.55 seconds\n",
      "epoch: 5 average loss: 0.504\n",
      "Test Accuracy : 83.6%, Test Loss: 0.45374877156351534\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.56 seconds\n",
      "epoch: 6 average loss: 0.497\n",
      "Test Accuracy : 83.3%, Test Loss: 0.4567739359862969\n",
      "Epoch Time (Training + Test) = 16.52 seconds\n",
      "epoch: 7 average loss: 0.485\n",
      "Test Accuracy : 84.1%, Test Loss: 0.4375923730604484\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.54 seconds\n",
      "epoch: 8 average loss: 0.476\n",
      "Test Accuracy : 84.5%, Test Loss: 0.42935509808228145\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.53 seconds\n",
      "epoch: 9 average loss: 0.465\n",
      "Test Accuracy : 84.4%, Test Loss: 0.4297309433636458\n",
      "Epoch Time (Training + Test) = 16.50 seconds\n",
      "epoch: 10 average loss: 0.468\n",
      "Test Accuracy : 84.5%, Test Loss: 0.4317586485992002\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.50 seconds\n",
      "epoch: 11 average loss: 0.463\n",
      "Test Accuracy : 84.4%, Test Loss: 0.425591597509811\n",
      "Epoch Time (Training + Test) = 16.50 seconds\n",
      "epoch: 12 average loss: 0.464\n",
      "Test Accuracy : 84.5%, Test Loss: 0.4328978703836041\n",
      "Epoch Time (Training + Test) = 16.46 seconds\n",
      "epoch: 13 average loss: 0.465\n",
      "Test Accuracy : 84.6%, Test Loss: 0.42539185209347463\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.51 seconds\n",
      "epoch: 14 average loss: 0.468\n",
      "Test Accuracy : 84.3%, Test Loss: 0.4303419975673451\n",
      "Epoch Time (Training + Test) = 16.46 seconds\n",
      "epoch: 15 average loss: 0.472\n",
      "Test Accuracy : 84.4%, Test Loss: 0.4330314963751132\n",
      "Epoch Time (Training + Test) = 16.47 seconds\n",
      "epoch: 16 average loss: 0.474\n",
      "Test Accuracy : 84.4%, Test Loss: 0.43712221844421933\n",
      "Epoch Time (Training + Test) = 16.51 seconds\n",
      "epoch: 17 average loss: 0.476\n",
      "Test Accuracy : 84.2%, Test Loss: 0.43451591868839606\n",
      "Epoch Time (Training + Test) = 16.51 seconds\n",
      "epoch: 18 average loss: 0.477\n",
      "Test Accuracy : 83.8%, Test Loss: 0.44500589161120413\n",
      "Epoch Time (Training + Test) = 16.48 seconds\n",
      "epoch: 19 average loss: 0.477\n",
      "Test Accuracy : 84.4%, Test Loss: 0.42853853346594156\n",
      "Epoch Time (Training + Test) = 16.48 seconds\n",
      "epoch: 20 average loss: 0.471\n",
      "Test Accuracy : 85.1%, Test Loss: 0.4106826645410274\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.65 seconds\n",
      "epoch: 21 average loss: 0.460\n",
      "Test Accuracy : 84.8%, Test Loss: 0.43016578077965073\n",
      "Epoch Time (Training + Test) = 16.57 seconds\n",
      "epoch: 22 average loss: 0.461\n",
      "Test Accuracy : 85.0%, Test Loss: 0.4163460458635979\n",
      "Epoch Time (Training + Test) = 16.60 seconds\n",
      "epoch: 23 average loss: 0.457\n",
      "Test Accuracy : 84.6%, Test Loss: 0.4312847452547849\n",
      "Epoch Time (Training + Test) = 16.54 seconds\n",
      "epoch: 24 average loss: 0.456\n",
      "Test Accuracy : 84.5%, Test Loss: 0.4289991142957107\n",
      "Epoch Time (Training + Test) = 16.56 seconds\n",
      "epoch: 25 average loss: 0.448\n",
      "Test Accuracy : 85.5%, Test Loss: 0.40490655117022717\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.86 seconds\n",
      "epoch: 26 average loss: 0.441\n",
      "Test Accuracy : 85.8%, Test Loss: 0.3982489716899974\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 17.25 seconds\n",
      "epoch: 27 average loss: 0.430\n",
      "Test Accuracy : 85.8%, Test Loss: 0.3937770978492849\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.98 seconds\n",
      "epoch: 28 average loss: 0.433\n",
      "Test Accuracy : 86.2%, Test Loss: 0.38689522551910954\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.68 seconds\n",
      "epoch: 29 average loss: 0.420\n",
      "Test Accuracy : 86.5%, Test Loss: 0.379198110278915\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.82 seconds\n",
      "epoch: 30 average loss: 0.422\n",
      "Test Accuracy : 86.2%, Test Loss: 0.3824453107688738\n",
      "Epoch Time (Training + Test) = 17.05 seconds\n",
      "epoch: 31 average loss: 0.421\n",
      "Test Accuracy : 86.0%, Test Loss: 0.3859675357027737\n",
      "Epoch Time (Training + Test) = 16.57 seconds\n",
      "epoch: 32 average loss: 0.418\n",
      "Test Accuracy : 86.2%, Test Loss: 0.3829808790436791\n",
      "Epoch Time (Training + Test) = 16.56 seconds\n",
      "epoch: 33 average loss: 0.420\n",
      "Test Accuracy : 86.0%, Test Loss: 0.3861369979579735\n",
      "Epoch Time (Training + Test) = 16.49 seconds\n",
      "epoch: 34 average loss: 0.429\n",
      "Test Accuracy : 86.1%, Test Loss: 0.3841629651044031\n",
      "Epoch Time (Training + Test) = 16.56 seconds\n",
      "epoch: 35 average loss: 0.429\n",
      "Test Accuracy : 86.3%, Test Loss: 0.3813935110483633\n",
      "Epoch Time (Training + Test) = 16.50 seconds\n",
      "epoch: 36 average loss: 0.435\n",
      "Test Accuracy : 86.1%, Test Loss: 0.3838504799796492\n",
      "Epoch Time (Training + Test) = 16.57 seconds\n",
      "epoch: 37 average loss: 0.437\n",
      "Test Accuracy : 86.2%, Test Loss: 0.38310012968299945\n",
      "Epoch Time (Training + Test) = 16.49 seconds\n",
      "epoch: 38 average loss: 0.438\n",
      "Test Accuracy : 85.3%, Test Loss: 0.4114070916953294\n",
      "Epoch Time (Training + Test) = 16.60 seconds\n",
      "epoch: 39 average loss: 0.439\n",
      "Test Accuracy : 86.2%, Test Loss: 0.384149173374676\n",
      "Epoch Time (Training + Test) = 16.59 seconds\n",
      "epoch: 40 average loss: 0.439\n",
      "Test Accuracy : 85.4%, Test Loss: 0.4025671158147895\n",
      "Epoch Time (Training + Test) = 16.93 seconds\n",
      "epoch: 41 average loss: 0.436\n",
      "Test Accuracy : 85.9%, Test Loss: 0.3860548217125866\n",
      "Epoch Time (Training + Test) = 16.86 seconds\n",
      "epoch: 42 average loss: 0.439\n",
      "Test Accuracy : 86.0%, Test Loss: 0.38829667107833316\n",
      "Epoch Time (Training + Test) = 16.85 seconds\n",
      "epoch: 43 average loss: 0.434\n",
      "Test Accuracy : 86.3%, Test Loss: 0.3838111666004981\n",
      "Epoch Time (Training + Test) = 16.73 seconds\n",
      "epoch: 44 average loss: 0.433\n",
      "Test Accuracy : 85.6%, Test Loss: 0.39404862924762396\n",
      "Epoch Time (Training + Test) = 17.07 seconds\n",
      "epoch: 45 average loss: 0.421\n",
      "Test Accuracy : 86.1%, Test Loss: 0.3824903118183546\n",
      "Epoch Time (Training + Test) = 16.80 seconds\n",
      "epoch: 46 average loss: 0.417\n",
      "Test Accuracy : 86.0%, Test Loss: 0.3849525883069734\n",
      "Epoch Time (Training + Test) = 16.81 seconds\n",
      "epoch: 47 average loss: 0.418\n",
      "Test Accuracy : 86.5%, Test Loss: 0.3731903011155555\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.87 seconds\n",
      "epoch: 48 average loss: 0.407\n",
      "Test Accuracy : 86.8%, Test Loss: 0.3650214770794525\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 17.10 seconds\n",
      "epoch: 49 average loss: 0.404\n",
      "Test Accuracy : 86.9%, Test Loss: 0.3626237613580111\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.91 seconds\n",
      "epoch: 50 average loss: 0.400\n",
      "Test Accuracy : 86.5%, Test Loss: 0.37020465198075375\n",
      "Epoch Time (Training + Test) = 16.72 seconds\n",
      "epoch: 51 average loss: 0.398\n",
      "Test Accuracy : 86.8%, Test Loss: 0.3608825305843597\n",
      "Epoch Time (Training + Test) = 16.79 seconds\n",
      "epoch: 52 average loss: 0.405\n",
      "Test Accuracy : 86.6%, Test Loss: 0.3663548414054734\n",
      "Epoch Time (Training + Test) = 16.77 seconds\n",
      "epoch: 53 average loss: 0.403\n",
      "Test Accuracy : 86.9%, Test Loss: 0.3615944327600777\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.71 seconds\n",
      "epoch: 54 average loss: 0.404\n",
      "Test Accuracy : 87.0%, Test Loss: 0.3577440368092578\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 17.13 seconds\n",
      "epoch: 55 average loss: 0.407\n",
      "Test Accuracy : 87.1%, Test Loss: 0.360457249538368\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.86 seconds\n",
      "epoch: 56 average loss: 0.413\n",
      "Test Accuracy : 86.8%, Test Loss: 0.36373622599236494\n",
      "Epoch Time (Training + Test) = 16.49 seconds\n",
      "epoch: 57 average loss: 0.414\n",
      "Test Accuracy : 86.1%, Test Loss: 0.37872220282359503\n",
      "Epoch Time (Training + Test) = 16.78 seconds\n",
      "epoch: 58 average loss: 0.421\n",
      "Test Accuracy : 86.5%, Test Loss: 0.37992734307675713\n",
      "Epoch Time (Training + Test) = 16.98 seconds\n",
      "epoch: 59 average loss: 0.420\n",
      "Test Accuracy : 86.3%, Test Loss: 0.3759547511634924\n",
      "Epoch Time (Training + Test) = 16.98 seconds\n",
      "epoch: 60 average loss: 0.421\n",
      "Test Accuracy : 86.5%, Test Loss: 0.36938541578819684\n",
      "Epoch Time (Training + Test) = 16.73 seconds\n",
      "epoch: 61 average loss: 0.415\n",
      "Test Accuracy : 86.6%, Test Loss: 0.3731181350967768\n",
      "Epoch Time (Training + Test) = 17.33 seconds\n",
      "epoch: 62 average loss: 0.419\n",
      "Test Accuracy : 86.6%, Test Loss: 0.37023177243712\n",
      "Epoch Time (Training + Test) = 16.80 seconds\n",
      "epoch: 63 average loss: 0.419\n",
      "Test Accuracy : 86.4%, Test Loss: 0.37656898609817485\n",
      "Epoch Time (Training + Test) = 16.70 seconds\n",
      "epoch: 64 average loss: 0.414\n",
      "Test Accuracy : 86.7%, Test Loss: 0.36369156894628957\n",
      "Epoch Time (Training + Test) = 16.74 seconds\n",
      "epoch: 65 average loss: 0.409\n",
      "Test Accuracy : 86.8%, Test Loss: 0.3622020972354333\n",
      "Epoch Time (Training + Test) = 17.08 seconds\n",
      "epoch: 66 average loss: 0.401\n",
      "Test Accuracy : 87.1%, Test Loss: 0.3537238204037137\n",
      "Epoch Time (Training + Test) = 16.94 seconds\n",
      "epoch: 67 average loss: 0.403\n",
      "Test Accuracy : 87.1%, Test Loss: 0.3527213977197247\n",
      "Epoch Time (Training + Test) = 16.67 seconds\n",
      "epoch: 68 average loss: 0.399\n",
      "Test Accuracy : 87.2%, Test Loss: 0.3577564453987209\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 17.15 seconds\n",
      "epoch: 69 average loss: 0.396\n",
      "Test Accuracy : 87.3%, Test Loss: 0.3510535051069601\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.65 seconds\n",
      "epoch: 70 average loss: 0.391\n",
      "Test Accuracy : 87.0%, Test Loss: 0.35770245243216414\n",
      "Epoch Time (Training + Test) = 16.59 seconds\n",
      "epoch: 71 average loss: 0.390\n",
      "Test Accuracy : 87.4%, Test Loss: 0.34812548470771526\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.58 seconds\n",
      "epoch: 72 average loss: 0.395\n",
      "Test Accuracy : 87.3%, Test Loss: 0.3497781425028506\n",
      "Epoch Time (Training + Test) = 16.43 seconds\n",
      "epoch: 73 average loss: 0.391\n",
      "Test Accuracy : 87.3%, Test Loss: 0.34982187169439655\n",
      "Epoch Time (Training + Test) = 16.46 seconds\n",
      "epoch: 74 average loss: 0.392\n",
      "Test Accuracy : 87.0%, Test Loss: 0.3578554512670888\n",
      "Epoch Time (Training + Test) = 16.44 seconds\n",
      "epoch: 75 average loss: 0.393\n",
      "Test Accuracy : 87.3%, Test Loss: 0.3507491892103649\n",
      "Epoch Time (Training + Test) = 16.58 seconds\n",
      "epoch: 76 average loss: 0.401\n",
      "Test Accuracy : 87.1%, Test Loss: 0.35574311696354993\n",
      "Epoch Time (Training + Test) = 16.77 seconds\n",
      "epoch: 77 average loss: 0.409\n",
      "Test Accuracy : 86.8%, Test Loss: 0.36286362106232994\n",
      "Epoch Time (Training + Test) = 17.03 seconds\n",
      "epoch: 78 average loss: 0.409\n",
      "Test Accuracy : 87.0%, Test Loss: 0.35806058354847264\n",
      "Epoch Time (Training + Test) = 16.86 seconds\n",
      "epoch: 79 average loss: 0.417\n",
      "Test Accuracy : 87.1%, Test Loss: 0.36493223737877656\n",
      "Epoch Time (Training + Test) = 17.03 seconds\n",
      "epoch: 80 average loss: 0.413\n",
      "Test Accuracy : 87.0%, Test Loss: 0.36241494946162717\n",
      "Epoch Time (Training + Test) = 17.39 seconds\n",
      "epoch: 81 average loss: 0.413\n",
      "Test Accuracy : 86.7%, Test Loss: 0.3701427209255336\n",
      "Epoch Time (Training + Test) = 17.60 seconds\n",
      "epoch: 82 average loss: 0.414\n",
      "Test Accuracy : 87.0%, Test Loss: 0.360090375708802\n",
      "Epoch Time (Training + Test) = 17.40 seconds\n",
      "epoch: 83 average loss: 0.406\n",
      "Test Accuracy : 87.2%, Test Loss: 0.35675998550394306\n",
      "Epoch Time (Training + Test) = 16.78 seconds\n",
      "epoch: 84 average loss: 0.412\n",
      "Test Accuracy : 87.0%, Test Loss: 0.35718132086727017\n",
      "Epoch Time (Training + Test) = 16.55 seconds\n",
      "epoch: 85 average loss: 0.401\n",
      "Test Accuracy : 86.5%, Test Loss: 0.3699509842926279\n",
      "Epoch Time (Training + Test) = 16.44 seconds\n",
      "epoch: 86 average loss: 0.398\n",
      "Test Accuracy : 87.2%, Test Loss: 0.34923107167491524\n",
      "Epoch Time (Training + Test) = 16.43 seconds\n",
      "epoch: 87 average loss: 0.391\n",
      "Test Accuracy : 87.5%, Test Loss: 0.3457074120755086\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.46 seconds\n",
      "epoch: 88 average loss: 0.392\n",
      "Test Accuracy : 87.5%, Test Loss: 0.34419935831176046\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.45 seconds\n",
      "epoch: 89 average loss: 0.383\n",
      "Test Accuracy : 87.7%, Test Loss: 0.34324940303554924\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.55 seconds\n",
      "epoch: 90 average loss: 0.387\n",
      "Test Accuracy : 87.6%, Test Loss: 0.34541359311326997\n",
      "Epoch Time (Training + Test) = 16.47 seconds\n",
      "epoch: 91 average loss: 0.383\n",
      "Test Accuracy : 87.5%, Test Loss: 0.34149681043137065\n",
      "Epoch Time (Training + Test) = 16.54 seconds\n",
      "epoch: 92 average loss: 0.389\n",
      "Test Accuracy : 87.7%, Test Loss: 0.3425236997549491\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.52 seconds\n",
      "epoch: 93 average loss: 0.380\n",
      "Test Accuracy : 87.5%, Test Loss: 0.34439766788116805\n",
      "Epoch Time (Training + Test) = 16.43 seconds\n",
      "epoch: 94 average loss: 0.392\n",
      "Test Accuracy : 87.7%, Test Loss: 0.34303626000804976\n",
      "Epoch Time (Training + Test) = 16.40 seconds\n",
      "epoch: 95 average loss: 0.388\n",
      "Test Accuracy : 87.5%, Test Loss: 0.3484004043862033\n",
      "Epoch Time (Training + Test) = 16.47 seconds\n",
      "epoch: 96 average loss: 0.390\n",
      "Test Accuracy : 87.6%, Test Loss: 0.3432461191397494\n",
      "Epoch Time (Training + Test) = 16.49 seconds\n",
      "epoch: 97 average loss: 0.398\n",
      "Test Accuracy : 86.6%, Test Loss: 0.3673676635374499\n",
      "Epoch Time (Training + Test) = 16.96 seconds\n",
      "epoch: 98 average loss: 0.396\n",
      "Test Accuracy : 87.2%, Test Loss: 0.3519699378010562\n",
      "Epoch Time (Training + Test) = 16.96 seconds\n",
      "epoch: 99 average loss: 0.402\n",
      "Test Accuracy : 86.8%, Test Loss: 0.36740410259312684\n",
      "Epoch Time (Training + Test) = 16.76 seconds\n",
      "epoch: 100 average loss: 0.410\n",
      "Test Accuracy : 87.0%, Test Loss: 0.359571149739463\n",
      "Epoch Time (Training + Test) = 16.67 seconds\n",
      "Data Saved to adp_layer2_adp_only.csv\n",
      "Finished Training: \n",
      "Total Time 0.928093 hours\n",
      " Average Time Per Epoch 33.41 seconds\n",
      "full_ft layer2 160\n",
      "Scheduler Set {'T_max': 10, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:fx5aexwk) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch time (s)</td><td>▁▆▆▆▅▅▅▅▆▆▆▆▇▅▅▆▆▆▆▇▆▆▅▇█▆▇▆▆▅▆▇█▆▅▆▅▅▇▆</td></tr><tr><td>lr</td><td>█▇▅▂▁▂▅▇█▇▅▂▁▂▅▇█▇▃▂▁▂▆▇█▆▃▁▁▃▆█▇▆▂▁▂▃▇█</td></tr><tr><td>test_accuracy</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>test_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.87696</td></tr><tr><td>Total Time (hours)</td><td>0.92809</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>16.66766</td></tr><tr><td>lr</td><td>0.1</td></tr><tr><td>test_accuracy</td><td>0.87044</td></tr><tr><td>test_loss</td><td>0.35957</td></tr><tr><td>training_loss</td><td>0.40972</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">polar-snowflake-24</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/fx5aexwk\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar5/runs/fx5aexwk</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221021_232645-fx5aexwk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:fx5aexwk). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b411a2f7d6c0406c94b8fb39d10b5a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221021_235503-33h4tp9j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/33h4tp9j\" target=\"_blank\">bright-bird-25</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name adp_layer2_full_ft \n",
      "\n",
      "\n",
      "Run Start : 2022-10-21 23-55-03\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4362655\n",
      "Initial accuracy:\n",
      "Test Accuracy : 7.1%, Test Loss: 4.672063447630314\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 6.3%, Test Loss: 4.930686494578486\n",
      "epoch: 1 average loss: 0.734\n",
      "Test Accuracy : 80.0%, Test Loss: 0.5462298654686765\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.22 seconds\n",
      "epoch: 2 average loss: 0.556\n",
      "Test Accuracy : 80.0%, Test Loss: 0.5506100953768587\n",
      "Epoch Time (Training + Test) = 27.24 seconds\n",
      "epoch: 3 average loss: 0.517\n",
      "Test Accuracy : 82.7%, Test Loss: 0.4800355967963138\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.35 seconds\n",
      "epoch: 4 average loss: 0.488\n",
      "Test Accuracy : 84.3%, Test Loss: 0.4279481671807711\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.12 seconds\n",
      "epoch: 5 average loss: 0.466\n",
      "Test Accuracy : 84.7%, Test Loss: 0.41946866212750944\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.95 seconds\n",
      "epoch: 6 average loss: 0.460\n",
      "Test Accuracy : 84.9%, Test Loss: 0.41374471250092587\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.04 seconds\n",
      "epoch: 7 average loss: 0.450\n",
      "Test Accuracy : 84.8%, Test Loss: 0.41710550103650984\n",
      "Epoch Time (Training + Test) = 27.18 seconds\n",
      "epoch: 8 average loss: 0.439\n",
      "Test Accuracy : 85.8%, Test Loss: 0.3935346141114564\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.06 seconds\n",
      "epoch: 9 average loss: 0.429\n",
      "Test Accuracy : 85.6%, Test Loss: 0.3954311540288389\n",
      "Epoch Time (Training + Test) = 27.41 seconds\n",
      "epoch: 10 average loss: 0.435\n",
      "Test Accuracy : 85.6%, Test Loss: 0.39898755616696596\n",
      "Epoch Time (Training + Test) = 27.24 seconds\n",
      "epoch: 11 average loss: 0.433\n",
      "Test Accuracy : 85.6%, Test Loss: 0.3924451323268968\n",
      "Epoch Time (Training + Test) = 26.22 seconds\n",
      "epoch: 12 average loss: 0.433\n",
      "Test Accuracy : 85.5%, Test Loss: 0.40183440491061684\n",
      "Epoch Time (Training + Test) = 26.98 seconds\n",
      "epoch: 13 average loss: 0.428\n",
      "Test Accuracy : 85.7%, Test Loss: 0.39477276946882456\n",
      "Epoch Time (Training + Test) = 27.60 seconds\n",
      "epoch: 14 average loss: 0.428\n",
      "Test Accuracy : 85.6%, Test Loss: 0.3955005804443603\n",
      "Epoch Time (Training + Test) = 27.33 seconds\n",
      "epoch: 15 average loss: 0.435\n",
      "Test Accuracy : 85.8%, Test Loss: 0.387571353055632\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.14 seconds\n",
      "epoch: 16 average loss: 0.442\n",
      "Test Accuracy : 85.2%, Test Loss: 0.4051718581515505\n",
      "Epoch Time (Training + Test) = 27.22 seconds\n",
      "epoch: 17 average loss: 0.435\n",
      "Test Accuracy : 84.9%, Test Loss: 0.41185013431569806\n",
      "Epoch Time (Training + Test) = 27.06 seconds\n",
      "epoch: 18 average loss: 0.433\n",
      "Test Accuracy : 85.9%, Test Loss: 0.3887244430954194\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.10 seconds\n",
      "epoch: 19 average loss: 0.434\n",
      "Test Accuracy : 85.4%, Test Loss: 0.40600121383319426\n",
      "Epoch Time (Training + Test) = 27.06 seconds\n",
      "epoch: 20 average loss: 0.433\n",
      "Test Accuracy : 85.8%, Test Loss: 0.3921092510642603\n",
      "Epoch Time (Training + Test) = 27.11 seconds\n",
      "epoch: 21 average loss: 0.428\n",
      "Test Accuracy : 85.7%, Test Loss: 0.39607940621845555\n",
      "Epoch Time (Training + Test) = 27.38 seconds\n",
      "epoch: 22 average loss: 0.424\n",
      "Test Accuracy : 85.6%, Test Loss: 0.39655127805059825\n",
      "Epoch Time (Training + Test) = 27.89 seconds\n",
      "epoch: 23 average loss: 0.415\n",
      "Test Accuracy : 86.4%, Test Loss: 0.3791218523479179\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.37 seconds\n",
      "epoch: 24 average loss: 0.411\n",
      "Test Accuracy : 86.4%, Test Loss: 0.37927995542126236\n",
      "Epoch Time (Training + Test) = 27.62 seconds\n",
      "epoch: 25 average loss: 0.404\n",
      "Test Accuracy : 86.7%, Test Loss: 0.3683355165564496\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.62 seconds\n",
      "epoch: 26 average loss: 0.399\n",
      "Test Accuracy : 87.1%, Test Loss: 0.35606073910165625\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.57 seconds\n",
      "epoch: 27 average loss: 0.390\n",
      "Test Accuracy : 87.1%, Test Loss: 0.3550306754496396\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.59 seconds\n",
      "epoch: 28 average loss: 0.394\n",
      "Test Accuracy : 87.5%, Test Loss: 0.35054383642228365\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.48 seconds\n",
      "epoch: 29 average loss: 0.381\n",
      "Test Accuracy : 87.8%, Test Loss: 0.3380593758105012\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.56 seconds\n",
      "epoch: 30 average loss: 0.377\n",
      "Test Accuracy : 87.8%, Test Loss: 0.3419289356835968\n",
      "Epoch Time (Training + Test) = 27.15 seconds\n",
      "epoch: 31 average loss: 0.378\n",
      "Test Accuracy : 87.7%, Test Loss: 0.34280997507102656\n",
      "Epoch Time (Training + Test) = 27.94 seconds\n",
      "epoch: 32 average loss: 0.378\n",
      "Test Accuracy : 87.8%, Test Loss: 0.34498783050443205\n",
      "Epoch Time (Training + Test) = 27.47 seconds\n",
      "epoch: 33 average loss: 0.387\n",
      "Test Accuracy : 87.3%, Test Loss: 0.3507443951523822\n",
      "Epoch Time (Training + Test) = 27.23 seconds\n",
      "epoch: 34 average loss: 0.388\n",
      "Test Accuracy : 87.5%, Test Loss: 0.34388642424665145\n",
      "Epoch Time (Training + Test) = 27.19 seconds\n",
      "epoch: 35 average loss: 0.386\n",
      "Test Accuracy : 87.5%, Test Loss: 0.34474257991441987\n",
      "Epoch Time (Training + Test) = 27.03 seconds\n",
      "epoch: 36 average loss: 0.394\n",
      "Test Accuracy : 87.1%, Test Loss: 0.3557804226494201\n",
      "Epoch Time (Training + Test) = 27.16 seconds\n",
      "epoch: 37 average loss: 0.395\n",
      "Test Accuracy : 86.9%, Test Loss: 0.36182595046279986\n",
      "Epoch Time (Training + Test) = 27.30 seconds\n",
      "epoch: 38 average loss: 0.400\n",
      "Test Accuracy : 86.3%, Test Loss: 0.3783793879858673\n",
      "Epoch Time (Training + Test) = 27.26 seconds\n",
      "epoch: 39 average loss: 0.398\n",
      "Test Accuracy : 87.4%, Test Loss: 0.34464216253260516\n",
      "Epoch Time (Training + Test) = 27.14 seconds\n",
      "epoch: 40 average loss: 0.399\n",
      "Test Accuracy : 87.1%, Test Loss: 0.35912017030712895\n",
      "Epoch Time (Training + Test) = 27.35 seconds\n",
      "epoch: 41 average loss: 0.395\n",
      "Test Accuracy : 87.2%, Test Loss: 0.35655579443477914\n",
      "Epoch Time (Training + Test) = 27.39 seconds\n",
      "epoch: 42 average loss: 0.397\n",
      "Test Accuracy : 87.1%, Test Loss: 0.3576685741658101\n",
      "Epoch Time (Training + Test) = 27.36 seconds\n",
      "epoch: 43 average loss: 0.390\n",
      "Test Accuracy : 87.3%, Test Loss: 0.3485529545475455\n",
      "Epoch Time (Training + Test) = 27.14 seconds\n",
      "epoch: 44 average loss: 0.394\n",
      "Test Accuracy : 86.7%, Test Loss: 0.36508450365584827\n",
      "Epoch Time (Training + Test) = 27.16 seconds\n",
      "epoch: 45 average loss: 0.386\n",
      "Test Accuracy : 87.4%, Test Loss: 0.3458316866927745\n",
      "Epoch Time (Training + Test) = 27.23 seconds\n",
      "epoch: 46 average loss: 0.379\n",
      "Test Accuracy : 87.2%, Test Loss: 0.3565261214209335\n",
      "Epoch Time (Training + Test) = 26.61 seconds\n",
      "epoch: 47 average loss: 0.375\n",
      "Test Accuracy : 88.4%, Test Loss: 0.3236592938299374\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.29 seconds\n",
      "epoch: 48 average loss: 0.370\n",
      "Test Accuracy : 88.4%, Test Loss: 0.3267277128746747\n",
      "Epoch Time (Training + Test) = 27.42 seconds\n",
      "epoch: 49 average loss: 0.367\n",
      "Test Accuracy : 88.4%, Test Loss: 0.3244571520010834\n",
      "Epoch Time (Training + Test) = 27.46 seconds\n",
      "epoch: 50 average loss: 0.362\n",
      "Test Accuracy : 88.0%, Test Loss: 0.3341540381731585\n",
      "Epoch Time (Training + Test) = 27.20 seconds\n",
      "epoch: 51 average loss: 0.366\n",
      "Test Accuracy : 88.2%, Test Loss: 0.32599490330271097\n",
      "Epoch Time (Training + Test) = 26.95 seconds\n",
      "epoch: 52 average loss: 0.366\n",
      "Test Accuracy : 88.1%, Test Loss: 0.33306305209541565\n",
      "Epoch Time (Training + Test) = 27.15 seconds\n",
      "epoch: 53 average loss: 0.365\n",
      "Test Accuracy : 88.5%, Test Loss: 0.3203222710458214\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.07 seconds\n",
      "epoch: 54 average loss: 0.362\n",
      "Test Accuracy : 86.7%, Test Loss: 0.36309106869008534\n",
      "Epoch Time (Training + Test) = 27.16 seconds\n",
      "epoch: 55 average loss: 0.371\n",
      "Test Accuracy : 88.3%, Test Loss: 0.32442596497590587\n",
      "Epoch Time (Training + Test) = 27.09 seconds\n",
      "epoch: 56 average loss: 0.380\n",
      "Test Accuracy : 87.1%, Test Loss: 0.3602085910413576\n",
      "Epoch Time (Training + Test) = 27.08 seconds\n",
      "epoch: 57 average loss: 0.375\n",
      "Test Accuracy : 87.8%, Test Loss: 0.33579121434780035\n",
      "Epoch Time (Training + Test) = 27.17 seconds\n",
      "epoch: 58 average loss: 0.385\n",
      "Test Accuracy : 87.8%, Test Loss: 0.3413421321098152\n",
      "Epoch Time (Training + Test) = 27.19 seconds\n",
      "epoch: 59 average loss: 0.383\n",
      "Test Accuracy : 86.8%, Test Loss: 0.3578046499310857\n",
      "Epoch Time (Training + Test) = 27.09 seconds\n",
      "epoch: 60 average loss: 0.381\n",
      "Test Accuracy : 87.6%, Test Loss: 0.3416897871000383\n",
      "Epoch Time (Training + Test) = 27.35 seconds\n",
      "epoch: 61 average loss: 0.382\n",
      "Test Accuracy : 87.8%, Test Loss: 0.3349114330604558\n",
      "Epoch Time (Training + Test) = 27.31 seconds\n",
      "epoch: 62 average loss: 0.384\n",
      "Test Accuracy : 87.8%, Test Loss: 0.3383413265504496\n",
      "Epoch Time (Training + Test) = 27.16 seconds\n",
      "epoch: 63 average loss: 0.382\n",
      "Test Accuracy : 87.4%, Test Loss: 0.3492340619682961\n",
      "Epoch Time (Training + Test) = 27.04 seconds\n",
      "epoch: 64 average loss: 0.375\n",
      "Test Accuracy : 87.9%, Test Loss: 0.33598305235433457\n",
      "Epoch Time (Training + Test) = 27.17 seconds\n",
      "epoch: 65 average loss: 0.373\n",
      "Test Accuracy : 87.9%, Test Loss: 0.3355874096417366\n",
      "Epoch Time (Training + Test) = 27.14 seconds\n",
      "epoch: 66 average loss: 0.367\n",
      "Test Accuracy : 88.1%, Test Loss: 0.3286717080742197\n",
      "Epoch Time (Training + Test) = 26.84 seconds\n",
      "epoch: 67 average loss: 0.368\n",
      "Test Accuracy : 88.4%, Test Loss: 0.3171450796982516\n",
      "Epoch Time (Training + Test) = 26.81 seconds\n",
      "epoch: 68 average loss: 0.363\n",
      "Test Accuracy : 88.6%, Test Loss: 0.31412009626169646\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 69 average loss: 0.356\n",
      "Test Accuracy : 88.7%, Test Loss: 0.31778113027591537\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.00 seconds\n",
      "epoch: 70 average loss: 0.351\n",
      "Test Accuracy : 88.3%, Test Loss: 0.324452684587225\n",
      "Epoch Time (Training + Test) = 27.16 seconds\n",
      "epoch: 71 average loss: 0.352\n",
      "Test Accuracy : 88.5%, Test Loss: 0.316301936440913\n",
      "Epoch Time (Training + Test) = 26.98 seconds\n",
      "epoch: 72 average loss: 0.351\n",
      "Test Accuracy : 88.7%, Test Loss: 0.3147022089613673\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.31 seconds\n",
      "epoch: 73 average loss: 0.354\n",
      "Test Accuracy : 88.7%, Test Loss: 0.31336943313593757\n",
      "Epoch Time (Training + Test) = 27.26 seconds\n",
      "epoch: 74 average loss: 0.362\n",
      "Test Accuracy : 88.4%, Test Loss: 0.3208639720059417\n",
      "Epoch Time (Training + Test) = 27.18 seconds\n",
      "epoch: 75 average loss: 0.361\n",
      "Test Accuracy : 88.2%, Test Loss: 0.32736954447406025\n",
      "Epoch Time (Training + Test) = 26.98 seconds\n",
      "epoch: 76 average loss: 0.367\n",
      "Test Accuracy : 87.8%, Test Loss: 0.33638568397830515\n",
      "Epoch Time (Training + Test) = 27.25 seconds\n",
      "epoch: 77 average loss: 0.373\n",
      "Test Accuracy : 88.2%, Test Loss: 0.3268344953198872\n",
      "Epoch Time (Training + Test) = 26.61 seconds\n",
      "epoch: 78 average loss: 0.372\n",
      "Test Accuracy : 87.3%, Test Loss: 0.3537696420460406\n",
      "Epoch Time (Training + Test) = 26.25 seconds\n",
      "epoch: 79 average loss: 0.383\n",
      "Test Accuracy : 87.5%, Test Loss: 0.3508773711712464\n",
      "Epoch Time (Training + Test) = 27.12 seconds\n",
      "epoch: 80 average loss: 0.376\n",
      "Test Accuracy : 87.4%, Test Loss: 0.3487292352654135\n",
      "Epoch Time (Training + Test) = 27.31 seconds\n",
      "epoch: 81 average loss: 0.375\n",
      "Test Accuracy : 87.4%, Test Loss: 0.34462883614975476\n",
      "Epoch Time (Training + Test) = 27.07 seconds\n",
      "epoch: 82 average loss: 0.372\n",
      "Test Accuracy : 86.4%, Test Loss: 0.3817245118758258\n",
      "Epoch Time (Training + Test) = 28.16 seconds\n",
      "epoch: 83 average loss: 0.369\n",
      "Test Accuracy : 85.7%, Test Loss: 0.39310370398985456\n",
      "Epoch Time (Training + Test) = 27.84 seconds\n",
      "epoch: 84 average loss: 0.373\n",
      "Test Accuracy : 88.4%, Test Loss: 0.31980956744050126\n",
      "Epoch Time (Training + Test) = 27.75 seconds\n",
      "epoch: 85 average loss: 0.366\n",
      "Test Accuracy : 87.7%, Test Loss: 0.34000054064690305\n",
      "Epoch Time (Training + Test) = 28.01 seconds\n",
      "epoch: 86 average loss: 0.364\n",
      "Test Accuracy : 88.2%, Test Loss: 0.3235811269306161\n",
      "Epoch Time (Training + Test) = 28.08 seconds\n",
      "epoch: 87 average loss: 0.356\n",
      "Test Accuracy : 88.7%, Test Loss: 0.31261035718042834\n",
      "Epoch Time (Training + Test) = 27.48 seconds\n",
      "epoch: 88 average loss: 0.353\n",
      "Test Accuracy : 88.5%, Test Loss: 0.32018342366456376\n",
      "Epoch Time (Training + Test) = 27.04 seconds\n",
      "epoch: 89 average loss: 0.351\n",
      "Test Accuracy : 88.8%, Test Loss: 0.31703596554525065\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.15 seconds\n",
      "epoch: 90 average loss: 0.349\n",
      "Test Accuracy : 89.1%, Test Loss: 0.30445293790620304\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.42 seconds\n",
      "epoch: 91 average loss: 0.343\n",
      "Test Accuracy : 89.2%, Test Loss: 0.30293014489323894\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.98 seconds\n",
      "epoch: 92 average loss: 0.355\n",
      "Test Accuracy : 88.9%, Test Loss: 0.3093470179325784\n",
      "Epoch Time (Training + Test) = 27.50 seconds\n",
      "epoch: 93 average loss: 0.348\n",
      "Test Accuracy : 89.1%, Test Loss: 0.3054787840151116\n",
      "Epoch Time (Training + Test) = 27.16 seconds\n",
      "epoch: 94 average loss: 0.362\n",
      "Test Accuracy : 89.1%, Test Loss: 0.3050940577369517\n",
      "Epoch Time (Training + Test) = 27.14 seconds\n",
      "epoch: 95 average loss: 0.352\n",
      "Test Accuracy : 88.7%, Test Loss: 0.3133054417569924\n",
      "Epoch Time (Training + Test) = 27.10 seconds\n",
      "epoch: 96 average loss: 0.359\n",
      "Test Accuracy : 88.3%, Test Loss: 0.32230454534673325\n",
      "Epoch Time (Training + Test) = 27.09 seconds\n",
      "epoch: 97 average loss: 0.363\n",
      "Test Accuracy : 87.3%, Test Loss: 0.34602321070783276\n",
      "Epoch Time (Training + Test) = 27.45 seconds\n",
      "epoch: 98 average loss: 0.359\n",
      "Test Accuracy : 87.4%, Test Loss: 0.351306762803546\n",
      "Epoch Time (Training + Test) = 25.90 seconds\n",
      "epoch: 99 average loss: 0.368\n",
      "Test Accuracy : 87.5%, Test Loss: 0.3446813385428675\n",
      "Epoch Time (Training + Test) = 25.87 seconds\n",
      "epoch: 100 average loss: 0.372\n",
      "Test Accuracy : 88.4%, Test Loss: 0.32098042785816483\n",
      "Epoch Time (Training + Test) = 26.91 seconds\n",
      "Data Saved to adp_layer2_full_ft.csv\n",
      "Finished Training: \n",
      "Total Time 1.511858 hours\n",
      " Average Time Per Epoch 54.43 seconds\n",
      "adp_only layer3 320\n",
      "Scheduler Set {'T_max': 10, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:33h4tp9j) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch time (s)</td><td>▁▇▇▇▇▇▇▇▇███▇▇▇██▇▇█▇▇▇▇█▇▇▇▇▇▇▇███▇█▇█▇</td></tr><tr><td>lr</td><td>█▇▅▂▁▂▅▇█▇▅▂▁▂▅▇█▇▃▂▁▂▆▇█▆▃▁▁▃▆█▇▆▂▁▂▃▇█</td></tr><tr><td>test_accuracy</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>test_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.89184</td></tr><tr><td>Total Time (hours)</td><td>1.51186</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>26.91144</td></tr><tr><td>lr</td><td>0.1</td></tr><tr><td>test_accuracy</td><td>0.88444</td></tr><tr><td>test_loss</td><td>0.32098</td></tr><tr><td>training_loss</td><td>0.37227</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">bright-bird-25</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/33h4tp9j\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar5/runs/33h4tp9j</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221021_235503-33h4tp9j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:33h4tp9j). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33910ca66eca40a682d98c1a9ad8e849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221022_004053-126k0wfi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/126k0wfi\" target=\"_blank\">young-fog-26</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name adp_layer3_adp_only \n",
      "\n",
      "\n",
      "Run Start : 2022-10-22 00-40-53\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4440095\n",
      "Initial accuracy:\n",
      "Test Accuracy : 20.0%, Test Loss: 2.5574629739727204\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 20.0%, Test Loss: 2.562192482716592\n",
      "epoch: 1 average loss: 1.608\n",
      "Test Accuracy : 37.7%, Test Loss: 1.4049944045293667\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.85 seconds\n",
      "epoch: 2 average loss: 1.413\n",
      "Test Accuracy : 39.0%, Test Loss: 1.3817411118456164\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.84 seconds\n",
      "epoch: 3 average loss: 1.395\n",
      "Test Accuracy : 44.5%, Test Loss: 1.3552783965454687\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.66 seconds\n",
      "epoch: 4 average loss: 1.375\n",
      "Test Accuracy : 41.9%, Test Loss: 1.3349346574919914\n",
      "Epoch Time (Training + Test) = 14.65 seconds\n",
      "epoch: 5 average loss: 1.363\n",
      "Test Accuracy : 32.8%, Test Loss: 1.3597033228105901\n",
      "Epoch Time (Training + Test) = 15.21 seconds\n",
      "epoch: 6 average loss: 1.345\n",
      "Test Accuracy : 46.7%, Test Loss: 1.314581913716348\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.64 seconds\n",
      "epoch: 7 average loss: 1.340\n",
      "Test Accuracy : 40.5%, Test Loss: 1.3240987105137856\n",
      "Epoch Time (Training + Test) = 15.15 seconds\n",
      "epoch: 8 average loss: 1.335\n",
      "Test Accuracy : 49.6%, Test Loss: 1.2874476366945544\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.26 seconds\n",
      "epoch: 9 average loss: 1.328\n",
      "Test Accuracy : 42.2%, Test Loss: 1.3128150341760776\n",
      "Epoch Time (Training + Test) = 14.72 seconds\n",
      "epoch: 10 average loss: 1.332\n",
      "Test Accuracy : 49.6%, Test Loss: 1.2758188287315466\n",
      "Epoch Time (Training + Test) = 14.82 seconds\n",
      "epoch: 11 average loss: 1.313\n",
      "Test Accuracy : 49.4%, Test Loss: 1.2805649822630236\n",
      "Epoch Time (Training + Test) = 14.89 seconds\n",
      "epoch: 12 average loss: 1.331\n",
      "Test Accuracy : 48.3%, Test Loss: 1.2843359163045274\n",
      "Epoch Time (Training + Test) = 15.35 seconds\n",
      "epoch: 13 average loss: 1.326\n",
      "Test Accuracy : 47.1%, Test Loss: 1.3085144008212077\n",
      "Epoch Time (Training + Test) = 15.25 seconds\n",
      "epoch: 14 average loss: 1.321\n",
      "Test Accuracy : 46.7%, Test Loss: 1.3288568791830937\n",
      "Epoch Time (Training + Test) = 15.45 seconds\n",
      "epoch: 15 average loss: 1.329\n",
      "Test Accuracy : 32.5%, Test Loss: 1.3505044657251108\n",
      "Epoch Time (Training + Test) = 15.19 seconds\n",
      "epoch: 16 average loss: 1.318\n",
      "Test Accuracy : 48.9%, Test Loss: 1.3162418530725153\n",
      "Epoch Time (Training + Test) = 14.74 seconds\n",
      "epoch: 17 average loss: 1.311\n",
      "Test Accuracy : 45.9%, Test Loss: 1.2692583598139342\n",
      "Epoch Time (Training + Test) = 14.75 seconds\n",
      "epoch: 18 average loss: 1.297\n",
      "Test Accuracy : 38.7%, Test Loss: 1.3375849684181116\n",
      "Epoch Time (Training + Test) = 14.76 seconds\n",
      "epoch: 19 average loss: 1.288\n",
      "Test Accuracy : 49.4%, Test Loss: 1.3382744580278616\n",
      "Epoch Time (Training + Test) = 14.77 seconds\n",
      "epoch: 20 average loss: 1.284\n",
      "Test Accuracy : 53.4%, Test Loss: 1.2365686087047352\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.79 seconds\n",
      "epoch: 21 average loss: 1.267\n",
      "Test Accuracy : 50.4%, Test Loss: 1.2508022910188836\n",
      "Epoch Time (Training + Test) = 14.69 seconds\n",
      "epoch: 22 average loss: 1.252\n",
      "Test Accuracy : 53.4%, Test Loss: 1.1745806063532525\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.81 seconds\n",
      "epoch: 23 average loss: 1.232\n",
      "Test Accuracy : 56.0%, Test Loss: 1.1957427836440104\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.74 seconds\n",
      "epoch: 24 average loss: 1.230\n",
      "Test Accuracy : 44.3%, Test Loss: 1.307449642349692\n",
      "Epoch Time (Training + Test) = 14.78 seconds\n",
      "epoch: 25 average loss: 1.220\n",
      "Test Accuracy : 33.8%, Test Loss: 1.2443407658115981\n",
      "Epoch Time (Training + Test) = 14.68 seconds\n",
      "epoch: 26 average loss: 1.213\n",
      "Test Accuracy : 43.8%, Test Loss: 1.2239657227340561\n",
      "Epoch Time (Training + Test) = 14.75 seconds\n",
      "epoch: 27 average loss: 1.200\n",
      "Test Accuracy : 42.5%, Test Loss: 1.2754873519053544\n",
      "Epoch Time (Training + Test) = 14.68 seconds\n",
      "epoch: 28 average loss: 1.200\n",
      "Test Accuracy : 57.3%, Test Loss: 1.1320164039006928\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.78 seconds\n",
      "epoch: 29 average loss: 1.197\n",
      "Test Accuracy : 45.2%, Test Loss: 1.261566171255868\n",
      "Epoch Time (Training + Test) = 14.68 seconds\n",
      "epoch: 30 average loss: 1.201\n",
      "Test Accuracy : 43.9%, Test Loss: 1.2432845791282556\n",
      "Epoch Time (Training + Test) = 14.73 seconds\n",
      "epoch: 31 average loss: 1.238\n",
      "Test Accuracy : 52.7%, Test Loss: 1.2077348188061239\n",
      "Epoch Time (Training + Test) = 14.94 seconds\n",
      "epoch: 32 average loss: 1.192\n",
      "Test Accuracy : 44.4%, Test Loss: 1.2251121839294044\n",
      "Epoch Time (Training + Test) = 14.94 seconds\n",
      "epoch: 33 average loss: 1.204\n",
      "Test Accuracy : 55.5%, Test Loss: 1.1287787170971142\n",
      "Epoch Time (Training + Test) = 15.00 seconds\n",
      "epoch: 34 average loss: 1.194\n",
      "Test Accuracy : 57.8%, Test Loss: 1.115112645394357\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.06 seconds\n",
      "epoch: 35 average loss: 1.197\n",
      "Test Accuracy : 44.2%, Test Loss: 1.2435679136944549\n",
      "Epoch Time (Training + Test) = 14.95 seconds\n",
      "epoch: 36 average loss: 1.189\n",
      "Test Accuracy : 56.2%, Test Loss: 1.1554206158498974\n",
      "Epoch Time (Training + Test) = 15.02 seconds\n",
      "epoch: 37 average loss: 1.183\n",
      "Test Accuracy : 56.9%, Test Loss: 1.144440387063624\n",
      "Epoch Time (Training + Test) = 14.86 seconds\n",
      "epoch: 38 average loss: 1.179\n",
      "Test Accuracy : 56.3%, Test Loss: 1.1257927007687367\n",
      "Epoch Time (Training + Test) = 15.62 seconds\n",
      "epoch: 39 average loss: 1.170\n",
      "Test Accuracy : 56.3%, Test Loss: 1.093657887652707\n",
      "Epoch Time (Training + Test) = 15.68 seconds\n",
      "epoch: 40 average loss: 1.158\n",
      "Test Accuracy : 53.4%, Test Loss: 1.1818087855568322\n",
      "Epoch Time (Training + Test) = 15.44 seconds\n",
      "epoch: 41 average loss: 1.156\n",
      "Test Accuracy : 57.0%, Test Loss: 1.121621397450147\n",
      "Epoch Time (Training + Test) = 15.44 seconds\n",
      "epoch: 42 average loss: 1.147\n",
      "Test Accuracy : 58.5%, Test Loss: 1.0812045055277206\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.51 seconds\n",
      "epoch: 43 average loss: 1.135\n",
      "Test Accuracy : 58.3%, Test Loss: 1.086877083839358\n",
      "Epoch Time (Training + Test) = 15.74 seconds\n",
      "epoch: 44 average loss: 1.127\n",
      "Test Accuracy : 59.4%, Test Loss: 1.0598403104125995\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.48 seconds\n",
      "epoch: 45 average loss: 1.112\n",
      "Test Accuracy : 59.0%, Test Loss: 1.0525294699327414\n",
      "Epoch Time (Training + Test) = 15.53 seconds\n",
      "epoch: 46 average loss: 1.114\n",
      "Test Accuracy : 60.3%, Test Loss: 1.0955405485294665\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.57 seconds\n",
      "epoch: 47 average loss: 1.105\n",
      "Test Accuracy : 59.1%, Test Loss: 1.0383212642596507\n",
      "Epoch Time (Training + Test) = 15.63 seconds\n",
      "epoch: 48 average loss: 1.106\n",
      "Test Accuracy : 57.0%, Test Loss: 1.0606503346387077\n",
      "Epoch Time (Training + Test) = 15.48 seconds\n",
      "epoch: 49 average loss: 1.100\n",
      "Test Accuracy : 49.6%, Test Loss: 1.1363782702809404\n",
      "Epoch Time (Training + Test) = 15.43 seconds\n",
      "epoch: 50 average loss: 1.105\n",
      "Test Accuracy : 48.9%, Test Loss: 1.1479371700750287\n",
      "Epoch Time (Training + Test) = 15.45 seconds\n",
      "epoch: 51 average loss: 1.180\n",
      "Test Accuracy : 39.2%, Test Loss: 1.1366295663597028\n",
      "Epoch Time (Training + Test) = 15.80 seconds\n",
      "epoch: 52 average loss: 1.092\n",
      "Test Accuracy : 48.7%, Test Loss: 1.1053689424034274\n",
      "Epoch Time (Training + Test) = 15.66 seconds\n",
      "epoch: 53 average loss: 1.103\n",
      "Test Accuracy : 48.7%, Test Loss: 1.1310610196474569\n",
      "Epoch Time (Training + Test) = 15.45 seconds\n",
      "epoch: 54 average loss: 1.096\n",
      "Test Accuracy : 59.7%, Test Loss: 1.0312156178762235\n",
      "Epoch Time (Training + Test) = 15.55 seconds\n",
      "epoch: 55 average loss: 1.103\n",
      "Test Accuracy : 59.1%, Test Loss: 1.0542131520598137\n",
      "Epoch Time (Training + Test) = 15.60 seconds\n",
      "epoch: 56 average loss: 1.103\n",
      "Test Accuracy : 60.6%, Test Loss: 1.047096398785291\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.75 seconds\n",
      "epoch: 57 average loss: 1.097\n",
      "Test Accuracy : 57.1%, Test Loss: 1.1397205883889552\n",
      "Epoch Time (Training + Test) = 15.71 seconds\n",
      "epoch: 58 average loss: 1.092\n",
      "Test Accuracy : 61.1%, Test Loss: 1.013240690883773\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.35 seconds\n",
      "epoch: 59 average loss: 1.083\n",
      "Test Accuracy : 54.9%, Test Loss: 1.061883234154538\n",
      "Epoch Time (Training + Test) = 15.35 seconds\n",
      "epoch: 60 average loss: 1.077\n",
      "Test Accuracy : 58.0%, Test Loss: 1.0680635373305787\n",
      "Epoch Time (Training + Test) = 15.25 seconds\n",
      "epoch: 61 average loss: 1.066\n",
      "Test Accuracy : 59.4%, Test Loss: 1.0461061689859765\n",
      "Epoch Time (Training + Test) = 15.25 seconds\n",
      "epoch: 62 average loss: 1.069\n",
      "Test Accuracy : 60.7%, Test Loss: 1.0067849125703583\n",
      "Epoch Time (Training + Test) = 15.23 seconds\n",
      "epoch: 63 average loss: 1.062\n",
      "Test Accuracy : 58.9%, Test Loss: 1.039356152724732\n",
      "Epoch Time (Training + Test) = 15.27 seconds\n",
      "epoch: 64 average loss: 1.054\n",
      "Test Accuracy : 61.3%, Test Loss: 0.9914421309595522\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.30 seconds\n",
      "epoch: 65 average loss: 1.049\n",
      "Test Accuracy : 59.6%, Test Loss: 1.004590855839917\n",
      "Epoch Time (Training + Test) = 15.25 seconds\n",
      "epoch: 66 average loss: 1.047\n",
      "Test Accuracy : 61.0%, Test Loss: 1.0041253341128453\n",
      "Epoch Time (Training + Test) = 15.23 seconds\n",
      "epoch: 67 average loss: 1.036\n",
      "Test Accuracy : 63.7%, Test Loss: 1.0105019312380525\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.26 seconds\n",
      "epoch: 68 average loss: 1.033\n",
      "Test Accuracy : 61.0%, Test Loss: 0.9916250874929111\n",
      "Epoch Time (Training + Test) = 15.25 seconds\n",
      "epoch: 69 average loss: 1.041\n",
      "Test Accuracy : 51.2%, Test Loss: 1.0450746688391546\n",
      "Epoch Time (Training + Test) = 15.21 seconds\n",
      "epoch: 70 average loss: 1.038\n",
      "Test Accuracy : 61.5%, Test Loss: 0.9751311093949906\n",
      "Epoch Time (Training + Test) = 15.21 seconds\n",
      "epoch: 71 average loss: 1.035\n",
      "Test Accuracy : 60.0%, Test Loss: 0.9747942670836778\n",
      "Epoch Time (Training + Test) = 15.20 seconds\n",
      "epoch: 72 average loss: 1.030\n",
      "Test Accuracy : 62.6%, Test Loss: 0.9703847300975829\n",
      "Epoch Time (Training + Test) = 15.23 seconds\n",
      "epoch: 73 average loss: 1.032\n",
      "Test Accuracy : 63.0%, Test Loss: 0.9706455524010427\n",
      "Epoch Time (Training + Test) = 15.19 seconds\n",
      "epoch: 74 average loss: 1.039\n",
      "Test Accuracy : 62.9%, Test Loss: 0.9698523391238258\n",
      "Epoch Time (Training + Test) = 15.20 seconds\n",
      "epoch: 75 average loss: 1.038\n",
      "Test Accuracy : 61.4%, Test Loss: 0.9617864680107292\n",
      "Epoch Time (Training + Test) = 15.25 seconds\n",
      "epoch: 76 average loss: 1.038\n",
      "Test Accuracy : 62.5%, Test Loss: 0.9728368055789977\n",
      "Epoch Time (Training + Test) = 15.19 seconds\n",
      "epoch: 77 average loss: 1.033\n",
      "Test Accuracy : 61.1%, Test Loss: 0.9985026842188043\n",
      "Epoch Time (Training + Test) = 15.21 seconds\n",
      "epoch: 78 average loss: 1.037\n",
      "Test Accuracy : 64.5%, Test Loss: 0.96997703539441\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.23 seconds\n",
      "epoch: 79 average loss: 1.029\n",
      "Test Accuracy : 52.6%, Test Loss: 1.0432589552591525\n",
      "Epoch Time (Training + Test) = 15.23 seconds\n",
      "epoch: 80 average loss: 1.023\n",
      "Test Accuracy : 63.6%, Test Loss: 1.0463295603347251\n",
      "Epoch Time (Training + Test) = 15.23 seconds\n",
      "epoch: 81 average loss: 1.026\n",
      "Test Accuracy : 47.8%, Test Loss: 1.0938477292085242\n",
      "Epoch Time (Training + Test) = 15.20 seconds\n",
      "epoch: 82 average loss: 1.023\n",
      "Test Accuracy : 63.7%, Test Loss: 0.9523825229281355\n",
      "Epoch Time (Training + Test) = 15.21 seconds\n",
      "epoch: 83 average loss: 1.016\n",
      "Test Accuracy : 64.3%, Test Loss: 0.9470018018846926\n",
      "Epoch Time (Training + Test) = 15.23 seconds\n",
      "epoch: 84 average loss: 1.015\n",
      "Test Accuracy : 61.8%, Test Loss: 0.9555392118975939\n",
      "Epoch Time (Training + Test) = 15.35 seconds\n",
      "epoch: 85 average loss: 1.018\n",
      "Test Accuracy : 64.0%, Test Loss: 0.9611105966141157\n",
      "Epoch Time (Training + Test) = 15.21 seconds\n",
      "epoch: 86 average loss: 1.008\n",
      "Test Accuracy : 51.6%, Test Loss: 1.0090853167921685\n",
      "Epoch Time (Training + Test) = 15.25 seconds\n",
      "epoch: 87 average loss: 1.012\n",
      "Test Accuracy : 59.9%, Test Loss: 0.9808443583490903\n",
      "Epoch Time (Training + Test) = 15.21 seconds\n",
      "epoch: 88 average loss: 1.005\n",
      "Test Accuracy : 63.9%, Test Loss: 0.9468096887973874\n",
      "Epoch Time (Training + Test) = 15.22 seconds\n",
      "epoch: 89 average loss: 1.004\n",
      "Test Accuracy : 60.4%, Test Loss: 0.967600470461199\n",
      "Epoch Time (Training + Test) = 15.22 seconds\n",
      "epoch: 90 average loss: 0.992\n",
      "Test Accuracy : 51.5%, Test Loss: 1.0450412670669653\n",
      "Epoch Time (Training + Test) = 15.23 seconds\n",
      "epoch: 91 average loss: 1.007\n",
      "Test Accuracy : 65.2%, Test Loss: 0.938282079251526\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.22 seconds\n",
      "epoch: 92 average loss: 1.008\n",
      "Test Accuracy : 50.0%, Test Loss: 1.0126067778033674\n",
      "Epoch Time (Training + Test) = 15.20 seconds\n",
      "epoch: 93 average loss: 1.004\n",
      "Test Accuracy : 64.4%, Test Loss: 0.9554869087455827\n",
      "Epoch Time (Training + Test) = 15.21 seconds\n",
      "epoch: 94 average loss: 1.009\n",
      "Test Accuracy : 64.6%, Test Loss: 0.966920393507194\n",
      "Epoch Time (Training + Test) = 15.22 seconds\n",
      "epoch: 95 average loss: 0.995\n",
      "Test Accuracy : 64.3%, Test Loss: 0.9487793585833382\n",
      "Epoch Time (Training + Test) = 15.21 seconds\n",
      "epoch: 96 average loss: 0.999\n",
      "Test Accuracy : 64.4%, Test Loss: 0.9259780651468146\n",
      "Epoch Time (Training + Test) = 15.24 seconds\n",
      "epoch: 97 average loss: 1.006\n",
      "Test Accuracy : 63.0%, Test Loss: 0.9297169564325182\n",
      "Epoch Time (Training + Test) = 15.23 seconds\n",
      "epoch: 98 average loss: 1.003\n",
      "Test Accuracy : 63.4%, Test Loss: 0.9975245280948746\n",
      "Epoch Time (Training + Test) = 15.22 seconds\n",
      "epoch: 99 average loss: 1.003\n",
      "Test Accuracy : 62.4%, Test Loss: 0.943348789916319\n",
      "Epoch Time (Training + Test) = 15.21 seconds\n",
      "epoch: 100 average loss: 0.998\n",
      "Test Accuracy : 65.4%, Test Loss: 0.9439454560389604\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.25 seconds\n",
      "Data Saved to adp_layer3_adp_only.csv\n",
      "Finished Training: \n",
      "Total Time 0.843603 hours\n",
      " Average Time Per Epoch 30.37 seconds\n",
      "full_ft layer3 320\n",
      "Scheduler Set {'T_max': 10, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:126k0wfi) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch time (s)</td><td>▁▃▅▅▃▆▅▂▃▂▂▃▂▄▄▇▆█▇▆█▆█▆▅▅▅▅▅▅▅▅▅▆▅▅▅▅▅▅</td></tr><tr><td>lr</td><td>█▇▅▂▁▂▅▇█▇▅▂▁▂▅▇█▇▃▂▁▂▆▇█▆▃▁▁▃▆█▇▆▂▁▂▃▇█</td></tr><tr><td>test_accuracy</td><td>▁▄▃▄▆▅▃▅▆▇▃▇▅▆▅▇▇▇▇▇▄▅▇▇▇▇▇▆▇██▆█▇▇▇▆███</td></tr><tr><td>test_loss</td><td>█▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.6544</td></tr><tr><td>Total Time (hours)</td><td>0.8436</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>15.25286</td></tr><tr><td>lr</td><td>0.1</td></tr><tr><td>test_accuracy</td><td>0.6544</td></tr><tr><td>test_loss</td><td>0.94395</td></tr><tr><td>training_loss</td><td>0.99839</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">young-fog-26</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/126k0wfi\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar5/runs/126k0wfi</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221022_004053-126k0wfi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:126k0wfi). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df0ea84dada489a8907abd3183daa8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221022_010640-bx11wfmt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/bx11wfmt\" target=\"_blank\">astral-grass-27</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name adp_layer3_full_ft \n",
      "\n",
      "\n",
      "Run Start : 2022-10-22 01-06-40\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4440095\n",
      "Initial accuracy:\n",
      "Test Accuracy : 20.0%, Test Loss: 2.5574629739727204\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 20.0%, Test Loss: 2.562192482716592\n",
      "epoch: 1 average loss: 1.513\n",
      "Test Accuracy : 42.5%, Test Loss: 1.2526966662663024\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.63 seconds\n",
      "epoch: 2 average loss: 1.219\n",
      "Test Accuracy : 51.4%, Test Loss: 1.1087592250245917\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.72 seconds\n",
      "epoch: 3 average loss: 1.090\n",
      "Test Accuracy : 44.4%, Test Loss: 1.098175029315607\n",
      "Epoch Time (Training + Test) = 26.60 seconds\n",
      "epoch: 4 average loss: 1.089\n",
      "Test Accuracy : 46.2%, Test Loss: 1.0849037042359257\n",
      "Epoch Time (Training + Test) = 26.72 seconds\n",
      "epoch: 5 average loss: 1.081\n",
      "Test Accuracy : 52.2%, Test Loss: 1.0363276890476647\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.67 seconds\n",
      "epoch: 6 average loss: 1.027\n",
      "Test Accuracy : 62.3%, Test Loss: 0.9543396943365522\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.73 seconds\n",
      "epoch: 7 average loss: 0.983\n",
      "Test Accuracy : 63.9%, Test Loss: 0.9206819342225409\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.70 seconds\n",
      "epoch: 8 average loss: 0.974\n",
      "Test Accuracy : 60.9%, Test Loss: 0.9241350300781562\n",
      "Epoch Time (Training + Test) = 26.76 seconds\n",
      "epoch: 9 average loss: 0.968\n",
      "Test Accuracy : 60.4%, Test Loss: 0.9389167521006007\n",
      "Epoch Time (Training + Test) = 26.77 seconds\n",
      "epoch: 10 average loss: 0.968\n",
      "Test Accuracy : 63.5%, Test Loss: 0.9196664549200736\n",
      "Epoch Time (Training + Test) = 26.18 seconds\n",
      "epoch: 11 average loss: 0.962\n",
      "Test Accuracy : 63.0%, Test Loss: 0.9101318749015593\n",
      "Epoch Time (Training + Test) = 26.31 seconds\n",
      "epoch: 12 average loss: 0.967\n",
      "Test Accuracy : 60.3%, Test Loss: 0.9387718990940572\n",
      "Epoch Time (Training + Test) = 26.22 seconds\n",
      "epoch: 13 average loss: 0.964\n",
      "Test Accuracy : 61.8%, Test Loss: 0.9206645642704976\n",
      "Epoch Time (Training + Test) = 26.30 seconds\n",
      "epoch: 14 average loss: 0.964\n",
      "Test Accuracy : 60.2%, Test Loss: 0.9366159884216231\n",
      "Epoch Time (Training + Test) = 26.24 seconds\n",
      "epoch: 15 average loss: 0.969\n",
      "Test Accuracy : 62.4%, Test Loss: 0.94686020624912\n",
      "Epoch Time (Training + Test) = 26.28 seconds\n",
      "epoch: 16 average loss: 0.980\n",
      "Test Accuracy : 61.3%, Test Loss: 0.9700412558167791\n",
      "Epoch Time (Training + Test) = 26.29 seconds\n",
      "epoch: 17 average loss: 0.984\n",
      "Test Accuracy : 62.8%, Test Loss: 0.9593224063553774\n",
      "Epoch Time (Training + Test) = 26.25 seconds\n",
      "epoch: 18 average loss: 0.956\n",
      "Test Accuracy : 65.1%, Test Loss: 0.9135306303763329\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.36 seconds\n",
      "epoch: 19 average loss: 0.926\n",
      "Test Accuracy : 62.3%, Test Loss: 0.909515493208795\n",
      "Epoch Time (Training + Test) = 26.31 seconds\n",
      "epoch: 20 average loss: 0.919\n",
      "Test Accuracy : 61.5%, Test Loss: 0.9186319141741603\n",
      "Epoch Time (Training + Test) = 26.34 seconds\n",
      "epoch: 21 average loss: 0.896\n",
      "Test Accuracy : 66.3%, Test Loss: 0.8180780738515927\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.33 seconds\n",
      "epoch: 22 average loss: 0.880\n",
      "Test Accuracy : 62.4%, Test Loss: 0.9320913338295335\n",
      "Epoch Time (Training + Test) = 26.36 seconds\n",
      "epoch: 23 average loss: 0.873\n",
      "Test Accuracy : 67.4%, Test Loss: 0.812900578731771\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.32 seconds\n",
      "epoch: 24 average loss: 0.840\n",
      "Test Accuracy : 65.0%, Test Loss: 0.8827231380030932\n",
      "Epoch Time (Training + Test) = 26.35 seconds\n",
      "epoch: 25 average loss: 0.820\n",
      "Test Accuracy : 71.9%, Test Loss: 0.7808649494215045\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.37 seconds\n",
      "epoch: 26 average loss: 0.801\n",
      "Test Accuracy : 72.4%, Test Loss: 0.7663955062704013\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.34 seconds\n",
      "epoch: 27 average loss: 0.786\n",
      "Test Accuracy : 69.9%, Test Loss: 0.8080688498514083\n",
      "Epoch Time (Training + Test) = 26.35 seconds\n",
      "epoch: 28 average loss: 0.779\n",
      "Test Accuracy : 73.0%, Test Loss: 0.8269993773354288\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.34 seconds\n",
      "epoch: 29 average loss: 0.773\n",
      "Test Accuracy : 72.7%, Test Loss: 0.74845852647596\n",
      "Epoch Time (Training + Test) = 26.34 seconds\n",
      "epoch: 30 average loss: 0.764\n",
      "Test Accuracy : 73.1%, Test Loss: 0.7321461123578689\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.32 seconds\n",
      "epoch: 31 average loss: 0.773\n",
      "Test Accuracy : 75.7%, Test Loss: 0.6946532463326174\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.30 seconds\n",
      "epoch: 32 average loss: 0.765\n",
      "Test Accuracy : 72.3%, Test Loss: 0.7450294262155548\n",
      "Epoch Time (Training + Test) = 26.30 seconds\n",
      "epoch: 33 average loss: 0.782\n",
      "Test Accuracy : 68.6%, Test Loss: 0.8205881534939836\n",
      "Epoch Time (Training + Test) = 26.28 seconds\n",
      "epoch: 34 average loss: 0.775\n",
      "Test Accuracy : 71.4%, Test Loss: 0.7998520936197637\n",
      "Epoch Time (Training + Test) = 26.33 seconds\n",
      "epoch: 35 average loss: 0.769\n",
      "Test Accuracy : 74.0%, Test Loss: 0.7156446281906284\n",
      "Epoch Time (Training + Test) = 26.33 seconds\n",
      "epoch: 36 average loss: 0.765\n",
      "Test Accuracy : 69.4%, Test Loss: 0.7585892456266886\n",
      "Epoch Time (Training + Test) = 26.31 seconds\n",
      "epoch: 37 average loss: 0.760\n",
      "Test Accuracy : 68.4%, Test Loss: 0.9218080769414487\n",
      "Epoch Time (Training + Test) = 26.29 seconds\n",
      "epoch: 38 average loss: 0.750\n",
      "Test Accuracy : 70.5%, Test Loss: 0.8242709565802914\n",
      "Epoch Time (Training + Test) = 26.38 seconds\n",
      "epoch: 39 average loss: 0.740\n",
      "Test Accuracy : 68.5%, Test Loss: 0.7883651600316968\n",
      "Epoch Time (Training + Test) = 26.31 seconds\n",
      "epoch: 40 average loss: 0.739\n",
      "Test Accuracy : 60.5%, Test Loss: 1.110899572939519\n",
      "Epoch Time (Training + Test) = 26.35 seconds\n",
      "epoch: 41 average loss: 0.725\n",
      "Test Accuracy : 75.2%, Test Loss: 0.6930860543952269\n",
      "Epoch Time (Training + Test) = 26.38 seconds\n",
      "epoch: 42 average loss: 0.728\n",
      "Test Accuracy : 71.3%, Test Loss: 0.8403784122765826\n",
      "Epoch Time (Training + Test) = 26.24 seconds\n",
      "epoch: 43 average loss: 0.718\n",
      "Test Accuracy : 70.0%, Test Loss: 0.8817110962575049\n",
      "Epoch Time (Training + Test) = 26.35 seconds\n",
      "epoch: 44 average loss: 0.710\n",
      "Test Accuracy : 68.0%, Test Loss: 0.9828404387854555\n",
      "Epoch Time (Training + Test) = 26.30 seconds\n",
      "epoch: 45 average loss: 0.704\n",
      "Test Accuracy : 66.9%, Test Loss: 0.9026295969553311\n",
      "Epoch Time (Training + Test) = 26.36 seconds\n",
      "epoch: 46 average loss: 0.689\n",
      "Test Accuracy : 75.9%, Test Loss: 0.6961977161714793\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.35 seconds\n",
      "epoch: 47 average loss: 0.680\n",
      "Test Accuracy : 55.8%, Test Loss: 1.1634108113205952\n",
      "Epoch Time (Training + Test) = 26.34 seconds\n",
      "epoch: 48 average loss: 0.676\n",
      "Test Accuracy : 76.0%, Test Loss: 0.6739137040074828\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.39 seconds\n",
      "epoch: 49 average loss: 0.665\n",
      "Test Accuracy : 78.6%, Test Loss: 0.6456720170462528\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.32 seconds\n",
      "epoch: 50 average loss: 0.667\n",
      "Test Accuracy : 72.6%, Test Loss: 0.7820355813674\n",
      "Epoch Time (Training + Test) = 26.32 seconds\n",
      "epoch: 51 average loss: 0.673\n",
      "Test Accuracy : 79.1%, Test Loss: 0.6272541761703199\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.29 seconds\n",
      "epoch: 52 average loss: 0.668\n",
      "Test Accuracy : 77.5%, Test Loss: 0.6409533092432924\n",
      "Epoch Time (Training + Test) = 26.32 seconds\n",
      "epoch: 53 average loss: 0.675\n",
      "Test Accuracy : 78.8%, Test Loss: 0.6141362478361105\n",
      "Epoch Time (Training + Test) = 26.26 seconds\n",
      "epoch: 54 average loss: 0.674\n",
      "Test Accuracy : 67.4%, Test Loss: 0.8681998221618136\n",
      "Epoch Time (Training + Test) = 26.28 seconds\n",
      "epoch: 55 average loss: 0.680\n",
      "Test Accuracy : 77.5%, Test Loss: 0.6660208901785829\n",
      "Epoch Time (Training + Test) = 26.30 seconds\n",
      "epoch: 56 average loss: 0.680\n",
      "Test Accuracy : 72.3%, Test Loss: 0.8277290464209779\n",
      "Epoch Time (Training + Test) = 26.28 seconds\n",
      "epoch: 57 average loss: 0.681\n",
      "Test Accuracy : 73.4%, Test Loss: 0.7462018911186081\n",
      "Epoch Time (Training + Test) = 26.31 seconds\n",
      "epoch: 58 average loss: 0.677\n",
      "Test Accuracy : 71.2%, Test Loss: 0.7868104268370382\n",
      "Epoch Time (Training + Test) = 26.33 seconds\n",
      "epoch: 59 average loss: 0.678\n",
      "Test Accuracy : 69.9%, Test Loss: 0.8362633482269619\n",
      "Epoch Time (Training + Test) = 26.27 seconds\n",
      "epoch: 60 average loss: 0.677\n",
      "Test Accuracy : 72.0%, Test Loss: 0.8264304763825653\n",
      "Epoch Time (Training + Test) = 26.27 seconds\n",
      "epoch: 61 average loss: 0.671\n",
      "Test Accuracy : 70.5%, Test Loss: 0.8138480849583131\n",
      "Epoch Time (Training + Test) = 26.30 seconds\n",
      "epoch: 62 average loss: 0.666\n",
      "Test Accuracy : 76.0%, Test Loss: 0.6777713510691358\n",
      "Epoch Time (Training + Test) = 26.25 seconds\n",
      "epoch: 63 average loss: 0.670\n",
      "Test Accuracy : 76.3%, Test Loss: 0.6851670489744153\n",
      "Epoch Time (Training + Test) = 26.29 seconds\n",
      "epoch: 64 average loss: 0.659\n",
      "Test Accuracy : 73.1%, Test Loss: 0.7343570678435323\n",
      "Epoch Time (Training + Test) = 26.35 seconds\n",
      "epoch: 65 average loss: 0.654\n",
      "Test Accuracy : 65.1%, Test Loss: 1.0538007129183815\n",
      "Epoch Time (Training + Test) = 26.33 seconds\n",
      "epoch: 66 average loss: 0.658\n",
      "Test Accuracy : 75.4%, Test Loss: 0.7240743151558634\n",
      "Epoch Time (Training + Test) = 26.30 seconds\n",
      "epoch: 67 average loss: 0.649\n",
      "Test Accuracy : 73.1%, Test Loss: 0.7849497326347225\n",
      "Epoch Time (Training + Test) = 26.31 seconds\n",
      "epoch: 68 average loss: 0.635\n",
      "Test Accuracy : 76.7%, Test Loss: 0.6854007513169438\n",
      "Epoch Time (Training + Test) = 26.39 seconds\n",
      "epoch: 69 average loss: 0.636\n",
      "Test Accuracy : 71.1%, Test Loss: 0.7851708990228755\n",
      "Epoch Time (Training + Test) = 26.31 seconds\n",
      "epoch: 70 average loss: 0.627\n",
      "Test Accuracy : 78.1%, Test Loss: 0.6144235037324374\n",
      "Epoch Time (Training + Test) = 26.36 seconds\n",
      "epoch: 71 average loss: 0.610\n",
      "Test Accuracy : 81.0%, Test Loss: 0.5538135855399129\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.39 seconds\n",
      "epoch: 72 average loss: 0.629\n",
      "Test Accuracy : 79.6%, Test Loss: 0.6017937277589003\n",
      "Epoch Time (Training + Test) = 26.27 seconds\n",
      "epoch: 73 average loss: 0.634\n",
      "Test Accuracy : 79.3%, Test Loss: 0.5986098182933105\n",
      "Epoch Time (Training + Test) = 26.30 seconds\n",
      "epoch: 74 average loss: 0.638\n",
      "Test Accuracy : 76.0%, Test Loss: 0.6581314112371801\n",
      "Epoch Time (Training + Test) = 26.25 seconds\n",
      "epoch: 75 average loss: 0.654\n",
      "Test Accuracy : 71.6%, Test Loss: 0.7827858661904055\n",
      "Epoch Time (Training + Test) = 26.29 seconds\n",
      "epoch: 76 average loss: 0.651\n",
      "Test Accuracy : 59.7%, Test Loss: 1.1558285908930748\n",
      "Epoch Time (Training + Test) = 26.27 seconds\n",
      "epoch: 77 average loss: 0.642\n",
      "Test Accuracy : 69.1%, Test Loss: 0.8797285014101307\n",
      "Epoch Time (Training + Test) = 26.29 seconds\n",
      "epoch: 78 average loss: 0.646\n",
      "Test Accuracy : 67.8%, Test Loss: 0.8737193452732642\n",
      "Epoch Time (Training + Test) = 26.25 seconds\n",
      "epoch: 79 average loss: 0.650\n",
      "Test Accuracy : 70.4%, Test Loss: 0.8498016739897716\n",
      "Epoch Time (Training + Test) = 26.29 seconds\n",
      "epoch: 80 average loss: 0.645\n",
      "Test Accuracy : 70.0%, Test Loss: 0.9016223923324624\n",
      "Epoch Time (Training + Test) = 26.30 seconds\n",
      "epoch: 81 average loss: 0.644\n",
      "Test Accuracy : 74.4%, Test Loss: 0.7329089455592358\n",
      "Epoch Time (Training + Test) = 26.28 seconds\n",
      "epoch: 82 average loss: 0.642\n",
      "Test Accuracy : 77.7%, Test Loss: 0.626373947200263\n",
      "Epoch Time (Training + Test) = 26.30 seconds\n",
      "epoch: 83 average loss: 0.644\n",
      "Test Accuracy : 74.4%, Test Loss: 0.7440274163432743\n",
      "Epoch Time (Training + Test) = 26.23 seconds\n",
      "epoch: 84 average loss: 0.642\n",
      "Test Accuracy : 77.8%, Test Loss: 0.6243021891397589\n",
      "Epoch Time (Training + Test) = 26.27 seconds\n",
      "epoch: 85 average loss: 0.641\n",
      "Test Accuracy : 73.6%, Test Loss: 0.7413419145909722\n",
      "Epoch Time (Training + Test) = 26.28 seconds\n",
      "epoch: 86 average loss: 0.634\n",
      "Test Accuracy : 74.1%, Test Loss: 0.7188930362844101\n",
      "Epoch Time (Training + Test) = 26.29 seconds\n",
      "epoch: 87 average loss: 0.631\n",
      "Test Accuracy : 75.8%, Test Loss: 0.6784591324951338\n",
      "Epoch Time (Training + Test) = 26.31 seconds\n",
      "epoch: 88 average loss: 0.626\n",
      "Test Accuracy : 76.2%, Test Loss: 0.6728404024830255\n",
      "Epoch Time (Training + Test) = 26.23 seconds\n",
      "epoch: 89 average loss: 0.621\n",
      "Test Accuracy : 68.1%, Test Loss: 0.8906417704756607\n",
      "Epoch Time (Training + Test) = 26.29 seconds\n",
      "epoch: 90 average loss: 0.615\n",
      "Test Accuracy : 77.3%, Test Loss: 0.6416096829849741\n",
      "Epoch Time (Training + Test) = 26.28 seconds\n",
      "epoch: 91 average loss: 0.618\n",
      "Test Accuracy : 80.0%, Test Loss: 0.568358476661965\n",
      "Epoch Time (Training + Test) = 26.27 seconds\n",
      "epoch: 92 average loss: 0.620\n",
      "Test Accuracy : 75.0%, Test Loss: 0.6938126411889215\n",
      "Epoch Time (Training + Test) = 26.25 seconds\n",
      "epoch: 93 average loss: 0.628\n",
      "Test Accuracy : 76.0%, Test Loss: 0.6314985535638716\n",
      "Epoch Time (Training + Test) = 26.28 seconds\n",
      "epoch: 94 average loss: 0.645\n",
      "Test Accuracy : 75.4%, Test Loss: 0.6653017212667733\n",
      "Epoch Time (Training + Test) = 26.28 seconds\n",
      "epoch: 95 average loss: 0.631\n",
      "Test Accuracy : 73.3%, Test Loss: 0.7678834814244829\n",
      "Epoch Time (Training + Test) = 26.23 seconds\n",
      "epoch: 96 average loss: 0.645\n",
      "Test Accuracy : 48.3%, Test Loss: 1.5301023270467968\n",
      "Epoch Time (Training + Test) = 26.28 seconds\n",
      "epoch: 97 average loss: 0.645\n",
      "Test Accuracy : 56.9%, Test Loss: 1.2035588358369325\n",
      "Epoch Time (Training + Test) = 26.25 seconds\n",
      "epoch: 98 average loss: 0.639\n",
      "Test Accuracy : 70.0%, Test Loss: 0.809996211925126\n",
      "Epoch Time (Training + Test) = 26.27 seconds\n",
      "epoch: 99 average loss: 0.637\n",
      "Test Accuracy : 63.9%, Test Loss: 1.117649784478385\n",
      "Epoch Time (Training + Test) = 26.25 seconds\n",
      "epoch: 100 average loss: 0.640\n",
      "Test Accuracy : 65.0%, Test Loss: 1.0363589990931703\n",
      "Epoch Time (Training + Test) = 26.27 seconds\n",
      "Data Saved to adp_layer3_full_ft.csv\n",
      "Finished Training: \n",
      "Total Time 1.463164 hours\n",
      " Average Time Per Epoch 52.67 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "PATH = '.\\SavedModels\\Cifar5\\Baseline_BNN_Resnet18_2022_10_21_10_47_20\\Baseline_BNN_Resnet18_best_acc.pth'\n",
    "BinCifar5_state_dict = torch.load(PATH,map_location= device)\n",
    "\n",
    "\n",
    "layers = ['layer1','layer2','layer3']\n",
    "channels = [80,160,320]\n",
    "\n",
    "\n",
    "for layer,channel in zip(layers,channels):\n",
    "    for t in ['adp_only','full_ft']:\n",
    "        print(t,layer,channel)\n",
    "        torch.manual_seed(42)\n",
    "        adapter_model = resnet18_adapt(num_classes=5)\n",
    "        adapter_model.load_state_dict(BinCifar5_state_dict)\n",
    "        \n",
    "        if t == 'adp_only':\n",
    "            adapter_model.freeze()\n",
    "        conv_adp = conv_adapter(channel,kernel = 1, padding= 0)\n",
    "        adapter_model.add_adapter(after = layer,adapter = conv_adp)\n",
    "        trainer = adapter_Trainer(model = adapter_model,seed = 123,model_name = f'adp_{layer}_{t}',project_name = 'Cifar5',classes = classes,binarise= True)\n",
    "        m = trainer.model\n",
    "        m.to(trainer.device)\n",
    "        for head in [m.fc,m.bn3,m.bn3]:\n",
    "            for p in head.parameters():\n",
    "                p.requires_grad = True\n",
    "            head.train()\n",
    "        trainer.lr = 0.01\n",
    "        trainer.batch_size = 32\n",
    "        trainer.epochs =100\n",
    "        trainer.epoch_chkpts = []\n",
    "        trainer.start_epoch = 0\n",
    "        # trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max= trainer.epochs)\n",
    "        trainer.tags = ['finetune',f'Training: {t}',f'Adpater Location {layer}']\n",
    "        trainer.train(train59_loader,test59_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0252f580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.1048, -10.0902, -42.1078,  -0.1369,  -2.0739]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = resnet18_adapt(num_classes=5)\n",
    "\n",
    "b.eval()\n",
    "x = torch.rand((1,3,32,32))\n",
    "\n",
    "b(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1600d878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): BinarizeConv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (tanh1): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "    (conv2): BinarizeConv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (tanh2): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "    (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): BinarizeConv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (tanh1): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "    (conv2): BinarizeConv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (tanh2): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "    (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.layer1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73a11b",
   "metadata": {},
   "source": [
    "# Adapters with init at zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8600fe1d",
   "metadata": {},
   "source": [
    "## Adp Only Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa69764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adp_only layer1 80\n",
      "Scheduler Set {'T_max': 10, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnny_suu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221022_110038-3050ff43</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/3050ff43\" target=\"_blank\">dazzling-snow-28</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name adp_layer1_adp_only \n",
      "\n",
      "\n",
      "Run Start : 2022-10-22 11-00-36\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4343135\n",
      "Initial accuracy:\n",
      "Test Accuracy : 20.0%, Test Loss: 3.4470722077752622\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 20.0%, Test Loss: 3.447869495967465\n",
      "epoch: 1 average loss: 1.378\n",
      "Test Accuracy : 39.9%, Test Loss: 1.3051697027957654\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.47 seconds\n",
      "epoch: 2 average loss: 1.309\n",
      "Test Accuracy : 39.3%, Test Loss: 1.3000686711362561\n",
      "Epoch Time (Training + Test) = 31.06 seconds\n",
      "epoch: 3 average loss: 1.268\n",
      "Test Accuracy : 44.8%, Test Loss: 1.224191718089306\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.17 seconds\n",
      "epoch: 4 average loss: 1.222\n",
      "Test Accuracy : 46.1%, Test Loss: 1.1897442180787206\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.74 seconds\n",
      "epoch: 5 average loss: 1.205\n",
      "Test Accuracy : 47.8%, Test Loss: 1.1720895934897615\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.47 seconds\n",
      "epoch: 6 average loss: 1.197\n",
      "Test Accuracy : 48.4%, Test Loss: 1.1625485260163426\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.17 seconds\n",
      "epoch: 7 average loss: 1.194\n",
      "Test Accuracy : 47.8%, Test Loss: 1.1724037672857495\n",
      "Epoch Time (Training + Test) = 35.58 seconds\n",
      "epoch: 8 average loss: 1.186\n",
      "Test Accuracy : 47.3%, Test Loss: 1.1632176543135777\n",
      "Epoch Time (Training + Test) = 34.33 seconds\n",
      "epoch: 9 average loss: 1.181\n",
      "Test Accuracy : 48.8%, Test Loss: 1.1621108250239927\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 35.28 seconds\n",
      "epoch: 10 average loss: 1.185\n",
      "Test Accuracy : 48.3%, Test Loss: 1.1604968033483267\n",
      "Epoch Time (Training + Test) = 36.16 seconds\n",
      "epoch: 11 average loss: 1.182\n",
      "Test Accuracy : 48.2%, Test Loss: 1.1639002610350508\n",
      "Epoch Time (Training + Test) = 35.89 seconds\n",
      "epoch: 12 average loss: 1.180\n",
      "Test Accuracy : 48.3%, Test Loss: 1.1621634888527033\n",
      "Epoch Time (Training + Test) = 35.31 seconds\n",
      "epoch: 13 average loss: 1.184\n",
      "Test Accuracy : 48.3%, Test Loss: 1.164474205287826\n",
      "Epoch Time (Training + Test) = 34.87 seconds\n",
      "epoch: 14 average loss: 1.179\n",
      "Test Accuracy : 48.3%, Test Loss: 1.1585034894211519\n",
      "Epoch Time (Training + Test) = 34.75 seconds\n",
      "epoch: 15 average loss: 1.180\n",
      "Test Accuracy : 48.7%, Test Loss: 1.152372045132815\n",
      "Epoch Time (Training + Test) = 35.28 seconds\n",
      "epoch: 16 average loss: 1.182\n",
      "Test Accuracy : 48.7%, Test Loss: 1.1514469981193542\n",
      "Epoch Time (Training + Test) = 36.85 seconds\n",
      "epoch: 17 average loss: 1.176\n",
      "Test Accuracy : 48.6%, Test Loss: 1.1563563064845932\n",
      "Epoch Time (Training + Test) = 37.11 seconds\n",
      "epoch: 18 average loss: 1.170\n",
      "Test Accuracy : 50.4%, Test Loss: 1.1304489304037655\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.17 seconds\n",
      "epoch: 19 average loss: 1.165\n",
      "Test Accuracy : 49.8%, Test Loss: 1.1319959409096663\n",
      "Epoch Time (Training + Test) = 35.85 seconds\n",
      "epoch: 20 average loss: 1.159\n",
      "Test Accuracy : 50.3%, Test Loss: 1.1325491834479524\n",
      "Epoch Time (Training + Test) = 34.59 seconds\n",
      "epoch: 21 average loss: 1.148\n",
      "Test Accuracy : 51.2%, Test Loss: 1.117419907046706\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 34.66 seconds\n",
      "epoch: 22 average loss: 1.148\n",
      "Test Accuracy : 51.4%, Test Loss: 1.1057894592699797\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.67 seconds\n",
      "epoch: 23 average loss: 1.142\n",
      "Test Accuracy : 49.9%, Test Loss: 1.0987255917790602\n",
      "Epoch Time (Training + Test) = 38.31 seconds\n",
      "epoch: 24 average loss: 1.137\n",
      "Test Accuracy : 51.5%, Test Loss: 1.0917830982476548\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.25 seconds\n",
      "epoch: 25 average loss: 1.127\n",
      "Test Accuracy : 52.1%, Test Loss: 1.0856243189033645\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 35.37 seconds\n",
      "epoch: 26 average loss: 1.123\n",
      "Test Accuracy : 52.4%, Test Loss: 1.0820041823265192\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 34.97 seconds\n",
      "epoch: 27 average loss: 1.116\n",
      "Test Accuracy : 52.6%, Test Loss: 1.077662479389659\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 35.31 seconds\n",
      "epoch: 28 average loss: 1.122\n",
      "Test Accuracy : 53.1%, Test Loss: 1.0721346075882388\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 35.74 seconds\n",
      "epoch: 29 average loss: 1.112\n",
      "Test Accuracy : 52.6%, Test Loss: 1.0715165456847462\n",
      "Epoch Time (Training + Test) = 36.72 seconds\n",
      "epoch: 30 average loss: 1.116\n",
      "Test Accuracy : 53.0%, Test Loss: 1.0673993636884958\n",
      "Epoch Time (Training + Test) = 35.87 seconds\n",
      "epoch: 31 average loss: 1.114\n",
      "Test Accuracy : 52.9%, Test Loss: 1.0701955527905613\n",
      "Epoch Time (Training + Test) = 35.94 seconds\n",
      "epoch: 32 average loss: 1.105\n",
      "Test Accuracy : 52.8%, Test Loss: 1.0720624788033077\n",
      "Epoch Time (Training + Test) = 35.58 seconds\n",
      "epoch: 33 average loss: 1.112\n",
      "Test Accuracy : 52.4%, Test Loss: 1.0706912420899666\n",
      "Epoch Time (Training + Test) = 35.09 seconds\n",
      "epoch: 34 average loss: 1.112\n",
      "Test Accuracy : 53.4%, Test Loss: 1.0700922266906485\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.29 seconds\n",
      "epoch: 35 average loss: 1.111\n",
      "Test Accuracy : 53.1%, Test Loss: 1.0710109292393755\n",
      "Epoch Time (Training + Test) = 37.24 seconds\n",
      "epoch: 36 average loss: 1.103\n",
      "Test Accuracy : 52.6%, Test Loss: 1.071581689750447\n",
      "Epoch Time (Training + Test) = 36.45 seconds\n",
      "epoch: 37 average loss: 1.105\n",
      "Test Accuracy : 53.5%, Test Loss: 1.0572299501475166\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 35.78 seconds\n",
      "epoch: 38 average loss: 1.103\n",
      "Test Accuracy : 52.6%, Test Loss: 1.0619443269336926\n",
      "Epoch Time (Training + Test) = 36.41 seconds\n",
      "epoch: 39 average loss: 1.097\n",
      "Test Accuracy : 53.0%, Test Loss: 1.0514972386762613\n",
      "Epoch Time (Training + Test) = 35.57 seconds\n",
      "epoch: 40 average loss: 1.088\n",
      "Test Accuracy : 54.2%, Test Loss: 1.0423584987440377\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.03 seconds\n",
      "epoch: 41 average loss: 1.082\n",
      "Test Accuracy : 54.8%, Test Loss: 1.0421332117846556\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.96 seconds\n",
      "epoch: 42 average loss: 1.078\n",
      "Test Accuracy : 53.9%, Test Loss: 1.0455767198291885\n",
      "Epoch Time (Training + Test) = 37.04 seconds\n",
      "epoch: 43 average loss: 1.072\n",
      "Test Accuracy : 54.6%, Test Loss: 1.035338913540706\n",
      "Epoch Time (Training + Test) = 36.17 seconds\n",
      "epoch: 44 average loss: 1.070\n",
      "Test Accuracy : 54.8%, Test Loss: 1.0311454604653751\n",
      "Epoch Time (Training + Test) = 35.73 seconds\n",
      "epoch: 45 average loss: 1.057\n",
      "Test Accuracy : 54.1%, Test Loss: 1.0396033566626137\n",
      "Epoch Time (Training + Test) = 35.92 seconds\n",
      "epoch: 46 average loss: 1.065\n",
      "Test Accuracy : 55.2%, Test Loss: 1.0245562724750061\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 35.12 seconds\n",
      "epoch: 47 average loss: 1.059\n",
      "Test Accuracy : 55.6%, Test Loss: 1.0270513242772779\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 35.79 seconds\n",
      "epoch: 48 average loss: 1.062\n",
      "Test Accuracy : 54.6%, Test Loss: 1.0278736839209066\n",
      "Epoch Time (Training + Test) = 36.77 seconds\n",
      "epoch: 49 average loss: 1.057\n",
      "Test Accuracy : 52.5%, Test Loss: 1.0653794613640633\n",
      "Epoch Time (Training + Test) = 34.99 seconds\n",
      "epoch: 50 average loss: 1.058\n",
      "Test Accuracy : 55.5%, Test Loss: 1.0190083265609449\n",
      "Epoch Time (Training + Test) = 35.31 seconds\n",
      "epoch: 51 average loss: 1.050\n",
      "Test Accuracy : 55.3%, Test Loss: 1.0207166612300727\n",
      "Epoch Time (Training + Test) = 36.60 seconds\n",
      "epoch: 52 average loss: 1.049\n",
      "Test Accuracy : 55.2%, Test Loss: 1.0205222487144763\n",
      "Epoch Time (Training + Test) = 35.30 seconds\n",
      "epoch: 53 average loss: 1.051\n",
      "Test Accuracy : 55.4%, Test Loss: 1.025073133466189\n",
      "Epoch Time (Training + Test) = 36.33 seconds\n",
      "epoch: 54 average loss: 1.059\n",
      "Test Accuracy : 54.4%, Test Loss: 1.0308944180493465\n",
      "Epoch Time (Training + Test) = 38.34 seconds\n",
      "epoch: 55 average loss: 1.058\n",
      "Test Accuracy : 52.0%, Test Loss: 1.0834611971360033\n",
      "Epoch Time (Training + Test) = 34.92 seconds\n",
      "epoch: 56 average loss: 1.067\n",
      "Test Accuracy : 55.0%, Test Loss: 1.0305042330871153\n",
      "Epoch Time (Training + Test) = 37.52 seconds\n",
      "epoch: 57 average loss: 1.061\n",
      "Test Accuracy : 52.9%, Test Loss: 1.056880276678773\n",
      "Epoch Time (Training + Test) = 36.37 seconds\n",
      "epoch: 58 average loss: 1.067\n",
      "Test Accuracy : 53.9%, Test Loss: 1.0414268148829564\n",
      "Epoch Time (Training + Test) = 36.66 seconds\n",
      "epoch: 59 average loss: 1.073\n",
      "Test Accuracy : 55.1%, Test Loss: 1.0288154979800934\n",
      "Epoch Time (Training + Test) = 36.85 seconds\n",
      "epoch: 60 average loss: 1.068\n",
      "Test Accuracy : 54.3%, Test Loss: 1.0379763986448498\n",
      "Epoch Time (Training + Test) = 38.31 seconds\n",
      "epoch: 61 average loss: 1.060\n",
      "Test Accuracy : 53.1%, Test Loss: 1.0516506288667469\n",
      "Epoch Time (Training + Test) = 37.94 seconds\n",
      "epoch: 62 average loss: 1.065\n",
      "Test Accuracy : 54.2%, Test Loss: 1.0372350741835201\n",
      "Epoch Time (Training + Test) = 37.06 seconds\n",
      "epoch: 63 average loss: 1.071\n",
      "Test Accuracy : 54.7%, Test Loss: 1.0459575201849194\n",
      "Epoch Time (Training + Test) = 36.95 seconds\n",
      "epoch: 64 average loss: 1.068\n",
      "Test Accuracy : 54.8%, Test Loss: 1.0378170618620675\n",
      "Epoch Time (Training + Test) = 36.47 seconds\n",
      "epoch: 65 average loss: 1.065\n",
      "Test Accuracy : 53.2%, Test Loss: 1.0433047101320818\n",
      "Epoch Time (Training + Test) = 37.17 seconds\n",
      "epoch: 66 average loss: 1.065\n",
      "Test Accuracy : 53.1%, Test Loss: 1.0631748431783807\n",
      "Epoch Time (Training + Test) = 39.24 seconds\n",
      "epoch: 67 average loss: 1.066\n",
      "Test Accuracy : 54.5%, Test Loss: 1.0321041351693976\n",
      "Epoch Time (Training + Test) = 38.31 seconds\n",
      "epoch: 68 average loss: 1.058\n",
      "Test Accuracy : 52.6%, Test Loss: 1.0698603574577195\n",
      "Epoch Time (Training + Test) = 37.79 seconds\n",
      "epoch: 69 average loss: 1.063\n",
      "Test Accuracy : 55.0%, Test Loss: 1.028649085013153\n",
      "Epoch Time (Training + Test) = 37.23 seconds\n",
      "epoch: 70 average loss: 1.056\n",
      "Test Accuracy : 55.8%, Test Loss: 1.015666975084778\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.08 seconds\n",
      "epoch: 71 average loss: 1.053\n",
      "Test Accuracy : 55.7%, Test Loss: 1.010363989016589\n",
      "Epoch Time (Training + Test) = 36.33 seconds\n",
      "epoch: 72 average loss: 1.052\n",
      "Test Accuracy : 54.8%, Test Loss: 1.0240677156106894\n",
      "Epoch Time (Training + Test) = 37.82 seconds\n",
      "epoch: 73 average loss: 1.060\n",
      "Test Accuracy : 56.0%, Test Loss: 1.0113748142786343\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.42 seconds\n",
      "epoch: 74 average loss: 1.066\n",
      "Test Accuracy : 53.8%, Test Loss: 1.0370048653439183\n",
      "Epoch Time (Training + Test) = 37.74 seconds\n",
      "epoch: 75 average loss: 1.067\n",
      "Test Accuracy : 53.7%, Test Loss: 1.0491814892310316\n",
      "Epoch Time (Training + Test) = 36.90 seconds\n",
      "epoch: 76 average loss: 1.070\n",
      "Test Accuracy : 54.9%, Test Loss: 1.0311454633617645\n",
      "Epoch Time (Training + Test) = 35.97 seconds\n",
      "epoch: 77 average loss: 1.067\n",
      "Test Accuracy : 55.1%, Test Loss: 1.0242045892169103\n",
      "Epoch Time (Training + Test) = 35.43 seconds\n",
      "epoch: 78 average loss: 1.074\n",
      "Test Accuracy : 53.0%, Test Loss: 1.0517000461478367\n",
      "Epoch Time (Training + Test) = 37.31 seconds\n",
      "epoch: 79 average loss: 1.073\n",
      "Test Accuracy : 55.8%, Test Loss: 1.0190763563451255\n",
      "Epoch Time (Training + Test) = 38.63 seconds\n",
      "epoch: 80 average loss: 1.070\n",
      "Test Accuracy : 54.8%, Test Loss: 1.0277795323630428\n",
      "Epoch Time (Training + Test) = 37.79 seconds\n",
      "epoch: 81 average loss: 1.069\n",
      "Test Accuracy : 54.3%, Test Loss: 1.0351012327786906\n",
      "Epoch Time (Training + Test) = 36.81 seconds\n",
      "epoch: 82 average loss: 1.069\n",
      "Test Accuracy : 52.7%, Test Loss: 1.0622586749703682\n",
      "Epoch Time (Training + Test) = 36.46 seconds\n",
      "epoch: 83 average loss: 1.075\n",
      "Test Accuracy : 54.3%, Test Loss: 1.0503847147802563\n",
      "Epoch Time (Training + Test) = 36.28 seconds\n",
      "epoch: 84 average loss: 1.070\n",
      "Test Accuracy : 54.0%, Test Loss: 1.046677126908851\n",
      "Epoch Time (Training + Test) = 36.54 seconds\n",
      "epoch: 85 average loss: 1.071\n",
      "Test Accuracy : 55.0%, Test Loss: 1.0280967745024834\n",
      "Epoch Time (Training + Test) = 36.10 seconds\n",
      "epoch: 86 average loss: 1.071\n",
      "Test Accuracy : 54.9%, Test Loss: 1.0599287074545156\n",
      "Epoch Time (Training + Test) = 35.97 seconds\n",
      "epoch: 87 average loss: 1.058\n",
      "Test Accuracy : 55.8%, Test Loss: 1.0306303075817236\n",
      "Epoch Time (Training + Test) = 35.89 seconds\n",
      "epoch: 88 average loss: 1.064\n",
      "Test Accuracy : 56.9%, Test Loss: 1.0119079296546214\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 35.67 seconds\n",
      "epoch: 89 average loss: 1.059\n",
      "Test Accuracy : 55.9%, Test Loss: 1.0247509865199818\n",
      "Epoch Time (Training + Test) = 35.81 seconds\n",
      "epoch: 90 average loss: 1.056\n",
      "Test Accuracy : 55.9%, Test Loss: 1.0157247981451967\n",
      "Epoch Time (Training + Test) = 36.38 seconds\n",
      "epoch: 91 average loss: 1.049\n",
      "Test Accuracy : 54.9%, Test Loss: 1.0268893376030885\n",
      "Epoch Time (Training + Test) = 37.44 seconds\n",
      "epoch: 92 average loss: 1.064\n",
      "Test Accuracy : 55.1%, Test Loss: 1.0426072851776162\n",
      "Epoch Time (Training + Test) = 38.16 seconds\n",
      "epoch: 93 average loss: 1.058\n",
      "Test Accuracy : 52.8%, Test Loss: 1.0785831334950673\n",
      "Epoch Time (Training + Test) = 36.53 seconds\n",
      "epoch: 94 average loss: 1.065\n",
      "Test Accuracy : 55.5%, Test Loss: 1.019684676624015\n",
      "Epoch Time (Training + Test) = 36.71 seconds\n",
      "epoch: 95 average loss: 1.066\n",
      "Test Accuracy : 55.7%, Test Loss: 1.0300181584285044\n",
      "Epoch Time (Training + Test) = 36.85 seconds\n",
      "epoch: 96 average loss: 1.062\n",
      "Test Accuracy : 55.3%, Test Loss: 1.038601450145702\n",
      "Epoch Time (Training + Test) = 36.05 seconds\n",
      "epoch: 97 average loss: 1.064\n",
      "Test Accuracy : 51.8%, Test Loss: 1.1014433690654042\n",
      "Epoch Time (Training + Test) = 37.40 seconds\n",
      "epoch: 98 average loss: 1.069\n",
      "Test Accuracy : 56.0%, Test Loss: 1.0296603201905175\n",
      "Epoch Time (Training + Test) = 36.99 seconds\n",
      "epoch: 99 average loss: 1.067\n",
      "Test Accuracy : 54.0%, Test Loss: 1.0629178768838459\n",
      "Epoch Time (Training + Test) = 36.86 seconds\n",
      "epoch: 100 average loss: 1.067\n",
      "Test Accuracy : 56.9%, Test Loss: 1.027879348801225\n",
      "Epoch Time (Training + Test) = 36.56 seconds\n",
      "Data Saved to adp_layer1_adp_only.csv\n",
      "Finished Training: \n",
      "Total Time 2.014643 hours\n",
      " Average Time Per Epoch 72.53 seconds\n",
      "adp_only layer2 160\n",
      "Scheduler Set {'T_max': 10, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3050ff43) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch time (s)</td><td>▁▅▇▇▇▇▇▇▆█▇▇▇▆▇▇▇▇▆▇▇▇▇▇█▇█▇▇▇▇█▇▇▇▇█▇▇▇</td></tr><tr><td>lr</td><td>█▇▅▂▁▂▅▇█▇▅▂▁▂▅▇█▇▃▂▁▂▆▇█▆▃▁▁▃▆█▇▆▂▁▂▃▇█</td></tr><tr><td>test_accuracy</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████▇▇█▇██▇██▇▇████▇█</td></tr><tr><td>test_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.56948</td></tr><tr><td>Current Best Acc</td><td>0.56948</td></tr><tr><td>Total Time (hours)</td><td>2.01464</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>36.56103</td></tr><tr><td>lr</td><td>0.1</td></tr><tr><td>test_accuracy</td><td>0.56932</td></tr><tr><td>test_loss</td><td>1.02788</td></tr><tr><td>training_loss</td><td>1.06739</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dazzling-snow-28</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/3050ff43\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar5/runs/3050ff43</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221022_110038-3050ff43\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3050ff43). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73b2c1612854517985a27583db6d281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666672124, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221022_120128-2ueo8g2e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/2ueo8g2e\" target=\"_blank\">wild-universe-30</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name adp_layer2_adp_only \n",
      "\n",
      "\n",
      "Run Start : 2022-10-22 12-01-28\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4362655\n",
      "Initial accuracy:\n",
      "Test Accuracy : 20.0%, Test Loss: 3.993683311335571\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 20.0%, Test Loss: 3.9929843113550443\n",
      "epoch: 1 average loss: 1.288\n",
      "Test Accuracy : 43.4%, Test Loss: 1.1975495796984115\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 30.25 seconds\n",
      "epoch: 2 average loss: 1.188\n",
      "Test Accuracy : 46.7%, Test Loss: 1.1470134069242746\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.75 seconds\n",
      "epoch: 3 average loss: 1.160\n",
      "Test Accuracy : 52.1%, Test Loss: 1.107030967617279\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 31.21 seconds\n",
      "epoch: 4 average loss: 1.121\n",
      "Test Accuracy : 53.8%, Test Loss: 1.0824058985771121\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 30.27 seconds\n",
      "epoch: 5 average loss: 1.105\n",
      "Test Accuracy : 54.5%, Test Loss: 1.0648375731295028\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 29.15 seconds\n",
      "epoch: 6 average loss: 1.097\n",
      "Test Accuracy : 54.3%, Test Loss: 1.05702393256185\n",
      "Epoch Time (Training + Test) = 27.50 seconds\n",
      "epoch: 7 average loss: 1.093\n",
      "Test Accuracy : 55.7%, Test Loss: 1.0544303303484417\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 30.29 seconds\n",
      "epoch: 8 average loss: 1.083\n",
      "Test Accuracy : 56.2%, Test Loss: 1.0507532541099411\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.84 seconds\n",
      "epoch: 9 average loss: 1.080\n",
      "Test Accuracy : 56.0%, Test Loss: 1.050462017278842\n",
      "Epoch Time (Training + Test) = 28.24 seconds\n",
      "epoch: 10 average loss: 1.079\n",
      "Test Accuracy : 55.8%, Test Loss: 1.0519488708442435\n",
      "Epoch Time (Training + Test) = 28.72 seconds\n",
      "epoch: 11 average loss: 1.080\n",
      "Test Accuracy : 56.2%, Test Loss: 1.0489708208062154\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 31.11 seconds\n",
      "epoch: 12 average loss: 1.079\n",
      "Test Accuracy : 56.0%, Test Loss: 1.0499768401960583\n",
      "Epoch Time (Training + Test) = 29.10 seconds\n",
      "epoch: 13 average loss: 1.084\n",
      "Test Accuracy : 56.3%, Test Loss: 1.0505675906720369\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.84 seconds\n",
      "epoch: 14 average loss: 1.076\n",
      "Test Accuracy : 56.4%, Test Loss: 1.0429565872987518\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.57 seconds\n",
      "epoch: 15 average loss: 1.078\n",
      "Test Accuracy : 57.0%, Test Loss: 1.0331653990708958\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 29.55 seconds\n",
      "epoch: 16 average loss: 1.076\n",
      "Test Accuracy : 56.8%, Test Loss: 1.0269481850707012\n",
      "Epoch Time (Training + Test) = 28.38 seconds\n",
      "epoch: 17 average loss: 1.065\n",
      "Test Accuracy : 54.9%, Test Loss: 1.0369107026578215\n",
      "Epoch Time (Training + Test) = 27.34 seconds\n",
      "epoch: 18 average loss: 1.054\n",
      "Test Accuracy : 58.9%, Test Loss: 1.0108964931019737\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 29.45 seconds\n",
      "epoch: 19 average loss: 1.052\n",
      "Test Accuracy : 57.7%, Test Loss: 1.0083729579015765\n",
      "Epoch Time (Training + Test) = 29.24 seconds\n",
      "epoch: 20 average loss: 1.038\n",
      "Test Accuracy : 59.9%, Test Loss: 0.9879637217277761\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.35 seconds\n",
      "epoch: 21 average loss: 1.019\n",
      "Test Accuracy : 59.8%, Test Loss: 0.9939654672237308\n",
      "Epoch Time (Training + Test) = 26.96 seconds\n",
      "epoch: 22 average loss: 1.020\n",
      "Test Accuracy : 61.3%, Test Loss: 0.9700269689950187\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 29.93 seconds\n",
      "epoch: 23 average loss: 1.012\n",
      "Test Accuracy : 61.4%, Test Loss: 0.9691556798832496\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.79 seconds\n",
      "epoch: 24 average loss: 0.996\n",
      "Test Accuracy : 61.7%, Test Loss: 0.982647472787696\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 21.39 seconds\n",
      "epoch: 25 average loss: 0.974\n",
      "Test Accuracy : 63.5%, Test Loss: 0.9332629489471845\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.83 seconds\n",
      "epoch: 26 average loss: 0.969\n",
      "Test Accuracy : 63.3%, Test Loss: 0.9363719116696312\n",
      "Epoch Time (Training + Test) = 28.09 seconds\n",
      "epoch: 27 average loss: 0.960\n",
      "Test Accuracy : 63.4%, Test Loss: 0.9307414093590758\n",
      "Epoch Time (Training + Test) = 26.29 seconds\n",
      "epoch: 28 average loss: 0.967\n",
      "Test Accuracy : 63.7%, Test Loss: 0.9390648858016714\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.77 seconds\n",
      "epoch: 29 average loss: 0.963\n",
      "Test Accuracy : 64.1%, Test Loss: 0.9244609731237602\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.33 seconds\n",
      "epoch: 30 average loss: 0.958\n",
      "Test Accuracy : 64.0%, Test Loss: 0.9300276487684616\n",
      "Epoch Time (Training + Test) = 27.61 seconds\n",
      "epoch: 31 average loss: 0.965\n",
      "Test Accuracy : 63.6%, Test Loss: 0.9290294827097823\n",
      "Epoch Time (Training + Test) = 26.97 seconds\n",
      "epoch: 32 average loss: 0.952\n",
      "Test Accuracy : 63.8%, Test Loss: 0.9303868326079815\n",
      "Epoch Time (Training + Test) = 29.21 seconds\n",
      "epoch: 33 average loss: 0.961\n",
      "Test Accuracy : 63.8%, Test Loss: 0.924627698748313\n",
      "Epoch Time (Training + Test) = 27.96 seconds\n",
      "epoch: 34 average loss: 0.957\n",
      "Test Accuracy : 63.8%, Test Loss: 0.9248659763189838\n",
      "Epoch Time (Training + Test) = 26.46 seconds\n",
      "epoch: 35 average loss: 0.967\n",
      "Test Accuracy : 63.9%, Test Loss: 0.9236768209720816\n",
      "Epoch Time (Training + Test) = 28.28 seconds\n",
      "epoch: 36 average loss: 0.952\n",
      "Test Accuracy : 63.7%, Test Loss: 0.9175786103129082\n",
      "Epoch Time (Training + Test) = 28.41 seconds\n",
      "epoch: 37 average loss: 0.955\n",
      "Test Accuracy : 64.2%, Test Loss: 0.9217683773516389\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.51 seconds\n",
      "epoch: 38 average loss: 0.954\n",
      "Test Accuracy : 62.3%, Test Loss: 0.9764008003732433\n",
      "Epoch Time (Training + Test) = 27.15 seconds\n",
      "epoch: 39 average loss: 0.944\n",
      "Test Accuracy : 63.7%, Test Loss: 0.9249116645749572\n",
      "Epoch Time (Training + Test) = 31.02 seconds\n",
      "epoch: 40 average loss: 0.942\n",
      "Test Accuracy : 64.7%, Test Loss: 0.9023833069045221\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 29.43 seconds\n",
      "epoch: 41 average loss: 0.943\n",
      "Test Accuracy : 62.9%, Test Loss: 0.9400566241625324\n",
      "Epoch Time (Training + Test) = 28.50 seconds\n",
      "epoch: 42 average loss: 0.940\n",
      "Test Accuracy : 63.4%, Test Loss: 0.9260629516123505\n",
      "Epoch Time (Training + Test) = 28.00 seconds\n",
      "epoch: 43 average loss: 0.938\n",
      "Test Accuracy : 62.1%, Test Loss: 0.9489007804094983\n",
      "Epoch Time (Training + Test) = 28.87 seconds\n",
      "epoch: 44 average loss: 0.937\n",
      "Test Accuracy : 63.9%, Test Loss: 0.9108616814893835\n",
      "Epoch Time (Training + Test) = 27.99 seconds\n",
      "epoch: 45 average loss: 0.932\n",
      "Test Accuracy : 61.8%, Test Loss: 0.9404625849955527\n",
      "Epoch Time (Training + Test) = 26.60 seconds\n",
      "epoch: 46 average loss: 0.935\n",
      "Test Accuracy : 63.8%, Test Loss: 0.9082158703328399\n",
      "Epoch Time (Training + Test) = 28.69 seconds\n",
      "epoch: 47 average loss: 0.928\n",
      "Test Accuracy : 63.3%, Test Loss: 0.9032750760807711\n",
      "Epoch Time (Training + Test) = 28.42 seconds\n",
      "epoch: 48 average loss: 0.931\n",
      "Test Accuracy : 64.1%, Test Loss: 0.8994804000305703\n",
      "Epoch Time (Training + Test) = 27.38 seconds\n",
      "epoch: 49 average loss: 0.920\n",
      "Test Accuracy : 63.5%, Test Loss: 0.9122993497897292\n",
      "Epoch Time (Training + Test) = 27.02 seconds\n",
      "epoch: 50 average loss: 0.923\n",
      "Test Accuracy : 64.6%, Test Loss: 0.8997069246628705\n",
      "Epoch Time (Training + Test) = 28.76 seconds\n",
      "epoch: 51 average loss: 0.927\n",
      "Test Accuracy : 64.7%, Test Loss: 0.8883915761547625\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.06 seconds\n",
      "epoch: 52 average loss: 0.914\n",
      "Test Accuracy : 65.4%, Test Loss: 0.8808266095188267\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.41 seconds\n",
      "epoch: 53 average loss: 0.928\n",
      "Test Accuracy : 65.0%, Test Loss: 0.8875191958664018\n",
      "Epoch Time (Training + Test) = 28.43 seconds\n",
      "epoch: 54 average loss: 0.928\n",
      "Test Accuracy : 63.7%, Test Loss: 0.9175216365043465\n",
      "Epoch Time (Training + Test) = 28.57 seconds\n",
      "epoch: 55 average loss: 0.930\n",
      "Test Accuracy : 64.7%, Test Loss: 0.8896915219019136\n",
      "Epoch Time (Training + Test) = 27.74 seconds\n",
      "epoch: 56 average loss: 0.932\n",
      "Test Accuracy : 64.9%, Test Loss: 0.8932938664160726\n",
      "Epoch Time (Training + Test) = 26.68 seconds\n",
      "epoch: 57 average loss: 0.935\n",
      "Test Accuracy : 63.4%, Test Loss: 0.9275323536694812\n",
      "Epoch Time (Training + Test) = 29.36 seconds\n",
      "epoch: 58 average loss: 0.936\n",
      "Test Accuracy : 64.2%, Test Loss: 0.9075370074233131\n",
      "Epoch Time (Training + Test) = 28.23 seconds\n",
      "epoch: 59 average loss: 0.935\n",
      "Test Accuracy : 63.7%, Test Loss: 0.905346678498456\n",
      "Epoch Time (Training + Test) = 27.29 seconds\n",
      "epoch: 60 average loss: 0.930\n",
      "Test Accuracy : 62.8%, Test Loss: 0.9262663455265562\n",
      "Epoch Time (Training + Test) = 27.88 seconds\n",
      "epoch: 61 average loss: 0.929\n",
      "Test Accuracy : 63.2%, Test Loss: 0.9208721228877602\n",
      "Epoch Time (Training + Test) = 29.00 seconds\n",
      "epoch: 62 average loss: 0.933\n",
      "Test Accuracy : 63.1%, Test Loss: 0.924343843136907\n",
      "Epoch Time (Training + Test) = 28.23 seconds\n",
      "epoch: 63 average loss: 0.932\n",
      "Test Accuracy : 64.1%, Test Loss: 0.9030750770398113\n",
      "Epoch Time (Training + Test) = 26.33 seconds\n",
      "epoch: 64 average loss: 0.929\n",
      "Test Accuracy : 65.5%, Test Loss: 0.8813821697783897\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 29.01 seconds\n",
      "epoch: 65 average loss: 0.933\n",
      "Test Accuracy : 64.1%, Test Loss: 0.9095601491306139\n",
      "Epoch Time (Training + Test) = 28.15 seconds\n",
      "epoch: 66 average loss: 0.925\n",
      "Test Accuracy : 62.8%, Test Loss: 0.9194418396181463\n",
      "Epoch Time (Training + Test) = 27.19 seconds\n",
      "epoch: 67 average loss: 0.920\n",
      "Test Accuracy : 63.0%, Test Loss: 0.9136133459218018\n",
      "Epoch Time (Training + Test) = 27.41 seconds\n",
      "epoch: 68 average loss: 0.924\n",
      "Test Accuracy : 63.2%, Test Loss: 0.9287366667367003\n",
      "Epoch Time (Training + Test) = 28.98 seconds\n",
      "epoch: 69 average loss: 0.930\n",
      "Test Accuracy : 62.8%, Test Loss: 0.9279288291321386\n",
      "Epoch Time (Training + Test) = 27.95 seconds\n",
      "epoch: 70 average loss: 0.915\n",
      "Test Accuracy : 63.7%, Test Loss: 0.9184412008051372\n",
      "Epoch Time (Training + Test) = 26.32 seconds\n",
      "epoch: 71 average loss: 0.929\n",
      "Test Accuracy : 64.2%, Test Loss: 0.8973760051495584\n",
      "Epoch Time (Training + Test) = 28.65 seconds\n",
      "epoch: 72 average loss: 0.918\n",
      "Test Accuracy : 64.4%, Test Loss: 0.9068520335895022\n",
      "Epoch Time (Training + Test) = 28.31 seconds\n",
      "epoch: 73 average loss: 0.922\n",
      "Test Accuracy : 63.5%, Test Loss: 0.9034395172163043\n",
      "Epoch Time (Training + Test) = 27.34 seconds\n",
      "epoch: 74 average loss: 0.930\n",
      "Test Accuracy : 63.2%, Test Loss: 0.9207095032762689\n",
      "Epoch Time (Training + Test) = 27.27 seconds\n",
      "epoch: 75 average loss: 0.929\n",
      "Test Accuracy : 61.0%, Test Loss: 0.9684458559431384\n",
      "Epoch Time (Training + Test) = 28.74 seconds\n",
      "epoch: 76 average loss: 0.939\n",
      "Test Accuracy : 65.3%, Test Loss: 0.8896451747935751\n",
      "Epoch Time (Training + Test) = 27.87 seconds\n",
      "epoch: 77 average loss: 0.934\n",
      "Test Accuracy : 63.6%, Test Loss: 0.9136218190802943\n",
      "Epoch Time (Training + Test) = 26.53 seconds\n",
      "epoch: 78 average loss: 0.941\n",
      "Test Accuracy : 61.5%, Test Loss: 0.9607557401327831\n",
      "Epoch Time (Training + Test) = 28.78 seconds\n",
      "epoch: 79 average loss: 0.933\n",
      "Test Accuracy : 57.8%, Test Loss: 1.0214798418457245\n",
      "Epoch Time (Training + Test) = 29.64 seconds\n",
      "epoch: 80 average loss: 0.939\n",
      "Test Accuracy : 63.4%, Test Loss: 0.907648141884133\n",
      "Epoch Time (Training + Test) = 30.01 seconds\n",
      "epoch: 81 average loss: 0.938\n",
      "Test Accuracy : 63.4%, Test Loss: 0.9248623286976534\n",
      "Epoch Time (Training + Test) = 28.55 seconds\n",
      "epoch: 82 average loss: 0.938\n",
      "Test Accuracy : 62.4%, Test Loss: 0.9274982660627731\n",
      "Epoch Time (Training + Test) = 31.17 seconds\n",
      "epoch: 83 average loss: 0.939\n",
      "Test Accuracy : 63.9%, Test Loss: 0.9050225190189488\n",
      "Epoch Time (Training + Test) = 30.36 seconds\n",
      "epoch: 84 average loss: 0.936\n",
      "Test Accuracy : 61.4%, Test Loss: 0.9596907705297251\n",
      "Epoch Time (Training + Test) = 29.68 seconds\n",
      "epoch: 85 average loss: 0.937\n",
      "Test Accuracy : 63.9%, Test Loss: 0.9083486380784408\n",
      "Epoch Time (Training + Test) = 29.23 seconds\n",
      "epoch: 86 average loss: 0.932\n",
      "Test Accuracy : 65.1%, Test Loss: 0.8869205717845341\n",
      "Epoch Time (Training + Test) = 30.89 seconds\n",
      "epoch: 87 average loss: 0.924\n",
      "Test Accuracy : 62.6%, Test Loss: 0.9222866482746875\n",
      "Epoch Time (Training + Test) = 28.88 seconds\n",
      "epoch: 88 average loss: 0.928\n",
      "Test Accuracy : 63.9%, Test Loss: 0.9123339270386854\n",
      "Epoch Time (Training + Test) = 29.06 seconds\n",
      "epoch: 89 average loss: 0.915\n",
      "Test Accuracy : 64.9%, Test Loss: 0.8906709937488332\n",
      "Epoch Time (Training + Test) = 29.76 seconds\n",
      "epoch: 90 average loss: 0.919\n",
      "Test Accuracy : 64.5%, Test Loss: 0.8894694218855075\n",
      "Epoch Time (Training + Test) = 31.49 seconds\n",
      "epoch: 91 average loss: 0.914\n",
      "Test Accuracy : 65.4%, Test Loss: 0.8870575635329537\n",
      "Epoch Time (Training + Test) = 30.00 seconds\n",
      "epoch: 92 average loss: 0.924\n",
      "Test Accuracy : 65.8%, Test Loss: 0.8803511054619498\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 29.22 seconds\n",
      "epoch: 93 average loss: 0.927\n",
      "Test Accuracy : 63.9%, Test Loss: 0.9090441364766387\n",
      "Epoch Time (Training + Test) = 30.08 seconds\n",
      "epoch: 94 average loss: 0.933\n",
      "Test Accuracy : 63.1%, Test Loss: 0.8966440590446257\n",
      "Epoch Time (Training + Test) = 31.72 seconds\n",
      "epoch: 95 average loss: 0.929\n",
      "Test Accuracy : 61.4%, Test Loss: 0.9753650928397313\n",
      "Epoch Time (Training + Test) = 30.22 seconds\n",
      "epoch: 96 average loss: 0.931\n",
      "Test Accuracy : 62.8%, Test Loss: 0.9311904330997516\n",
      "Epoch Time (Training + Test) = 29.31 seconds\n",
      "epoch: 97 average loss: 0.938\n",
      "Test Accuracy : 58.8%, Test Loss: 0.9921352183422469\n",
      "Epoch Time (Training + Test) = 30.82 seconds\n",
      "epoch: 98 average loss: 0.938\n",
      "Test Accuracy : 62.8%, Test Loss: 0.9475454744475577\n",
      "Epoch Time (Training + Test) = 30.44 seconds\n",
      "epoch: 99 average loss: 0.935\n",
      "Test Accuracy : 61.9%, Test Loss: 0.9270227030110176\n",
      "Epoch Time (Training + Test) = 29.58 seconds\n",
      "epoch: 100 average loss: 0.936\n",
      "Test Accuracy : 61.5%, Test Loss: 0.9458957852609932\n",
      "Epoch Time (Training + Test) = 28.81 seconds\n",
      "Data Saved to adp_layer2_adp_only.csv\n",
      "Finished Training: \n",
      "Total Time 1.582997 hours\n",
      " Average Time Per Epoch 56.99 seconds\n",
      "adp_only layer3 320\n",
      "Scheduler Set {'T_max': 10, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2ueo8g2e) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>▁▅▆▆▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch time (s)</td><td>▇▆▇▇▆▇▇▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆▅▆▇▇▆▆▆▆▆▇█▇▆▇▇██▆</td></tr><tr><td>lr</td><td>█▇▅▂▁▂▅▇█▇▅▂▁▂▅▇█▇▃▂▁▂▆▇█▆▃▁▁▃▆█▇▆▂▁▂▃▇█</td></tr><tr><td>test_accuracy</td><td>▁▅▆▆▆▆▇▆▇▇█████▇█▇█████████████▇▇▇████▇▇</td></tr><tr><td>test_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.65848</td></tr><tr><td>Current Best Acc</td><td>0.65848</td></tr><tr><td>Total Time (hours)</td><td>1.583</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>28.80798</td></tr><tr><td>lr</td><td>0.1</td></tr><tr><td>test_accuracy</td><td>0.61504</td></tr><tr><td>test_loss</td><td>0.9459</td></tr><tr><td>training_loss</td><td>0.93563</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wild-universe-30</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/2ueo8g2e\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar5/runs/2ueo8g2e</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221022_120128-2ueo8g2e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2ueo8g2e). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4bfa9ca46d42e4a294bc37937b8ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221022_124939-10f3n9zq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/10f3n9zq\" target=\"_blank\">charmed-sky-32</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name adp_layer3_adp_only \n",
      "\n",
      "\n",
      "Run Start : 2022-10-22 12-49-39\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4440095\n",
      "Initial accuracy:\n",
      "Test Accuracy : 20.0%, Test Loss: 2.556679776867332\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 20.0%, Test Loss: 2.5566383127666192\n",
      "epoch: 1 average loss: 1.539\n",
      "Test Accuracy : 29.9%, Test Loss: 1.4480573743810434\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.51 seconds\n",
      "epoch: 2 average loss: 1.424\n",
      "Test Accuracy : 35.6%, Test Loss: 1.4382181316995255\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.92 seconds\n",
      "epoch: 3 average loss: 1.421\n",
      "Test Accuracy : 38.1%, Test Loss: 1.4454956326033452\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.75 seconds\n",
      "epoch: 4 average loss: 1.416\n",
      "Test Accuracy : 36.3%, Test Loss: 1.4716848976471846\n",
      "Epoch Time (Training + Test) = 27.58 seconds\n",
      "epoch: 5 average loss: 1.417\n",
      "Test Accuracy : 40.4%, Test Loss: 1.3573578888802882\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.82 seconds\n",
      "epoch: 6 average loss: 1.418\n",
      "Test Accuracy : 36.4%, Test Loss: 1.4243747941063494\n",
      "Epoch Time (Training + Test) = 27.48 seconds\n",
      "epoch: 7 average loss: 1.415\n",
      "Test Accuracy : 32.3%, Test Loss: 1.405577289173975\n",
      "Epoch Time (Training + Test) = 26.93 seconds\n",
      "epoch: 8 average loss: 1.414\n",
      "Test Accuracy : 38.3%, Test Loss: 1.392249457061748\n",
      "Epoch Time (Training + Test) = 29.03 seconds\n",
      "epoch: 9 average loss: 1.413\n",
      "Test Accuracy : 39.8%, Test Loss: 1.3455740353640389\n",
      "Epoch Time (Training + Test) = 27.85 seconds\n",
      "epoch: 10 average loss: 1.414\n",
      "Test Accuracy : 38.4%, Test Loss: 1.3866059432554123\n",
      "Epoch Time (Training + Test) = 26.17 seconds\n",
      "epoch: 11 average loss: 1.425\n",
      "Test Accuracy : 38.3%, Test Loss: 1.3895241421506839\n",
      "Epoch Time (Training + Test) = 28.99 seconds\n",
      "epoch: 12 average loss: 1.413\n",
      "Test Accuracy : 32.8%, Test Loss: 1.5021377341521671\n",
      "Epoch Time (Training + Test) = 28.06 seconds\n",
      "epoch: 13 average loss: 1.415\n",
      "Test Accuracy : 33.0%, Test Loss: 1.4692643182661833\n",
      "Epoch Time (Training + Test) = 27.07 seconds\n",
      "epoch: 14 average loss: 1.411\n",
      "Test Accuracy : 37.4%, Test Loss: 1.4888136371627183\n",
      "Epoch Time (Training + Test) = 28.13 seconds\n",
      "epoch: 15 average loss: 1.416\n",
      "Test Accuracy : 39.0%, Test Loss: 1.3761380913922243\n",
      "Epoch Time (Training + Test) = 28.69 seconds\n",
      "epoch: 16 average loss: 1.415\n",
      "Test Accuracy : 41.6%, Test Loss: 1.3430895110225434\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.46 seconds\n",
      "epoch: 17 average loss: 1.415\n",
      "Test Accuracy : 32.5%, Test Loss: 1.4054480562429599\n",
      "Epoch Time (Training + Test) = 27.40 seconds\n",
      "epoch: 18 average loss: 1.410\n",
      "Test Accuracy : 39.2%, Test Loss: 1.3801843620017362\n",
      "Epoch Time (Training + Test) = 28.99 seconds\n",
      "epoch: 19 average loss: 1.415\n",
      "Test Accuracy : 36.0%, Test Loss: 1.47799013368309\n",
      "Epoch Time (Training + Test) = 27.84 seconds\n",
      "epoch: 20 average loss: 1.412\n",
      "Test Accuracy : 38.0%, Test Loss: 1.411932306826267\n",
      "Epoch Time (Training + Test) = 26.48 seconds\n",
      "epoch: 21 average loss: 1.407\n",
      "Test Accuracy : 34.2%, Test Loss: 1.4390001431145631\n",
      "Epoch Time (Training + Test) = 29.50 seconds\n",
      "epoch: 22 average loss: 1.402\n",
      "Test Accuracy : 36.8%, Test Loss: 1.418895728752741\n",
      "Epoch Time (Training + Test) = 28.36 seconds\n",
      "epoch: 23 average loss: 1.395\n",
      "Test Accuracy : 37.3%, Test Loss: 1.397689217496711\n",
      "Epoch Time (Training + Test) = 26.52 seconds\n",
      "epoch: 24 average loss: 1.397\n",
      "Test Accuracy : 36.9%, Test Loss: 1.3943405331248213\n",
      "Epoch Time (Training + Test) = 28.60 seconds\n",
      "epoch: 25 average loss: 1.403\n",
      "Test Accuracy : 36.1%, Test Loss: 1.3712743133535166\n",
      "Epoch Time (Training + Test) = 28.21 seconds\n",
      "epoch: 26 average loss: 1.385\n",
      "Test Accuracy : 37.3%, Test Loss: 1.3977081607979582\n",
      "Epoch Time (Training + Test) = 27.13 seconds\n",
      "epoch: 27 average loss: 1.390\n",
      "Test Accuracy : 40.9%, Test Loss: 1.3279878084007126\n",
      "Epoch Time (Training + Test) = 27.86 seconds\n",
      "epoch: 28 average loss: 1.383\n",
      "Test Accuracy : 42.5%, Test Loss: 1.3197308501319203\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.63 seconds\n",
      "epoch: 29 average loss: 1.383\n",
      "Test Accuracy : 39.4%, Test Loss: 1.3718256191219516\n",
      "Epoch Time (Training + Test) = 27.36 seconds\n",
      "epoch: 30 average loss: 1.387\n",
      "Test Accuracy : 38.7%, Test Loss: 1.348408286528819\n",
      "Epoch Time (Training + Test) = 26.98 seconds\n",
      "epoch: 31 average loss: 1.375\n",
      "Test Accuracy : 38.6%, Test Loss: 1.3332105618913461\n",
      "Epoch Time (Training + Test) = 29.03 seconds\n",
      "epoch: 32 average loss: 1.389\n",
      "Test Accuracy : 39.6%, Test Loss: 1.323918326126645\n",
      "Epoch Time (Training + Test) = 26.58 seconds\n",
      "epoch: 33 average loss: 1.387\n",
      "Test Accuracy : 41.7%, Test Loss: 1.3518920493552753\n",
      "Epoch Time (Training + Test) = 24.90 seconds\n",
      "epoch: 34 average loss: 1.388\n",
      "Test Accuracy : 38.4%, Test Loss: 1.3713784623328986\n",
      "Epoch Time (Training + Test) = 27.68 seconds\n",
      "epoch: 35 average loss: 1.391\n",
      "Test Accuracy : 37.7%, Test Loss: 1.4334165226772924\n",
      "Epoch Time (Training + Test) = 26.69 seconds\n",
      "epoch: 36 average loss: 1.387\n",
      "Test Accuracy : 41.6%, Test Loss: 1.312150223175888\n",
      "Epoch Time (Training + Test) = 25.67 seconds\n",
      "epoch: 37 average loss: 1.384\n",
      "Test Accuracy : 37.1%, Test Loss: 1.3603533616151346\n",
      "Epoch Time (Training + Test) = 26.58 seconds\n",
      "epoch: 38 average loss: 1.389\n",
      "Test Accuracy : 37.7%, Test Loss: 1.3663130144938789\n",
      "Epoch Time (Training + Test) = 27.27 seconds\n",
      "epoch: 39 average loss: 1.388\n",
      "Test Accuracy : 41.9%, Test Loss: 1.3213420185591558\n",
      "Epoch Time (Training + Test) = 26.16 seconds\n",
      "epoch: 40 average loss: 1.384\n",
      "Test Accuracy : 39.9%, Test Loss: 1.3998980427642003\n",
      "Epoch Time (Training + Test) = 25.41 seconds\n",
      "epoch: 41 average loss: 1.385\n",
      "Test Accuracy : 39.0%, Test Loss: 1.3893264135741212\n",
      "Epoch Time (Training + Test) = 27.91 seconds\n",
      "epoch: 42 average loss: 1.384\n",
      "Test Accuracy : 39.5%, Test Loss: 1.3487974338214417\n",
      "Epoch Time (Training + Test) = 26.61 seconds\n",
      "epoch: 43 average loss: 1.377\n",
      "Test Accuracy : 36.8%, Test Loss: 1.3634410666687715\n",
      "Epoch Time (Training + Test) = 25.18 seconds\n",
      "epoch: 44 average loss: 1.376\n",
      "Test Accuracy : 35.8%, Test Loss: 1.410609464206354\n",
      "Epoch Time (Training + Test) = 27.26 seconds\n",
      "epoch: 45 average loss: 1.371\n",
      "Test Accuracy : 43.5%, Test Loss: 1.3133791203389082\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.70 seconds\n",
      "epoch: 46 average loss: 1.375\n",
      "Test Accuracy : 43.4%, Test Loss: 1.3294661124344067\n",
      "Epoch Time (Training + Test) = 25.68 seconds\n",
      "epoch: 47 average loss: 1.369\n",
      "Test Accuracy : 43.5%, Test Loss: 1.3152323638081855\n",
      "Epoch Time (Training + Test) = 26.43 seconds\n",
      "epoch: 48 average loss: 1.373\n",
      "Test Accuracy : 42.7%, Test Loss: 1.3077718049973783\n",
      "Epoch Time (Training + Test) = 27.51 seconds\n",
      "epoch: 49 average loss: 1.369\n",
      "Test Accuracy : 39.2%, Test Loss: 1.344402456832359\n",
      "Epoch Time (Training + Test) = 26.42 seconds\n",
      "epoch: 50 average loss: 1.369\n",
      "Test Accuracy : 33.2%, Test Loss: 1.476338674955051\n",
      "Epoch Time (Training + Test) = 25.15 seconds\n",
      "epoch: 51 average loss: 1.400\n",
      "Test Accuracy : 34.1%, Test Loss: 1.3714827832663457\n",
      "Epoch Time (Training + Test) = 27.90 seconds\n",
      "epoch: 52 average loss: 1.369\n",
      "Test Accuracy : 34.4%, Test Loss: 1.454027028339903\n",
      "Epoch Time (Training + Test) = 26.62 seconds\n",
      "epoch: 53 average loss: 1.372\n",
      "Test Accuracy : 41.0%, Test Loss: 1.337830327355953\n",
      "Epoch Time (Training + Test) = 25.28 seconds\n",
      "epoch: 54 average loss: 1.366\n",
      "Test Accuracy : 36.7%, Test Loss: 1.4096547002377717\n",
      "Epoch Time (Training + Test) = 27.04 seconds\n",
      "epoch: 55 average loss: 1.372\n",
      "Test Accuracy : 33.2%, Test Loss: 1.4975996804054437\n",
      "Epoch Time (Training + Test) = 26.95 seconds\n",
      "epoch: 56 average loss: 1.370\n",
      "Test Accuracy : 41.2%, Test Loss: 1.3108407359598848\n",
      "Epoch Time (Training + Test) = 25.83 seconds\n",
      "epoch: 57 average loss: 1.377\n",
      "Test Accuracy : 36.3%, Test Loss: 1.3849440953310799\n",
      "Epoch Time (Training + Test) = 26.03 seconds\n",
      "epoch: 58 average loss: 1.376\n",
      "Test Accuracy : 45.1%, Test Loss: 1.2905136862069444\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.55 seconds\n",
      "epoch: 59 average loss: 1.370\n",
      "Test Accuracy : 45.5%, Test Loss: 1.284754280239115\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.60 seconds\n",
      "epoch: 60 average loss: 1.369\n",
      "Test Accuracy : 34.9%, Test Loss: 1.3915912611100374\n",
      "Epoch Time (Training + Test) = 25.02 seconds\n",
      "epoch: 61 average loss: 1.363\n",
      "Test Accuracy : 44.1%, Test Loss: 1.3066672733067857\n",
      "Epoch Time (Training + Test) = 28.13 seconds\n",
      "epoch: 62 average loss: 1.369\n",
      "Test Accuracy : 36.2%, Test Loss: 1.4409454996933413\n",
      "Epoch Time (Training + Test) = 26.68 seconds\n",
      "epoch: 63 average loss: 1.368\n",
      "Test Accuracy : 44.8%, Test Loss: 1.286402085553045\n",
      "Epoch Time (Training + Test) = 22.71 seconds\n",
      "epoch: 64 average loss: 1.361\n",
      "Test Accuracy : 38.3%, Test Loss: 1.4321774024792644\n",
      "Epoch Time (Training + Test) = 16.33 seconds\n",
      "epoch: 65 average loss: 1.362\n",
      "Test Accuracy : 39.8%, Test Loss: 1.3309957453661867\n",
      "Epoch Time (Training + Test) = 24.49 seconds\n",
      "epoch: 66 average loss: 1.363\n",
      "Test Accuracy : 41.5%, Test Loss: 1.3321338013919723\n",
      "Epoch Time (Training + Test) = 25.99 seconds\n",
      "epoch: 67 average loss: 1.365\n",
      "Test Accuracy : 41.1%, Test Loss: 1.3839658739621683\n",
      "Epoch Time (Training + Test) = 27.20 seconds\n",
      "epoch: 68 average loss: 1.364\n",
      "Test Accuracy : 44.2%, Test Loss: 1.3043759759429776\n",
      "Epoch Time (Training + Test) = 26.59 seconds\n",
      "epoch: 69 average loss: 1.363\n",
      "Test Accuracy : 35.4%, Test Loss: 1.4716518242340868\n",
      "Epoch Time (Training + Test) = 24.34 seconds\n",
      "epoch: 70 average loss: 1.360\n",
      "Test Accuracy : 37.7%, Test Loss: 1.3102086626965066\n",
      "Epoch Time (Training + Test) = 27.52 seconds\n",
      "epoch: 71 average loss: 1.347\n",
      "Test Accuracy : 43.9%, Test Loss: 1.282102215625441\n",
      "Epoch Time (Training + Test) = 26.74 seconds\n",
      "epoch: 72 average loss: 1.358\n",
      "Test Accuracy : 42.6%, Test Loss: 1.290194069942855\n",
      "Epoch Time (Training + Test) = 25.20 seconds\n",
      "epoch: 73 average loss: 1.357\n",
      "Test Accuracy : 36.4%, Test Loss: 1.4201354010940512\n",
      "Epoch Time (Training + Test) = 26.11 seconds\n",
      "epoch: 74 average loss: 1.360\n",
      "Test Accuracy : 36.2%, Test Loss: 1.3660463856919038\n",
      "Epoch Time (Training + Test) = 26.97 seconds\n",
      "epoch: 75 average loss: 1.362\n",
      "Test Accuracy : 44.7%, Test Loss: 1.2940280318565076\n",
      "Epoch Time (Training + Test) = 26.17 seconds\n",
      "epoch: 76 average loss: 1.362\n",
      "Test Accuracy : 38.5%, Test Loss: 1.3322239632496748\n",
      "Epoch Time (Training + Test) = 24.89 seconds\n",
      "epoch: 77 average loss: 1.362\n",
      "Test Accuracy : 41.9%, Test Loss: 1.3762665130293277\n",
      "Epoch Time (Training + Test) = 27.59 seconds\n",
      "epoch: 78 average loss: 1.363\n",
      "Test Accuracy : 39.7%, Test Loss: 1.3758627234212577\n",
      "Epoch Time (Training + Test) = 26.81 seconds\n",
      "epoch: 79 average loss: 1.360\n",
      "Test Accuracy : 42.2%, Test Loss: 1.2966902054789122\n",
      "Epoch Time (Training + Test) = 25.15 seconds\n",
      "epoch: 80 average loss: 1.358\n",
      "Test Accuracy : 42.4%, Test Loss: 1.345359525717128\n",
      "Epoch Time (Training + Test) = 26.55 seconds\n",
      "epoch: 81 average loss: 1.361\n",
      "Test Accuracy : 41.9%, Test Loss: 1.3872297084544931\n",
      "Epoch Time (Training + Test) = 26.83 seconds\n",
      "epoch: 82 average loss: 1.365\n",
      "Test Accuracy : 44.9%, Test Loss: 1.2885131363368705\n",
      "Epoch Time (Training + Test) = 25.85 seconds\n",
      "epoch: 83 average loss: 1.361\n",
      "Test Accuracy : 34.3%, Test Loss: 1.4814732416206613\n",
      "Epoch Time (Training + Test) = 25.18 seconds\n",
      "epoch: 84 average loss: 1.353\n",
      "Test Accuracy : 36.8%, Test Loss: 1.3748385488529644\n",
      "Epoch Time (Training + Test) = 27.21 seconds\n",
      "epoch: 85 average loss: 1.357\n",
      "Test Accuracy : 43.2%, Test Loss: 1.3187939767032633\n",
      "Epoch Time (Training + Test) = 26.59 seconds\n",
      "epoch: 86 average loss: 1.347\n",
      "Test Accuracy : 42.6%, Test Loss: 1.4088630121382302\n",
      "Epoch Time (Training + Test) = 24.53 seconds\n",
      "epoch: 87 average loss: 1.353\n",
      "Test Accuracy : 34.2%, Test Loss: 1.382542299797468\n",
      "Epoch Time (Training + Test) = 27.33 seconds\n",
      "epoch: 88 average loss: 1.351\n",
      "Test Accuracy : 45.4%, Test Loss: 1.282209497888375\n",
      "Epoch Time (Training + Test) = 26.71 seconds\n",
      "epoch: 89 average loss: 1.348\n",
      "Test Accuracy : 36.8%, Test Loss: 1.4177766041377622\n",
      "Epoch Time (Training + Test) = 25.69 seconds\n",
      "epoch: 90 average loss: 1.347\n",
      "Test Accuracy : 44.4%, Test Loss: 1.351290255251443\n",
      "Epoch Time (Training + Test) = 25.68 seconds\n",
      "epoch: 91 average loss: 1.340\n",
      "Test Accuracy : 44.5%, Test Loss: 1.2845902302685905\n",
      "Epoch Time (Training + Test) = 27.08 seconds\n",
      "epoch: 92 average loss: 1.351\n",
      "Test Accuracy : 29.2%, Test Loss: 1.4315741327412599\n",
      "Epoch Time (Training + Test) = 26.40 seconds\n",
      "epoch: 93 average loss: 1.353\n",
      "Test Accuracy : 44.4%, Test Loss: 1.3144620839897019\n",
      "Epoch Time (Training + Test) = 24.34 seconds\n",
      "epoch: 94 average loss: 1.351\n",
      "Test Accuracy : 40.8%, Test Loss: 1.299942461730879\n",
      "Epoch Time (Training + Test) = 27.55 seconds\n",
      "epoch: 95 average loss: 1.355\n",
      "Test Accuracy : 39.3%, Test Loss: 1.356209417438263\n",
      "Epoch Time (Training + Test) = 26.77 seconds\n",
      "epoch: 96 average loss: 1.353\n",
      "Test Accuracy : 43.1%, Test Loss: 1.3287142152371614\n",
      "Epoch Time (Training + Test) = 24.96 seconds\n",
      "epoch: 97 average loss: 1.353\n",
      "Test Accuracy : 42.7%, Test Loss: 1.3542672816444845\n",
      "Epoch Time (Training + Test) = 26.40 seconds\n",
      "epoch: 98 average loss: 1.352\n",
      "Test Accuracy : 45.9%, Test Loss: 1.292967132290306\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.02 seconds\n",
      "epoch: 99 average loss: 1.353\n",
      "Test Accuracy : 41.6%, Test Loss: 1.3236890573940618\n",
      "Epoch Time (Training + Test) = 25.98 seconds\n",
      "epoch: 100 average loss: 1.352\n",
      "Test Accuracy : 40.6%, Test Loss: 1.3160791494657316\n",
      "Epoch Time (Training + Test) = 25.06 seconds\n",
      "Data Saved to adp_layer3_adp_only.csv\n",
      "Finished Training: \n",
      "Total Time 1.482354 hours\n",
      " Average Time Per Epoch 53.36 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "PATH = '.\\SavedModels\\Cifar5\\Baseline_BNN_Resnet18_2022_10_21_10_47_20\\Baseline_BNN_Resnet18_best_acc.pth'\n",
    "BinCifar5_state_dict = torch.load(PATH,map_location= device)\n",
    "\n",
    "\n",
    "layers = ['layer1','layer2','layer3']\n",
    "channels = [80,160,320]\n",
    "\n",
    "\n",
    "for layer,channel in zip(layers,channels):\n",
    "    for t in ['adp_only']:\n",
    "        print(t,layer,channel)\n",
    "        torch.manual_seed(42)\n",
    "        adapter_model = resnet18_adapt(num_classes=5)\n",
    "        adapter_model.load_state_dict(BinCifar5_state_dict)\n",
    "        \n",
    "        if t == 'adp_only':\n",
    "            adapter_model.freeze()\n",
    "        conv_adp = conv_adapter(channel,kernel = 1, padding= 0)\n",
    "        conv_adp.init_weight_zeros()\n",
    "\n",
    "        adapter_model.add_adapter(after = layer,adapter = conv_adp)\n",
    "        trainer = adapter_Trainer(model = adapter_model,seed = 123,model_name = f'adp_{layer}_{t}',project_name = 'Cifar5',classes = classes,binarise= True)\n",
    "        m = trainer.model\n",
    "        m.to(trainer.device)\n",
    "        for head in [m.fc,m.bn3,m.bn3]:\n",
    "            for p in head.parameters():\n",
    "                p.requires_grad = True\n",
    "            head.train()\n",
    "        trainer.lr = 0.01\n",
    "        trainer.batch_size = 32\n",
    "        trainer.epochs =100\n",
    "        trainer.epoch_chkpts = []\n",
    "        trainer.start_epoch = 0\n",
    "        # trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max= trainer.epochs)\n",
    "        trainer.tags = ['finetune',f'Training: {t}',f'Adpater Location {layer}']\n",
    "        trainer.train(train59_loader,test59_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eff35e",
   "metadata": {},
   "source": [
    "## Adp = FullFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "PATH = '.\\SavedModels\\Cifar5\\Baseline_BNN_Resnet18_2022_10_21_10_47_20\\Baseline_BNN_Resnet18_best_acc.pth'\n",
    "BinCifar5_state_dict = torch.load(PATH,map_location= device)\n",
    "\n",
    "\n",
    "layers = ['layer1','layer2','layer3']\n",
    "channels = [80,160,320]\n",
    "\n",
    "\n",
    "for layer,channel in zip(layers,channels):\n",
    "    for t in ['full_ft']:\n",
    "        print(t,layer,channel)\n",
    "        torch.manual_seed(42)\n",
    "        adapter_model = resnet18_adapt(num_classes=5)\n",
    "        adapter_model.load_state_dict(BinCifar5_state_dict)\n",
    "        \n",
    "        if t == 'adp_only':\n",
    "            adapter_model.freeze()\n",
    "        conv_adp = conv_adapter(channel,kernel = 1, padding= 0)\n",
    "        conv_adp.init_weight_zeros()\n",
    "        adapter_model.add_adapter(after = layer,adapter = conv_adp)\n",
    "        trainer = adapter_Trainer(model = adapter_model,seed = 123,model_name = f'adp_{layer}_{t}',project_name = 'Cifar5',classes = classes,binarise= True)\n",
    "        m = trainer.model\n",
    "        m.to(trainer.device)\n",
    "        for head in [m.fc,m.bn3,m.bn3]:\n",
    "            for p in head.parameters():\n",
    "                p.requires_grad = True\n",
    "            head.train()\n",
    "        trainer.lr = 0.01\n",
    "        trainer.batch_size = 32\n",
    "        trainer.epochs =100\n",
    "        trainer.epoch_chkpts = []\n",
    "        trainer.start_epoch = 0\n",
    "        # trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max= trainer.epochs)\n",
    "        trainer.tags = ['finetune',f'Training: {t}',f'Adpater Location {layer}','Init_weight: {} ']\n",
    "        trainer.train(train59_loader,test59_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

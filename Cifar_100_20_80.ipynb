{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bb2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_Thesis.nn_classes import *\n",
    "from NN_Thesis.trainer import *\n",
    "from NN_Thesis.adapters import *\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c5ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_Thesis.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb6e4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 3, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.5034, 0.4852, 0.4427]), tensor([0.2684, 0.2562, 0.2766]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "random.seed(123)\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "from NN_Thesis.dataset import cifar_100_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_path = 'data/cifar-100/cifar-80/'\n",
    "\n",
    "train_data = cifar_100_split(data_path,train = True)\n",
    "test_data = cifar_100_split(data_path,train = False)\n",
    "\n",
    "\n",
    "def normalize_channels(data):\n",
    "    #We have a nxCxWxH array\n",
    "    d = data\n",
    "    d = torch.flatten(data,2,-1).to(dtype = torch.float32)\n",
    "    print(d.shape)\n",
    "    mean= torch.mean(d,dim = [0,2])\n",
    "    std = torch.std(d,dim = [0,2])\n",
    "    return mean,std\n",
    "\n",
    "\n",
    "mean,std = normalize_channels(train_data.data)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_data.transform = train_transform\n",
    "test_data.transform = test_transform\n",
    "\n",
    "mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d234b683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 3, 1024])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Cifar_100_20_80.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Su/Downloads/SydneyUni/thesis/Thesis/Cifar_100_20_80.ipynb#X53sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m mean,std\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Su/Downloads/SydneyUni/thesis/Thesis/Cifar_100_20_80.ipynb#X53sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m img \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39mdata[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/John%20Su/Downloads/SydneyUni/thesis/Thesis/Cifar_100_20_80.ipynb#X53sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m img \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39;49mToTensor()(img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Su/Downloads/SydneyUni/thesis/Thesis/Cifar_100_20_80.ipynb#X53sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m img\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\transforms\\transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    127\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\transforms\\functional.py:138\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    136\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[0;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (F_pil\u001b[39m.\u001b[39m_is_pil_image(pic) \u001b[39mor\u001b[39;00m _is_numpy(pic)):\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(pic)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    140\u001b[0m \u001b[39mif\u001b[39;00m _is_numpy(pic) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[0;32m    141\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be 2/3 dimensional. Got \u001b[39m\u001b[39m{\u001b[39;00mpic\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m dimensions.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d94e3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oak_tree\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotImage(dataset,idx):\n",
    "    img,label = dataset[idx]\n",
    "    img = (255*img).to(torch.uint8).numpy()\n",
    "    img = np.moveaxis(img,0,-1)\n",
    "    print(dataset.classes[label])\n",
    "    plt.imshow(img)\n",
    "\n",
    "idx = random.randint(0,len(train_data))\n",
    "plotImage(train_data,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa0941e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_data,batch_size =64,shuffle = True)\n",
    "\n",
    "x = train_data[0]\n",
    "img,label = next(iter(train_dataloader))\n",
    "\n",
    "img.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf0c4b0",
   "metadata": {},
   "source": [
    "# Code For Initial Cifar5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b940877d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet_cifar10(\n",
       "  (conv1): BinarizeConv2d(3, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (tanh1): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "  (tanh2): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): BinarizeConv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (tanh1): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "      (conv2): BinarizeConv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (tanh2): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): BinarizeConv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (tanh1): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "      (conv2): BinarizeConv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (tanh2): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): BinarizeConv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (tanh1): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "      (conv2): BinarizeConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (tanh2): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): BinarizeConv2d(80, 160, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): BinarizeConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (tanh1): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "      (conv2): BinarizeConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (tanh2): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): BinarizeConv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (tanh1): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "      (conv2): BinarizeConv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (tanh2): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): BinarizeConv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): BinarizeConv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (tanh1): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "      (conv2): BinarizeConv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (tanh2): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (bn2): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (logsoftmax): LogSoftmax(dim=-1)\n",
       "  (fc): BinarizeLinear(in_features=320, out_features=80, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BNN_resnet18 = resnet_binary(num_classes = 80 , depth = 18, dataset = 'cifar10')\n",
    "\n",
    "BNN_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d540a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnny_suu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221025_090754-1mco3trz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/1mco3trz\" target=\"_blank\">incandescent-moon-24</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name Baseline_Resnet18 \n",
      "\n",
      "\n",
      "Run Start : 2022-10-25 09-07-51\n",
      "start_epoch : 0\n",
      "initial_lr : 0.2\n",
      "batch_size : 64\n",
      "epochs : 200\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.models.resnet.ResNet_cifar10'>\n",
      "binerised_training : False\n",
      "Number of Elements : 179808\n",
      "Initial accuracy:\n",
      "Test Accuracy : 1.2%, Test Loss: 4.484759097290039\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 1.1%, Test Loss: 4.472571231842041\n",
      "epoch: 1 average loss: 3.708\n",
      "Test Accuracy : 15.6%, Test Loss: 3.3641172828674315\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.44 seconds\n",
      "epoch: 2 average loss: 3.144\n",
      "Test Accuracy : 24.8%, Test Loss: 2.951922887802124\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.30 seconds\n",
      "epoch: 3 average loss: 2.735\n",
      "Test Accuracy : 27.4%, Test Loss: 2.9499129428863524\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.01 seconds\n",
      "epoch: 4 average loss: 2.423\n",
      "Test Accuracy : 36.0%, Test Loss: 2.4599291439056397\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.18 seconds\n",
      "epoch: 5 average loss: 2.186\n",
      "Test Accuracy : 40.6%, Test Loss: 2.2579381170272828\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.01 seconds\n",
      "epoch: 6 average loss: 2.015\n",
      "Test Accuracy : 43.1%, Test Loss: 2.248494715690613\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.16 seconds\n",
      "epoch: 7 average loss: 1.868\n",
      "Test Accuracy : 47.3%, Test Loss: 1.961914144515991\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.06 seconds\n",
      "epoch: 8 average loss: 1.753\n",
      "Test Accuracy : 49.1%, Test Loss: 1.871227765083313\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.00 seconds\n",
      "epoch: 9 average loss: 1.650\n",
      "Test Accuracy : 52.4%, Test Loss: 1.7301492490768433\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.06 seconds\n",
      "epoch: 10 average loss: 1.564\n",
      "Test Accuracy : 53.5%, Test Loss: 1.7605241165161132\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.04 seconds\n",
      "epoch: 11 average loss: 1.495\n",
      "Test Accuracy : 54.4%, Test Loss: 1.6889599103927613\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.05 seconds\n",
      "epoch: 12 average loss: 1.425\n",
      "Test Accuracy : 56.2%, Test Loss: 1.623530514717102\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 13.87 seconds\n",
      "epoch: 13 average loss: 1.362\n",
      "Test Accuracy : 57.8%, Test Loss: 1.5485787296295166\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 13.83 seconds\n",
      "epoch: 14 average loss: 1.308\n",
      "Test Accuracy : 58.9%, Test Loss: 1.5187776608467103\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.07 seconds\n",
      "epoch: 15 average loss: 1.254\n",
      "Test Accuracy : 59.8%, Test Loss: 1.4916467366218567\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.05 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Cifar_100_20_80.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Su/Downloads/SydneyUni/thesis/Thesis/Cifar_100_20_80.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m trainer\u001b[39m.\u001b[39mlr \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Su/Downloads/SydneyUni/thesis/Thesis/Cifar_100_20_80.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m trainer\u001b[39m.\u001b[39mepochs \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/John%20Su/Downloads/SydneyUni/thesis/Thesis/Cifar_100_20_80.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(train_dataloader,test_dataloader)\n",
      "File \u001b[1;32mc:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\NN_Thesis\\trainer.py:150\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, trainloader, testloader, **wandb_kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m    149\u001b[0m \u001b[39m#Train and Test Results\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m train_loss,(test_loss,test_acc)\u001b[39m=\u001b[39m  (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_epoch(epoch,trainloader),\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest(testloader))\n\u001b[0;32m    151\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_losses\u001b[39m.\u001b[39mappend( (train_loss,test_loss,test_acc))\n\u001b[0;32m    153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_time\n",
      "File \u001b[1;32mc:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\NN_Thesis\\trainer.py:229\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[1;34m(self, epoch, trainloader)\u001b[0m\n\u001b[0;32m    227\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(images)\n\u001b[0;32m    228\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(outputs, labels)\n\u001b[1;32m--> 229\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    231\u001b[0m \u001b[39m#Change the weight back to non binarised and then clamp weight between 1 and -1\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinarise:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_data,batch_size =64,shuffle = True,num_workers=4,pin_memory=True)\n",
    "test_dataloader = DataLoader(test_data,batch_size =64,num_workers=4,pin_memory=True)\n",
    "\n",
    "classes = tuple(train_data.classes)\n",
    "\n",
    "BNN_resnet18 = resnet_binary(num_classes = 80 , depth = 18, dataset = 'cifar10')\n",
    "resnet18 = resnet(num_classes = 80 , depth = 18, dataset = 'cifar10')\n",
    "\n",
    "\n",
    "BNN_trainer = Trainer(BNN_resnet18,model_name = 'Baseline_BNN_Resnet18',project_name = 'Cifar80-20',classes = classes,seed = 123,binarise = True)\n",
    "resnet_trainer =Trainer(resnet18,model_name = 'Baseline_Resnet18',project_name='Cifar80-20',classes = classes,seed = 123)\n",
    "\n",
    "#Set Training Params\n",
    "for trainer in [resnet_trainer,BNN_trainer]:\n",
    "    trainer.lr = 0.2\n",
    "    trainer.epochs = 200\n",
    "    trainer.train(train_dataloader,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490c822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df59347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Default (SGD) Optimizer\n",
      "Scheduler Set {'T_max': 200, 'eta_min': 0, 'base_lrs': [0.2], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.2]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2halhpu7) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">proud-frost-8</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/2halhpu7\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/2halhpu7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221023_095707-2halhpu7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2halhpu7). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42bd0291038c407a9e7bc45069c28a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221023_095719-2pc3read</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/2pc3read\" target=\"_blank\">giddy-smoke-9</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name Baseline_BNN_Resnet18_inflate_1 \n",
      "\n",
      "\n",
      "Run Start : 2022-10-23 09-57-19\n",
      "start_epoch : 0\n",
      "initial_lr : 0.2\n",
      "batch_size : 32\n",
      "epochs : 200\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.2\n",
      "    lr: 0.2\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.models.resnet_binary.ResNet_cifar10'>\n",
      "binerised_training : True\n",
      "Number of Elements : 180096\n",
      "Initial accuracy:\n",
      "Test Accuracy : 1.3%, Test Loss: 19.607304489135743\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 1.2%, Test Loss: 19.53532987976074\n",
      "epoch: 1 average loss: 4.201\n",
      "Test Accuracy : 6.8%, Test Loss: 4.003477426528931\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.18 seconds\n",
      "epoch: 2 average loss: 3.913\n",
      "Test Accuracy : 8.3%, Test Loss: 3.8278928184509278\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.18 seconds\n",
      "epoch: 3 average loss: 3.780\n",
      "Test Accuracy : 9.9%, Test Loss: 3.738513731002808\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.37 seconds\n",
      "epoch: 4 average loss: 3.701\n",
      "Test Accuracy : 11.8%, Test Loss: 3.6740194931030272\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.18 seconds\n",
      "epoch: 5 average loss: 3.637\n",
      "Test Accuracy : 12.2%, Test Loss: 3.588625577926636\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.17 seconds\n",
      "epoch: 6 average loss: 3.602\n",
      "Test Accuracy : 12.8%, Test Loss: 3.5489267864227294\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.10 seconds\n",
      "epoch: 7 average loss: 3.558\n",
      "Test Accuracy : 13.7%, Test Loss: 3.506737024307251\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.87 seconds\n",
      "epoch: 8 average loss: 3.512\n",
      "Test Accuracy : 13.9%, Test Loss: 3.497140823364258\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.93 seconds\n",
      "epoch: 9 average loss: 3.489\n",
      "Test Accuracy : 15.4%, Test Loss: 3.428533712387085\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.85 seconds\n",
      "epoch: 10 average loss: 3.461\n",
      "Test Accuracy : 15.8%, Test Loss: 3.4042883491516114\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.03 seconds\n",
      "epoch: 11 average loss: 3.438\n",
      "Test Accuracy : 15.7%, Test Loss: 3.396643669128418\n",
      "Epoch Time (Training + Test) = 15.01 seconds\n",
      "epoch: 12 average loss: 3.415\n",
      "Test Accuracy : 15.7%, Test Loss: 3.425557285308838\n",
      "Epoch Time (Training + Test) = 16.06 seconds\n",
      "epoch: 13 average loss: 3.401\n",
      "Test Accuracy : 16.7%, Test Loss: 3.383439453125\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 16.15 seconds\n",
      "epoch: 14 average loss: 3.394\n",
      "Test Accuracy : 16.9%, Test Loss: 3.3888914012908935\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.79 seconds\n",
      "epoch: 15 average loss: 3.369\n",
      "Test Accuracy : 16.7%, Test Loss: 3.4039550952911375\n",
      "Epoch Time (Training + Test) = 15.06 seconds\n",
      "epoch: 16 average loss: 3.373\n",
      "Test Accuracy : 16.7%, Test Loss: 3.355097148895264\n",
      "Epoch Time (Training + Test) = 14.80 seconds\n",
      "epoch: 17 average loss: 3.350\n",
      "Test Accuracy : 17.8%, Test Loss: 3.3069097862243653\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.90 seconds\n",
      "epoch: 18 average loss: 3.344\n",
      "Test Accuracy : 18.9%, Test Loss: 3.2657102966308593\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.99 seconds\n",
      "epoch: 19 average loss: 3.330\n",
      "Test Accuracy : 18.8%, Test Loss: 3.284082920074463\n",
      "Epoch Time (Training + Test) = 14.73 seconds\n",
      "epoch: 20 average loss: 3.323\n",
      "Test Accuracy : 17.7%, Test Loss: 3.357802463531494\n",
      "Epoch Time (Training + Test) = 14.91 seconds\n",
      "epoch: 21 average loss: 3.312\n",
      "Test Accuracy : 18.3%, Test Loss: 3.307969274520874\n",
      "Epoch Time (Training + Test) = 14.73 seconds\n",
      "epoch: 22 average loss: 3.301\n",
      "Test Accuracy : 19.2%, Test Loss: 3.2402249488830566\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.74 seconds\n",
      "epoch: 23 average loss: 3.300\n",
      "Test Accuracy : 18.1%, Test Loss: 3.2696818714141846\n",
      "Epoch Time (Training + Test) = 14.75 seconds\n",
      "epoch: 24 average loss: 3.271\n",
      "Test Accuracy : 19.0%, Test Loss: 3.257704772949219\n",
      "Epoch Time (Training + Test) = 15.12 seconds\n",
      "epoch: 25 average loss: 3.269\n",
      "Test Accuracy : 19.6%, Test Loss: 3.229490720748901\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.86 seconds\n",
      "epoch: 26 average loss: 3.259\n",
      "Test Accuracy : 19.2%, Test Loss: 3.2742730350494385\n",
      "Epoch Time (Training + Test) = 15.04 seconds\n",
      "epoch: 27 average loss: 3.251\n",
      "Test Accuracy : 19.9%, Test Loss: 3.2286049823760985\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.70 seconds\n",
      "epoch: 28 average loss: 3.246\n",
      "Test Accuracy : 19.8%, Test Loss: 3.223465913772583\n",
      "Epoch Time (Training + Test) = 15.34 seconds\n",
      "epoch: 29 average loss: 3.245\n",
      "Test Accuracy : 19.9%, Test Loss: 3.201879453659058\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.87 seconds\n",
      "epoch: 30 average loss: 3.233\n",
      "Test Accuracy : 20.1%, Test Loss: 3.2190933170318603\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.89 seconds\n",
      "epoch: 31 average loss: 3.229\n",
      "Test Accuracy : 19.5%, Test Loss: 3.210584897994995\n",
      "Epoch Time (Training + Test) = 14.74 seconds\n",
      "epoch: 32 average loss: 3.221\n",
      "Test Accuracy : 20.4%, Test Loss: 3.1925155239105223\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.17 seconds\n",
      "epoch: 33 average loss: 3.209\n",
      "Test Accuracy : 20.9%, Test Loss: 3.1900695953369143\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.67 seconds\n",
      "epoch: 34 average loss: 3.208\n",
      "Test Accuracy : 20.4%, Test Loss: 3.1690801639556883\n",
      "Epoch Time (Training + Test) = 15.30 seconds\n",
      "epoch: 35 average loss: 3.208\n",
      "Test Accuracy : 21.0%, Test Loss: 3.169017921447754\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 15.58 seconds\n",
      "epoch: 36 average loss: 3.196\n",
      "Test Accuracy : 20.6%, Test Loss: 3.18104697227478\n",
      "Epoch Time (Training + Test) = 15.17 seconds\n",
      "epoch: 37 average loss: 3.178\n",
      "Test Accuracy : 20.7%, Test Loss: 3.1671916542053222\n",
      "Epoch Time (Training + Test) = 14.93 seconds\n",
      "epoch: 38 average loss: 3.174\n",
      "Test Accuracy : 19.9%, Test Loss: 3.2057340316772462\n",
      "Epoch Time (Training + Test) = 15.07 seconds\n",
      "epoch: 39 average loss: 3.169\n",
      "Test Accuracy : 21.3%, Test Loss: 3.1713531856536865\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.98 seconds\n",
      "epoch: 40 average loss: 3.165\n",
      "Test Accuracy : 21.7%, Test Loss: 3.1438109664916993\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.92 seconds\n",
      "epoch: 41 average loss: 3.155\n",
      "Test Accuracy : 21.4%, Test Loss: 3.1460100650787353\n",
      "Epoch Time (Training + Test) = 14.85 seconds\n",
      "epoch: 42 average loss: 3.151\n",
      "Test Accuracy : 21.6%, Test Loss: 3.143396696090698\n",
      "Epoch Time (Training + Test) = 14.86 seconds\n",
      "epoch: 43 average loss: 3.152\n",
      "Test Accuracy : 22.0%, Test Loss: 3.0980701732635496\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.87 seconds\n",
      "epoch: 44 average loss: 3.149\n",
      "Test Accuracy : 22.5%, Test Loss: 3.0904064731597902\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.88 seconds\n",
      "epoch: 45 average loss: 3.144\n",
      "Test Accuracy : 21.3%, Test Loss: 3.1453187694549563\n",
      "Epoch Time (Training + Test) = 14.87 seconds\n",
      "epoch: 46 average loss: 3.136\n",
      "Test Accuracy : 23.3%, Test Loss: 3.0634838829040527\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.93 seconds\n",
      "epoch: 47 average loss: 3.143\n",
      "Test Accuracy : 21.8%, Test Loss: 3.1400647964477537\n",
      "Epoch Time (Training + Test) = 14.90 seconds\n",
      "epoch: 48 average loss: 3.130\n",
      "Test Accuracy : 21.6%, Test Loss: 3.142390607833862\n",
      "Epoch Time (Training + Test) = 15.00 seconds\n",
      "epoch: 49 average loss: 3.129\n",
      "Test Accuracy : 22.5%, Test Loss: 3.109894659042358\n",
      "Epoch Time (Training + Test) = 15.17 seconds\n",
      "epoch: 50 average loss: 3.116\n",
      "Test Accuracy : 22.1%, Test Loss: 3.123165885925293\n",
      "Epoch Time (Training + Test) = 15.15 seconds\n",
      "epoch: 51 average loss: 3.123\n",
      "Test Accuracy : 23.0%, Test Loss: 3.112294776916504\n",
      "Epoch Time (Training + Test) = 15.09 seconds\n",
      "epoch: 52 average loss: 3.113\n",
      "Test Accuracy : 22.1%, Test Loss: 3.1116019821166994\n",
      "Epoch Time (Training + Test) = 15.05 seconds\n",
      "epoch: 53 average loss: 3.102\n",
      "Test Accuracy : 23.1%, Test Loss: 3.073721429824829\n",
      "Epoch Time (Training + Test) = 14.78 seconds\n",
      "epoch: 54 average loss: 3.110\n",
      "Test Accuracy : 22.4%, Test Loss: 3.0789672508239745\n",
      "Epoch Time (Training + Test) = 14.84 seconds\n",
      "epoch: 55 average loss: 3.096\n",
      "Test Accuracy : 22.6%, Test Loss: 3.0954183158874513\n",
      "Epoch Time (Training + Test) = 14.80 seconds\n",
      "epoch: 56 average loss: 3.094\n",
      "Test Accuracy : 21.6%, Test Loss: 3.1597572078704834\n",
      "Epoch Time (Training + Test) = 14.45 seconds\n",
      "epoch: 57 average loss: 3.100\n",
      "Test Accuracy : 21.5%, Test Loss: 3.1412974491119385\n",
      "Epoch Time (Training + Test) = 14.48 seconds\n",
      "epoch: 58 average loss: 3.086\n",
      "Test Accuracy : 22.0%, Test Loss: 3.141468999862671\n",
      "Epoch Time (Training + Test) = 14.55 seconds\n",
      "epoch: 59 average loss: 3.077\n",
      "Test Accuracy : 23.1%, Test Loss: 3.025468494415283\n",
      "Epoch Time (Training + Test) = 14.38 seconds\n",
      "epoch: 60 average loss: 3.073\n",
      "Test Accuracy : 23.5%, Test Loss: 3.075980405807495\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.45 seconds\n",
      "epoch: 61 average loss: 3.070\n",
      "Test Accuracy : 23.2%, Test Loss: 3.0584379959106447\n",
      "Epoch Time (Training + Test) = 14.39 seconds\n",
      "epoch: 62 average loss: 3.063\n",
      "Test Accuracy : 22.8%, Test Loss: 3.065165802001953\n",
      "Epoch Time (Training + Test) = 14.64 seconds\n",
      "epoch: 63 average loss: 3.070\n",
      "Test Accuracy : 24.3%, Test Loss: 3.037657911300659\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.34 seconds\n",
      "epoch: 64 average loss: 3.059\n",
      "Test Accuracy : 22.8%, Test Loss: 3.101889795303345\n",
      "Epoch Time (Training + Test) = 14.40 seconds\n",
      "epoch: 65 average loss: 3.057\n",
      "Test Accuracy : 22.4%, Test Loss: 3.0821705837249755\n",
      "Epoch Time (Training + Test) = 14.36 seconds\n",
      "epoch: 66 average loss: 3.048\n",
      "Test Accuracy : 22.1%, Test Loss: 3.1426153774261474\n",
      "Epoch Time (Training + Test) = 14.53 seconds\n",
      "epoch: 67 average loss: 3.059\n",
      "Test Accuracy : 22.2%, Test Loss: 3.1125110626220702\n",
      "Epoch Time (Training + Test) = 14.79 seconds\n",
      "epoch: 68 average loss: 3.050\n",
      "Test Accuracy : 23.2%, Test Loss: 3.0636649150848387\n",
      "Epoch Time (Training + Test) = 14.56 seconds\n",
      "epoch: 69 average loss: 3.052\n",
      "Test Accuracy : 24.3%, Test Loss: 2.998315231323242\n",
      "Epoch Time (Training + Test) = 14.39 seconds\n",
      "epoch: 70 average loss: 3.049\n",
      "Test Accuracy : 23.1%, Test Loss: 3.0754988288879392\n",
      "Epoch Time (Training + Test) = 14.49 seconds\n",
      "epoch: 71 average loss: 3.047\n",
      "Test Accuracy : 24.0%, Test Loss: 3.0394249095916748\n",
      "Epoch Time (Training + Test) = 14.96 seconds\n",
      "epoch: 72 average loss: 3.041\n",
      "Test Accuracy : 23.6%, Test Loss: 3.0344870853424073\n",
      "Epoch Time (Training + Test) = 14.53 seconds\n",
      "epoch: 73 average loss: 3.042\n",
      "Test Accuracy : 24.1%, Test Loss: 3.011583003997803\n",
      "Epoch Time (Training + Test) = 14.32 seconds\n",
      "epoch: 74 average loss: 3.031\n",
      "Test Accuracy : 25.1%, Test Loss: 2.979317455291748\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.42 seconds\n",
      "epoch: 75 average loss: 3.034\n",
      "Test Accuracy : 23.9%, Test Loss: 3.025202989578247\n",
      "Epoch Time (Training + Test) = 14.42 seconds\n",
      "epoch: 76 average loss: 3.025\n",
      "Test Accuracy : 23.0%, Test Loss: 3.09875860786438\n",
      "Epoch Time (Training + Test) = 14.58 seconds\n",
      "epoch: 77 average loss: 3.019\n",
      "Test Accuracy : 24.9%, Test Loss: 2.995512958526611\n",
      "Epoch Time (Training + Test) = 14.59 seconds\n",
      "epoch: 78 average loss: 3.024\n",
      "Test Accuracy : 24.7%, Test Loss: 2.9913625202178955\n",
      "Epoch Time (Training + Test) = 15.00 seconds\n",
      "epoch: 79 average loss: 3.017\n",
      "Test Accuracy : 25.3%, Test Loss: 2.9867462997436522\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.87 seconds\n",
      "epoch: 80 average loss: 3.022\n",
      "Test Accuracy : 24.6%, Test Loss: 3.002017406463623\n",
      "Epoch Time (Training + Test) = 15.10 seconds\n",
      "epoch: 81 average loss: 3.014\n",
      "Test Accuracy : 25.0%, Test Loss: 3.0086562271118162\n",
      "Epoch Time (Training + Test) = 14.51 seconds\n",
      "epoch: 82 average loss: 3.007\n",
      "Test Accuracy : 24.1%, Test Loss: 3.0176441135406495\n",
      "Epoch Time (Training + Test) = 14.63 seconds\n",
      "epoch: 83 average loss: 3.013\n",
      "Test Accuracy : 24.1%, Test Loss: 3.0033882007598875\n",
      "Epoch Time (Training + Test) = 15.01 seconds\n",
      "epoch: 84 average loss: 3.011\n",
      "Test Accuracy : 24.5%, Test Loss: 3.007871244430542\n",
      "Epoch Time (Training + Test) = 14.91 seconds\n",
      "epoch: 85 average loss: 3.001\n",
      "Test Accuracy : 25.5%, Test Loss: 2.972735034942627\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.69 seconds\n",
      "epoch: 86 average loss: 2.994\n",
      "Test Accuracy : 25.8%, Test Loss: 2.9542968673706054\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.79 seconds\n",
      "epoch: 87 average loss: 2.997\n",
      "Test Accuracy : 24.4%, Test Loss: 3.000119846343994\n",
      "Epoch Time (Training + Test) = 14.91 seconds\n",
      "epoch: 88 average loss: 3.001\n",
      "Test Accuracy : 24.8%, Test Loss: 2.960746019363403\n",
      "Epoch Time (Training + Test) = 15.07 seconds\n",
      "epoch: 89 average loss: 2.992\n",
      "Test Accuracy : 25.2%, Test Loss: 2.962097578048706\n",
      "Epoch Time (Training + Test) = 15.03 seconds\n",
      "epoch: 90 average loss: 3.000\n",
      "Test Accuracy : 25.0%, Test Loss: 2.9961982345581055\n",
      "Epoch Time (Training + Test) = 14.65 seconds\n",
      "epoch: 91 average loss: 2.991\n",
      "Test Accuracy : 25.0%, Test Loss: 2.995120958328247\n",
      "Epoch Time (Training + Test) = 14.45 seconds\n",
      "epoch: 92 average loss: 2.988\n",
      "Test Accuracy : 25.0%, Test Loss: 2.978436393737793\n",
      "Epoch Time (Training + Test) = 14.55 seconds\n",
      "epoch: 93 average loss: 2.991\n",
      "Test Accuracy : 24.1%, Test Loss: 2.9844922065734862\n",
      "Epoch Time (Training + Test) = 14.49 seconds\n",
      "epoch: 94 average loss: 2.979\n",
      "Test Accuracy : 23.5%, Test Loss: 3.0362287921905518\n",
      "Epoch Time (Training + Test) = 14.43 seconds\n",
      "epoch: 95 average loss: 2.977\n",
      "Test Accuracy : 24.7%, Test Loss: 3.015907175064087\n",
      "Epoch Time (Training + Test) = 14.45 seconds\n",
      "epoch: 96 average loss: 2.974\n",
      "Test Accuracy : 25.2%, Test Loss: 2.944741291046143\n",
      "Epoch Time (Training + Test) = 14.73 seconds\n",
      "epoch: 97 average loss: 2.967\n",
      "Test Accuracy : 27.6%, Test Loss: 2.8867174396514894\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.55 seconds\n",
      "epoch: 98 average loss: 2.972\n",
      "Test Accuracy : 25.6%, Test Loss: 2.9500604629516602\n",
      "Epoch Time (Training + Test) = 14.95 seconds\n",
      "epoch: 99 average loss: 2.974\n",
      "Test Accuracy : 26.2%, Test Loss: 2.9281123695373537\n",
      "Epoch Time (Training + Test) = 14.66 seconds\n",
      "epoch: 100 average loss: 2.970\n",
      "Test Accuracy : 24.2%, Test Loss: 3.03709041595459\n",
      "Epoch Time (Training + Test) = 15.06 seconds\n",
      "epoch: 101 average loss: 2.970\n",
      "Test Accuracy : 24.2%, Test Loss: 3.0072583904266357\n",
      "Epoch Time (Training + Test) = 15.83 seconds\n",
      "epoch: 102 average loss: 2.969\n",
      "Test Accuracy : 25.6%, Test Loss: 2.990346483230591\n",
      "Epoch Time (Training + Test) = 14.91 seconds\n",
      "epoch: 103 average loss: 2.959\n",
      "Test Accuracy : 24.8%, Test Loss: 2.9762402477264405\n",
      "Epoch Time (Training + Test) = 14.87 seconds\n",
      "epoch: 104 average loss: 2.949\n",
      "Test Accuracy : 24.4%, Test Loss: 2.9601002254486084\n",
      "Epoch Time (Training + Test) = 14.99 seconds\n",
      "epoch: 105 average loss: 2.958\n",
      "Test Accuracy : 24.6%, Test Loss: 3.0106907081604004\n",
      "Epoch Time (Training + Test) = 14.81 seconds\n",
      "epoch: 106 average loss: 2.958\n",
      "Test Accuracy : 26.2%, Test Loss: 2.935791648864746\n",
      "Epoch Time (Training + Test) = 14.78 seconds\n",
      "epoch: 107 average loss: 2.955\n",
      "Test Accuracy : 25.6%, Test Loss: 2.9344917488098146\n",
      "Epoch Time (Training + Test) = 15.10 seconds\n",
      "epoch: 108 average loss: 2.962\n",
      "Test Accuracy : 26.4%, Test Loss: 2.905346221923828\n",
      "Epoch Time (Training + Test) = 14.88 seconds\n",
      "epoch: 109 average loss: 2.951\n",
      "Test Accuracy : 26.6%, Test Loss: 2.925231418609619\n",
      "Epoch Time (Training + Test) = 15.35 seconds\n",
      "epoch: 110 average loss: 2.955\n",
      "Test Accuracy : 26.3%, Test Loss: 2.910422216415405\n",
      "Epoch Time (Training + Test) = 14.84 seconds\n",
      "epoch: 111 average loss: 2.950\n",
      "Test Accuracy : 26.5%, Test Loss: 2.8981742439270017\n",
      "Epoch Time (Training + Test) = 14.97 seconds\n",
      "epoch: 112 average loss: 2.941\n",
      "Test Accuracy : 25.8%, Test Loss: 2.9116221313476562\n",
      "Epoch Time (Training + Test) = 15.00 seconds\n",
      "epoch: 113 average loss: 2.934\n",
      "Test Accuracy : 26.1%, Test Loss: 2.9350274276733397\n",
      "Epoch Time (Training + Test) = 15.04 seconds\n",
      "epoch: 114 average loss: 2.936\n",
      "Test Accuracy : 27.2%, Test Loss: 2.9136371421813965\n",
      "Epoch Time (Training + Test) = 15.14 seconds\n",
      "epoch: 115 average loss: 2.935\n",
      "Test Accuracy : 26.7%, Test Loss: 2.9074003162384034\n",
      "Epoch Time (Training + Test) = 15.35 seconds\n",
      "epoch: 116 average loss: 2.944\n",
      "Test Accuracy : 24.7%, Test Loss: 2.982618444442749\n",
      "Epoch Time (Training + Test) = 15.17 seconds\n",
      "epoch: 117 average loss: 2.938\n",
      "Test Accuracy : 24.8%, Test Loss: 3.0198363189697264\n",
      "Epoch Time (Training + Test) = 14.88 seconds\n",
      "epoch: 118 average loss: 2.940\n",
      "Test Accuracy : 26.8%, Test Loss: 2.9308394622802734\n",
      "Epoch Time (Training + Test) = 14.96 seconds\n",
      "epoch: 119 average loss: 2.938\n",
      "Test Accuracy : 27.1%, Test Loss: 2.868793186187744\n",
      "Epoch Time (Training + Test) = 14.79 seconds\n",
      "epoch: 120 average loss: 2.935\n",
      "Test Accuracy : 25.9%, Test Loss: 2.921269779205322\n",
      "Epoch Time (Training + Test) = 14.52 seconds\n",
      "epoch: 121 average loss: 2.929\n",
      "Test Accuracy : 27.5%, Test Loss: 2.8591509532928465\n",
      "Epoch Time (Training + Test) = 14.98 seconds\n",
      "epoch: 122 average loss: 2.922\n",
      "Test Accuracy : 26.2%, Test Loss: 2.936081359863281\n",
      "Epoch Time (Training + Test) = 14.96 seconds\n",
      "epoch: 123 average loss: 2.925\n",
      "Test Accuracy : 26.7%, Test Loss: 2.90543723487854\n",
      "Epoch Time (Training + Test) = 14.86 seconds\n",
      "epoch: 124 average loss: 2.924\n",
      "Test Accuracy : 26.9%, Test Loss: 2.8847227706909178\n",
      "Epoch Time (Training + Test) = 14.82 seconds\n",
      "epoch: 125 average loss: 2.916\n",
      "Test Accuracy : 27.4%, Test Loss: 2.8790164127349853\n",
      "Epoch Time (Training + Test) = 14.79 seconds\n",
      "epoch: 126 average loss: 2.923\n",
      "Test Accuracy : 27.0%, Test Loss: 2.864565486907959\n",
      "Epoch Time (Training + Test) = 15.37 seconds\n",
      "epoch: 127 average loss: 2.908\n",
      "Test Accuracy : 25.9%, Test Loss: 2.9328498687744142\n",
      "Epoch Time (Training + Test) = 15.01 seconds\n",
      "epoch: 128 average loss: 2.922\n",
      "Test Accuracy : 27.3%, Test Loss: 2.8593640441894532\n",
      "Epoch Time (Training + Test) = 14.71 seconds\n",
      "epoch: 129 average loss: 2.911\n",
      "Test Accuracy : 26.6%, Test Loss: 2.914280303955078\n",
      "Epoch Time (Training + Test) = 14.87 seconds\n",
      "epoch: 130 average loss: 2.906\n",
      "Test Accuracy : 27.5%, Test Loss: 2.8576986865997314\n",
      "Epoch Time (Training + Test) = 14.70 seconds\n",
      "epoch: 131 average loss: 2.902\n",
      "Test Accuracy : 27.6%, Test Loss: 2.8679564151763914\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.91 seconds\n",
      "epoch: 132 average loss: 2.895\n",
      "Test Accuracy : 26.2%, Test Loss: 2.895417715072632\n",
      "Epoch Time (Training + Test) = 15.05 seconds\n",
      "epoch: 133 average loss: 2.901\n",
      "Test Accuracy : 27.1%, Test Loss: 2.87816845703125\n",
      "Epoch Time (Training + Test) = 14.75 seconds\n",
      "epoch: 134 average loss: 2.903\n",
      "Test Accuracy : 25.5%, Test Loss: 2.9630505237579348\n",
      "Epoch Time (Training + Test) = 14.65 seconds\n",
      "epoch: 135 average loss: 2.905\n",
      "Test Accuracy : 26.9%, Test Loss: 2.8585713119506835\n",
      "Epoch Time (Training + Test) = 14.47 seconds\n",
      "epoch: 136 average loss: 2.899\n",
      "Test Accuracy : 25.9%, Test Loss: 2.911728910446167\n",
      "Epoch Time (Training + Test) = 14.83 seconds\n",
      "epoch: 137 average loss: 2.890\n",
      "Test Accuracy : 26.9%, Test Loss: 2.8558512172698975\n",
      "Epoch Time (Training + Test) = 14.77 seconds\n",
      "epoch: 138 average loss: 2.893\n",
      "Test Accuracy : 26.0%, Test Loss: 2.958619089126587\n",
      "Epoch Time (Training + Test) = 15.01 seconds\n",
      "epoch: 139 average loss: 2.902\n",
      "Test Accuracy : 27.1%, Test Loss: 2.8988048191070557\n",
      "Epoch Time (Training + Test) = 14.47 seconds\n",
      "epoch: 140 average loss: 2.892\n",
      "Test Accuracy : 29.2%, Test Loss: 2.823483528137207\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.92 seconds\n",
      "epoch: 141 average loss: 2.884\n",
      "Test Accuracy : 26.9%, Test Loss: 2.8644813995361327\n",
      "Epoch Time (Training + Test) = 14.32 seconds\n",
      "epoch: 142 average loss: 2.890\n",
      "Test Accuracy : 28.0%, Test Loss: 2.858195823669434\n",
      "Epoch Time (Training + Test) = 14.44 seconds\n",
      "epoch: 143 average loss: 2.886\n",
      "Test Accuracy : 28.4%, Test Loss: 2.8320398502349855\n",
      "Epoch Time (Training + Test) = 14.31 seconds\n",
      "epoch: 144 average loss: 2.879\n",
      "Test Accuracy : 27.7%, Test Loss: 2.829362180709839\n",
      "Epoch Time (Training + Test) = 14.38 seconds\n",
      "epoch: 145 average loss: 2.883\n",
      "Test Accuracy : 27.1%, Test Loss: 2.854984676361084\n",
      "Epoch Time (Training + Test) = 14.46 seconds\n",
      "epoch: 146 average loss: 2.870\n",
      "Test Accuracy : 27.4%, Test Loss: 2.8655164604187013\n",
      "Epoch Time (Training + Test) = 15.04 seconds\n",
      "epoch: 147 average loss: 2.875\n",
      "Test Accuracy : 27.4%, Test Loss: 2.8450446853637694\n",
      "Epoch Time (Training + Test) = 14.99 seconds\n",
      "epoch: 148 average loss: 2.875\n",
      "Test Accuracy : 27.7%, Test Loss: 2.860632703781128\n",
      "Epoch Time (Training + Test) = 14.99 seconds\n",
      "epoch: 149 average loss: 2.876\n",
      "Test Accuracy : 28.1%, Test Loss: 2.8135589447021485\n",
      "Epoch Time (Training + Test) = 14.50 seconds\n",
      "epoch: 150 average loss: 2.877\n",
      "Test Accuracy : 27.4%, Test Loss: 2.8525188598632814\n",
      "Epoch Time (Training + Test) = 14.41 seconds\n",
      "epoch: 151 average loss: 2.878\n",
      "Test Accuracy : 27.6%, Test Loss: 2.853665658950806\n",
      "Epoch Time (Training + Test) = 14.37 seconds\n",
      "epoch: 152 average loss: 2.865\n",
      "Test Accuracy : 26.8%, Test Loss: 2.8653214530944826\n",
      "Epoch Time (Training + Test) = 14.49 seconds\n",
      "epoch: 153 average loss: 2.864\n",
      "Test Accuracy : 27.7%, Test Loss: 2.839287733078003\n",
      "Epoch Time (Training + Test) = 14.47 seconds\n",
      "epoch: 154 average loss: 2.868\n",
      "Test Accuracy : 28.2%, Test Loss: 2.8373985424041748\n",
      "Epoch Time (Training + Test) = 14.42 seconds\n",
      "epoch: 155 average loss: 2.866\n",
      "Test Accuracy : 28.1%, Test Loss: 2.8153787021636965\n",
      "Epoch Time (Training + Test) = 14.43 seconds\n",
      "epoch: 156 average loss: 2.856\n",
      "Test Accuracy : 28.2%, Test Loss: 2.8481335372924805\n",
      "Epoch Time (Training + Test) = 14.49 seconds\n",
      "epoch: 157 average loss: 2.868\n",
      "Test Accuracy : 27.2%, Test Loss: 2.861296232223511\n",
      "Epoch Time (Training + Test) = 14.49 seconds\n",
      "epoch: 158 average loss: 2.862\n",
      "Test Accuracy : 27.9%, Test Loss: 2.8289575576782227\n",
      "Epoch Time (Training + Test) = 14.38 seconds\n",
      "epoch: 159 average loss: 2.862\n",
      "Test Accuracy : 27.9%, Test Loss: 2.8240149726867676\n",
      "Epoch Time (Training + Test) = 14.45 seconds\n",
      "epoch: 160 average loss: 2.861\n",
      "Test Accuracy : 28.8%, Test Loss: 2.816450199127197\n",
      "Epoch Time (Training + Test) = 14.46 seconds\n",
      "epoch: 161 average loss: 2.859\n",
      "Test Accuracy : 28.1%, Test Loss: 2.8318101768493653\n",
      "Epoch Time (Training + Test) = 14.49 seconds\n",
      "epoch: 162 average loss: 2.860\n",
      "Test Accuracy : 29.2%, Test Loss: 2.8197553539276123\n",
      "Epoch Time (Training + Test) = 15.41 seconds\n",
      "epoch: 163 average loss: 2.854\n",
      "Test Accuracy : 28.2%, Test Loss: 2.8044650840759275\n",
      "Epoch Time (Training + Test) = 15.35 seconds\n",
      "epoch: 164 average loss: 2.858\n",
      "Test Accuracy : 28.6%, Test Loss: 2.8552671699523926\n",
      "Epoch Time (Training + Test) = 15.21 seconds\n",
      "epoch: 165 average loss: 2.846\n",
      "Test Accuracy : 25.5%, Test Loss: 2.9466294708251954\n",
      "Epoch Time (Training + Test) = 14.99 seconds\n",
      "epoch: 166 average loss: 2.852\n",
      "Test Accuracy : 28.0%, Test Loss: 2.8483264751434327\n",
      "Epoch Time (Training + Test) = 15.23 seconds\n",
      "epoch: 167 average loss: 2.846\n",
      "Test Accuracy : 28.6%, Test Loss: 2.813981945037842\n",
      "Epoch Time (Training + Test) = 15.25 seconds\n",
      "epoch: 168 average loss: 2.853\n",
      "Test Accuracy : 26.4%, Test Loss: 2.8962091064453124\n",
      "Epoch Time (Training + Test) = 15.14 seconds\n",
      "epoch: 169 average loss: 2.843\n",
      "Test Accuracy : 28.9%, Test Loss: 2.8213395385742186\n",
      "Epoch Time (Training + Test) = 15.31 seconds\n",
      "epoch: 170 average loss: 2.843\n",
      "Test Accuracy : 29.4%, Test Loss: 2.807664512634277\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.69 seconds\n",
      "epoch: 171 average loss: 2.836\n",
      "Test Accuracy : 28.6%, Test Loss: 2.8080760650634766\n",
      "Epoch Time (Training + Test) = 14.53 seconds\n",
      "epoch: 172 average loss: 2.836\n",
      "Test Accuracy : 28.5%, Test Loss: 2.8136500244140623\n",
      "Epoch Time (Training + Test) = 14.51 seconds\n",
      "epoch: 173 average loss: 2.840\n",
      "Test Accuracy : 28.8%, Test Loss: 2.824880712509155\n",
      "Epoch Time (Training + Test) = 14.57 seconds\n",
      "epoch: 174 average loss: 2.834\n",
      "Test Accuracy : 27.6%, Test Loss: 2.833393424987793\n",
      "Epoch Time (Training + Test) = 14.53 seconds\n",
      "epoch: 175 average loss: 2.839\n",
      "Test Accuracy : 29.3%, Test Loss: 2.7938110752105714\n",
      "Epoch Time (Training + Test) = 14.50 seconds\n",
      "epoch: 176 average loss: 2.835\n",
      "Test Accuracy : 28.1%, Test Loss: 2.8352349853515624\n",
      "Epoch Time (Training + Test) = 14.49 seconds\n",
      "epoch: 177 average loss: 2.839\n",
      "Test Accuracy : 29.0%, Test Loss: 2.802715389251709\n",
      "Epoch Time (Training + Test) = 14.54 seconds\n",
      "epoch: 178 average loss: 2.821\n",
      "Test Accuracy : 29.1%, Test Loss: 2.7792986907958985\n",
      "Epoch Time (Training + Test) = 14.61 seconds\n",
      "epoch: 179 average loss: 2.827\n",
      "Test Accuracy : 28.7%, Test Loss: 2.804014081954956\n",
      "Epoch Time (Training + Test) = 14.49 seconds\n",
      "epoch: 180 average loss: 2.825\n",
      "Test Accuracy : 29.3%, Test Loss: 2.7786718082427977\n",
      "Epoch Time (Training + Test) = 14.56 seconds\n",
      "epoch: 181 average loss: 2.821\n",
      "Test Accuracy : 28.8%, Test Loss: 2.8257354526519776\n",
      "Epoch Time (Training + Test) = 14.49 seconds\n",
      "epoch: 182 average loss: 2.820\n",
      "Test Accuracy : 28.6%, Test Loss: 2.8094785232543944\n",
      "Epoch Time (Training + Test) = 14.58 seconds\n",
      "epoch: 183 average loss: 2.818\n",
      "Test Accuracy : 29.2%, Test Loss: 2.785393939971924\n",
      "Epoch Time (Training + Test) = 14.42 seconds\n",
      "epoch: 184 average loss: 2.816\n",
      "Test Accuracy : 29.1%, Test Loss: 2.7725449237823487\n",
      "Epoch Time (Training + Test) = 14.52 seconds\n",
      "epoch: 185 average loss: 2.800\n",
      "Test Accuracy : 29.4%, Test Loss: 2.75744144821167\n",
      "Epoch Time (Training + Test) = 14.41 seconds\n",
      "epoch: 186 average loss: 2.813\n",
      "Test Accuracy : 28.9%, Test Loss: 2.7838811798095704\n",
      "Epoch Time (Training + Test) = 14.68 seconds\n",
      "epoch: 187 average loss: 2.804\n",
      "Test Accuracy : 29.1%, Test Loss: 2.812647350311279\n",
      "Epoch Time (Training + Test) = 14.45 seconds\n",
      "epoch: 188 average loss: 2.808\n",
      "Test Accuracy : 29.8%, Test Loss: 2.767521053314209\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.54 seconds\n",
      "epoch: 189 average loss: 2.813\n",
      "Test Accuracy : 28.7%, Test Loss: 2.8039051666259764\n",
      "Epoch Time (Training + Test) = 14.75 seconds\n",
      "epoch: 190 average loss: 2.801\n",
      "Test Accuracy : 29.9%, Test Loss: 2.7985999641418458\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.67 seconds\n",
      "epoch: 191 average loss: 2.804\n",
      "Test Accuracy : 29.2%, Test Loss: 2.7847850799560545\n",
      "Epoch Time (Training + Test) = 14.48 seconds\n",
      "epoch: 192 average loss: 2.813\n",
      "Test Accuracy : 30.1%, Test Loss: 2.7626752071380616\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.48 seconds\n",
      "epoch: 193 average loss: 2.795\n",
      "Test Accuracy : 29.7%, Test Loss: 2.767168144226074\n",
      "Epoch Time (Training + Test) = 14.52 seconds\n",
      "epoch: 194 average loss: 2.805\n",
      "Test Accuracy : 29.4%, Test Loss: 2.7710754680633545\n",
      "Epoch Time (Training + Test) = 14.55 seconds\n",
      "epoch: 195 average loss: 2.798\n",
      "Test Accuracy : 29.2%, Test Loss: 2.808769432067871\n",
      "Epoch Time (Training + Test) = 14.37 seconds\n",
      "epoch: 196 average loss: 2.780\n",
      "Test Accuracy : 29.6%, Test Loss: 2.7666187534332276\n",
      "Epoch Time (Training + Test) = 14.57 seconds\n",
      "epoch: 197 average loss: 2.783\n",
      "Test Accuracy : 29.4%, Test Loss: 2.766905656814575\n",
      "Epoch Time (Training + Test) = 14.39 seconds\n",
      "epoch: 198 average loss: 2.777\n",
      "Test Accuracy : 28.8%, Test Loss: 2.7775074043273924\n",
      "Epoch Time (Training + Test) = 14.50 seconds\n",
      "epoch: 199 average loss: 2.767\n",
      "Test Accuracy : 29.7%, Test Loss: 2.739818534851074\n",
      "Epoch Time (Training + Test) = 14.40 seconds\n",
      "epoch: 200 average loss: 2.762\n",
      "Test Accuracy : 30.9%, Test Loss: 2.7283018436431883\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 14.51 seconds\n",
      "Data Saved to Baseline_BNN_Resnet18_inflate_1.csv\n",
      "Finished Training: \n",
      "Total Time 1.644649 hours\n",
      " Average Time Per Epoch 29.60 seconds\n",
      "Using Default (SGD) Optimizer\n",
      "Scheduler Set {'T_max': 200, 'eta_min': 0, 'base_lrs': [0.2], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.2]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2pc3read) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>â–â–ƒâ–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch time (s)</td><td>â–…â–…â–„â–„â–ƒâ–„â–ƒâ–‡â–„â–„â–…â–ƒâ–â–ƒâ–„â–‚â–‚â–„â–‚â–‚â–ˆâ–…â–„â–„â–„â–„â–ƒâ–ƒâ–â–„â–‚â–‚â–†â–…â–‚â–‚â–‚â–‚â–‚â–</td></tr><tr><td>lr</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–</td></tr><tr><td>test_accuracy</td><td>â–â–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>test_loss</td><td>â–ˆâ–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–</td></tr><tr><td>training_loss</td><td>â–ˆâ–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.30912</td></tr><tr><td>Current Best Acc</td><td>0.30912</td></tr><tr><td>Total Time (hours)</td><td>1.64465</td></tr><tr><td>epoch</td><td>200</td></tr><tr><td>epoch time (s)</td><td>14.5087</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>test_accuracy</td><td>0.30912</td></tr><tr><td>test_loss</td><td>2.7283</td></tr><tr><td>training_loss</td><td>2.76227</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">giddy-smoke-9</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/2pc3read\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/2pc3read</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221023_095719-2pc3read\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2pc3read). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ccb99a390241e9ab7772b7b0b78609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221023_104702-3ts5t0ro</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/3ts5t0ro\" target=\"_blank\">avid-glitter-10</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name Baseline_BNN_Resnet18_inflate_2 \n",
      "\n",
      "\n",
      "Run Start : 2022-10-23 10-47-02\n",
      "start_epoch : 0\n",
      "initial_lr : 0.2\n",
      "batch_size : 32\n",
      "epochs : 200\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.2\n",
      "    lr: 0.2\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.models.resnet_binary.ResNet_cifar10'>\n",
      "binerised_training : True\n",
      "Number of Elements : 706064\n",
      "Initial accuracy:\n",
      "Test Accuracy : 1.1%, Test Loss: 28.011135665893555\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 1.2%, Test Loss: 27.81398631286621\n",
      "best_acc.pth saved!\n",
      "epoch: 1 average loss: 4.104\n",
      "Test Accuracy : 7.9%, Test Loss: 3.9044494762420654\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.35 seconds\n",
      "epoch: 2 average loss: 3.842\n",
      "Test Accuracy : 9.1%, Test Loss: 3.7446407947540283\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.44 seconds\n",
      "epoch: 3 average loss: 3.688\n",
      "Test Accuracy : 12.4%, Test Loss: 3.589548223495483\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.40 seconds\n",
      "epoch: 4 average loss: 3.587\n",
      "Test Accuracy : 13.7%, Test Loss: 3.519991102218628\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.48 seconds\n",
      "epoch: 5 average loss: 3.509\n",
      "Test Accuracy : 15.5%, Test Loss: 3.399691432952881\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.36 seconds\n",
      "epoch: 6 average loss: 3.439\n",
      "Test Accuracy : 16.4%, Test Loss: 3.3577839946746826\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 7 average loss: 3.383\n",
      "Test Accuracy : 16.7%, Test Loss: 3.342824851989746\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.38 seconds\n",
      "epoch: 8 average loss: 3.328\n",
      "Test Accuracy : 17.9%, Test Loss: 3.276796434402466\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.44 seconds\n",
      "epoch: 9 average loss: 3.293\n",
      "Test Accuracy : 19.2%, Test Loss: 3.240922649383545\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.36 seconds\n",
      "epoch: 10 average loss: 3.251\n",
      "Test Accuracy : 19.7%, Test Loss: 3.272385305404663\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.41 seconds\n",
      "epoch: 11 average loss: 3.222\n",
      "Test Accuracy : 20.5%, Test Loss: 3.1697613582611086\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.38 seconds\n",
      "epoch: 12 average loss: 3.200\n",
      "Test Accuracy : 22.0%, Test Loss: 3.134518747329712\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.39 seconds\n",
      "epoch: 13 average loss: 3.168\n",
      "Test Accuracy : 22.2%, Test Loss: 3.10027795791626\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.45 seconds\n",
      "epoch: 14 average loss: 3.150\n",
      "Test Accuracy : 21.4%, Test Loss: 3.1005368061065672\n",
      "Epoch Time (Training + Test) = 18.33 seconds\n",
      "epoch: 15 average loss: 3.119\n",
      "Test Accuracy : 22.0%, Test Loss: 3.0852956867218015\n",
      "Epoch Time (Training + Test) = 18.48 seconds\n",
      "epoch: 16 average loss: 3.100\n",
      "Test Accuracy : 24.0%, Test Loss: 3.0136015129089357\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.39 seconds\n",
      "epoch: 17 average loss: 3.081\n",
      "Test Accuracy : 23.5%, Test Loss: 3.024123456954956\n",
      "Epoch Time (Training + Test) = 18.36 seconds\n",
      "epoch: 18 average loss: 3.061\n",
      "Test Accuracy : 24.7%, Test Loss: 2.9822542304992674\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.41 seconds\n",
      "epoch: 19 average loss: 3.042\n",
      "Test Accuracy : 23.9%, Test Loss: 3.0093256740570067\n",
      "Epoch Time (Training + Test) = 18.26 seconds\n",
      "epoch: 20 average loss: 3.026\n",
      "Test Accuracy : 24.9%, Test Loss: 2.9794799976348876\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.43 seconds\n",
      "epoch: 21 average loss: 2.999\n",
      "Test Accuracy : 24.7%, Test Loss: 2.9670801219940186\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 22 average loss: 2.976\n",
      "Test Accuracy : 25.4%, Test Loss: 2.9249228019714355\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.43 seconds\n",
      "epoch: 23 average loss: 2.966\n",
      "Test Accuracy : 25.0%, Test Loss: 2.9561667671203615\n",
      "Epoch Time (Training + Test) = 18.31 seconds\n",
      "epoch: 24 average loss: 2.937\n",
      "Test Accuracy : 26.7%, Test Loss: 2.8991373176574706\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.37 seconds\n",
      "epoch: 25 average loss: 2.929\n",
      "Test Accuracy : 26.2%, Test Loss: 2.8821775760650636\n",
      "Epoch Time (Training + Test) = 18.25 seconds\n",
      "epoch: 26 average loss: 2.916\n",
      "Test Accuracy : 27.6%, Test Loss: 2.833172269821167\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.36 seconds\n",
      "epoch: 27 average loss: 2.889\n",
      "Test Accuracy : 26.8%, Test Loss: 2.8607764472961428\n",
      "Epoch Time (Training + Test) = 18.24 seconds\n",
      "epoch: 28 average loss: 2.882\n",
      "Test Accuracy : 27.5%, Test Loss: 2.8305042724609377\n",
      "Epoch Time (Training + Test) = 18.28 seconds\n",
      "epoch: 29 average loss: 2.864\n",
      "Test Accuracy : 27.7%, Test Loss: 2.84409393119812\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 30 average loss: 2.856\n",
      "Test Accuracy : 28.3%, Test Loss: 2.792612777709961\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.43 seconds\n",
      "epoch: 31 average loss: 2.846\n",
      "Test Accuracy : 28.6%, Test Loss: 2.7903675060272217\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 32 average loss: 2.820\n",
      "Test Accuracy : 28.3%, Test Loss: 2.768478464126587\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 33 average loss: 2.811\n",
      "Test Accuracy : 29.6%, Test Loss: 2.7656232242584227\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.28 seconds\n",
      "epoch: 34 average loss: 2.808\n",
      "Test Accuracy : 29.5%, Test Loss: 2.733182289123535\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 35 average loss: 2.790\n",
      "Test Accuracy : 29.4%, Test Loss: 2.7535538330078126\n",
      "Epoch Time (Training + Test) = 18.24 seconds\n",
      "epoch: 36 average loss: 2.777\n",
      "Test Accuracy : 27.5%, Test Loss: 2.889017095565796\n",
      "Epoch Time (Training + Test) = 18.41 seconds\n",
      "epoch: 37 average loss: 2.754\n",
      "Test Accuracy : 30.0%, Test Loss: 2.704764516830444\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.32 seconds\n",
      "epoch: 38 average loss: 2.752\n",
      "Test Accuracy : 30.0%, Test Loss: 2.7083469791412353\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 39 average loss: 2.739\n",
      "Test Accuracy : 30.8%, Test Loss: 2.7049483585357668\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.32 seconds\n",
      "epoch: 40 average loss: 2.735\n",
      "Test Accuracy : 30.2%, Test Loss: 2.7216669940948486\n",
      "Epoch Time (Training + Test) = 18.40 seconds\n",
      "epoch: 41 average loss: 2.721\n",
      "Test Accuracy : 30.1%, Test Loss: 2.726437452316284\n",
      "Epoch Time (Training + Test) = 18.23 seconds\n",
      "epoch: 42 average loss: 2.705\n",
      "Test Accuracy : 31.2%, Test Loss: 2.6838953666687013\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 43 average loss: 2.697\n",
      "Test Accuracy : 31.8%, Test Loss: 2.645554636001587\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 44 average loss: 2.677\n",
      "Test Accuracy : 29.6%, Test Loss: 2.7399571704864503\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 45 average loss: 2.667\n",
      "Test Accuracy : 29.5%, Test Loss: 2.7744098529815675\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 46 average loss: 2.649\n",
      "Test Accuracy : 31.1%, Test Loss: 2.6769442977905276\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 47 average loss: 2.644\n",
      "Test Accuracy : 32.6%, Test Loss: 2.6022524471282957\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 48 average loss: 2.629\n",
      "Test Accuracy : 31.8%, Test Loss: 2.650412130355835\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 49 average loss: 2.622\n",
      "Test Accuracy : 33.0%, Test Loss: 2.6008773155212404\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.38 seconds\n",
      "epoch: 50 average loss: 2.613\n",
      "Test Accuracy : 32.7%, Test Loss: 2.6012919616699217\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 51 average loss: 2.604\n",
      "Test Accuracy : 32.5%, Test Loss: 2.6219893112182615\n",
      "Epoch Time (Training + Test) = 18.26 seconds\n",
      "epoch: 52 average loss: 2.576\n",
      "Test Accuracy : 33.5%, Test Loss: 2.565182952880859\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.35 seconds\n",
      "epoch: 53 average loss: 2.576\n",
      "Test Accuracy : 32.7%, Test Loss: 2.620442901611328\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 54 average loss: 2.579\n",
      "Test Accuracy : 34.4%, Test Loss: 2.5194637565612794\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 55 average loss: 2.565\n",
      "Test Accuracy : 33.2%, Test Loss: 2.574477508544922\n",
      "Epoch Time (Training + Test) = 18.34 seconds\n",
      "epoch: 56 average loss: 2.547\n",
      "Test Accuracy : 33.4%, Test Loss: 2.5611499195098877\n",
      "Epoch Time (Training + Test) = 18.31 seconds\n",
      "epoch: 57 average loss: 2.551\n",
      "Test Accuracy : 31.6%, Test Loss: 2.6731996822357176\n",
      "Epoch Time (Training + Test) = 18.24 seconds\n",
      "epoch: 58 average loss: 2.538\n",
      "Test Accuracy : 34.1%, Test Loss: 2.547420711517334\n",
      "Epoch Time (Training + Test) = 18.31 seconds\n",
      "epoch: 59 average loss: 2.521\n",
      "Test Accuracy : 34.5%, Test Loss: 2.5296688251495363\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 60 average loss: 2.510\n",
      "Test Accuracy : 34.5%, Test Loss: 2.525546459197998\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 61 average loss: 2.489\n",
      "Test Accuracy : 36.6%, Test Loss: 2.4403166351318357\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 62 average loss: 2.487\n",
      "Test Accuracy : 34.3%, Test Loss: 2.4980812015533447\n",
      "Epoch Time (Training + Test) = 18.37 seconds\n",
      "epoch: 63 average loss: 2.487\n",
      "Test Accuracy : 35.1%, Test Loss: 2.5019463901519776\n",
      "Epoch Time (Training + Test) = 18.31 seconds\n",
      "epoch: 64 average loss: 2.481\n",
      "Test Accuracy : 34.9%, Test Loss: 2.489173589706421\n",
      "Epoch Time (Training + Test) = 18.31 seconds\n",
      "epoch: 65 average loss: 2.475\n",
      "Test Accuracy : 35.5%, Test Loss: 2.499916227340698\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 66 average loss: 2.459\n",
      "Test Accuracy : 36.7%, Test Loss: 2.4433192682266234\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.34 seconds\n",
      "epoch: 67 average loss: 2.456\n",
      "Test Accuracy : 36.5%, Test Loss: 2.4437760934829713\n",
      "Epoch Time (Training + Test) = 18.20 seconds\n",
      "epoch: 68 average loss: 2.446\n",
      "Test Accuracy : 35.1%, Test Loss: 2.47404621887207\n",
      "Epoch Time (Training + Test) = 18.28 seconds\n",
      "epoch: 69 average loss: 2.435\n",
      "Test Accuracy : 35.7%, Test Loss: 2.4826228790283205\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 70 average loss: 2.427\n",
      "Test Accuracy : 34.6%, Test Loss: 2.53500710105896\n",
      "Epoch Time (Training + Test) = 18.31 seconds\n",
      "epoch: 71 average loss: 2.429\n",
      "Test Accuracy : 34.5%, Test Loss: 2.5337877750396727\n",
      "Epoch Time (Training + Test) = 18.21 seconds\n",
      "epoch: 72 average loss: 2.420\n",
      "Test Accuracy : 36.3%, Test Loss: 2.4647447576522827\n",
      "Epoch Time (Training + Test) = 18.39 seconds\n",
      "epoch: 73 average loss: 2.405\n",
      "Test Accuracy : 36.2%, Test Loss: 2.455890633583069\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 74 average loss: 2.406\n",
      "Test Accuracy : 36.9%, Test Loss: 2.42325740814209\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.32 seconds\n",
      "epoch: 75 average loss: 2.393\n",
      "Test Accuracy : 37.1%, Test Loss: 2.392116918563843\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.33 seconds\n",
      "epoch: 76 average loss: 2.388\n",
      "Test Accuracy : 36.5%, Test Loss: 2.414520016670227\n",
      "Epoch Time (Training + Test) = 18.38 seconds\n",
      "epoch: 77 average loss: 2.389\n",
      "Test Accuracy : 35.4%, Test Loss: 2.461376085281372\n",
      "Epoch Time (Training + Test) = 18.21 seconds\n",
      "epoch: 78 average loss: 2.377\n",
      "Test Accuracy : 36.7%, Test Loss: 2.4519961223602293\n",
      "Epoch Time (Training + Test) = 18.28 seconds\n",
      "epoch: 79 average loss: 2.372\n",
      "Test Accuracy : 36.9%, Test Loss: 2.3809146976470945\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 80 average loss: 2.357\n",
      "Test Accuracy : 38.4%, Test Loss: 2.3658472013473513\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.33 seconds\n",
      "epoch: 81 average loss: 2.353\n",
      "Test Accuracy : 38.6%, Test Loss: 2.3168197326660156\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 82 average loss: 2.351\n",
      "Test Accuracy : 38.1%, Test Loss: 2.350736659049988\n",
      "Epoch Time (Training + Test) = 18.33 seconds\n",
      "epoch: 83 average loss: 2.339\n",
      "Test Accuracy : 39.6%, Test Loss: 2.303532928466797\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.25 seconds\n",
      "epoch: 84 average loss: 2.331\n",
      "Test Accuracy : 36.4%, Test Loss: 2.426051211357117\n",
      "Epoch Time (Training + Test) = 18.28 seconds\n",
      "epoch: 85 average loss: 2.330\n",
      "Test Accuracy : 39.1%, Test Loss: 2.3195353355407713\n",
      "Epoch Time (Training + Test) = 18.34 seconds\n",
      "epoch: 86 average loss: 2.320\n",
      "Test Accuracy : 39.7%, Test Loss: 2.2858436126708983\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.36 seconds\n",
      "epoch: 87 average loss: 2.317\n",
      "Test Accuracy : 38.4%, Test Loss: 2.376061586380005\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 88 average loss: 2.300\n",
      "Test Accuracy : 37.7%, Test Loss: 2.3971950750350954\n",
      "Epoch Time (Training + Test) = 18.46 seconds\n",
      "epoch: 89 average loss: 2.306\n",
      "Test Accuracy : 38.8%, Test Loss: 2.327634922027588\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 90 average loss: 2.299\n",
      "Test Accuracy : 39.1%, Test Loss: 2.3401464223861694\n",
      "Epoch Time (Training + Test) = 18.31 seconds\n",
      "epoch: 91 average loss: 2.287\n",
      "Test Accuracy : 39.5%, Test Loss: 2.2801050186157226\n",
      "Epoch Time (Training + Test) = 18.25 seconds\n",
      "epoch: 92 average loss: 2.287\n",
      "Test Accuracy : 38.7%, Test Loss: 2.3298186979293822\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 93 average loss: 2.289\n",
      "Test Accuracy : 39.8%, Test Loss: 2.287193849563599\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.24 seconds\n",
      "epoch: 94 average loss: 2.276\n",
      "Test Accuracy : 39.0%, Test Loss: 2.33455376625061\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 95 average loss: 2.279\n",
      "Test Accuracy : 38.3%, Test Loss: 2.370848795890808\n",
      "Epoch Time (Training + Test) = 18.34 seconds\n",
      "epoch: 96 average loss: 2.269\n",
      "Test Accuracy : 39.4%, Test Loss: 2.2995968704223633\n",
      "Epoch Time (Training + Test) = 18.34 seconds\n",
      "epoch: 97 average loss: 2.261\n",
      "Test Accuracy : 40.5%, Test Loss: 2.251659655570984\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 98 average loss: 2.261\n",
      "Test Accuracy : 39.5%, Test Loss: 2.2856320905685426\n",
      "Epoch Time (Training + Test) = 18.36 seconds\n",
      "epoch: 99 average loss: 2.243\n",
      "Test Accuracy : 40.7%, Test Loss: 2.215078037261963\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.36 seconds\n",
      "epoch: 100 average loss: 2.248\n",
      "Test Accuracy : 39.8%, Test Loss: 2.309408037185669\n",
      "Epoch Time (Training + Test) = 18.25 seconds\n",
      "epoch: 101 average loss: 2.232\n",
      "Test Accuracy : 37.9%, Test Loss: 2.4267350788116455\n",
      "Epoch Time (Training + Test) = 18.25 seconds\n",
      "epoch: 102 average loss: 2.235\n",
      "Test Accuracy : 41.0%, Test Loss: 2.265979651451111\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.35 seconds\n",
      "epoch: 103 average loss: 2.222\n",
      "Test Accuracy : 39.5%, Test Loss: 2.298408324241638\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 104 average loss: 2.232\n",
      "Test Accuracy : 41.5%, Test Loss: 2.201640585899353\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.28 seconds\n",
      "epoch: 105 average loss: 2.213\n",
      "Test Accuracy : 41.8%, Test Loss: 2.2180963191986085\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.31 seconds\n",
      "epoch: 106 average loss: 2.220\n",
      "Test Accuracy : 40.7%, Test Loss: 2.2195969591140745\n",
      "Epoch Time (Training + Test) = 18.28 seconds\n",
      "epoch: 107 average loss: 2.222\n",
      "Test Accuracy : 40.6%, Test Loss: 2.228821572303772\n",
      "Epoch Time (Training + Test) = 18.32 seconds\n",
      "epoch: 108 average loss: 2.216\n",
      "Test Accuracy : 40.3%, Test Loss: 2.269283042907715\n",
      "Epoch Time (Training + Test) = 18.39 seconds\n",
      "epoch: 109 average loss: 2.207\n",
      "Test Accuracy : 40.4%, Test Loss: 2.2562222995758057\n",
      "Epoch Time (Training + Test) = 18.26 seconds\n",
      "epoch: 110 average loss: 2.197\n",
      "Test Accuracy : 39.9%, Test Loss: 2.289191644668579\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 111 average loss: 2.191\n",
      "Test Accuracy : 41.3%, Test Loss: 2.232884237289429\n",
      "Epoch Time (Training + Test) = 18.23 seconds\n",
      "epoch: 112 average loss: 2.190\n",
      "Test Accuracy : 38.1%, Test Loss: 2.360419954299927\n",
      "Epoch Time (Training + Test) = 18.42 seconds\n",
      "epoch: 113 average loss: 2.181\n",
      "Test Accuracy : 41.6%, Test Loss: 2.2155815410614013\n",
      "Epoch Time (Training + Test) = 18.23 seconds\n",
      "epoch: 114 average loss: 2.180\n",
      "Test Accuracy : 41.9%, Test Loss: 2.1892901363372803\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 115 average loss: 2.187\n",
      "Test Accuracy : 40.7%, Test Loss: 2.2646329345703125\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 116 average loss: 2.175\n",
      "Test Accuracy : 42.2%, Test Loss: 2.1938571739196777\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.28 seconds\n",
      "epoch: 117 average loss: 2.174\n",
      "Test Accuracy : 42.8%, Test Loss: 2.1800532989501953\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.23 seconds\n",
      "epoch: 118 average loss: 2.160\n",
      "Test Accuracy : 41.4%, Test Loss: 2.202977102279663\n",
      "Epoch Time (Training + Test) = 18.33 seconds\n",
      "epoch: 119 average loss: 2.161\n",
      "Test Accuracy : 42.3%, Test Loss: 2.170669741630554\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 120 average loss: 2.159\n",
      "Test Accuracy : 42.0%, Test Loss: 2.175740001678467\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 121 average loss: 2.153\n",
      "Test Accuracy : 43.0%, Test Loss: 2.155024321556091\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.46 seconds\n",
      "epoch: 122 average loss: 2.158\n",
      "Test Accuracy : 41.8%, Test Loss: 2.175173168182373\n",
      "Epoch Time (Training + Test) = 18.34 seconds\n",
      "epoch: 123 average loss: 2.140\n",
      "Test Accuracy : 41.0%, Test Loss: 2.2245366220474243\n",
      "Epoch Time (Training + Test) = 18.22 seconds\n",
      "epoch: 124 average loss: 2.151\n",
      "Test Accuracy : 42.3%, Test Loss: 2.1824635457992554\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 125 average loss: 2.130\n",
      "Test Accuracy : 43.1%, Test Loss: 2.150451537132263\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.31 seconds\n",
      "epoch: 126 average loss: 2.144\n",
      "Test Accuracy : 41.3%, Test Loss: 2.2145537605285646\n",
      "Epoch Time (Training + Test) = 18.26 seconds\n",
      "epoch: 127 average loss: 2.136\n",
      "Test Accuracy : 42.7%, Test Loss: 2.1574674072265627\n",
      "Epoch Time (Training + Test) = 18.26 seconds\n",
      "epoch: 128 average loss: 2.137\n",
      "Test Accuracy : 41.9%, Test Loss: 2.193022996902466\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 129 average loss: 2.125\n",
      "Test Accuracy : 41.7%, Test Loss: 2.1707169189453124\n",
      "Epoch Time (Training + Test) = 18.25 seconds\n",
      "epoch: 130 average loss: 2.128\n",
      "Test Accuracy : 43.4%, Test Loss: 2.121347063064575\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 131 average loss: 2.125\n",
      "Test Accuracy : 42.8%, Test Loss: 2.172962607383728\n",
      "Epoch Time (Training + Test) = 18.36 seconds\n",
      "epoch: 132 average loss: 2.113\n",
      "Test Accuracy : 42.9%, Test Loss: 2.151347831726074\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 133 average loss: 2.112\n",
      "Test Accuracy : 42.3%, Test Loss: 2.150873815536499\n",
      "Epoch Time (Training + Test) = 18.23 seconds\n",
      "epoch: 134 average loss: 2.109\n",
      "Test Accuracy : 42.9%, Test Loss: 2.148032427787781\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 135 average loss: 2.111\n",
      "Test Accuracy : 42.8%, Test Loss: 2.1525947074890137\n",
      "Epoch Time (Training + Test) = 18.37 seconds\n",
      "epoch: 136 average loss: 2.111\n",
      "Test Accuracy : 42.6%, Test Loss: 2.184642066001892\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 137 average loss: 2.097\n",
      "Test Accuracy : 42.9%, Test Loss: 2.1254537134170532\n",
      "Epoch Time (Training + Test) = 18.21 seconds\n",
      "epoch: 138 average loss: 2.103\n",
      "Test Accuracy : 44.1%, Test Loss: 2.1117353382110595\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 139 average loss: 2.103\n",
      "Test Accuracy : 43.2%, Test Loss: 2.1393186044692993\n",
      "Epoch Time (Training + Test) = 18.23 seconds\n",
      "epoch: 140 average loss: 2.086\n",
      "Test Accuracy : 43.5%, Test Loss: 2.1233766622543335\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 141 average loss: 2.086\n",
      "Test Accuracy : 43.0%, Test Loss: 2.1801283025741576\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 142 average loss: 2.098\n",
      "Test Accuracy : 43.7%, Test Loss: 2.126267788887024\n",
      "Epoch Time (Training + Test) = 18.25 seconds\n",
      "epoch: 143 average loss: 2.085\n",
      "Test Accuracy : 43.8%, Test Loss: 2.1190625133514405\n",
      "Epoch Time (Training + Test) = 18.22 seconds\n",
      "epoch: 144 average loss: 2.087\n",
      "Test Accuracy : 43.8%, Test Loss: 2.1388848028182985\n",
      "Epoch Time (Training + Test) = 18.37 seconds\n",
      "epoch: 145 average loss: 2.069\n",
      "Test Accuracy : 42.7%, Test Loss: 2.1624546909332274\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 146 average loss: 2.067\n",
      "Test Accuracy : 43.8%, Test Loss: 2.0994437770843506\n",
      "Epoch Time (Training + Test) = 18.34 seconds\n",
      "epoch: 147 average loss: 2.064\n",
      "Test Accuracy : 43.1%, Test Loss: 2.160550573348999\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 148 average loss: 2.074\n",
      "Test Accuracy : 44.9%, Test Loss: 2.1003893795013426\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.33 seconds\n",
      "epoch: 149 average loss: 2.067\n",
      "Test Accuracy : 45.2%, Test Loss: 2.07534440612793\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.22 seconds\n",
      "epoch: 150 average loss: 2.066\n",
      "Test Accuracy : 44.3%, Test Loss: 2.085816051483154\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 151 average loss: 2.067\n",
      "Test Accuracy : 43.4%, Test Loss: 2.149540383338928\n",
      "Epoch Time (Training + Test) = 18.25 seconds\n",
      "epoch: 152 average loss: 2.053\n",
      "Test Accuracy : 43.7%, Test Loss: 2.128814835548401\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 153 average loss: 2.044\n",
      "Test Accuracy : 43.6%, Test Loss: 2.118256142616272\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 154 average loss: 2.058\n",
      "Test Accuracy : 44.7%, Test Loss: 2.0940396118164064\n",
      "Epoch Time (Training + Test) = 18.49 seconds\n",
      "epoch: 155 average loss: 2.045\n",
      "Test Accuracy : 45.0%, Test Loss: 2.0548056316375733\n",
      "Epoch Time (Training + Test) = 18.21 seconds\n",
      "epoch: 156 average loss: 2.044\n",
      "Test Accuracy : 43.8%, Test Loss: 2.1359782457351684\n",
      "Epoch Time (Training + Test) = 18.33 seconds\n",
      "epoch: 157 average loss: 2.049\n",
      "Test Accuracy : 44.9%, Test Loss: 2.07311279296875\n",
      "Epoch Time (Training + Test) = 18.25 seconds\n",
      "epoch: 158 average loss: 2.053\n",
      "Test Accuracy : 43.5%, Test Loss: 2.1312276554107665\n",
      "Epoch Time (Training + Test) = 18.31 seconds\n",
      "epoch: 159 average loss: 2.043\n",
      "Test Accuracy : 44.3%, Test Loss: 2.097175793647766\n",
      "Epoch Time (Training + Test) = 18.24 seconds\n",
      "epoch: 160 average loss: 2.036\n",
      "Test Accuracy : 44.0%, Test Loss: 2.1088566761016847\n",
      "Epoch Time (Training + Test) = 18.28 seconds\n",
      "epoch: 161 average loss: 2.035\n",
      "Test Accuracy : 44.3%, Test Loss: 2.089820484161377\n",
      "Epoch Time (Training + Test) = 18.28 seconds\n",
      "epoch: 162 average loss: 2.026\n",
      "Test Accuracy : 44.5%, Test Loss: 2.08786794757843\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 163 average loss: 2.030\n",
      "Test Accuracy : 44.2%, Test Loss: 2.1069987506866457\n",
      "Epoch Time (Training + Test) = 18.25 seconds\n",
      "epoch: 164 average loss: 2.037\n",
      "Test Accuracy : 44.0%, Test Loss: 2.105938431739807\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 165 average loss: 2.018\n",
      "Test Accuracy : 45.4%, Test Loss: 2.0564313068389892\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.23 seconds\n",
      "epoch: 166 average loss: 2.011\n",
      "Test Accuracy : 43.1%, Test Loss: 2.136024797439575\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 167 average loss: 2.006\n",
      "Test Accuracy : 44.5%, Test Loss: 2.102637969970703\n",
      "Epoch Time (Training + Test) = 18.33 seconds\n",
      "epoch: 168 average loss: 2.027\n",
      "Test Accuracy : 44.2%, Test Loss: 2.0997762212753295\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 169 average loss: 2.005\n",
      "Test Accuracy : 44.4%, Test Loss: 2.100309630393982\n",
      "Epoch Time (Training + Test) = 18.25 seconds\n",
      "epoch: 170 average loss: 2.019\n",
      "Test Accuracy : 44.9%, Test Loss: 2.0485132484436037\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 171 average loss: 2.008\n",
      "Test Accuracy : 45.4%, Test Loss: 2.050277228355408\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.37 seconds\n",
      "epoch: 172 average loss: 2.002\n",
      "Test Accuracy : 45.4%, Test Loss: 2.056609179496765\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.30 seconds\n",
      "epoch: 173 average loss: 1.991\n",
      "Test Accuracy : 45.2%, Test Loss: 2.0563891172409057\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 174 average loss: 2.002\n",
      "Test Accuracy : 45.0%, Test Loss: 2.079047203063965\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 175 average loss: 2.003\n",
      "Test Accuracy : 46.1%, Test Loss: 2.016259728431702\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.20 seconds\n",
      "epoch: 176 average loss: 2.000\n",
      "Test Accuracy : 44.4%, Test Loss: 2.0830987167358397\n",
      "Epoch Time (Training + Test) = 18.21 seconds\n",
      "epoch: 177 average loss: 2.004\n",
      "Test Accuracy : 45.8%, Test Loss: 2.0274141397476195\n",
      "Epoch Time (Training + Test) = 18.33 seconds\n",
      "epoch: 178 average loss: 1.996\n",
      "Test Accuracy : 45.1%, Test Loss: 2.050168872833252\n",
      "Epoch Time (Training + Test) = 18.25 seconds\n",
      "epoch: 179 average loss: 1.987\n",
      "Test Accuracy : 44.0%, Test Loss: 2.0964569721221924\n",
      "Epoch Time (Training + Test) = 18.26 seconds\n",
      "epoch: 180 average loss: 1.997\n",
      "Test Accuracy : 46.1%, Test Loss: 2.035874806404114\n",
      "Epoch Time (Training + Test) = 18.21 seconds\n",
      "epoch: 181 average loss: 1.976\n",
      "Test Accuracy : 45.5%, Test Loss: 2.036091156005859\n",
      "Epoch Time (Training + Test) = 18.28 seconds\n",
      "epoch: 182 average loss: 1.987\n",
      "Test Accuracy : 45.0%, Test Loss: 2.0755968599319456\n",
      "Epoch Time (Training + Test) = 18.23 seconds\n",
      "epoch: 183 average loss: 1.976\n",
      "Test Accuracy : 45.4%, Test Loss: 2.0434359664916992\n",
      "Epoch Time (Training + Test) = 18.24 seconds\n",
      "epoch: 184 average loss: 1.972\n",
      "Test Accuracy : 46.1%, Test Loss: 2.0442748956680297\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 185 average loss: 1.981\n",
      "Test Accuracy : 45.6%, Test Loss: 2.0730848875045775\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 186 average loss: 1.979\n",
      "Test Accuracy : 46.4%, Test Loss: 2.0231679916381835\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.46 seconds\n",
      "epoch: 187 average loss: 1.969\n",
      "Test Accuracy : 46.3%, Test Loss: 2.0203004035949705\n",
      "Epoch Time (Training + Test) = 18.39 seconds\n",
      "epoch: 188 average loss: 1.964\n",
      "Test Accuracy : 46.2%, Test Loss: 2.0188286752700804\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 189 average loss: 1.960\n",
      "Test Accuracy : 44.9%, Test Loss: 2.0834034366607668\n",
      "Epoch Time (Training + Test) = 18.23 seconds\n",
      "epoch: 190 average loss: 1.968\n",
      "Test Accuracy : 46.0%, Test Loss: 2.0250768251419067\n",
      "Epoch Time (Training + Test) = 18.39 seconds\n",
      "epoch: 191 average loss: 1.961\n",
      "Test Accuracy : 46.5%, Test Loss: 2.0120719146728514\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 192 average loss: 1.959\n",
      "Test Accuracy : 46.4%, Test Loss: 2.019254333496094\n",
      "Epoch Time (Training + Test) = 18.22 seconds\n",
      "epoch: 193 average loss: 1.950\n",
      "Test Accuracy : 46.9%, Test Loss: 1.9908122272491455\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.25 seconds\n",
      "epoch: 194 average loss: 1.955\n",
      "Test Accuracy : 46.0%, Test Loss: 2.0475544290542604\n",
      "Epoch Time (Training + Test) = 18.29 seconds\n",
      "epoch: 195 average loss: 1.942\n",
      "Test Accuracy : 46.7%, Test Loss: 2.0054996395111084\n",
      "Epoch Time (Training + Test) = 18.18 seconds\n",
      "epoch: 196 average loss: 1.941\n",
      "Test Accuracy : 46.5%, Test Loss: 2.0156436166763307\n",
      "Epoch Time (Training + Test) = 18.23 seconds\n",
      "epoch: 197 average loss: 1.933\n",
      "Test Accuracy : 45.9%, Test Loss: 2.014092493057251\n",
      "Epoch Time (Training + Test) = 18.21 seconds\n",
      "epoch: 198 average loss: 1.926\n",
      "Test Accuracy : 46.5%, Test Loss: 1.9973637771606445\n",
      "Epoch Time (Training + Test) = 18.27 seconds\n",
      "epoch: 199 average loss: 1.925\n",
      "Test Accuracy : 46.7%, Test Loss: 1.989076289176941\n",
      "Epoch Time (Training + Test) = 18.21 seconds\n",
      "epoch: 200 average loss: 1.909\n",
      "Test Accuracy : 47.5%, Test Loss: 1.9617347450256348\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 18.41 seconds\n",
      "Data Saved to Baseline_BNN_Resnet18_inflate_2.csv\n",
      "Finished Training: \n",
      "Total Time 2.033727 hours\n",
      " Average Time Per Epoch 36.61 seconds\n",
      "Using Default (SGD) Optimizer\n",
      "Scheduler Set {'T_max': 200, 'eta_min': 0, 'base_lrs': [0.2], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.2]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3ts5t0ro) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>â–â–‚â–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch time (s)</td><td>â–…â–…â–…â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–„â–ƒâ–â–â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–‚â–‚â–‡â–ƒâ–‚â–â–â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–„â–‚â–†â–‚â–</td></tr><tr><td>lr</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–</td></tr><tr><td>test_accuracy</td><td>â–â–‚â–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>test_loss</td><td>â–ˆâ–†â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>training_loss</td><td>â–ˆâ–†â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.47487</td></tr><tr><td>Current Best Acc</td><td>0.47487</td></tr><tr><td>Total Time (hours)</td><td>2.03373</td></tr><tr><td>epoch</td><td>200</td></tr><tr><td>epoch time (s)</td><td>18.41067</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>test_accuracy</td><td>0.47487</td></tr><tr><td>test_loss</td><td>1.96173</td></tr><tr><td>training_loss</td><td>1.90905</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">avid-glitter-10</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/3ts5t0ro\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/3ts5t0ro</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221023_104702-3ts5t0ro\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3ts5t0ro). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24acd7012494fdd979e9c08d9664301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221023_114828-2xgrrp6u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/2xgrrp6u\" target=\"_blank\">dulcet-thunder-11</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name Baseline_BNN_Resnet18_inflate_3 \n",
      "\n",
      "\n",
      "Run Start : 2022-10-23 11-48-28\n",
      "start_epoch : 0\n",
      "initial_lr : 0.2\n",
      "batch_size : 32\n",
      "epochs : 200\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.2\n",
      "    lr: 0.2\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.models.resnet_binary.ResNet_cifar10'>\n",
      "binerised_training : True\n",
      "Number of Elements : 1578144\n",
      "Initial accuracy:\n",
      "Test Accuracy : 1.3%, Test Loss: 33.51741357421875\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 1.2%, Test Loss: 33.42912989807129\n",
      "epoch: 1 average loss: 4.072\n",
      "Test Accuracy : 8.8%, Test Loss: 3.8390874557495116\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 2 average loss: 3.780\n",
      "Test Accuracy : 11.7%, Test Loss: 3.6329634017944334\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.80 seconds\n",
      "epoch: 3 average loss: 3.621\n",
      "Test Accuracy : 12.6%, Test Loss: 3.574101114273071\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 4 average loss: 3.510\n",
      "Test Accuracy : 16.3%, Test Loss: 3.3973598556518554\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.77 seconds\n",
      "epoch: 5 average loss: 3.436\n",
      "Test Accuracy : 16.7%, Test Loss: 3.3398843612670897\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 6 average loss: 3.362\n",
      "Test Accuracy : 18.2%, Test Loss: 3.286829874038696\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 7 average loss: 3.304\n",
      "Test Accuracy : 18.4%, Test Loss: 3.2833907737731933\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.61 seconds\n",
      "epoch: 8 average loss: 3.250\n",
      "Test Accuracy : 20.8%, Test Loss: 3.1732524185180666\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 9 average loss: 3.208\n",
      "Test Accuracy : 21.3%, Test Loss: 3.15655023765564\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 10 average loss: 3.166\n",
      "Test Accuracy : 21.8%, Test Loss: 3.129395906448364\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.71 seconds\n",
      "epoch: 11 average loss: 3.131\n",
      "Test Accuracy : 20.8%, Test Loss: 3.1424522609710692\n",
      "Epoch Time (Training + Test) = 22.57 seconds\n",
      "epoch: 12 average loss: 3.100\n",
      "Test Accuracy : 23.8%, Test Loss: 2.9946905212402344\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.81 seconds\n",
      "epoch: 13 average loss: 3.074\n",
      "Test Accuracy : 25.0%, Test Loss: 2.9811948280334475\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 14 average loss: 3.036\n",
      "Test Accuracy : 24.3%, Test Loss: 2.9747223682403563\n",
      "Epoch Time (Training + Test) = 22.76 seconds\n",
      "epoch: 15 average loss: 3.000\n",
      "Test Accuracy : 25.8%, Test Loss: 2.9359156875610353\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 16 average loss: 2.980\n",
      "Test Accuracy : 24.9%, Test Loss: 2.9411663932800294\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 17 average loss: 2.947\n",
      "Test Accuracy : 23.9%, Test Loss: 2.980159004211426\n",
      "Epoch Time (Training + Test) = 22.61 seconds\n",
      "epoch: 18 average loss: 2.932\n",
      "Test Accuracy : 27.6%, Test Loss: 2.8417440662384035\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.73 seconds\n",
      "epoch: 19 average loss: 2.899\n",
      "Test Accuracy : 27.4%, Test Loss: 2.8806711750030516\n",
      "Epoch Time (Training + Test) = 22.62 seconds\n",
      "epoch: 20 average loss: 2.882\n",
      "Test Accuracy : 28.5%, Test Loss: 2.8191970920562746\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.73 seconds\n",
      "epoch: 21 average loss: 2.849\n",
      "Test Accuracy : 26.0%, Test Loss: 2.9239257621765136\n",
      "Epoch Time (Training + Test) = 22.61 seconds\n",
      "epoch: 22 average loss: 2.832\n",
      "Test Accuracy : 28.2%, Test Loss: 2.8045113677978515\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 23 average loss: 2.807\n",
      "Test Accuracy : 30.3%, Test Loss: 2.7186829528808594\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.69 seconds\n",
      "epoch: 24 average loss: 2.779\n",
      "Test Accuracy : 29.4%, Test Loss: 2.7722844161987306\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 25 average loss: 2.757\n",
      "Test Accuracy : 30.3%, Test Loss: 2.7063805179595946\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 26 average loss: 2.736\n",
      "Test Accuracy : 28.6%, Test Loss: 2.7911381130218507\n",
      "Epoch Time (Training + Test) = 22.69 seconds\n",
      "epoch: 27 average loss: 2.721\n",
      "Test Accuracy : 29.6%, Test Loss: 2.737817081451416\n",
      "Epoch Time (Training + Test) = 22.60 seconds\n",
      "epoch: 28 average loss: 2.688\n",
      "Test Accuracy : 30.1%, Test Loss: 2.7317050609588622\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 29 average loss: 2.670\n",
      "Test Accuracy : 31.7%, Test Loss: 2.639427797317505\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 30 average loss: 2.649\n",
      "Test Accuracy : 30.2%, Test Loss: 2.722037046432495\n",
      "Epoch Time (Training + Test) = 22.62 seconds\n",
      "epoch: 31 average loss: 2.627\n",
      "Test Accuracy : 31.4%, Test Loss: 2.6395081920623777\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 32 average loss: 2.607\n",
      "Test Accuracy : 32.6%, Test Loss: 2.5795640411376954\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 33 average loss: 2.592\n",
      "Test Accuracy : 31.6%, Test Loss: 2.6722660789489745\n",
      "Epoch Time (Training + Test) = 22.62 seconds\n",
      "epoch: 34 average loss: 2.587\n",
      "Test Accuracy : 33.0%, Test Loss: 2.5971712112426757\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.80 seconds\n",
      "epoch: 35 average loss: 2.563\n",
      "Test Accuracy : 32.8%, Test Loss: 2.572363185882568\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 36 average loss: 2.536\n",
      "Test Accuracy : 34.8%, Test Loss: 2.539613578796387\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 37 average loss: 2.512\n",
      "Test Accuracy : 33.6%, Test Loss: 2.55633909034729\n",
      "Epoch Time (Training + Test) = 22.68 seconds\n",
      "epoch: 38 average loss: 2.499\n",
      "Test Accuracy : 35.1%, Test Loss: 2.48687894821167\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.68 seconds\n",
      "epoch: 39 average loss: 2.484\n",
      "Test Accuracy : 36.0%, Test Loss: 2.4536477174758913\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.68 seconds\n",
      "epoch: 40 average loss: 2.466\n",
      "Test Accuracy : 34.6%, Test Loss: 2.4964586124420167\n",
      "Epoch Time (Training + Test) = 22.69 seconds\n",
      "epoch: 41 average loss: 2.456\n",
      "Test Accuracy : 35.1%, Test Loss: 2.5091827411651613\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 42 average loss: 2.428\n",
      "Test Accuracy : 34.9%, Test Loss: 2.512528902053833\n",
      "Epoch Time (Training + Test) = 22.74 seconds\n",
      "epoch: 43 average loss: 2.411\n",
      "Test Accuracy : 36.8%, Test Loss: 2.4047905445098876\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.62 seconds\n",
      "epoch: 44 average loss: 2.396\n",
      "Test Accuracy : 36.9%, Test Loss: 2.384416679382324\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.68 seconds\n",
      "epoch: 45 average loss: 2.381\n",
      "Test Accuracy : 35.9%, Test Loss: 2.473087100982666\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 46 average loss: 2.369\n",
      "Test Accuracy : 37.4%, Test Loss: 2.4273352289199828\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 47 average loss: 2.347\n",
      "Test Accuracy : 36.9%, Test Loss: 2.432200346946716\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 48 average loss: 2.329\n",
      "Test Accuracy : 38.5%, Test Loss: 2.349924735069275\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.68 seconds\n",
      "epoch: 49 average loss: 2.319\n",
      "Test Accuracy : 38.7%, Test Loss: 2.3542545280456544\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 50 average loss: 2.306\n",
      "Test Accuracy : 39.8%, Test Loss: 2.294349449157715\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.73 seconds\n",
      "epoch: 51 average loss: 2.296\n",
      "Test Accuracy : 39.2%, Test Loss: 2.297207667350769\n",
      "Epoch Time (Training + Test) = 22.61 seconds\n",
      "epoch: 52 average loss: 2.275\n",
      "Test Accuracy : 39.3%, Test Loss: 2.301686366081238\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 53 average loss: 2.268\n",
      "Test Accuracy : 39.2%, Test Loss: 2.33914737701416\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 54 average loss: 2.247\n",
      "Test Accuracy : 39.0%, Test Loss: 2.3097304401397705\n",
      "Epoch Time (Training + Test) = 22.62 seconds\n",
      "epoch: 55 average loss: 2.235\n",
      "Test Accuracy : 40.2%, Test Loss: 2.2848814640045165\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.71 seconds\n",
      "epoch: 56 average loss: 2.231\n",
      "Test Accuracy : 40.2%, Test Loss: 2.25994881439209\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 57 average loss: 2.203\n",
      "Test Accuracy : 41.2%, Test Loss: 2.2522700872421266\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 58 average loss: 2.196\n",
      "Test Accuracy : 40.5%, Test Loss: 2.250314402580261\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 59 average loss: 2.190\n",
      "Test Accuracy : 39.9%, Test Loss: 2.2814171800613403\n",
      "Epoch Time (Training + Test) = 22.60 seconds\n",
      "epoch: 60 average loss: 2.167\n",
      "Test Accuracy : 41.0%, Test Loss: 2.2161468563079834\n",
      "Epoch Time (Training + Test) = 22.75 seconds\n",
      "epoch: 61 average loss: 2.155\n",
      "Test Accuracy : 42.2%, Test Loss: 2.2193339910507204\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.76 seconds\n",
      "epoch: 62 average loss: 2.138\n",
      "Test Accuracy : 42.4%, Test Loss: 2.1805342254638673\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.69 seconds\n",
      "epoch: 63 average loss: 2.135\n",
      "Test Accuracy : 42.5%, Test Loss: 2.206130316734314\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.71 seconds\n",
      "epoch: 64 average loss: 2.114\n",
      "Test Accuracy : 42.5%, Test Loss: 2.1678705682754518\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.67 seconds\n",
      "epoch: 65 average loss: 2.114\n",
      "Test Accuracy : 42.9%, Test Loss: 2.1733942556381227\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 66 average loss: 2.109\n",
      "Test Accuracy : 43.9%, Test Loss: 2.115448763847351\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.73 seconds\n",
      "epoch: 67 average loss: 2.099\n",
      "Test Accuracy : 42.5%, Test Loss: 2.1806868925094602\n",
      "Epoch Time (Training + Test) = 22.82 seconds\n",
      "epoch: 68 average loss: 2.074\n",
      "Test Accuracy : 42.8%, Test Loss: 2.170672830581665\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 69 average loss: 2.071\n",
      "Test Accuracy : 43.3%, Test Loss: 2.1360090646743775\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 70 average loss: 2.067\n",
      "Test Accuracy : 42.0%, Test Loss: 2.1969821310043334\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 71 average loss: 2.054\n",
      "Test Accuracy : 43.5%, Test Loss: 2.1241874017715454\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 72 average loss: 2.041\n",
      "Test Accuracy : 43.0%, Test Loss: 2.157215553283691\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 73 average loss: 2.027\n",
      "Test Accuracy : 42.6%, Test Loss: 2.1834495487213137\n",
      "Epoch Time (Training + Test) = 22.58 seconds\n",
      "epoch: 74 average loss: 2.024\n",
      "Test Accuracy : 43.2%, Test Loss: 2.110734824180603\n",
      "Epoch Time (Training + Test) = 22.74 seconds\n",
      "epoch: 75 average loss: 2.022\n",
      "Test Accuracy : 44.1%, Test Loss: 2.1288949775695802\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 76 average loss: 2.010\n",
      "Test Accuracy : 42.7%, Test Loss: 2.150915675163269\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 77 average loss: 1.993\n",
      "Test Accuracy : 44.8%, Test Loss: 2.0781522397994996\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 78 average loss: 1.991\n",
      "Test Accuracy : 43.6%, Test Loss: 2.153554443359375\n",
      "Epoch Time (Training + Test) = 22.67 seconds\n",
      "epoch: 79 average loss: 1.980\n",
      "Test Accuracy : 45.0%, Test Loss: 2.067590991973877\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.69 seconds\n",
      "epoch: 80 average loss: 1.984\n",
      "Test Accuracy : 45.9%, Test Loss: 2.0194893188476564\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 81 average loss: 1.975\n",
      "Test Accuracy : 45.8%, Test Loss: 2.047090217590332\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 82 average loss: 1.966\n",
      "Test Accuracy : 43.5%, Test Loss: 2.118926326751709\n",
      "Epoch Time (Training + Test) = 22.71 seconds\n",
      "epoch: 83 average loss: 1.954\n",
      "Test Accuracy : 47.0%, Test Loss: 1.9982737169265747\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 84 average loss: 1.950\n",
      "Test Accuracy : 45.2%, Test Loss: 2.045698826789856\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 85 average loss: 1.937\n",
      "Test Accuracy : 45.7%, Test Loss: 2.0468881187438965\n",
      "Epoch Time (Training + Test) = 22.62 seconds\n",
      "epoch: 86 average loss: 1.935\n",
      "Test Accuracy : 45.9%, Test Loss: 2.02850674533844\n",
      "Epoch Time (Training + Test) = 22.62 seconds\n",
      "epoch: 87 average loss: 1.916\n",
      "Test Accuracy : 46.2%, Test Loss: 2.0228418741226197\n",
      "Epoch Time (Training + Test) = 22.67 seconds\n",
      "epoch: 88 average loss: 1.907\n",
      "Test Accuracy : 47.4%, Test Loss: 1.9803399505615233\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.67 seconds\n",
      "epoch: 89 average loss: 1.911\n",
      "Test Accuracy : 46.1%, Test Loss: 2.0679347906112673\n",
      "Epoch Time (Training + Test) = 22.62 seconds\n",
      "epoch: 90 average loss: 1.907\n",
      "Test Accuracy : 46.2%, Test Loss: 2.043906859397888\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 91 average loss: 1.894\n",
      "Test Accuracy : 46.9%, Test Loss: 1.9868844165802002\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 92 average loss: 1.898\n",
      "Test Accuracy : 46.1%, Test Loss: 2.0344173355102537\n",
      "Epoch Time (Training + Test) = 22.68 seconds\n",
      "epoch: 93 average loss: 1.893\n",
      "Test Accuracy : 46.7%, Test Loss: 2.0123915643692016\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 94 average loss: 1.868\n",
      "Test Accuracy : 45.9%, Test Loss: 2.0319665937423705\n",
      "Epoch Time (Training + Test) = 22.75 seconds\n",
      "epoch: 95 average loss: 1.873\n",
      "Test Accuracy : 47.8%, Test Loss: 1.9777659730911255\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.67 seconds\n",
      "epoch: 96 average loss: 1.861\n",
      "Test Accuracy : 47.1%, Test Loss: 2.0257804861068727\n",
      "Epoch Time (Training + Test) = 22.67 seconds\n",
      "epoch: 97 average loss: 1.867\n",
      "Test Accuracy : 46.1%, Test Loss: 2.0440618324279787\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 98 average loss: 1.866\n",
      "Test Accuracy : 47.3%, Test Loss: 1.9803420171737671\n",
      "Epoch Time (Training + Test) = 22.72 seconds\n",
      "epoch: 99 average loss: 1.853\n",
      "Test Accuracy : 47.4%, Test Loss: 1.9713399953842163\n",
      "Epoch Time (Training + Test) = 22.67 seconds\n",
      "epoch: 100 average loss: 1.839\n",
      "Test Accuracy : 46.9%, Test Loss: 2.000288224220276\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 101 average loss: 1.841\n",
      "Test Accuracy : 47.7%, Test Loss: 1.9778493003845214\n",
      "Epoch Time (Training + Test) = 22.60 seconds\n",
      "epoch: 102 average loss: 1.842\n",
      "Test Accuracy : 46.6%, Test Loss: 2.0074402799606323\n",
      "Epoch Time (Training + Test) = 22.60 seconds\n",
      "epoch: 103 average loss: 1.823\n",
      "Test Accuracy : 47.6%, Test Loss: 1.941894187927246\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 104 average loss: 1.824\n",
      "Test Accuracy : 48.2%, Test Loss: 1.9561064758300781\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.68 seconds\n",
      "epoch: 105 average loss: 1.824\n",
      "Test Accuracy : 48.5%, Test Loss: 1.9398240432739258\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 106 average loss: 1.815\n",
      "Test Accuracy : 48.7%, Test Loss: 1.9238123159408569\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.77 seconds\n",
      "epoch: 107 average loss: 1.804\n",
      "Test Accuracy : 48.7%, Test Loss: 1.9393330354690552\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 108 average loss: 1.806\n",
      "Test Accuracy : 48.8%, Test Loss: 1.9341200876235962\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.71 seconds\n",
      "epoch: 109 average loss: 1.809\n",
      "Test Accuracy : 49.2%, Test Loss: 1.914094554901123\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 110 average loss: 1.800\n",
      "Test Accuracy : 48.3%, Test Loss: 1.9159311876296996\n",
      "Epoch Time (Training + Test) = 22.72 seconds\n",
      "epoch: 111 average loss: 1.787\n",
      "Test Accuracy : 48.5%, Test Loss: 1.933048231124878\n",
      "Epoch Time (Training + Test) = 22.72 seconds\n",
      "epoch: 112 average loss: 1.779\n",
      "Test Accuracy : 48.1%, Test Loss: 1.9391241989135741\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 113 average loss: 1.780\n",
      "Test Accuracy : 49.2%, Test Loss: 1.9001193447113036\n",
      "Epoch Time (Training + Test) = 22.62 seconds\n",
      "epoch: 114 average loss: 1.773\n",
      "Test Accuracy : 48.3%, Test Loss: 1.952197546005249\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 115 average loss: 1.770\n",
      "Test Accuracy : 47.8%, Test Loss: 1.9705997428894042\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 116 average loss: 1.762\n",
      "Test Accuracy : 49.3%, Test Loss: 1.9065384569168091\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.71 seconds\n",
      "epoch: 117 average loss: 1.764\n",
      "Test Accuracy : 46.9%, Test Loss: 2.0141130905151368\n",
      "Epoch Time (Training + Test) = 22.59 seconds\n",
      "epoch: 118 average loss: 1.762\n",
      "Test Accuracy : 48.8%, Test Loss: 1.9250879278182984\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 119 average loss: 1.751\n",
      "Test Accuracy : 49.2%, Test Loss: 1.9008763589859008\n",
      "Epoch Time (Training + Test) = 22.67 seconds\n",
      "epoch: 120 average loss: 1.744\n",
      "Test Accuracy : 49.4%, Test Loss: 1.8971383829116821\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.74 seconds\n",
      "epoch: 121 average loss: 1.732\n",
      "Test Accuracy : 49.2%, Test Loss: 1.9185050220489501\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 122 average loss: 1.739\n",
      "Test Accuracy : 49.0%, Test Loss: 1.9454947185516358\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 123 average loss: 1.726\n",
      "Test Accuracy : 49.8%, Test Loss: 1.8841716165542604\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 124 average loss: 1.731\n",
      "Test Accuracy : 49.9%, Test Loss: 1.895703966140747\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.69 seconds\n",
      "epoch: 125 average loss: 1.722\n",
      "Test Accuracy : 49.7%, Test Loss: 1.8760585470199584\n",
      "Epoch Time (Training + Test) = 22.62 seconds\n",
      "epoch: 126 average loss: 1.726\n",
      "Test Accuracy : 50.5%, Test Loss: 1.8626782331466676\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.61 seconds\n",
      "epoch: 127 average loss: 1.722\n",
      "Test Accuracy : 49.8%, Test Loss: 1.896000147819519\n",
      "Epoch Time (Training + Test) = 22.68 seconds\n",
      "epoch: 128 average loss: 1.717\n",
      "Test Accuracy : 49.8%, Test Loss: 1.87750075340271\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 129 average loss: 1.710\n",
      "Test Accuracy : 49.7%, Test Loss: 1.8919514427185058\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 130 average loss: 1.703\n",
      "Test Accuracy : 50.4%, Test Loss: 1.87568900680542\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 131 average loss: 1.694\n",
      "Test Accuracy : 49.2%, Test Loss: 1.869932165145874\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 132 average loss: 1.692\n",
      "Test Accuracy : 50.1%, Test Loss: 1.8776286668777467\n",
      "Epoch Time (Training + Test) = 22.75 seconds\n",
      "epoch: 133 average loss: 1.693\n",
      "Test Accuracy : 49.0%, Test Loss: 1.9089162635803223\n",
      "Epoch Time (Training + Test) = 22.60 seconds\n",
      "epoch: 134 average loss: 1.700\n",
      "Test Accuracy : 50.1%, Test Loss: 1.8576709289550781\n",
      "Epoch Time (Training + Test) = 22.60 seconds\n",
      "epoch: 135 average loss: 1.688\n",
      "Test Accuracy : 49.4%, Test Loss: 1.9062564210891724\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 136 average loss: 1.692\n",
      "Test Accuracy : 51.0%, Test Loss: 1.8499124784469605\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 137 average loss: 1.684\n",
      "Test Accuracy : 50.5%, Test Loss: 1.8523456153869629\n",
      "Epoch Time (Training + Test) = 22.67 seconds\n",
      "epoch: 138 average loss: 1.671\n",
      "Test Accuracy : 50.8%, Test Loss: 1.8646260089874267\n",
      "Epoch Time (Training + Test) = 22.61 seconds\n",
      "epoch: 139 average loss: 1.673\n",
      "Test Accuracy : 50.6%, Test Loss: 1.864177565574646\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 140 average loss: 1.670\n",
      "Test Accuracy : 50.3%, Test Loss: 1.8688141508102416\n",
      "Epoch Time (Training + Test) = 22.72 seconds\n",
      "epoch: 141 average loss: 1.663\n",
      "Test Accuracy : 50.7%, Test Loss: 1.8626516828536988\n",
      "Epoch Time (Training + Test) = 22.60 seconds\n",
      "epoch: 142 average loss: 1.662\n",
      "Test Accuracy : 50.4%, Test Loss: 1.8854956531524658\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 143 average loss: 1.652\n",
      "Test Accuracy : 50.7%, Test Loss: 1.858231629371643\n",
      "Epoch Time (Training + Test) = 22.69 seconds\n",
      "epoch: 144 average loss: 1.654\n",
      "Test Accuracy : 50.6%, Test Loss: 1.8184094924926757\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 145 average loss: 1.649\n",
      "Test Accuracy : 51.3%, Test Loss: 1.8433447408676147\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.69 seconds\n",
      "epoch: 146 average loss: 1.644\n",
      "Test Accuracy : 51.7%, Test Loss: 1.8339262571334838\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.67 seconds\n",
      "epoch: 147 average loss: 1.649\n",
      "Test Accuracy : 50.7%, Test Loss: 1.852868293762207\n",
      "Epoch Time (Training + Test) = 22.77 seconds\n",
      "epoch: 148 average loss: 1.640\n",
      "Test Accuracy : 51.2%, Test Loss: 1.8490430221557617\n",
      "Epoch Time (Training + Test) = 22.74 seconds\n",
      "epoch: 149 average loss: 1.638\n",
      "Test Accuracy : 52.1%, Test Loss: 1.81400057888031\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 150 average loss: 1.640\n",
      "Test Accuracy : 52.1%, Test Loss: 1.8015830907821655\n",
      "Epoch Time (Training + Test) = 22.69 seconds\n",
      "epoch: 151 average loss: 1.637\n",
      "Test Accuracy : 51.2%, Test Loss: 1.8546226854324341\n",
      "Epoch Time (Training + Test) = 22.71 seconds\n",
      "epoch: 152 average loss: 1.618\n",
      "Test Accuracy : 53.0%, Test Loss: 1.7879508390426635\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.71 seconds\n",
      "epoch: 153 average loss: 1.632\n",
      "Test Accuracy : 51.5%, Test Loss: 1.8264592351913451\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 154 average loss: 1.615\n",
      "Test Accuracy : 51.1%, Test Loss: 1.843719274520874\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 155 average loss: 1.614\n",
      "Test Accuracy : 51.5%, Test Loss: 1.8311603689193725\n",
      "Epoch Time (Training + Test) = 22.62 seconds\n",
      "epoch: 156 average loss: 1.618\n",
      "Test Accuracy : 51.7%, Test Loss: 1.820120509147644\n",
      "Epoch Time (Training + Test) = 22.71 seconds\n",
      "epoch: 157 average loss: 1.607\n",
      "Test Accuracy : 51.1%, Test Loss: 1.8448877277374267\n",
      "Epoch Time (Training + Test) = 22.58 seconds\n",
      "epoch: 158 average loss: 1.613\n",
      "Test Accuracy : 50.9%, Test Loss: 1.850357169151306\n",
      "Epoch Time (Training + Test) = 22.68 seconds\n",
      "epoch: 159 average loss: 1.609\n",
      "Test Accuracy : 51.5%, Test Loss: 1.829759147644043\n",
      "Epoch Time (Training + Test) = 22.66 seconds\n",
      "epoch: 160 average loss: 1.608\n",
      "Test Accuracy : 51.8%, Test Loss: 1.813573076248169\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 161 average loss: 1.605\n",
      "Test Accuracy : 51.1%, Test Loss: 1.822595534324646\n",
      "Epoch Time (Training + Test) = 22.69 seconds\n",
      "epoch: 162 average loss: 1.601\n",
      "Test Accuracy : 51.6%, Test Loss: 1.8045091066360475\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 163 average loss: 1.598\n",
      "Test Accuracy : 51.9%, Test Loss: 1.8179980096817017\n",
      "Epoch Time (Training + Test) = 22.60 seconds\n",
      "epoch: 164 average loss: 1.607\n",
      "Test Accuracy : 50.5%, Test Loss: 1.8299152421951295\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 165 average loss: 1.589\n",
      "Test Accuracy : 52.1%, Test Loss: 1.7949099760055542\n",
      "Epoch Time (Training + Test) = 22.62 seconds\n",
      "epoch: 166 average loss: 1.588\n",
      "Test Accuracy : 53.0%, Test Loss: 1.777577341079712\n",
      "Epoch Time (Training + Test) = 22.68 seconds\n",
      "epoch: 167 average loss: 1.573\n",
      "Test Accuracy : 52.4%, Test Loss: 1.7989479770660401\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 168 average loss: 1.578\n",
      "Test Accuracy : 51.1%, Test Loss: 1.8435114641189576\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 169 average loss: 1.569\n",
      "Test Accuracy : 51.2%, Test Loss: 1.8448694133758545\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 170 average loss: 1.574\n",
      "Test Accuracy : 51.6%, Test Loss: 1.8077625665664674\n",
      "Epoch Time (Training + Test) = 22.61 seconds\n",
      "epoch: 171 average loss: 1.572\n",
      "Test Accuracy : 51.9%, Test Loss: 1.7978223819732666\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 172 average loss: 1.573\n",
      "Test Accuracy : 51.8%, Test Loss: 1.819065489768982\n",
      "Epoch Time (Training + Test) = 22.69 seconds\n",
      "epoch: 173 average loss: 1.562\n",
      "Test Accuracy : 51.0%, Test Loss: 1.8299374790191651\n",
      "Epoch Time (Training + Test) = 22.69 seconds\n",
      "epoch: 174 average loss: 1.557\n",
      "Test Accuracy : 52.1%, Test Loss: 1.7827360954284668\n",
      "Epoch Time (Training + Test) = 22.69 seconds\n",
      "epoch: 175 average loss: 1.569\n",
      "Test Accuracy : 52.1%, Test Loss: 1.786494987487793\n",
      "Epoch Time (Training + Test) = 22.61 seconds\n",
      "epoch: 176 average loss: 1.557\n",
      "Test Accuracy : 52.0%, Test Loss: 1.799153902053833\n",
      "Epoch Time (Training + Test) = 22.68 seconds\n",
      "epoch: 177 average loss: 1.557\n",
      "Test Accuracy : 51.5%, Test Loss: 1.8372350931167603\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 178 average loss: 1.551\n",
      "Test Accuracy : 53.3%, Test Loss: 1.7745550985336305\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.63 seconds\n",
      "epoch: 179 average loss: 1.546\n",
      "Test Accuracy : 51.4%, Test Loss: 1.7999547805786134\n",
      "Epoch Time (Training + Test) = 22.59 seconds\n",
      "epoch: 180 average loss: 1.554\n",
      "Test Accuracy : 51.9%, Test Loss: 1.8132383327484132\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 181 average loss: 1.537\n",
      "Test Accuracy : 52.7%, Test Loss: 1.7701831789016724\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 182 average loss: 1.541\n",
      "Test Accuracy : 52.2%, Test Loss: 1.8033650922775268\n",
      "Epoch Time (Training + Test) = 22.71 seconds\n",
      "epoch: 183 average loss: 1.541\n",
      "Test Accuracy : 52.7%, Test Loss: 1.7731486148834228\n",
      "Epoch Time (Training + Test) = 22.59 seconds\n",
      "epoch: 184 average loss: 1.539\n",
      "Test Accuracy : 52.6%, Test Loss: 1.7691436834335328\n",
      "Epoch Time (Training + Test) = 22.68 seconds\n",
      "epoch: 185 average loss: 1.541\n",
      "Test Accuracy : 53.0%, Test Loss: 1.7641180839538575\n",
      "Epoch Time (Training + Test) = 22.67 seconds\n",
      "epoch: 186 average loss: 1.535\n",
      "Test Accuracy : 53.1%, Test Loss: 1.7602563934326172\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 187 average loss: 1.533\n",
      "Test Accuracy : 52.8%, Test Loss: 1.7599993743896485\n",
      "Epoch Time (Training + Test) = 22.60 seconds\n",
      "epoch: 188 average loss: 1.528\n",
      "Test Accuracy : 52.8%, Test Loss: 1.7890165157318114\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 189 average loss: 1.522\n",
      "Test Accuracy : 54.1%, Test Loss: 1.7442805366516114\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 190 average loss: 1.531\n",
      "Test Accuracy : 51.9%, Test Loss: 1.8013545484542848\n",
      "Epoch Time (Training + Test) = 22.71 seconds\n",
      "epoch: 191 average loss: 1.511\n",
      "Test Accuracy : 52.0%, Test Loss: 1.8189987850189209\n",
      "Epoch Time (Training + Test) = 22.60 seconds\n",
      "epoch: 192 average loss: 1.511\n",
      "Test Accuracy : 53.1%, Test Loss: 1.7633451805114746\n",
      "Epoch Time (Training + Test) = 22.70 seconds\n",
      "epoch: 193 average loss: 1.502\n",
      "Test Accuracy : 54.1%, Test Loss: 1.7356517114639283\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 22.73 seconds\n",
      "epoch: 194 average loss: 1.507\n",
      "Test Accuracy : 53.2%, Test Loss: 1.7845132312774659\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 195 average loss: 1.509\n",
      "Test Accuracy : 53.7%, Test Loss: 1.7676896858215332\n",
      "Epoch Time (Training + Test) = 22.61 seconds\n",
      "epoch: 196 average loss: 1.503\n",
      "Test Accuracy : 53.2%, Test Loss: 1.7557009630203246\n",
      "Epoch Time (Training + Test) = 22.71 seconds\n",
      "epoch: 197 average loss: 1.491\n",
      "Test Accuracy : 53.2%, Test Loss: 1.7679226369857788\n",
      "Epoch Time (Training + Test) = 22.65 seconds\n",
      "epoch: 198 average loss: 1.487\n",
      "Test Accuracy : 52.8%, Test Loss: 1.7593359117507934\n",
      "Epoch Time (Training + Test) = 22.73 seconds\n",
      "epoch: 199 average loss: 1.485\n",
      "Test Accuracy : 53.1%, Test Loss: 1.7563405742645264\n",
      "Epoch Time (Training + Test) = 22.64 seconds\n",
      "epoch: 200 average loss: 1.477\n",
      "Test Accuracy : 53.4%, Test Loss: 1.748018711090088\n",
      "Epoch Time (Training + Test) = 22.76 seconds\n",
      "Data Saved to Baseline_BNN_Resnet18_inflate_3.csv\n",
      "Finished Training: \n",
      "Total Time 2.518524 hours\n",
      " Average Time Per Epoch 45.33 seconds\n",
      "Using Default (SGD) Optimizer\n",
      "Scheduler Set {'T_max': 200, 'eta_min': 0, 'base_lrs': [0.2], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.2]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2xgrrp6u) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>â–â–‚â–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch time (s)</td><td>â–…â–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–…â–†â–ˆâ–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–…â–‚â–ƒâ–„â–‚â–„â–„â–‡â–ƒâ–â–‚â–ƒâ–„â–ƒâ–â–‚â–…â–ƒ</td></tr><tr><td>lr</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–</td></tr><tr><td>test_accuracy</td><td>â–â–‚â–ƒâ–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>test_loss</td><td>â–ˆâ–†â–†â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>training_loss</td><td>â–ˆâ–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.54125</td></tr><tr><td>Current Best Acc</td><td>0.54125</td></tr><tr><td>Total Time (hours)</td><td>2.51852</td></tr><tr><td>epoch</td><td>200</td></tr><tr><td>epoch time (s)</td><td>22.76123</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>test_accuracy</td><td>0.53412</td></tr><tr><td>test_loss</td><td>1.74802</td></tr><tr><td>training_loss</td><td>1.47739</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dulcet-thunder-11</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/2xgrrp6u\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/2xgrrp6u</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221023_114828-2xgrrp6u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2xgrrp6u). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3425d929b3644ef8a787ce852e97f37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333145128, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221023_130429-5zw8azig</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/5zw8azig\" target=\"_blank\">apricot-shape-12</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name Baseline_BNN_Resnet18_inflate_4 \n",
      "\n",
      "\n",
      "Run Start : 2022-10-23 13-04-29\n",
      "start_epoch : 0\n",
      "initial_lr : 0.2\n",
      "batch_size : 32\n",
      "epochs : 200\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.2\n",
      "    lr: 0.2\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.models.resnet_binary.ResNet_cifar10'>\n",
      "binerised_training : True\n",
      "Number of Elements : 2796336\n",
      "Initial accuracy:\n",
      "Test Accuracy : 1.3%, Test Loss: 38.64717101745605\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 1.4%, Test Loss: 38.78788375854492\n",
      "best_acc.pth saved!\n",
      "epoch: 1 average loss: 4.057\n",
      "Test Accuracy : 9.0%, Test Loss: 3.833388271331787\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.94 seconds\n",
      "epoch: 2 average loss: 3.775\n",
      "Test Accuracy : 10.5%, Test Loss: 3.669631546020508\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 3 average loss: 3.629\n",
      "Test Accuracy : 13.4%, Test Loss: 3.545806438446045\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.79 seconds\n",
      "epoch: 4 average loss: 3.509\n",
      "Test Accuracy : 15.7%, Test Loss: 3.4227551364898683\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 5 average loss: 3.415\n",
      "Test Accuracy : 18.2%, Test Loss: 3.2822254848480226\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.82 seconds\n",
      "epoch: 6 average loss: 3.342\n",
      "Test Accuracy : 18.1%, Test Loss: 3.2624872417449953\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 7 average loss: 3.273\n",
      "Test Accuracy : 20.2%, Test Loss: 3.1869533863067625\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.83 seconds\n",
      "epoch: 8 average loss: 3.212\n",
      "Test Accuracy : 21.2%, Test Loss: 3.1502675189971923\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.90 seconds\n",
      "epoch: 9 average loss: 3.166\n",
      "Test Accuracy : 22.5%, Test Loss: 3.0702759552001955\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 10 average loss: 3.112\n",
      "Test Accuracy : 22.9%, Test Loss: 3.066811641693115\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.98 seconds\n",
      "epoch: 11 average loss: 3.076\n",
      "Test Accuracy : 24.1%, Test Loss: 2.998911678314209\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.90 seconds\n",
      "epoch: 12 average loss: 3.037\n",
      "Test Accuracy : 24.4%, Test Loss: 2.9687459144592285\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.92 seconds\n",
      "epoch: 13 average loss: 3.002\n",
      "Test Accuracy : 26.0%, Test Loss: 2.925030960083008\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 14 average loss: 2.954\n",
      "Test Accuracy : 26.1%, Test Loss: 2.894076982498169\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 15 average loss: 2.916\n",
      "Test Accuracy : 26.6%, Test Loss: 2.8571322441101072\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 16 average loss: 2.877\n",
      "Test Accuracy : 27.3%, Test Loss: 2.818039695739746\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.90 seconds\n",
      "epoch: 17 average loss: 2.829\n",
      "Test Accuracy : 27.5%, Test Loss: 2.838209108352661\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 18 average loss: 2.802\n",
      "Test Accuracy : 29.8%, Test Loss: 2.73674591255188\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 19 average loss: 2.764\n",
      "Test Accuracy : 29.0%, Test Loss: 2.779336753845215\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 20 average loss: 2.732\n",
      "Test Accuracy : 29.3%, Test Loss: 2.7659272785186766\n",
      "Epoch Time (Training + Test) = 26.90 seconds\n",
      "epoch: 21 average loss: 2.683\n",
      "Test Accuracy : 30.7%, Test Loss: 2.724083305358887\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.99 seconds\n",
      "epoch: 22 average loss: 2.647\n",
      "Test Accuracy : 32.5%, Test Loss: 2.616971736907959\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.96 seconds\n",
      "epoch: 23 average loss: 2.631\n",
      "Test Accuracy : 34.2%, Test Loss: 2.543529125213623\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.83 seconds\n",
      "epoch: 24 average loss: 2.578\n",
      "Test Accuracy : 34.2%, Test Loss: 2.542272699356079\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 25 average loss: 2.543\n",
      "Test Accuracy : 34.0%, Test Loss: 2.5418354930877687\n",
      "Epoch Time (Training + Test) = 26.82 seconds\n",
      "epoch: 26 average loss: 2.513\n",
      "Test Accuracy : 34.4%, Test Loss: 2.534747821807861\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 27 average loss: 2.475\n",
      "Test Accuracy : 35.4%, Test Loss: 2.4537126445770263\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 28 average loss: 2.433\n",
      "Test Accuracy : 36.3%, Test Loss: 2.414024433135986\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.94 seconds\n",
      "epoch: 29 average loss: 2.408\n",
      "Test Accuracy : 37.6%, Test Loss: 2.3524432125091552\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 30 average loss: 2.372\n",
      "Test Accuracy : 38.4%, Test Loss: 2.3371645765304567\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.91 seconds\n",
      "epoch: 31 average loss: 2.343\n",
      "Test Accuracy : 37.6%, Test Loss: 2.360812763214111\n",
      "Epoch Time (Training + Test) = 26.94 seconds\n",
      "epoch: 32 average loss: 2.322\n",
      "Test Accuracy : 38.4%, Test Loss: 2.3299004077911376\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 33 average loss: 2.287\n",
      "Test Accuracy : 39.0%, Test Loss: 2.32724711227417\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 34 average loss: 2.267\n",
      "Test Accuracy : 40.1%, Test Loss: 2.263195008277893\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 35 average loss: 2.242\n",
      "Test Accuracy : 39.5%, Test Loss: 2.285444201469421\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 36 average loss: 2.209\n",
      "Test Accuracy : 41.3%, Test Loss: 2.235389380455017\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 37 average loss: 2.197\n",
      "Test Accuracy : 40.8%, Test Loss: 2.233400942802429\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 38 average loss: 2.180\n",
      "Test Accuracy : 42.0%, Test Loss: 2.188683250427246\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.93 seconds\n",
      "epoch: 39 average loss: 2.147\n",
      "Test Accuracy : 41.9%, Test Loss: 2.169275273323059\n",
      "Epoch Time (Training + Test) = 26.96 seconds\n",
      "epoch: 40 average loss: 2.142\n",
      "Test Accuracy : 41.5%, Test Loss: 2.2078245668411256\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 41 average loss: 2.128\n",
      "Test Accuracy : 42.9%, Test Loss: 2.150942529678345\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.91 seconds\n",
      "epoch: 42 average loss: 2.102\n",
      "Test Accuracy : 41.9%, Test Loss: 2.2072476062774657\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 43 average loss: 2.086\n",
      "Test Accuracy : 43.2%, Test Loss: 2.1540494575500486\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.98 seconds\n",
      "epoch: 44 average loss: 2.064\n",
      "Test Accuracy : 44.9%, Test Loss: 2.066113450050354\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.94 seconds\n",
      "epoch: 45 average loss: 2.044\n",
      "Test Accuracy : 43.6%, Test Loss: 2.1211320915222167\n",
      "Epoch Time (Training + Test) = 26.80 seconds\n",
      "epoch: 46 average loss: 2.033\n",
      "Test Accuracy : 45.1%, Test Loss: 2.067191394805908\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 47 average loss: 2.012\n",
      "Test Accuracy : 45.8%, Test Loss: 2.044773140907288\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 48 average loss: 1.996\n",
      "Test Accuracy : 43.5%, Test Loss: 2.116526122093201\n",
      "Epoch Time (Training + Test) = 26.96 seconds\n",
      "epoch: 49 average loss: 1.981\n",
      "Test Accuracy : 45.9%, Test Loss: 2.0220335693359375\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 50 average loss: 1.970\n",
      "Test Accuracy : 45.7%, Test Loss: 2.026400679588318\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 51 average loss: 1.958\n",
      "Test Accuracy : 45.5%, Test Loss: 2.0412753238677976\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 52 average loss: 1.930\n",
      "Test Accuracy : 45.5%, Test Loss: 2.060883172035217\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 53 average loss: 1.920\n",
      "Test Accuracy : 47.1%, Test Loss: 1.989752130508423\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 54 average loss: 1.915\n",
      "Test Accuracy : 46.0%, Test Loss: 2.0206297340393067\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 55 average loss: 1.910\n",
      "Test Accuracy : 47.1%, Test Loss: 1.992212082862854\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 56 average loss: 1.887\n",
      "Test Accuracy : 46.5%, Test Loss: 2.0085056743621825\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 57 average loss: 1.876\n",
      "Test Accuracy : 47.0%, Test Loss: 1.99621905708313\n",
      "Epoch Time (Training + Test) = 26.93 seconds\n",
      "epoch: 58 average loss: 1.868\n",
      "Test Accuracy : 47.2%, Test Loss: 1.9701376399993897\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.90 seconds\n",
      "epoch: 59 average loss: 1.864\n",
      "Test Accuracy : 47.3%, Test Loss: 1.9759884281158446\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.82 seconds\n",
      "epoch: 60 average loss: 1.839\n",
      "Test Accuracy : 48.5%, Test Loss: 1.9198969058990478\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.02 seconds\n",
      "epoch: 61 average loss: 1.833\n",
      "Test Accuracy : 47.4%, Test Loss: 1.954556757926941\n",
      "Epoch Time (Training + Test) = 26.81 seconds\n",
      "epoch: 62 average loss: 1.824\n",
      "Test Accuracy : 47.0%, Test Loss: 1.983890814781189\n",
      "Epoch Time (Training + Test) = 26.97 seconds\n",
      "epoch: 63 average loss: 1.816\n",
      "Test Accuracy : 48.5%, Test Loss: 1.9256665782928466\n",
      "Epoch Time (Training + Test) = 26.80 seconds\n",
      "epoch: 64 average loss: 1.799\n",
      "Test Accuracy : 48.4%, Test Loss: 1.9627915849685669\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 65 average loss: 1.791\n",
      "Test Accuracy : 47.4%, Test Loss: 1.9657552213668823\n",
      "Epoch Time (Training + Test) = 26.83 seconds\n",
      "epoch: 66 average loss: 1.788\n",
      "Test Accuracy : 49.4%, Test Loss: 1.8858152236938477\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.01 seconds\n",
      "epoch: 67 average loss: 1.774\n",
      "Test Accuracy : 48.1%, Test Loss: 1.9301589326858521\n",
      "Epoch Time (Training + Test) = 26.82 seconds\n",
      "epoch: 68 average loss: 1.764\n",
      "Test Accuracy : 49.6%, Test Loss: 1.9026603899002075\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.94 seconds\n",
      "epoch: 69 average loss: 1.746\n",
      "Test Accuracy : 48.7%, Test Loss: 1.9222510852813721\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 70 average loss: 1.740\n",
      "Test Accuracy : 49.3%, Test Loss: 1.9040451850891114\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 71 average loss: 1.736\n",
      "Test Accuracy : 49.3%, Test Loss: 1.8834863367080688\n",
      "Epoch Time (Training + Test) = 26.90 seconds\n",
      "epoch: 72 average loss: 1.712\n",
      "Test Accuracy : 49.0%, Test Loss: 1.8904636640548707\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 73 average loss: 1.716\n",
      "Test Accuracy : 49.0%, Test Loss: 1.9315552368164062\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 74 average loss: 1.700\n",
      "Test Accuracy : 47.8%, Test Loss: 1.9673618927001952\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 75 average loss: 1.694\n",
      "Test Accuracy : 48.7%, Test Loss: 1.9135940151214599\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 76 average loss: 1.690\n",
      "Test Accuracy : 50.3%, Test Loss: 1.874756757736206\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.92 seconds\n",
      "epoch: 77 average loss: 1.675\n",
      "Test Accuracy : 50.2%, Test Loss: 1.8754661083221436\n",
      "Epoch Time (Training + Test) = 26.95 seconds\n",
      "epoch: 78 average loss: 1.682\n",
      "Test Accuracy : 49.9%, Test Loss: 1.8628112831115722\n",
      "Epoch Time (Training + Test) = 26.84 seconds\n",
      "epoch: 79 average loss: 1.666\n",
      "Test Accuracy : 50.1%, Test Loss: 1.8659441242218018\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 80 average loss: 1.663\n",
      "Test Accuracy : 51.0%, Test Loss: 1.8377994298934937\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.97 seconds\n",
      "epoch: 81 average loss: 1.649\n",
      "Test Accuracy : 50.1%, Test Loss: 1.8777614707946777\n",
      "Epoch Time (Training + Test) = 26.77 seconds\n",
      "epoch: 82 average loss: 1.641\n",
      "Test Accuracy : 51.0%, Test Loss: 1.8482150917053222\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 83 average loss: 1.629\n",
      "Test Accuracy : 48.6%, Test Loss: 1.8993934955596923\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 84 average loss: 1.624\n",
      "Test Accuracy : 51.2%, Test Loss: 1.8486435384750366\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 85 average loss: 1.615\n",
      "Test Accuracy : 52.1%, Test Loss: 1.7881522932052611\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.83 seconds\n",
      "epoch: 86 average loss: 1.618\n",
      "Test Accuracy : 51.1%, Test Loss: 1.8408497152328491\n",
      "Epoch Time (Training + Test) = 26.91 seconds\n",
      "epoch: 87 average loss: 1.598\n",
      "Test Accuracy : 51.2%, Test Loss: 1.8543550300598144\n",
      "Epoch Time (Training + Test) = 26.81 seconds\n",
      "epoch: 88 average loss: 1.598\n",
      "Test Accuracy : 51.2%, Test Loss: 1.8474494047164918\n",
      "Epoch Time (Training + Test) = 26.91 seconds\n",
      "epoch: 89 average loss: 1.587\n",
      "Test Accuracy : 52.5%, Test Loss: 1.7989396982192993\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.90 seconds\n",
      "epoch: 90 average loss: 1.584\n",
      "Test Accuracy : 50.7%, Test Loss: 1.8468781185150147\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 91 average loss: 1.572\n",
      "Test Accuracy : 51.9%, Test Loss: 1.805184606552124\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 92 average loss: 1.576\n",
      "Test Accuracy : 51.1%, Test Loss: 1.8198259420394898\n",
      "Epoch Time (Training + Test) = 26.83 seconds\n",
      "epoch: 93 average loss: 1.558\n",
      "Test Accuracy : 51.4%, Test Loss: 1.8180446405410766\n",
      "Epoch Time (Training + Test) = 26.82 seconds\n",
      "epoch: 94 average loss: 1.556\n",
      "Test Accuracy : 52.8%, Test Loss: 1.765641761779785\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 95 average loss: 1.551\n",
      "Test Accuracy : 52.8%, Test Loss: 1.7585849075317384\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.84 seconds\n",
      "epoch: 96 average loss: 1.548\n",
      "Test Accuracy : 51.0%, Test Loss: 1.841053957939148\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 97 average loss: 1.533\n",
      "Test Accuracy : 51.2%, Test Loss: 1.8001622753143312\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 98 average loss: 1.532\n",
      "Test Accuracy : 52.1%, Test Loss: 1.8050791931152343\n",
      "Epoch Time (Training + Test) = 26.93 seconds\n",
      "epoch: 99 average loss: 1.526\n",
      "Test Accuracy : 52.2%, Test Loss: 1.7645622777938843\n",
      "Epoch Time (Training + Test) = 26.80 seconds\n",
      "epoch: 100 average loss: 1.513\n",
      "Test Accuracy : 51.5%, Test Loss: 1.8285156421661377\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 101 average loss: 1.506\n",
      "Test Accuracy : 52.2%, Test Loss: 1.796700192451477\n",
      "Epoch Time (Training + Test) = 26.81 seconds\n",
      "epoch: 102 average loss: 1.510\n",
      "Test Accuracy : 52.4%, Test Loss: 1.7834619245529175\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 103 average loss: 1.498\n",
      "Test Accuracy : 51.6%, Test Loss: 1.79683349609375\n",
      "Epoch Time (Training + Test) = 26.83 seconds\n",
      "epoch: 104 average loss: 1.489\n",
      "Test Accuracy : 53.0%, Test Loss: 1.7834298629760743\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.90 seconds\n",
      "epoch: 105 average loss: 1.489\n",
      "Test Accuracy : 53.4%, Test Loss: 1.729413405418396\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 106 average loss: 1.478\n",
      "Test Accuracy : 52.3%, Test Loss: 1.7815475206375122\n",
      "Epoch Time (Training + Test) = 26.98 seconds\n",
      "epoch: 107 average loss: 1.480\n",
      "Test Accuracy : 53.0%, Test Loss: 1.767760377883911\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 108 average loss: 1.476\n",
      "Test Accuracy : 53.7%, Test Loss: 1.7383247270584106\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 109 average loss: 1.474\n",
      "Test Accuracy : 52.9%, Test Loss: 1.7571739711761474\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 110 average loss: 1.466\n",
      "Test Accuracy : 53.7%, Test Loss: 1.7368159284591675\n",
      "Epoch Time (Training + Test) = 26.97 seconds\n",
      "epoch: 111 average loss: 1.448\n",
      "Test Accuracy : 53.0%, Test Loss: 1.7700050048828124\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 112 average loss: 1.447\n",
      "Test Accuracy : 52.8%, Test Loss: 1.7814012413024902\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 113 average loss: 1.444\n",
      "Test Accuracy : 53.8%, Test Loss: 1.7297362718582154\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 114 average loss: 1.437\n",
      "Test Accuracy : 53.3%, Test Loss: 1.7452047452926636\n",
      "Epoch Time (Training + Test) = 26.83 seconds\n",
      "epoch: 115 average loss: 1.434\n",
      "Test Accuracy : 53.4%, Test Loss: 1.7346281423568726\n",
      "Epoch Time (Training + Test) = 27.00 seconds\n",
      "epoch: 116 average loss: 1.429\n",
      "Test Accuracy : 53.0%, Test Loss: 1.7434380683898927\n",
      "Epoch Time (Training + Test) = 26.84 seconds\n",
      "epoch: 117 average loss: 1.414\n",
      "Test Accuracy : 54.3%, Test Loss: 1.7272570962905884\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 118 average loss: 1.422\n",
      "Test Accuracy : 53.7%, Test Loss: 1.7310428915023803\n",
      "Epoch Time (Training + Test) = 26.92 seconds\n",
      "epoch: 119 average loss: 1.410\n",
      "Test Accuracy : 53.5%, Test Loss: 1.7413915281295775\n",
      "Epoch Time (Training + Test) = 26.82 seconds\n",
      "epoch: 120 average loss: 1.407\n",
      "Test Accuracy : 54.3%, Test Loss: 1.733587296485901\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.91 seconds\n",
      "epoch: 121 average loss: 1.395\n",
      "Test Accuracy : 52.8%, Test Loss: 1.7723423061370849\n",
      "Epoch Time (Training + Test) = 26.80 seconds\n",
      "epoch: 122 average loss: 1.401\n",
      "Test Accuracy : 54.4%, Test Loss: 1.7294059162139892\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 123 average loss: 1.387\n",
      "Test Accuracy : 54.4%, Test Loss: 1.722119800567627\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.83 seconds\n",
      "epoch: 124 average loss: 1.393\n",
      "Test Accuracy : 54.4%, Test Loss: 1.713466311454773\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 125 average loss: 1.383\n",
      "Test Accuracy : 54.8%, Test Loss: 1.6986873159408569\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.84 seconds\n",
      "epoch: 126 average loss: 1.383\n",
      "Test Accuracy : 53.9%, Test Loss: 1.7294152793884277\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 127 average loss: 1.379\n",
      "Test Accuracy : 54.6%, Test Loss: 1.7051848459243775\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 128 average loss: 1.367\n",
      "Test Accuracy : 55.3%, Test Loss: 1.6840890579223633\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.91 seconds\n",
      "epoch: 129 average loss: 1.367\n",
      "Test Accuracy : 53.9%, Test Loss: 1.7504497518539428\n",
      "Epoch Time (Training + Test) = 26.78 seconds\n",
      "epoch: 130 average loss: 1.365\n",
      "Test Accuracy : 55.0%, Test Loss: 1.7027601127624512\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 131 average loss: 1.352\n",
      "Test Accuracy : 54.0%, Test Loss: 1.723084321975708\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 132 average loss: 1.349\n",
      "Test Accuracy : 54.1%, Test Loss: 1.733670825958252\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 133 average loss: 1.342\n",
      "Test Accuracy : 54.5%, Test Loss: 1.695454466819763\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 134 average loss: 1.336\n",
      "Test Accuracy : 54.1%, Test Loss: 1.716442409515381\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 135 average loss: 1.343\n",
      "Test Accuracy : 54.0%, Test Loss: 1.72111630153656\n",
      "Epoch Time (Training + Test) = 26.91 seconds\n",
      "epoch: 136 average loss: 1.334\n",
      "Test Accuracy : 55.4%, Test Loss: 1.6903718309402467\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.94 seconds\n",
      "epoch: 137 average loss: 1.328\n",
      "Test Accuracy : 53.9%, Test Loss: 1.722261028289795\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 138 average loss: 1.321\n",
      "Test Accuracy : 55.2%, Test Loss: 1.6849389743804932\n",
      "Epoch Time (Training + Test) = 26.94 seconds\n",
      "epoch: 139 average loss: 1.320\n",
      "Test Accuracy : 55.4%, Test Loss: 1.6897014055252075\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 140 average loss: 1.314\n",
      "Test Accuracy : 54.8%, Test Loss: 1.687644416809082\n",
      "Epoch Time (Training + Test) = 26.90 seconds\n",
      "epoch: 141 average loss: 1.308\n",
      "Test Accuracy : 55.4%, Test Loss: 1.6901432628631592\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 142 average loss: 1.313\n",
      "Test Accuracy : 54.8%, Test Loss: 1.7087587223052978\n",
      "Epoch Time (Training + Test) = 26.90 seconds\n",
      "epoch: 143 average loss: 1.308\n",
      "Test Accuracy : 54.9%, Test Loss: 1.7143812923431396\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 144 average loss: 1.306\n",
      "Test Accuracy : 54.9%, Test Loss: 1.7205055313110351\n",
      "Epoch Time (Training + Test) = 27.00 seconds\n",
      "epoch: 145 average loss: 1.290\n",
      "Test Accuracy : 55.5%, Test Loss: 1.6850223112106324\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 146 average loss: 1.295\n",
      "Test Accuracy : 55.2%, Test Loss: 1.7182986335754395\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 147 average loss: 1.291\n",
      "Test Accuracy : 55.3%, Test Loss: 1.6755091247558593\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 148 average loss: 1.284\n",
      "Test Accuracy : 55.0%, Test Loss: 1.7090894718170166\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 149 average loss: 1.279\n",
      "Test Accuracy : 55.3%, Test Loss: 1.7076255626678467\n",
      "Epoch Time (Training + Test) = 26.86 seconds\n",
      "epoch: 150 average loss: 1.283\n",
      "Test Accuracy : 55.5%, Test Loss: 1.6925883626937865\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 151 average loss: 1.280\n",
      "Test Accuracy : 54.9%, Test Loss: 1.6965367403030396\n",
      "Epoch Time (Training + Test) = 26.83 seconds\n",
      "epoch: 152 average loss: 1.271\n",
      "Test Accuracy : 54.6%, Test Loss: 1.7085245122909547\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 153 average loss: 1.265\n",
      "Test Accuracy : 55.2%, Test Loss: 1.6806175088882447\n",
      "Epoch Time (Training + Test) = 26.92 seconds\n",
      "epoch: 154 average loss: 1.268\n",
      "Test Accuracy : 54.6%, Test Loss: 1.7375764846801758\n",
      "Epoch Time (Training + Test) = 26.83 seconds\n",
      "epoch: 155 average loss: 1.256\n",
      "Test Accuracy : 55.0%, Test Loss: 1.7020044317245484\n",
      "Epoch Time (Training + Test) = 26.95 seconds\n",
      "epoch: 156 average loss: 1.250\n",
      "Test Accuracy : 55.7%, Test Loss: 1.693916301727295\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.93 seconds\n",
      "epoch: 157 average loss: 1.265\n",
      "Test Accuracy : 56.2%, Test Loss: 1.655677080154419\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.80 seconds\n",
      "epoch: 158 average loss: 1.254\n",
      "Test Accuracy : 55.8%, Test Loss: 1.6713323926925658\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 159 average loss: 1.243\n",
      "Test Accuracy : 55.0%, Test Loss: 1.6987088737487792\n",
      "Epoch Time (Training + Test) = 26.81 seconds\n",
      "epoch: 160 average loss: 1.236\n",
      "Test Accuracy : 55.3%, Test Loss: 1.7239379177093506\n",
      "Epoch Time (Training + Test) = 26.92 seconds\n",
      "epoch: 161 average loss: 1.241\n",
      "Test Accuracy : 55.9%, Test Loss: 1.6673246479034425\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 162 average loss: 1.236\n",
      "Test Accuracy : 56.6%, Test Loss: 1.653756826400757\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.89 seconds\n",
      "epoch: 163 average loss: 1.234\n",
      "Test Accuracy : 56.5%, Test Loss: 1.654031834602356\n",
      "Epoch Time (Training + Test) = 26.81 seconds\n",
      "epoch: 164 average loss: 1.235\n",
      "Test Accuracy : 56.0%, Test Loss: 1.6611249713897704\n",
      "Epoch Time (Training + Test) = 26.90 seconds\n",
      "epoch: 165 average loss: 1.221\n",
      "Test Accuracy : 56.9%, Test Loss: 1.6547378091812133\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 26.94 seconds\n",
      "epoch: 166 average loss: 1.215\n",
      "Test Accuracy : 56.4%, Test Loss: 1.6598462839126586\n",
      "Epoch Time (Training + Test) = 26.98 seconds\n",
      "epoch: 167 average loss: 1.211\n",
      "Test Accuracy : 56.4%, Test Loss: 1.66294944190979\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 168 average loss: 1.210\n",
      "Test Accuracy : 55.9%, Test Loss: 1.6990025358200074\n",
      "Epoch Time (Training + Test) = 26.88 seconds\n",
      "epoch: 169 average loss: 1.210\n",
      "Test Accuracy : 56.1%, Test Loss: 1.6805470447540283\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 170 average loss: 1.210\n",
      "Test Accuracy : 56.6%, Test Loss: 1.6619683923721313\n",
      "Epoch Time (Training + Test) = 26.84 seconds\n",
      "epoch: 171 average loss: 1.204\n",
      "Test Accuracy : 56.1%, Test Loss: 1.6868113021850586\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 172 average loss: 1.218\n",
      "Test Accuracy : 55.4%, Test Loss: 1.705815119743347\n",
      "Epoch Time (Training + Test) = 26.85 seconds\n",
      "epoch: 173 average loss: 1.194\n",
      "Test Accuracy : 56.5%, Test Loss: 1.6522237167358398\n",
      "Epoch Time (Training + Test) = 26.93 seconds\n",
      "epoch: 174 average loss: 1.197\n",
      "Test Accuracy : 56.2%, Test Loss: 1.6761822662353516\n",
      "Epoch Time (Training + Test) = 26.82 seconds\n",
      "epoch: 175 average loss: 1.193\n",
      "Test Accuracy : 55.8%, Test Loss: 1.712856128692627\n",
      "Epoch Time (Training + Test) = 26.83 seconds\n",
      "epoch: 176 average loss: 1.181\n",
      "Test Accuracy : 56.9%, Test Loss: 1.6595914468765258\n",
      "Epoch Time (Training + Test) = 26.95 seconds\n",
      "epoch: 177 average loss: 1.185\n",
      "Test Accuracy : 56.3%, Test Loss: 1.6661624412536622\n",
      "Epoch Time (Training + Test) = 26.94 seconds\n",
      "epoch: 178 average loss: 1.188\n",
      "Test Accuracy : 56.8%, Test Loss: 1.6430793533325194\n",
      "Epoch Time (Training + Test) = 26.87 seconds\n",
      "epoch: 179 average loss: 1.189\n",
      "Test Accuracy : 56.5%, Test Loss: 1.6393696851730346\n",
      "Epoch Time (Training + Test) = 26.79 seconds\n",
      "epoch: 180 average loss: 1.176\n",
      "Test Accuracy : 56.3%, Test Loss: 1.6851354656219482\n",
      "Epoch Time (Training + Test) = 27.28 seconds\n",
      "epoch: 181 average loss: 1.173\n",
      "Test Accuracy : 56.7%, Test Loss: 1.6455084962844848\n",
      "Epoch Time (Training + Test) = 26.99 seconds\n",
      "epoch: 182 average loss: 1.174\n",
      "Test Accuracy : 57.0%, Test Loss: 1.6506825046539306\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 27.08 seconds\n",
      "epoch: 183 average loss: 1.165\n",
      "Test Accuracy : 57.2%, Test Loss: 1.6482371034622192\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.36 seconds\n",
      "epoch: 184 average loss: 1.167\n",
      "Test Accuracy : 56.5%, Test Loss: 1.6639933919906615\n",
      "Epoch Time (Training + Test) = 27.91 seconds\n",
      "epoch: 185 average loss: 1.157\n",
      "Test Accuracy : 56.8%, Test Loss: 1.648723419189453\n",
      "Epoch Time (Training + Test) = 27.18 seconds\n",
      "epoch: 186 average loss: 1.167\n",
      "Test Accuracy : 56.8%, Test Loss: 1.6391101331710816\n",
      "Epoch Time (Training + Test) = 28.11 seconds\n",
      "epoch: 187 average loss: 1.162\n",
      "Test Accuracy : 57.0%, Test Loss: 1.6522882318496703\n",
      "Epoch Time (Training + Test) = 29.14 seconds\n",
      "epoch: 188 average loss: 1.153\n",
      "Test Accuracy : 57.0%, Test Loss: 1.6367921867370605\n",
      "Epoch Time (Training + Test) = 28.87 seconds\n",
      "epoch: 189 average loss: 1.159\n",
      "Test Accuracy : 56.8%, Test Loss: 1.6481097230911255\n",
      "Epoch Time (Training + Test) = 28.70 seconds\n",
      "epoch: 190 average loss: 1.151\n",
      "Test Accuracy : 56.7%, Test Loss: 1.6605696344375611\n",
      "Epoch Time (Training + Test) = 28.80 seconds\n",
      "epoch: 191 average loss: 1.144\n",
      "Test Accuracy : 57.4%, Test Loss: 1.6221904592514038\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.68 seconds\n",
      "epoch: 192 average loss: 1.143\n",
      "Test Accuracy : 57.1%, Test Loss: 1.6351186571121217\n",
      "Epoch Time (Training + Test) = 27.68 seconds\n",
      "epoch: 193 average loss: 1.133\n",
      "Test Accuracy : 57.5%, Test Loss: 1.6197828598022461\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.10 seconds\n",
      "epoch: 194 average loss: 1.145\n",
      "Test Accuracy : 57.4%, Test Loss: 1.6354122190475464\n",
      "Epoch Time (Training + Test) = 29.39 seconds\n",
      "epoch: 195 average loss: 1.130\n",
      "Test Accuracy : 57.2%, Test Loss: 1.6090471477508546\n",
      "Epoch Time (Training + Test) = 29.40 seconds\n",
      "epoch: 196 average loss: 1.130\n",
      "Test Accuracy : 56.2%, Test Loss: 1.6657066979408264\n",
      "Epoch Time (Training + Test) = 29.18 seconds\n",
      "epoch: 197 average loss: 1.118\n",
      "Test Accuracy : 56.7%, Test Loss: 1.6394582691192627\n",
      "Epoch Time (Training + Test) = 29.43 seconds\n",
      "epoch: 198 average loss: 1.116\n",
      "Test Accuracy : 56.7%, Test Loss: 1.6372052478790282\n",
      "Epoch Time (Training + Test) = 29.13 seconds\n",
      "epoch: 199 average loss: 1.105\n",
      "Test Accuracy : 57.7%, Test Loss: 1.6248632841110229\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 28.84 seconds\n",
      "epoch: 200 average loss: 1.101\n",
      "Test Accuracy : 57.1%, Test Loss: 1.6125262928009034\n",
      "Epoch Time (Training + Test) = 28.34 seconds\n",
      "Data Saved to Baseline_BNN_Resnet18_inflate_4.csv\n",
      "Finished Training: \n",
      "Total Time 3.004479 hours\n",
      " Average Time Per Epoch 54.08 seconds\n",
      "Using Default (SGD) Optimizer\n",
      "Scheduler Set {'T_max': 200, 'eta_min': 0, 'base_lrs': [0.2], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.2]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:5zw8azig) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>â–â–‚â–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch time (s)</td><td>â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–ˆâ–…â–‡</td></tr><tr><td>lr</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–</td></tr><tr><td>test_accuracy</td><td>â–â–‚â–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>test_loss</td><td>â–ˆâ–†â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>training_loss</td><td>â–ˆâ–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.57663</td></tr><tr><td>Current Best Acc</td><td>0.57663</td></tr><tr><td>Total Time (hours)</td><td>3.00448</td></tr><tr><td>epoch</td><td>200</td></tr><tr><td>epoch time (s)</td><td>28.3381</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>test_accuracy</td><td>0.57125</td></tr><tr><td>test_loss</td><td>1.61253</td></tr><tr><td>training_loss</td><td>1.10079</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">apricot-shape-12</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/5zw8azig\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/5zw8azig</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221023_130429-5zw8azig\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:5zw8azig). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518566256bdc4a71b2c8510b3512f1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221023_143504-x4bx8n4x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/x4bx8n4x\" target=\"_blank\">prime-firefly-13</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name Baseline_BNN_Resnet18_inflate_5 \n",
      "\n",
      "\n",
      "Run Start : 2022-10-23 14-35-04\n",
      "start_epoch : 0\n",
      "initial_lr : 0.2\n",
      "batch_size : 32\n",
      "epochs : 200\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.2\n",
      "    lr: 0.2\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.models.resnet_binary.ResNet_cifar10'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4360640\n",
      "Initial accuracy:\n",
      "Test Accuracy : 1.2%, Test Loss: 43.934367578125\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 1.2%, Test Loss: 44.11837606811523\n",
      "epoch: 1 average loss: 4.050\n",
      "Test Accuracy : 9.3%, Test Loss: 3.8131789264678955\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.42 seconds\n",
      "epoch: 2 average loss: 3.735\n",
      "Test Accuracy : 11.8%, Test Loss: 3.6042515964508057\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.53 seconds\n",
      "epoch: 3 average loss: 3.575\n",
      "Test Accuracy : 14.3%, Test Loss: 3.4917849578857423\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.50 seconds\n",
      "epoch: 4 average loss: 3.465\n",
      "Test Accuracy : 16.8%, Test Loss: 3.373245090484619\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.05 seconds\n",
      "epoch: 5 average loss: 3.379\n",
      "Test Accuracy : 18.9%, Test Loss: 3.2483049240112303\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.24 seconds\n",
      "epoch: 6 average loss: 3.307\n",
      "Test Accuracy : 19.9%, Test Loss: 3.198115547180176\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.52 seconds\n",
      "epoch: 7 average loss: 3.235\n",
      "Test Accuracy : 20.5%, Test Loss: 3.1767442417144776\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.74 seconds\n",
      "epoch: 8 average loss: 3.177\n",
      "Test Accuracy : 21.7%, Test Loss: 3.131566783905029\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.67 seconds\n",
      "epoch: 9 average loss: 3.123\n",
      "Test Accuracy : 23.2%, Test Loss: 3.035620838165283\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.48 seconds\n",
      "epoch: 10 average loss: 3.064\n",
      "Test Accuracy : 23.7%, Test Loss: 3.0256154537200928\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.52 seconds\n",
      "epoch: 11 average loss: 3.027\n",
      "Test Accuracy : 24.7%, Test Loss: 2.9748084411621094\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.13 seconds\n",
      "epoch: 12 average loss: 2.985\n",
      "Test Accuracy : 25.9%, Test Loss: 2.88687628364563\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.19 seconds\n",
      "epoch: 13 average loss: 2.952\n",
      "Test Accuracy : 27.9%, Test Loss: 2.8439663524627687\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.27 seconds\n",
      "epoch: 14 average loss: 2.902\n",
      "Test Accuracy : 26.6%, Test Loss: 2.8930236740112303\n",
      "Epoch Time (Training + Test) = 38.37 seconds\n",
      "epoch: 15 average loss: 2.857\n",
      "Test Accuracy : 29.0%, Test Loss: 2.7826749324798583\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.65 seconds\n",
      "epoch: 16 average loss: 2.823\n",
      "Test Accuracy : 29.5%, Test Loss: 2.743663442611694\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.27 seconds\n",
      "epoch: 17 average loss: 2.773\n",
      "Test Accuracy : 29.0%, Test Loss: 2.758422201156616\n",
      "Epoch Time (Training + Test) = 38.24 seconds\n",
      "epoch: 18 average loss: 2.750\n",
      "Test Accuracy : 30.7%, Test Loss: 2.686768438339233\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.37 seconds\n",
      "epoch: 19 average loss: 2.708\n",
      "Test Accuracy : 31.3%, Test Loss: 2.6827833290100096\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.17 seconds\n",
      "epoch: 20 average loss: 2.681\n",
      "Test Accuracy : 32.6%, Test Loss: 2.63915753364563\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.37 seconds\n",
      "epoch: 21 average loss: 2.636\n",
      "Test Accuracy : 32.9%, Test Loss: 2.600274694442749\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.37 seconds\n",
      "epoch: 22 average loss: 2.596\n",
      "Test Accuracy : 33.5%, Test Loss: 2.5773393535614013\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.38 seconds\n",
      "epoch: 23 average loss: 2.575\n",
      "Test Accuracy : 34.0%, Test Loss: 2.569934959411621\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.31 seconds\n",
      "epoch: 24 average loss: 2.527\n",
      "Test Accuracy : 34.2%, Test Loss: 2.5231218795776367\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.28 seconds\n",
      "epoch: 25 average loss: 2.496\n",
      "Test Accuracy : 34.3%, Test Loss: 2.545331614494324\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.26 seconds\n",
      "epoch: 26 average loss: 2.477\n",
      "Test Accuracy : 35.8%, Test Loss: 2.4573927278518677\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.90 seconds\n",
      "epoch: 27 average loss: 2.436\n",
      "Test Accuracy : 36.3%, Test Loss: 2.4127387256622312\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.64 seconds\n",
      "epoch: 28 average loss: 2.403\n",
      "Test Accuracy : 36.6%, Test Loss: 2.4181701612472533\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.98 seconds\n",
      "epoch: 29 average loss: 2.382\n",
      "Test Accuracy : 38.6%, Test Loss: 2.33092835521698\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.88 seconds\n",
      "epoch: 30 average loss: 2.349\n",
      "Test Accuracy : 37.7%, Test Loss: 2.364748035430908\n",
      "Epoch Time (Training + Test) = 37.64 seconds\n",
      "epoch: 31 average loss: 2.312\n",
      "Test Accuracy : 38.8%, Test Loss: 2.3105328645706176\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.63 seconds\n",
      "epoch: 32 average loss: 2.290\n",
      "Test Accuracy : 39.6%, Test Loss: 2.2888276300430297\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.57 seconds\n",
      "epoch: 33 average loss: 2.265\n",
      "Test Accuracy : 39.5%, Test Loss: 2.307247226715088\n",
      "Epoch Time (Training + Test) = 37.66 seconds\n",
      "epoch: 34 average loss: 2.235\n",
      "Test Accuracy : 40.8%, Test Loss: 2.256508804321289\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.90 seconds\n",
      "epoch: 35 average loss: 2.201\n",
      "Test Accuracy : 40.7%, Test Loss: 2.229448100090027\n",
      "Epoch Time (Training + Test) = 38.22 seconds\n",
      "epoch: 36 average loss: 2.182\n",
      "Test Accuracy : 40.5%, Test Loss: 2.2664398441314697\n",
      "Epoch Time (Training + Test) = 38.03 seconds\n",
      "epoch: 37 average loss: 2.148\n",
      "Test Accuracy : 41.3%, Test Loss: 2.2105497179031373\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.77 seconds\n",
      "epoch: 38 average loss: 2.124\n",
      "Test Accuracy : 42.7%, Test Loss: 2.1803921213150024\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.79 seconds\n",
      "epoch: 39 average loss: 2.092\n",
      "Test Accuracy : 43.7%, Test Loss: 2.124295858383179\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.84 seconds\n",
      "epoch: 40 average loss: 2.087\n",
      "Test Accuracy : 43.8%, Test Loss: 2.1049340019226075\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.78 seconds\n",
      "epoch: 41 average loss: 2.068\n",
      "Test Accuracy : 42.0%, Test Loss: 2.184654085159302\n",
      "Epoch Time (Training + Test) = 38.02 seconds\n",
      "epoch: 42 average loss: 2.039\n",
      "Test Accuracy : 41.9%, Test Loss: 2.265653953552246\n",
      "Epoch Time (Training + Test) = 37.96 seconds\n",
      "epoch: 43 average loss: 2.013\n",
      "Test Accuracy : 43.8%, Test Loss: 2.100272575378418\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.68 seconds\n",
      "epoch: 44 average loss: 1.999\n",
      "Test Accuracy : 45.2%, Test Loss: 2.0404763526916505\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.94 seconds\n",
      "epoch: 45 average loss: 1.987\n",
      "Test Accuracy : 43.8%, Test Loss: 2.1160470724105833\n",
      "Epoch Time (Training + Test) = 38.16 seconds\n",
      "epoch: 46 average loss: 1.965\n",
      "Test Accuracy : 44.7%, Test Loss: 2.050447151184082\n",
      "Epoch Time (Training + Test) = 37.84 seconds\n",
      "epoch: 47 average loss: 1.938\n",
      "Test Accuracy : 44.9%, Test Loss: 2.062507088661194\n",
      "Epoch Time (Training + Test) = 37.72 seconds\n",
      "epoch: 48 average loss: 1.917\n",
      "Test Accuracy : 45.3%, Test Loss: 2.0498764295578003\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.97 seconds\n",
      "epoch: 49 average loss: 1.905\n",
      "Test Accuracy : 47.2%, Test Loss: 1.9773055438995362\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.88 seconds\n",
      "epoch: 50 average loss: 1.884\n",
      "Test Accuracy : 46.7%, Test Loss: 1.9998001594543457\n",
      "Epoch Time (Training + Test) = 37.73 seconds\n",
      "epoch: 51 average loss: 1.870\n",
      "Test Accuracy : 45.1%, Test Loss: 2.045485263824463\n",
      "Epoch Time (Training + Test) = 37.84 seconds\n",
      "epoch: 52 average loss: 1.850\n",
      "Test Accuracy : 47.5%, Test Loss: 1.9439933185577392\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.23 seconds\n",
      "epoch: 53 average loss: 1.847\n",
      "Test Accuracy : 46.2%, Test Loss: 2.0120701398849485\n",
      "Epoch Time (Training + Test) = 37.67 seconds\n",
      "epoch: 54 average loss: 1.820\n",
      "Test Accuracy : 47.6%, Test Loss: 1.9408370609283447\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.86 seconds\n",
      "epoch: 55 average loss: 1.812\n",
      "Test Accuracy : 48.0%, Test Loss: 1.9174687480926513\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.67 seconds\n",
      "epoch: 56 average loss: 1.793\n",
      "Test Accuracy : 47.9%, Test Loss: 1.938456889152527\n",
      "Epoch Time (Training + Test) = 37.80 seconds\n",
      "epoch: 57 average loss: 1.780\n",
      "Test Accuracy : 48.1%, Test Loss: 1.9422545461654663\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.86 seconds\n",
      "epoch: 58 average loss: 1.771\n",
      "Test Accuracy : 48.9%, Test Loss: 1.8912013273239137\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.64 seconds\n",
      "epoch: 59 average loss: 1.758\n",
      "Test Accuracy : 49.0%, Test Loss: 1.897690710067749\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.61 seconds\n",
      "epoch: 60 average loss: 1.739\n",
      "Test Accuracy : 49.3%, Test Loss: 1.8610058012008668\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.19 seconds\n",
      "epoch: 61 average loss: 1.727\n",
      "Test Accuracy : 49.5%, Test Loss: 1.8716609287261963\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.88 seconds\n",
      "epoch: 62 average loss: 1.717\n",
      "Test Accuracy : 49.0%, Test Loss: 1.8937654466629028\n",
      "Epoch Time (Training + Test) = 38.16 seconds\n",
      "epoch: 63 average loss: 1.702\n",
      "Test Accuracy : 50.2%, Test Loss: 1.8703407230377198\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.48 seconds\n",
      "epoch: 64 average loss: 1.687\n",
      "Test Accuracy : 49.0%, Test Loss: 1.9017915554046632\n",
      "Epoch Time (Training + Test) = 37.22 seconds\n",
      "epoch: 65 average loss: 1.676\n",
      "Test Accuracy : 50.2%, Test Loss: 1.8488001346588134\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.35 seconds\n",
      "epoch: 66 average loss: 1.660\n",
      "Test Accuracy : 50.3%, Test Loss: 1.8542147560119628\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.96 seconds\n",
      "epoch: 67 average loss: 1.660\n",
      "Test Accuracy : 50.0%, Test Loss: 1.8794398231506348\n",
      "Epoch Time (Training + Test) = 37.68 seconds\n",
      "epoch: 68 average loss: 1.649\n",
      "Test Accuracy : 50.2%, Test Loss: 1.8430783739089966\n",
      "Epoch Time (Training + Test) = 38.00 seconds\n",
      "epoch: 69 average loss: 1.638\n",
      "Test Accuracy : 50.7%, Test Loss: 1.8176253862380982\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.93 seconds\n",
      "epoch: 70 average loss: 1.628\n",
      "Test Accuracy : 50.3%, Test Loss: 1.8472399663925172\n",
      "Epoch Time (Training + Test) = 37.70 seconds\n",
      "epoch: 71 average loss: 1.609\n",
      "Test Accuracy : 50.3%, Test Loss: 1.8207439804077148\n",
      "Epoch Time (Training + Test) = 37.81 seconds\n",
      "epoch: 72 average loss: 1.597\n",
      "Test Accuracy : 51.8%, Test Loss: 1.803188772201538\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.01 seconds\n",
      "epoch: 73 average loss: 1.591\n",
      "Test Accuracy : 51.4%, Test Loss: 1.8269055633544922\n",
      "Epoch Time (Training + Test) = 37.04 seconds\n",
      "epoch: 74 average loss: 1.578\n",
      "Test Accuracy : 51.5%, Test Loss: 1.8254311246871948\n",
      "Epoch Time (Training + Test) = 35.78 seconds\n",
      "epoch: 75 average loss: 1.567\n",
      "Test Accuracy : 51.1%, Test Loss: 1.8228482847213745\n",
      "Epoch Time (Training + Test) = 35.76 seconds\n",
      "epoch: 76 average loss: 1.552\n",
      "Test Accuracy : 53.2%, Test Loss: 1.7611942501068116\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 35.79 seconds\n",
      "epoch: 77 average loss: 1.549\n",
      "Test Accuracy : 51.8%, Test Loss: 1.8042753343582154\n",
      "Epoch Time (Training + Test) = 35.89 seconds\n",
      "epoch: 78 average loss: 1.540\n",
      "Test Accuracy : 51.8%, Test Loss: 1.8094841766357421\n",
      "Epoch Time (Training + Test) = 35.89 seconds\n",
      "epoch: 79 average loss: 1.532\n",
      "Test Accuracy : 50.5%, Test Loss: 1.8416906204223633\n",
      "Epoch Time (Training + Test) = 35.77 seconds\n",
      "epoch: 80 average loss: 1.516\n",
      "Test Accuracy : 52.7%, Test Loss: 1.7441243772506714\n",
      "Epoch Time (Training + Test) = 35.79 seconds\n",
      "epoch: 81 average loss: 1.507\n",
      "Test Accuracy : 52.1%, Test Loss: 1.7713080739974976\n",
      "Epoch Time (Training + Test) = 35.71 seconds\n",
      "epoch: 82 average loss: 1.495\n",
      "Test Accuracy : 53.1%, Test Loss: 1.7579694967269897\n",
      "Epoch Time (Training + Test) = 35.80 seconds\n",
      "epoch: 83 average loss: 1.493\n",
      "Test Accuracy : 51.0%, Test Loss: 1.8360369329452515\n",
      "Epoch Time (Training + Test) = 36.80 seconds\n",
      "epoch: 84 average loss: 1.479\n",
      "Test Accuracy : 53.3%, Test Loss: 1.756103172302246\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.17 seconds\n",
      "epoch: 85 average loss: 1.477\n",
      "Test Accuracy : 53.3%, Test Loss: 1.735378279685974\n",
      "Epoch Time (Training + Test) = 37.07 seconds\n",
      "epoch: 86 average loss: 1.470\n",
      "Test Accuracy : 52.2%, Test Loss: 1.803749713897705\n",
      "Epoch Time (Training + Test) = 38.18 seconds\n",
      "epoch: 87 average loss: 1.460\n",
      "Test Accuracy : 52.8%, Test Loss: 1.771934588432312\n",
      "Epoch Time (Training + Test) = 38.03 seconds\n",
      "epoch: 88 average loss: 1.448\n",
      "Test Accuracy : 53.4%, Test Loss: 1.7394490852355957\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.60 seconds\n",
      "epoch: 89 average loss: 1.439\n",
      "Test Accuracy : 52.8%, Test Loss: 1.773217035293579\n",
      "Epoch Time (Training + Test) = 38.16 seconds\n",
      "epoch: 90 average loss: 1.433\n",
      "Test Accuracy : 53.3%, Test Loss: 1.7537616415023805\n",
      "Epoch Time (Training + Test) = 36.09 seconds\n",
      "epoch: 91 average loss: 1.435\n",
      "Test Accuracy : 53.9%, Test Loss: 1.7273344192504883\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.12 seconds\n",
      "epoch: 92 average loss: 1.417\n",
      "Test Accuracy : 53.0%, Test Loss: 1.7607616071701049\n",
      "Epoch Time (Training + Test) = 36.47 seconds\n",
      "epoch: 93 average loss: 1.413\n",
      "Test Accuracy : 52.3%, Test Loss: 1.7934862613677978\n",
      "Epoch Time (Training + Test) = 35.59 seconds\n",
      "epoch: 94 average loss: 1.402\n",
      "Test Accuracy : 53.4%, Test Loss: 1.7487094287872313\n",
      "Epoch Time (Training + Test) = 35.85 seconds\n",
      "epoch: 95 average loss: 1.396\n",
      "Test Accuracy : 54.1%, Test Loss: 1.689776041984558\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 35.81 seconds\n",
      "epoch: 96 average loss: 1.376\n",
      "Test Accuracy : 52.2%, Test Loss: 1.8090546970367432\n",
      "Epoch Time (Training + Test) = 37.53 seconds\n",
      "epoch: 97 average loss: 1.378\n",
      "Test Accuracy : 53.5%, Test Loss: 1.7341624746322633\n",
      "Epoch Time (Training + Test) = 36.95 seconds\n",
      "epoch: 98 average loss: 1.370\n",
      "Test Accuracy : 54.5%, Test Loss: 1.687751100540161\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.12 seconds\n",
      "epoch: 99 average loss: 1.354\n",
      "Test Accuracy : 54.4%, Test Loss: 1.7340002899169922\n",
      "Epoch Time (Training + Test) = 36.72 seconds\n",
      "epoch: 100 average loss: 1.365\n",
      "Test Accuracy : 54.4%, Test Loss: 1.7144246969223023\n",
      "Epoch Time (Training + Test) = 35.73 seconds\n",
      "epoch: 101 average loss: 1.349\n",
      "Test Accuracy : 54.0%, Test Loss: 1.7106959438323974\n",
      "Epoch Time (Training + Test) = 36.06 seconds\n",
      "epoch: 102 average loss: 1.340\n",
      "Test Accuracy : 54.3%, Test Loss: 1.7073044939041138\n",
      "Epoch Time (Training + Test) = 35.88 seconds\n",
      "epoch: 103 average loss: 1.336\n",
      "Test Accuracy : 53.7%, Test Loss: 1.7208280200958253\n",
      "Epoch Time (Training + Test) = 37.22 seconds\n",
      "epoch: 104 average loss: 1.326\n",
      "Test Accuracy : 54.3%, Test Loss: 1.7033415021896363\n",
      "Epoch Time (Training + Test) = 38.42 seconds\n",
      "epoch: 105 average loss: 1.324\n",
      "Test Accuracy : 54.6%, Test Loss: 1.7102141742706298\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.11 seconds\n",
      "epoch: 106 average loss: 1.310\n",
      "Test Accuracy : 55.2%, Test Loss: 1.677421085357666\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.18 seconds\n",
      "epoch: 107 average loss: 1.303\n",
      "Test Accuracy : 54.6%, Test Loss: 1.7280659275054933\n",
      "Epoch Time (Training + Test) = 38.17 seconds\n",
      "epoch: 108 average loss: 1.305\n",
      "Test Accuracy : 55.2%, Test Loss: 1.689002082824707\n",
      "Epoch Time (Training + Test) = 38.36 seconds\n",
      "epoch: 109 average loss: 1.301\n",
      "Test Accuracy : 54.7%, Test Loss: 1.6878839750289918\n",
      "Epoch Time (Training + Test) = 38.30 seconds\n",
      "epoch: 110 average loss: 1.291\n",
      "Test Accuracy : 55.4%, Test Loss: 1.6840068092346192\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.42 seconds\n",
      "epoch: 111 average loss: 1.269\n",
      "Test Accuracy : 53.8%, Test Loss: 1.7107495546340943\n",
      "Epoch Time (Training + Test) = 38.21 seconds\n",
      "epoch: 112 average loss: 1.271\n",
      "Test Accuracy : 55.4%, Test Loss: 1.6840026130676269\n",
      "Epoch Time (Training + Test) = 38.17 seconds\n",
      "epoch: 113 average loss: 1.267\n",
      "Test Accuracy : 55.6%, Test Loss: 1.6599348258972169\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.25 seconds\n",
      "epoch: 114 average loss: 1.262\n",
      "Test Accuracy : 56.1%, Test Loss: 1.649853141784668\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.24 seconds\n",
      "epoch: 115 average loss: 1.255\n",
      "Test Accuracy : 55.5%, Test Loss: 1.6876071062088012\n",
      "Epoch Time (Training + Test) = 38.64 seconds\n",
      "epoch: 116 average loss: 1.243\n",
      "Test Accuracy : 55.7%, Test Loss: 1.6638606100082398\n",
      "Epoch Time (Training + Test) = 38.25 seconds\n",
      "epoch: 117 average loss: 1.242\n",
      "Test Accuracy : 55.9%, Test Loss: 1.6717091660499572\n",
      "Epoch Time (Training + Test) = 38.21 seconds\n",
      "epoch: 118 average loss: 1.234\n",
      "Test Accuracy : 57.0%, Test Loss: 1.6181865653991698\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.61 seconds\n",
      "epoch: 119 average loss: 1.223\n",
      "Test Accuracy : 55.0%, Test Loss: 1.6766773881912231\n",
      "Epoch Time (Training + Test) = 38.32 seconds\n",
      "epoch: 120 average loss: 1.223\n",
      "Test Accuracy : 56.1%, Test Loss: 1.666153123855591\n",
      "Epoch Time (Training + Test) = 38.14 seconds\n",
      "epoch: 121 average loss: 1.218\n",
      "Test Accuracy : 55.2%, Test Loss: 1.6733190698623657\n",
      "Epoch Time (Training + Test) = 38.38 seconds\n",
      "epoch: 122 average loss: 1.208\n",
      "Test Accuracy : 55.7%, Test Loss: 1.6669968452453614\n",
      "Epoch Time (Training + Test) = 38.44 seconds\n",
      "epoch: 123 average loss: 1.208\n",
      "Test Accuracy : 55.5%, Test Loss: 1.6744095439910889\n",
      "Epoch Time (Training + Test) = 38.26 seconds\n",
      "epoch: 124 average loss: 1.201\n",
      "Test Accuracy : 56.3%, Test Loss: 1.6671695594787597\n",
      "Epoch Time (Training + Test) = 38.32 seconds\n",
      "epoch: 125 average loss: 1.192\n",
      "Test Accuracy : 55.4%, Test Loss: 1.6533607358932496\n",
      "Epoch Time (Training + Test) = 38.54 seconds\n",
      "epoch: 126 average loss: 1.176\n",
      "Test Accuracy : 56.6%, Test Loss: 1.641561551094055\n",
      "Epoch Time (Training + Test) = 38.44 seconds\n",
      "epoch: 127 average loss: 1.181\n",
      "Test Accuracy : 56.9%, Test Loss: 1.640247434616089\n",
      "Epoch Time (Training + Test) = 38.03 seconds\n",
      "epoch: 128 average loss: 1.175\n",
      "Test Accuracy : 56.3%, Test Loss: 1.6605010299682617\n",
      "Epoch Time (Training + Test) = 38.01 seconds\n",
      "epoch: 129 average loss: 1.174\n",
      "Test Accuracy : 56.4%, Test Loss: 1.640112235069275\n",
      "Epoch Time (Training + Test) = 38.20 seconds\n",
      "epoch: 130 average loss: 1.168\n",
      "Test Accuracy : 56.9%, Test Loss: 1.6368478450775146\n",
      "Epoch Time (Training + Test) = 37.76 seconds\n",
      "epoch: 131 average loss: 1.172\n",
      "Test Accuracy : 56.0%, Test Loss: 1.6535817427635193\n",
      "Epoch Time (Training + Test) = 37.87 seconds\n",
      "epoch: 132 average loss: 1.149\n",
      "Test Accuracy : 56.3%, Test Loss: 1.683546051979065\n",
      "Epoch Time (Training + Test) = 38.15 seconds\n",
      "epoch: 133 average loss: 1.160\n",
      "Test Accuracy : 56.2%, Test Loss: 1.6746127614974975\n",
      "Epoch Time (Training + Test) = 37.67 seconds\n",
      "epoch: 134 average loss: 1.147\n",
      "Test Accuracy : 56.4%, Test Loss: 1.6437132482528687\n",
      "Epoch Time (Training + Test) = 37.81 seconds\n",
      "epoch: 135 average loss: 1.148\n",
      "Test Accuracy : 57.0%, Test Loss: 1.6525293684005737\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.93 seconds\n",
      "epoch: 136 average loss: 1.141\n",
      "Test Accuracy : 56.2%, Test Loss: 1.6848382701873779\n",
      "Epoch Time (Training + Test) = 37.81 seconds\n",
      "epoch: 137 average loss: 1.130\n",
      "Test Accuracy : 57.1%, Test Loss: 1.6262133421897889\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.94 seconds\n",
      "epoch: 138 average loss: 1.125\n",
      "Test Accuracy : 57.0%, Test Loss: 1.6083035507202148\n",
      "Epoch Time (Training + Test) = 37.95 seconds\n",
      "epoch: 139 average loss: 1.124\n",
      "Test Accuracy : 56.6%, Test Loss: 1.6842814559936523\n",
      "Epoch Time (Training + Test) = 37.81 seconds\n",
      "epoch: 140 average loss: 1.128\n",
      "Test Accuracy : 57.0%, Test Loss: 1.6321480264663697\n",
      "Epoch Time (Training + Test) = 37.95 seconds\n",
      "epoch: 141 average loss: 1.114\n",
      "Test Accuracy : 57.3%, Test Loss: 1.6298496193885803\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.84 seconds\n",
      "epoch: 142 average loss: 1.118\n",
      "Test Accuracy : 56.7%, Test Loss: 1.669565933227539\n",
      "Epoch Time (Training + Test) = 37.78 seconds\n",
      "epoch: 143 average loss: 1.111\n",
      "Test Accuracy : 56.1%, Test Loss: 1.6864554777145386\n",
      "Epoch Time (Training + Test) = 37.68 seconds\n",
      "epoch: 144 average loss: 1.103\n",
      "Test Accuracy : 56.4%, Test Loss: 1.6409882984161377\n",
      "Epoch Time (Training + Test) = 37.76 seconds\n",
      "epoch: 145 average loss: 1.087\n",
      "Test Accuracy : 57.2%, Test Loss: 1.6172722816467284\n",
      "Epoch Time (Training + Test) = 37.88 seconds\n",
      "epoch: 146 average loss: 1.082\n",
      "Test Accuracy : 56.8%, Test Loss: 1.6537829885482789\n",
      "Epoch Time (Training + Test) = 38.15 seconds\n",
      "epoch: 147 average loss: 1.094\n",
      "Test Accuracy : 57.5%, Test Loss: 1.610781325340271\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.74 seconds\n",
      "epoch: 148 average loss: 1.081\n",
      "Test Accuracy : 57.4%, Test Loss: 1.6494170064926148\n",
      "Epoch Time (Training + Test) = 38.00 seconds\n",
      "epoch: 149 average loss: 1.082\n",
      "Test Accuracy : 57.5%, Test Loss: 1.641624575138092\n",
      "Epoch Time (Training + Test) = 37.87 seconds\n",
      "epoch: 150 average loss: 1.078\n",
      "Test Accuracy : 58.4%, Test Loss: 1.6222694025039672\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.19 seconds\n",
      "epoch: 151 average loss: 1.069\n",
      "Test Accuracy : 57.9%, Test Loss: 1.6343706083297729\n",
      "Epoch Time (Training + Test) = 38.25 seconds\n",
      "epoch: 152 average loss: 1.057\n",
      "Test Accuracy : 57.2%, Test Loss: 1.625135756969452\n",
      "Epoch Time (Training + Test) = 38.43 seconds\n",
      "epoch: 153 average loss: 1.067\n",
      "Test Accuracy : 57.1%, Test Loss: 1.6411190557479858\n",
      "Epoch Time (Training + Test) = 38.02 seconds\n",
      "epoch: 154 average loss: 1.060\n",
      "Test Accuracy : 57.5%, Test Loss: 1.6143473768234253\n",
      "Epoch Time (Training + Test) = 37.65 seconds\n",
      "epoch: 155 average loss: 1.048\n",
      "Test Accuracy : 57.1%, Test Loss: 1.6597232961654662\n",
      "Epoch Time (Training + Test) = 37.93 seconds\n",
      "epoch: 156 average loss: 1.045\n",
      "Test Accuracy : 56.9%, Test Loss: 1.6554131984710694\n",
      "Epoch Time (Training + Test) = 37.67 seconds\n",
      "epoch: 157 average loss: 1.041\n",
      "Test Accuracy : 57.9%, Test Loss: 1.6255303621292114\n",
      "Epoch Time (Training + Test) = 37.87 seconds\n",
      "epoch: 158 average loss: 1.046\n",
      "Test Accuracy : 58.0%, Test Loss: 1.632467975616455\n",
      "Epoch Time (Training + Test) = 37.92 seconds\n",
      "epoch: 159 average loss: 1.035\n",
      "Test Accuracy : 57.5%, Test Loss: 1.617345892906189\n",
      "Epoch Time (Training + Test) = 37.92 seconds\n",
      "epoch: 160 average loss: 1.035\n",
      "Test Accuracy : 56.5%, Test Loss: 1.6881410217285155\n",
      "Epoch Time (Training + Test) = 37.67 seconds\n",
      "epoch: 161 average loss: 1.032\n",
      "Test Accuracy : 57.0%, Test Loss: 1.6117386174201966\n",
      "Epoch Time (Training + Test) = 37.98 seconds\n",
      "epoch: 162 average loss: 1.018\n",
      "Test Accuracy : 56.7%, Test Loss: 1.672959225654602\n",
      "Epoch Time (Training + Test) = 37.74 seconds\n",
      "epoch: 163 average loss: 1.023\n",
      "Test Accuracy : 57.6%, Test Loss: 1.630954538345337\n",
      "Epoch Time (Training + Test) = 37.90 seconds\n",
      "epoch: 164 average loss: 1.028\n",
      "Test Accuracy : 57.4%, Test Loss: 1.6195850214958192\n",
      "Epoch Time (Training + Test) = 37.72 seconds\n",
      "epoch: 165 average loss: 1.014\n",
      "Test Accuracy : 57.6%, Test Loss: 1.6195298838615417\n",
      "Epoch Time (Training + Test) = 37.78 seconds\n",
      "epoch: 166 average loss: 0.999\n",
      "Test Accuracy : 58.2%, Test Loss: 1.6191982913017273\n",
      "Epoch Time (Training + Test) = 38.04 seconds\n",
      "epoch: 167 average loss: 0.995\n",
      "Test Accuracy : 57.1%, Test Loss: 1.6932820606231689\n",
      "Epoch Time (Training + Test) = 38.44 seconds\n",
      "epoch: 168 average loss: 1.002\n",
      "Test Accuracy : 56.8%, Test Loss: 1.6703334550857545\n",
      "Epoch Time (Training + Test) = 38.17 seconds\n",
      "epoch: 169 average loss: 0.988\n",
      "Test Accuracy : 57.9%, Test Loss: 1.6142572784423828\n",
      "Epoch Time (Training + Test) = 38.44 seconds\n",
      "epoch: 170 average loss: 0.995\n",
      "Test Accuracy : 58.7%, Test Loss: 1.5820546140670777\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.01 seconds\n",
      "epoch: 171 average loss: 0.989\n",
      "Test Accuracy : 57.9%, Test Loss: 1.6254292392730714\n",
      "Epoch Time (Training + Test) = 38.28 seconds\n",
      "epoch: 172 average loss: 0.995\n",
      "Test Accuracy : 57.9%, Test Loss: 1.6376440725326538\n",
      "Epoch Time (Training + Test) = 37.85 seconds\n",
      "epoch: 173 average loss: 0.978\n",
      "Test Accuracy : 58.3%, Test Loss: 1.6195155944824218\n",
      "Epoch Time (Training + Test) = 37.89 seconds\n",
      "epoch: 174 average loss: 0.978\n",
      "Test Accuracy : 57.8%, Test Loss: 1.6100968255996704\n",
      "Epoch Time (Training + Test) = 38.01 seconds\n",
      "epoch: 175 average loss: 0.970\n",
      "Test Accuracy : 58.2%, Test Loss: 1.6241916093826294\n",
      "Epoch Time (Training + Test) = 37.86 seconds\n",
      "epoch: 176 average loss: 0.969\n",
      "Test Accuracy : 58.4%, Test Loss: 1.6014709033966064\n",
      "Epoch Time (Training + Test) = 37.99 seconds\n",
      "epoch: 177 average loss: 0.978\n",
      "Test Accuracy : 57.7%, Test Loss: 1.643633430480957\n",
      "Epoch Time (Training + Test) = 38.27 seconds\n",
      "epoch: 178 average loss: 0.964\n",
      "Test Accuracy : 58.2%, Test Loss: 1.6253903365135194\n",
      "Epoch Time (Training + Test) = 38.03 seconds\n",
      "epoch: 179 average loss: 0.969\n",
      "Test Accuracy : 58.1%, Test Loss: 1.6235052671432495\n",
      "Epoch Time (Training + Test) = 37.80 seconds\n",
      "epoch: 180 average loss: 0.961\n",
      "Test Accuracy : 58.0%, Test Loss: 1.6355502262115478\n",
      "Epoch Time (Training + Test) = 38.86 seconds\n",
      "epoch: 181 average loss: 0.955\n",
      "Test Accuracy : 58.6%, Test Loss: 1.5812708597183227\n",
      "Epoch Time (Training + Test) = 37.93 seconds\n",
      "epoch: 182 average loss: 0.954\n",
      "Test Accuracy : 58.2%, Test Loss: 1.639439458847046\n",
      "Epoch Time (Training + Test) = 37.38 seconds\n",
      "epoch: 183 average loss: 0.952\n",
      "Test Accuracy : 58.2%, Test Loss: 1.6194277353286743\n",
      "Epoch Time (Training + Test) = 37.71 seconds\n",
      "epoch: 184 average loss: 0.946\n",
      "Test Accuracy : 58.1%, Test Loss: 1.6476579661369324\n",
      "Epoch Time (Training + Test) = 37.73 seconds\n",
      "epoch: 185 average loss: 0.947\n",
      "Test Accuracy : 58.6%, Test Loss: 1.614897265434265\n",
      "Epoch Time (Training + Test) = 37.51 seconds\n",
      "epoch: 186 average loss: 0.946\n",
      "Test Accuracy : 58.6%, Test Loss: 1.5957058801651\n",
      "Epoch Time (Training + Test) = 36.42 seconds\n",
      "epoch: 187 average loss: 0.946\n",
      "Test Accuracy : 58.4%, Test Loss: 1.6353456964492799\n",
      "Epoch Time (Training + Test) = 38.07 seconds\n",
      "epoch: 188 average loss: 0.938\n",
      "Test Accuracy : 58.3%, Test Loss: 1.6023647680282593\n",
      "Epoch Time (Training + Test) = 37.75 seconds\n",
      "epoch: 189 average loss: 0.928\n",
      "Test Accuracy : 59.1%, Test Loss: 1.5862825269699097\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.83 seconds\n",
      "epoch: 190 average loss: 0.932\n",
      "Test Accuracy : 58.7%, Test Loss: 1.59080784034729\n",
      "Epoch Time (Training + Test) = 37.85 seconds\n",
      "epoch: 191 average loss: 0.931\n",
      "Test Accuracy : 59.0%, Test Loss: 1.5939969224929809\n",
      "Epoch Time (Training + Test) = 37.99 seconds\n",
      "epoch: 192 average loss: 0.931\n",
      "Test Accuracy : 58.2%, Test Loss: 1.6387396688461304\n",
      "Epoch Time (Training + Test) = 37.55 seconds\n",
      "epoch: 193 average loss: 0.924\n",
      "Test Accuracy : 58.1%, Test Loss: 1.6218999285697937\n",
      "Epoch Time (Training + Test) = 37.65 seconds\n",
      "epoch: 194 average loss: 0.924\n",
      "Test Accuracy : 58.6%, Test Loss: 1.6165552110671997\n",
      "Epoch Time (Training + Test) = 37.37 seconds\n",
      "epoch: 195 average loss: 0.912\n",
      "Test Accuracy : 59.2%, Test Loss: 1.5928067173957825\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.06 seconds\n",
      "epoch: 196 average loss: 0.916\n",
      "Test Accuracy : 58.7%, Test Loss: 1.6163351373672485\n",
      "Epoch Time (Training + Test) = 36.07 seconds\n",
      "epoch: 197 average loss: 0.915\n",
      "Test Accuracy : 59.4%, Test Loss: 1.5894903116226196\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.00 seconds\n",
      "epoch: 198 average loss: 0.905\n",
      "Test Accuracy : 58.7%, Test Loss: 1.5863705592155457\n",
      "Epoch Time (Training + Test) = 36.85 seconds\n",
      "epoch: 199 average loss: 0.887\n",
      "Test Accuracy : 58.6%, Test Loss: 1.595792673110962\n",
      "Epoch Time (Training + Test) = 39.36 seconds\n",
      "epoch: 200 average loss: 0.883\n",
      "Test Accuracy : 59.8%, Test Loss: 1.5685216312408448\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 40.42 seconds\n",
      "Data Saved to Baseline_BNN_Resnet18_inflate_5.csv\n",
      "Finished Training: \n",
      "Total Time 4.187438 hours\n",
      " Average Time Per Epoch 75.37 seconds\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_data,batch_size =64,shuffle = True,num_workers=4,pin_memory=True)\n",
    "test_dataloader = DataLoader(test_data,batch_size =64,num_workers=4,pin_memory=True)\n",
    "\n",
    "classes = tuple(train_data.classes)\n",
    "\n",
    "# BNN_resnet18 = ResNet_cifar10(num_classes = 80 , depth = 18, inflate =)\n",
    "# # resnet18 = resnet(num_classes = 80 , depth = 18, dataset = 'cifar10')\n",
    "\n",
    "\n",
    "\n",
    "# resnet_trainer =Trainer(resnet18,model_name = 'Baseline_Resnet18',project_name='Cifar80-20',classes = classes,seed = 123)\n",
    "\n",
    "#Set Training Params\n",
    "for i in range(1,6):\n",
    "    BNN_resnet18 = ResNet_cifar10(num_classes = 80 , depth = 18, inflate =i)\n",
    "    trainer = Trainer(BNN_resnet18,model_name = f'Baseline_BNN_Resnet18_inflate_{i}',project_name = 'Cifar80-20',classes = classes,seed = 123,binarise = True)\n",
    "    trainer.tags = ['BNN Inflation Test',f'inflate {i}']\n",
    "    trainer.lr = 0.2\n",
    "    trainer.epochs = 200\n",
    "    trainer.set_optimizer()\n",
    "    trainer.set_scheduler(optim.lr_scheduler.CosineAnnealingLR,T_max = trainer.epochs)\n",
    "    trainer.train(train_dataloader,test_dataloader,group ='BNN Inflation Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_channels(data):\n",
    "    #We have a nxCxWxH array\n",
    "    d = data\n",
    "    d = torch.flatten(data,2,-1).to(dtype = torch.float32)/255\n",
    "    mean= torch.mean(d,dim = [0,2])\n",
    "    std = torch.std(d,dim = [0,2])\n",
    "    return mean,std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd87e4",
   "metadata": {},
   "source": [
    "# Code For Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 3, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 'aquarium_fish',\n",
       " 'baby',\n",
       " 'bear',\n",
       " 'beaver',\n",
       " 'bed',\n",
       " 'bee',\n",
       " 'beetle',\n",
       " 'bicycle',\n",
       " 'bottle',\n",
       " 'bowl',\n",
       " 'boy',\n",
       " 'bridge',\n",
       " 'bus',\n",
       " 'butterfly',\n",
       " 'camel',\n",
       " 'can',\n",
       " 'castle',\n",
       " 'caterpillar',\n",
       " 'cattle']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from NN_Thesis.dataset import cifar_100_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_path = 'data/cifar-100/cifar-20/'\n",
    "\n",
    "train_data20 = cifar_100_split(data_path,train = True)\n",
    "test_data20 = cifar_100_split(data_path,train = False)\n",
    "\n",
    "\n",
    "def normalize_channels(data):\n",
    "    #We have a nxCxWxH array\n",
    "    d = data\n",
    "    d = torch.flatten(data,2,-1).to(dtype = torch.float32)\n",
    "    print(d.shape)\n",
    "    mean= torch.mean(d,dim = [0,2])\n",
    "    std = torch.std(d,dim = [0,2])\n",
    "    return mean,std\n",
    "\n",
    "\n",
    "mean,std = normalize_channels(train_data20.data)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_data20.transform = train_transform\n",
    "test_data20.transform = test_transform\n",
    "\n",
    "mean,std\n",
    "train20_loader = DataLoader(train_data20,batch_size=64,shuffle=True)\n",
    "test20_loader = DataLoader(test_data20,batch_size=64,shuffle=True)\n",
    "classes = train_data20.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7738f11",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630f80ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Default (SGD) Optimizer\n",
      "Scheduler Set {'T_max': 20, 'eta_min': 0, 'base_lrs': [0.01], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.01]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:301ih79a) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3624b0e3d9ff499691a11b2aa50f6a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.151782â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">northern-breeze-14</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/301ih79a\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/301ih79a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221024_143931-301ih79a\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:301ih79a). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fb9286fbe74a4c879bbda0e729b3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221024_144444-34q3pl8m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/34q3pl8m\" target=\"_blank\">fast-blaze-15</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name feat_extract \n",
      "\n",
      "\n",
      "Run Start : 2022-10-24 14-44-44\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 64\n",
      "epochs : 20\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4341260\n",
      "Initial accuracy:\n",
      "Test Accuracy : 3.7%, Test Loss: 35.48689526357469\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 3.0%, Test Loss: 34.90783363580704\n",
      "epoch: 1 average loss: 2.927\n",
      "Test Accuracy : 28.9%, Test Loss: 2.447059504687786\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.79 seconds\n",
      "epoch: 2 average loss: 2.279\n",
      "Test Accuracy : 39.6%, Test Loss: 2.019582949578762\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.55 seconds\n",
      "epoch: 3 average loss: 1.927\n",
      "Test Accuracy : 48.1%, Test Loss: 1.7326117977499962\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.59 seconds\n",
      "epoch: 4 average loss: 1.723\n",
      "Test Accuracy : 51.0%, Test Loss: 1.5640427097678185\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 5 average loss: 1.596\n",
      "Test Accuracy : 53.5%, Test Loss: 1.4605691470205784\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.71 seconds\n",
      "epoch: 6 average loss: 1.527\n",
      "Test Accuracy : 54.8%, Test Loss: 1.4306804910302162\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.64 seconds\n",
      "epoch: 7 average loss: 1.490\n",
      "Test Accuracy : 57.2%, Test Loss: 1.3508130088448524\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.60 seconds\n",
      "epoch: 8 average loss: 1.437\n",
      "Test Accuracy : 57.1%, Test Loss: 1.3256949987262487\n",
      "Epoch Time (Training + Test) = 4.47 seconds\n",
      "epoch: 9 average loss: 1.419\n",
      "Test Accuracy : 58.1%, Test Loss: 1.2865298986434937\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.49 seconds\n",
      "epoch: 10 average loss: 1.410\n",
      "Test Accuracy : 59.0%, Test Loss: 1.313125118613243\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.46 seconds\n",
      "epoch: 11 average loss: 1.390\n",
      "Test Accuracy : 60.9%, Test Loss: 1.2484002597630024\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.51 seconds\n",
      "epoch: 12 average loss: 1.375\n",
      "Test Accuracy : 59.8%, Test Loss: 1.2614622116088867\n",
      "Epoch Time (Training + Test) = 4.46 seconds\n",
      "epoch: 13 average loss: 1.352\n",
      "Test Accuracy : 60.1%, Test Loss: 1.2334648445248604\n",
      "Epoch Time (Training + Test) = 4.45 seconds\n",
      "epoch: 14 average loss: 1.358\n",
      "Test Accuracy : 59.5%, Test Loss: 1.2499681897461414\n",
      "Epoch Time (Training + Test) = 4.43 seconds\n",
      "epoch: 15 average loss: 1.344\n",
      "Test Accuracy : 58.6%, Test Loss: 1.2628842145204544\n",
      "Epoch Time (Training + Test) = 4.48 seconds\n",
      "epoch: 16 average loss: 1.353\n",
      "Test Accuracy : 59.6%, Test Loss: 1.2755833566188812\n",
      "Epoch Time (Training + Test) = 4.45 seconds\n",
      "epoch: 17 average loss: 1.349\n",
      "Test Accuracy : 58.9%, Test Loss: 1.2667645812034607\n",
      "Epoch Time (Training + Test) = 4.45 seconds\n",
      "epoch: 18 average loss: 1.351\n",
      "Test Accuracy : 59.2%, Test Loss: 1.249191552400589\n",
      "Epoch Time (Training + Test) = 4.45 seconds\n",
      "epoch: 19 average loss: 1.326\n",
      "Test Accuracy : 60.4%, Test Loss: 1.2300053238868713\n",
      "Epoch Time (Training + Test) = 4.48 seconds\n",
      "epoch: 20 average loss: 1.343\n",
      "Test Accuracy : 60.5%, Test Loss: 1.2528311423957348\n",
      "Epoch Time (Training + Test) = 4.46 seconds\n",
      "Data Saved to feat_extract.csv\n",
      "Finished Training: \n",
      "Total Time 0.050376 hours\n",
      " Average Time Per Epoch 9.07 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "PATH = '.\\SavedModels\\Cifar80-20\\Baseline_BNN_Resnet18_inflate_5_2022-10-23 14-35-04\\Baseline_BNN_Resnet18_inflate_5_best_acc.pth'\n",
    "BinCifar5_state_dict = torch.load(PATH,map_location= device)\n",
    "\n",
    "feat_extr_model = resnet18_adapt(num_classes= 80)\n",
    "feat_extr_model.load_state_dict(BinCifar5_state_dict)\n",
    "feat_extr_model.freeze()\n",
    "feat_extr_model.fc = BinarizeLinear(64*5,20)\n",
    "feat_extr_model.bn3 = nn.BatchNorm1d(20)\n",
    "\n",
    "\n",
    "feat_ex = Trainer(feat_extr_model,model_name = 'feat_extract',project_name = 'Cifar80-20',classes = classes,seed = 123,binarise = True)\n",
    "feat_ex.lr = 0.01\n",
    "feat_ex.epochs = 20\n",
    "feat_ex.set_optimizer()\n",
    "feat_ex.set_scheduler(optim.lr_scheduler.CosineAnnealingLR,T_max = feat_ex.epochs)\n",
    "feat_ex.tags =['finetune','feature extraction']\n",
    "feat_ex.train(train20_loader,test20_loader,group = 'cifar-20')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454a51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "PATH = '.\\SavedModels\\Cifar80-20\\Baseline_BNN_Resnet18_inflate_5_2022-10-23 14-35-04\\Baseline_BNN_Resnet18_inflate_5_best_acc.pth'\n",
    "BinCifar5_state_dict = torch.load(PATH,map_location= device)\n",
    "\n",
    "\n",
    "finetune_model = resnet18_adapt(num_classes= 80)\n",
    "finetune_model.load_state_dict(BinCifar5_state_dict)\n",
    "finetune_model.freeze()\n",
    "finetune_model.fc = BinarizeLinear(64*5,20)\n",
    "finetune_model.bn3 = nn.BatchNorm1d(20)\n",
    "\n",
    "finetune = Trainer(finetune_model,model_name = 'Full_finetune',project_name='Cifar80-20',classes = classes,seed = 123,binarise = True)\n",
    "finetune.tags = ['finetune','full ft']\n",
    "m = finetune.model\n",
    "# m.to(finetune.device)\n",
    "# for layer in [m.fc,m.bn3,m.bn3]:\n",
    "#     for p in layer.parameters():\n",
    "#         p.requires_grad = True\n",
    "#     layer.train()\n",
    "# finetune.train(train59_loader,test59_loader)\n",
    "\n",
    "\n",
    "#FineTune\n",
    "finetune.epochs = 100\n",
    "finetune.lr = 0.1\n",
    "finetune.set_optimizer()\n",
    "finetune.set_scheduler(optim.lr_scheduler.CosineAnnealingLR,T_max = finetune.epochs)\n",
    "m.unfreeze()\n",
    "finetune.train(train20_loader,test20_loader,group ='cifar-20')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988480bb",
   "metadata": {},
   "source": [
    "## Baseline Resnet FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a38177ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Default (SGD) Optimizer\n",
      "Scheduler Set {'T_max': 100, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:xf90rao4) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">saccharine-lantern-25</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/xf90rao4\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/xf90rao4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221025_091342-xf90rao4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:xf90rao4). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490493f1f1524926ba421ccfa026d929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221025_091500-1d4rb2ba</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/1d4rb2ba\" target=\"_blank\">vivid-prosperity-26</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name Non BNN Full_finetune \n",
      "\n",
      "\n",
      "Run Start : 2022-10-25 09-15-00\n",
      "start_epoch : 0\n",
      "initial_lr : 0.1\n",
      "batch_size : 64\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.models.resnet.ResNet_cifar10'>\n",
      "binerised_training : False\n",
      "Number of Elements : 175908\n",
      "Initial accuracy:\n",
      "Test Accuracy : 5.5%, Test Loss: 3.0209460319227475\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 5.9%, Test Loss: 3.0360041186213493\n",
      "best_acc.pth saved!\n",
      "epoch: 1 average loss: 1.407\n",
      "Test Accuracy : 64.0%, Test Loss: 1.1786473002284765\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 2 average loss: 1.026\n",
      "Test Accuracy : 63.7%, Test Loss: 1.103893518447876\n",
      "Epoch Time (Training + Test) = 2.91 seconds\n",
      "epoch: 3 average loss: 0.920\n",
      "Test Accuracy : 68.9%, Test Loss: 1.0045073870569468\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.92 seconds\n",
      "epoch: 4 average loss: 0.842\n",
      "Test Accuracy : 67.7%, Test Loss: 1.0514607094228268\n",
      "Epoch Time (Training + Test) = 2.94 seconds\n",
      "epoch: 5 average loss: 0.789\n",
      "Test Accuracy : 71.3%, Test Loss: 0.8996030166745186\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.93 seconds\n",
      "epoch: 6 average loss: 0.740\n",
      "Test Accuracy : 69.0%, Test Loss: 0.9731181878596544\n",
      "Epoch Time (Training + Test) = 2.94 seconds\n",
      "epoch: 7 average loss: 0.691\n",
      "Test Accuracy : 72.0%, Test Loss: 0.9054120602086186\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.94 seconds\n",
      "epoch: 8 average loss: 0.654\n",
      "Test Accuracy : 67.8%, Test Loss: 1.0787589624524117\n",
      "Epoch Time (Training + Test) = 2.96 seconds\n",
      "epoch: 9 average loss: 0.626\n",
      "Test Accuracy : 71.9%, Test Loss: 0.8758104871958494\n",
      "Epoch Time (Training + Test) = 2.86 seconds\n",
      "epoch: 10 average loss: 0.595\n",
      "Test Accuracy : 71.4%, Test Loss: 0.9721075631678104\n",
      "Epoch Time (Training + Test) = 2.92 seconds\n",
      "epoch: 11 average loss: 0.570\n",
      "Test Accuracy : 69.6%, Test Loss: 1.1218806337565184\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 12 average loss: 0.566\n",
      "Test Accuracy : 72.0%, Test Loss: 0.9710854347795248\n",
      "Epoch Time (Training + Test) = 2.92 seconds\n",
      "epoch: 13 average loss: 0.520\n",
      "Test Accuracy : 73.2%, Test Loss: 0.905535108409822\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.91 seconds\n",
      "epoch: 14 average loss: 0.498\n",
      "Test Accuracy : 74.2%, Test Loss: 0.8692115498706698\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.85 seconds\n",
      "epoch: 15 average loss: 0.488\n",
      "Test Accuracy : 73.0%, Test Loss: 0.9206274235621095\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 16 average loss: 0.478\n",
      "Test Accuracy : 72.2%, Test Loss: 1.053098164498806\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 17 average loss: 0.464\n",
      "Test Accuracy : 74.8%, Test Loss: 0.8854094110429287\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.86 seconds\n",
      "epoch: 18 average loss: 0.452\n",
      "Test Accuracy : 76.5%, Test Loss: 0.8126502195373178\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.90 seconds\n",
      "epoch: 19 average loss: 0.425\n",
      "Test Accuracy : 75.0%, Test Loss: 0.8850207347422838\n",
      "Epoch Time (Training + Test) = 2.85 seconds\n",
      "epoch: 20 average loss: 0.411\n",
      "Test Accuracy : 75.8%, Test Loss: 0.8424782138317823\n",
      "Epoch Time (Training + Test) = 2.87 seconds\n",
      "epoch: 21 average loss: 0.398\n",
      "Test Accuracy : 75.2%, Test Loss: 0.8595608230680227\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 22 average loss: 0.367\n",
      "Test Accuracy : 75.0%, Test Loss: 0.8654152266681194\n",
      "Epoch Time (Training + Test) = 2.86 seconds\n",
      "epoch: 23 average loss: 0.366\n",
      "Test Accuracy : 74.4%, Test Loss: 0.8987889885902405\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 24 average loss: 0.353\n",
      "Test Accuracy : 75.4%, Test Loss: 0.905874889343977\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 25 average loss: 0.347\n",
      "Test Accuracy : 76.2%, Test Loss: 0.9225630480796099\n",
      "Epoch Time (Training + Test) = 2.85 seconds\n",
      "epoch: 26 average loss: 0.319\n",
      "Test Accuracy : 74.3%, Test Loss: 1.0655136220157146\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 27 average loss: 0.314\n",
      "Test Accuracy : 77.4%, Test Loss: 0.9545540921390057\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.86 seconds\n",
      "epoch: 28 average loss: 0.308\n",
      "Test Accuracy : 75.6%, Test Loss: 0.9122615493834019\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 29 average loss: 0.272\n",
      "Test Accuracy : 75.2%, Test Loss: 0.9466461036354303\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 30 average loss: 0.276\n",
      "Test Accuracy : 77.8%, Test Loss: 0.875035360455513\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.84 seconds\n",
      "epoch: 31 average loss: 0.266\n",
      "Test Accuracy : 75.8%, Test Loss: 1.0422260090708733\n",
      "Epoch Time (Training + Test) = 2.87 seconds\n",
      "epoch: 32 average loss: 0.250\n",
      "Test Accuracy : 76.7%, Test Loss: 0.9219185970723629\n",
      "Epoch Time (Training + Test) = 2.90 seconds\n",
      "epoch: 33 average loss: 0.259\n",
      "Test Accuracy : 75.2%, Test Loss: 1.1107219737023115\n",
      "Epoch Time (Training + Test) = 2.85 seconds\n",
      "epoch: 34 average loss: 0.241\n",
      "Test Accuracy : 77.6%, Test Loss: 0.889295183122158\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 35 average loss: 0.234\n",
      "Test Accuracy : 78.0%, Test Loss: 0.8731614146381617\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.85 seconds\n",
      "epoch: 36 average loss: 0.226\n",
      "Test Accuracy : 78.0%, Test Loss: 0.9443549448624253\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 37 average loss: 0.221\n",
      "Test Accuracy : 77.0%, Test Loss: 0.9047392001375556\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 38 average loss: 0.201\n",
      "Test Accuracy : 77.8%, Test Loss: 0.9113454334437847\n",
      "Epoch Time (Training + Test) = 2.86 seconds\n",
      "epoch: 39 average loss: 0.186\n",
      "Test Accuracy : 79.0%, Test Loss: 0.9343055887147784\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.87 seconds\n",
      "epoch: 40 average loss: 0.189\n",
      "Test Accuracy : 79.1%, Test Loss: 0.852800976485014\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 41 average loss: 0.182\n",
      "Test Accuracy : 78.1%, Test Loss: 0.8771595489233732\n",
      "Epoch Time (Training + Test) = 2.86 seconds\n",
      "epoch: 42 average loss: 0.171\n",
      "Test Accuracy : 78.8%, Test Loss: 0.8854228788986802\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 43 average loss: 0.157\n",
      "Test Accuracy : 78.5%, Test Loss: 0.9496977385133505\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 44 average loss: 0.140\n",
      "Test Accuracy : 79.2%, Test Loss: 0.973631295375526\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.86 seconds\n",
      "epoch: 45 average loss: 0.139\n",
      "Test Accuracy : 79.0%, Test Loss: 0.914151004049927\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 46 average loss: 0.139\n",
      "Test Accuracy : 77.3%, Test Loss: 0.9626332614570856\n",
      "Epoch Time (Training + Test) = 2.86 seconds\n",
      "epoch: 47 average loss: 0.140\n",
      "Test Accuracy : 79.7%, Test Loss: 0.9090393353253603\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.87 seconds\n",
      "epoch: 48 average loss: 0.127\n",
      "Test Accuracy : 77.7%, Test Loss: 1.04480108525604\n",
      "Epoch Time (Training + Test) = 2.90 seconds\n",
      "epoch: 49 average loss: 0.131\n",
      "Test Accuracy : 79.0%, Test Loss: 0.9288437580689788\n",
      "Epoch Time (Training + Test) = 2.84 seconds\n",
      "epoch: 50 average loss: 0.121\n",
      "Test Accuracy : 78.5%, Test Loss: 0.9621329456567764\n",
      "Epoch Time (Training + Test) = 2.93 seconds\n",
      "epoch: 51 average loss: 0.116\n",
      "Test Accuracy : 78.3%, Test Loss: 0.9758086763322353\n",
      "Epoch Time (Training + Test) = 2.97 seconds\n",
      "epoch: 52 average loss: 0.113\n",
      "Test Accuracy : 78.3%, Test Loss: 0.9418257847428322\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 53 average loss: 0.096\n",
      "Test Accuracy : 79.8%, Test Loss: 0.9316650545224547\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 54 average loss: 0.101\n",
      "Test Accuracy : 80.0%, Test Loss: 0.9272558940574527\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.83 seconds\n",
      "epoch: 55 average loss: 0.095\n",
      "Test Accuracy : 79.2%, Test Loss: 0.959776736330241\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 56 average loss: 0.088\n",
      "Test Accuracy : 80.0%, Test Loss: 0.9377354178577662\n",
      "Epoch Time (Training + Test) = 2.90 seconds\n",
      "epoch: 57 average loss: 0.082\n",
      "Test Accuracy : 79.8%, Test Loss: 0.9717515055090189\n",
      "Epoch Time (Training + Test) = 2.85 seconds\n",
      "epoch: 58 average loss: 0.083\n",
      "Test Accuracy : 80.2%, Test Loss: 0.8986239265650511\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 59 average loss: 0.076\n",
      "Test Accuracy : 80.4%, Test Loss: 0.874331365339458\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 60 average loss: 0.073\n",
      "Test Accuracy : 80.6%, Test Loss: 0.9085504962131381\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.85 seconds\n",
      "epoch: 61 average loss: 0.068\n",
      "Test Accuracy : 80.0%, Test Loss: 0.9351489460095763\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 62 average loss: 0.063\n",
      "Test Accuracy : 80.4%, Test Loss: 0.9555420381948352\n",
      "Epoch Time (Training + Test) = 2.86 seconds\n",
      "epoch: 63 average loss: 0.060\n",
      "Test Accuracy : 80.6%, Test Loss: 0.9031137112760916\n",
      "Epoch Time (Training + Test) = 2.87 seconds\n",
      "epoch: 64 average loss: 0.062\n",
      "Test Accuracy : 79.2%, Test Loss: 0.9581302627921104\n",
      "Epoch Time (Training + Test) = 2.87 seconds\n",
      "epoch: 65 average loss: 0.058\n",
      "Test Accuracy : 80.2%, Test Loss: 0.9383446760475636\n",
      "Epoch Time (Training + Test) = 2.85 seconds\n",
      "epoch: 66 average loss: 0.054\n",
      "Test Accuracy : 79.8%, Test Loss: 0.9476413913071156\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 67 average loss: 0.051\n",
      "Test Accuracy : 80.4%, Test Loss: 0.9966909023933113\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 68 average loss: 0.047\n",
      "Test Accuracy : 80.8%, Test Loss: 0.9415515204891562\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.86 seconds\n",
      "epoch: 69 average loss: 0.049\n",
      "Test Accuracy : 80.3%, Test Loss: 0.9543717177584767\n",
      "Epoch Time (Training + Test) = 2.87 seconds\n",
      "epoch: 70 average loss: 0.048\n",
      "Test Accuracy : 79.7%, Test Loss: 0.9853721130639315\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 71 average loss: 0.045\n",
      "Test Accuracy : 80.3%, Test Loss: 0.9446555180475116\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 72 average loss: 0.043\n",
      "Test Accuracy : 79.2%, Test Loss: 1.0031162118539214\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 73 average loss: 0.039\n",
      "Test Accuracy : 80.5%, Test Loss: 0.9730127062648535\n",
      "Epoch Time (Training + Test) = 2.85 seconds\n",
      "epoch: 74 average loss: 0.037\n",
      "Test Accuracy : 81.0%, Test Loss: 0.9828697359189391\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.88 seconds\n",
      "epoch: 75 average loss: 0.040\n",
      "Test Accuracy : 81.0%, Test Loss: 0.945249349810183\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 76 average loss: 0.037\n",
      "Test Accuracy : 81.1%, Test Loss: 0.905208601616323\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.90 seconds\n",
      "epoch: 77 average loss: 0.035\n",
      "Test Accuracy : 81.0%, Test Loss: 0.9152901088818908\n",
      "Epoch Time (Training + Test) = 2.94 seconds\n",
      "epoch: 78 average loss: 0.035\n",
      "Test Accuracy : 80.6%, Test Loss: 0.9927642503753304\n",
      "Epoch Time (Training + Test) = 2.81 seconds\n",
      "epoch: 79 average loss: 0.031\n",
      "Test Accuracy : 80.9%, Test Loss: 0.9534080065786839\n",
      "Epoch Time (Training + Test) = 2.84 seconds\n",
      "epoch: 80 average loss: 0.032\n",
      "Test Accuracy : 80.5%, Test Loss: 0.9564802278764546\n",
      "Epoch Time (Training + Test) = 2.84 seconds\n",
      "epoch: 81 average loss: 0.030\n",
      "Test Accuracy : 80.7%, Test Loss: 0.9801778933033347\n",
      "Epoch Time (Training + Test) = 2.85 seconds\n",
      "epoch: 82 average loss: 0.031\n",
      "Test Accuracy : 80.3%, Test Loss: 1.0144668575376272\n",
      "Epoch Time (Training + Test) = 2.90 seconds\n",
      "epoch: 83 average loss: 0.029\n",
      "Test Accuracy : 81.0%, Test Loss: 0.9562354004010558\n",
      "Epoch Time (Training + Test) = 2.91 seconds\n",
      "epoch: 84 average loss: 0.029\n",
      "Test Accuracy : 81.0%, Test Loss: 0.9727530833333731\n",
      "Epoch Time (Training + Test) = 2.87 seconds\n",
      "epoch: 85 average loss: 0.027\n",
      "Test Accuracy : 80.8%, Test Loss: 0.9490117765963078\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 86 average loss: 0.027\n",
      "Test Accuracy : 80.6%, Test Loss: 0.9511253852397203\n",
      "Epoch Time (Training + Test) = 2.90 seconds\n",
      "epoch: 87 average loss: 0.028\n",
      "Test Accuracy : 80.8%, Test Loss: 0.9857028452679515\n",
      "Epoch Time (Training + Test) = 2.86 seconds\n",
      "epoch: 88 average loss: 0.029\n",
      "Test Accuracy : 80.5%, Test Loss: 0.9590361397713423\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 89 average loss: 0.029\n",
      "Test Accuracy : 80.5%, Test Loss: 0.9894092725589871\n",
      "Epoch Time (Training + Test) = 2.86 seconds\n",
      "epoch: 90 average loss: 0.028\n",
      "Test Accuracy : 81.2%, Test Loss: 0.9369711468461901\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.90 seconds\n",
      "epoch: 91 average loss: 0.027\n",
      "Test Accuracy : 80.9%, Test Loss: 0.9567676139995456\n",
      "Epoch Time (Training + Test) = 2.90 seconds\n",
      "epoch: 92 average loss: 0.030\n",
      "Test Accuracy : 80.8%, Test Loss: 0.9776361733675003\n",
      "Epoch Time (Training + Test) = 2.87 seconds\n",
      "epoch: 93 average loss: 0.025\n",
      "Test Accuracy : 81.3%, Test Loss: 0.9387359609827399\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 2.91 seconds\n",
      "epoch: 94 average loss: 0.028\n",
      "Test Accuracy : 80.9%, Test Loss: 0.9460931271314621\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 95 average loss: 0.024\n",
      "Test Accuracy : 80.8%, Test Loss: 0.9745727935805917\n",
      "Epoch Time (Training + Test) = 2.87 seconds\n",
      "epoch: 96 average loss: 0.025\n",
      "Test Accuracy : 80.7%, Test Loss: 0.9531368578318506\n",
      "Epoch Time (Training + Test) = 2.89 seconds\n",
      "epoch: 97 average loss: 0.027\n",
      "Test Accuracy : 81.0%, Test Loss: 0.9711793549358845\n",
      "Epoch Time (Training + Test) = 2.86 seconds\n",
      "epoch: 98 average loss: 0.025\n",
      "Test Accuracy : 80.9%, Test Loss: 0.9490862339735031\n",
      "Epoch Time (Training + Test) = 2.90 seconds\n",
      "epoch: 99 average loss: 0.027\n",
      "Test Accuracy : 81.0%, Test Loss: 0.9522475693374872\n",
      "Epoch Time (Training + Test) = 2.90 seconds\n",
      "epoch: 100 average loss: 0.026\n",
      "Test Accuracy : 81.0%, Test Loss: 0.9442556421272457\n",
      "Epoch Time (Training + Test) = 2.87 seconds\n",
      "Data Saved to Non BNN Full_finetune.csv\n",
      "Finished Training: \n",
      "Total Time 0.160064 hours\n",
      " Average Time Per Epoch 5.76 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "PATH = '.\\SavedModels\\Cifar80-20\\Baseline_Resnet18_2022-10-25 09-07-51\\Baseline_Resnet18_best_acc.pth'\n",
    "Cifar5_state_dict = torch.load(PATH,map_location= device)\n",
    "\n",
    "\n",
    "finetune_model = resnet(num_classes = 80 , depth = 18, dataset = 'cifar10')\n",
    "finetune_model.load_state_dict(Cifar5_state_dict)\n",
    "\n",
    "finetune_model.fc = nn.Linear(64,20)\n",
    "# finetune_model.bn3 = nn.BatchNorm1d(20)\n",
    "\n",
    "finetune = Trainer(finetune_model,model_name = 'Non BNN Full_finetune',project_name='Cifar80-20',classes = classes,seed = 123,binarise = False)\n",
    "finetune.tags = ['finetune','full ft']\n",
    "m = finetune.model\n",
    "# m.to(finetune.device)\n",
    "# for layer in [m.fc,m.bn3,m.bn3]:\n",
    "#     for p in layer.parameters():\n",
    "#         p.requires_grad = True\n",
    "#     layer.train()\n",
    "# finetune.train(train59_loader,test59_loader)\n",
    "\n",
    "\n",
    "#FineTune\n",
    "finetune.epochs = 100\n",
    "finetune.lr = 0.1\n",
    "finetune.set_optimizer()\n",
    "finetune.set_scheduler(optim.lr_scheduler.CosineAnnealingLR,T_max = finetune.epochs)\n",
    "# m.unfreeze()\n",
    "finetune.train(train20_loader,test20_loader,group = 'Adapter Location Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab91d0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4336415"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = finetune.get_param_info()\n",
    "\n",
    "z = finetune.model\n",
    "element_info = dict()\n",
    "for layer in z.parameters():\n",
    "    if str(layer.dtype) not in element_info.keys():\n",
    "        element_info[str(layer.dtype)] = layer.numel()\n",
    "    else:\n",
    "        element_info[str(layer.dtype)] += layer.numel()\n",
    "\n",
    "element_info[str(layer.dtype)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76552806",
   "metadata": {},
   "source": [
    "# Adapter FineTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5909160e",
   "metadata": {},
   "source": [
    "## Single Autoencoder After bn2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e6b460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start_epoch : 0\n",
      "lr : 0.01\n",
      "batch_size : 128\n",
      "epochs : 70\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "epoch: 1 average loss: 1.388 Epoch Time 0.14 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 44.1%\n",
      "best_acc.pth saved!\n",
      "epoch: 2 average loss: 1.144 Epoch Time 0.28 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 52.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 3 average loss: 1.068 Epoch Time 0.42 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 57.9%\n",
      "best_acc.pth saved!\n",
      "epoch: 4 average loss: 1.011 Epoch Time 0.56 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 60.9%\n",
      "best_acc.pth saved!\n",
      "epoch: 5 average loss: 0.980 Epoch Time 0.69 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 65.1%\n",
      "best_acc.pth saved!\n",
      "epoch: 6 average loss: 0.940 Epoch Time 0.83 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 65.2%\n",
      "best_acc.pth saved!\n",
      "epoch: 7 average loss: 0.910 Epoch Time 0.97 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 67.1%\n",
      "best_acc.pth saved!\n",
      "epoch: 8 average loss: 0.888 Epoch Time 1.10 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 69.2%\n",
      "best_acc.pth saved!\n",
      "epoch: 9 average loss: 0.867 Epoch Time 1.24 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 69.8%\n",
      "best_acc.pth saved!\n",
      "epoch: 10 average loss: 0.847 Epoch Time 1.37 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 69.3%\n",
      "epoch: 11 average loss: 0.840 Epoch Time 1.50 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 71.1%\n",
      "best_acc.pth saved!\n",
      "epoch: 12 average loss: 0.832 Epoch Time 1.64 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 71.1%\n",
      "epoch: 13 average loss: 0.819 Epoch Time 1.77 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 71.6%\n",
      "best_acc.pth saved!\n",
      "epoch: 14 average loss: 0.803 Epoch Time 1.91 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.2%\n",
      "best_acc.pth saved!\n",
      "epoch: 15 average loss: 0.792 Epoch Time 2.04 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 16 average loss: 0.790 Epoch Time 2.18 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.2%\n",
      "epoch: 17 average loss: 0.780 Epoch Time 2.31 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.0%\n",
      "best_acc.pth saved!\n",
      "epoch: 18 average loss: 0.765 Epoch Time 2.45 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.1%\n",
      "epoch: 19 average loss: 0.762 Epoch Time 2.58 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 20 average loss: 0.757 Epoch Time 2.71 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.5%\n",
      "best_acc.pth saved!\n",
      "epoch: 21 average loss: 0.752 Epoch Time 2.85 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.3%\n",
      "epoch: 22 average loss: 0.750 Epoch Time 2.98 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.1%\n",
      "epoch: 23 average loss: 0.750 Epoch Time 3.12 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.6%\n",
      "best_acc.pth saved!\n",
      "epoch: 24 average loss: 0.749 Epoch Time 3.25 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.2%\n",
      "epoch: 25 average loss: 0.752 Epoch Time 3.38 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.6%\n",
      "epoch: 26 average loss: 0.748 Epoch Time 3.52 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.9%\n",
      "best_acc.pth saved!\n",
      "epoch: 27 average loss: 0.744 Epoch Time 3.65 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.5%\n",
      "epoch: 28 average loss: 0.747 Epoch Time 3.79 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.8%\n",
      "epoch: 29 average loss: 0.749 Epoch Time 3.92 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.8%\n",
      "epoch: 30 average loss: 0.745 Epoch Time 4.06 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.8%\n",
      "epoch: 31 average loss: 0.745 Epoch Time 4.19 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 32 average loss: 0.742 Epoch Time 4.32 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.0%\n",
      "epoch: 33 average loss: 0.745 Epoch Time 4.46 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.7%\n",
      "epoch: 34 average loss: 0.745 Epoch Time 4.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.8%\n",
      "epoch: 35 average loss: 0.746 Epoch Time 4.73 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.4%\n",
      "epoch: 36 average loss: 0.744 Epoch Time 4.86 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.8%\n",
      "epoch: 37 average loss: 0.746 Epoch Time 4.99 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 70.4%\n",
      "epoch: 38 average loss: 0.744 Epoch Time 5.13 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.2%\n",
      "epoch: 39 average loss: 0.744 Epoch Time 5.26 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.5%\n",
      "epoch: 40 average loss: 0.745 Epoch Time 5.40 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.8%\n",
      "epoch: 41 average loss: 0.742 Epoch Time 5.53 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.4%\n",
      "epoch: 42 average loss: 0.746 Epoch Time 5.67 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.7%\n",
      "epoch: 43 average loss: 0.746 Epoch Time 5.81 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.3%\n",
      "epoch: 44 average loss: 0.740 Epoch Time 5.95 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.2%\n",
      "epoch: 45 average loss: 0.741 Epoch Time 6.09 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.7%\n",
      "epoch: 46 average loss: 0.743 Epoch Time 6.22 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.2%\n",
      "epoch: 47 average loss: 0.740 Epoch Time 6.36 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.4%\n",
      "epoch: 48 average loss: 0.742 Epoch Time 6.49 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.6%\n",
      "epoch: 49 average loss: 0.739 Epoch Time 6.63 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.0%\n",
      "epoch: 50 average loss: 0.740 Epoch Time 6.77 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.5%\n",
      "epoch: 51 average loss: 0.741 Epoch Time 6.90 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.9%\n",
      "epoch: 52 average loss: 0.740 Epoch Time 7.04 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.0%\n",
      "epoch: 53 average loss: 0.740 Epoch Time 7.18 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.0%\n",
      "epoch: 54 average loss: 0.738 Epoch Time 7.32 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.9%\n",
      "epoch: 55 average loss: 0.737 Epoch Time 7.46 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.4%\n",
      "epoch: 56 average loss: 0.739 Epoch Time 7.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.2%\n",
      "epoch: 57 average loss: 0.741 Epoch Time 7.73 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 58 average loss: 0.739 Epoch Time 7.87 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.9%\n",
      "epoch: 59 average loss: 0.740 Epoch Time 8.02 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.4%\n",
      "epoch: 60 average loss: 0.735 Epoch Time 8.16 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.2%\n",
      "epoch: 61 average loss: 0.741 Epoch Time 8.30 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.0%\n",
      "epoch: 62 average loss: 0.738 Epoch Time 8.45 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.0%\n",
      "epoch: 63 average loss: 0.732 Epoch Time 8.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.1%\n",
      "epoch: 64 average loss: 0.736 Epoch Time 8.73 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.4%\n",
      "epoch: 65 average loss: 0.737 Epoch Time 8.87 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 72.6%\n",
      "epoch: 66 average loss: 0.738 Epoch Time 9.01 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.2%\n",
      "epoch: 67 average loss: 0.733 Epoch Time 9.15 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.9%\n",
      "epoch: 68 average loss: 0.736 Epoch Time 9.29 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.2%\n",
      "epoch: 69 average loss: 0.732 Epoch Time 9.44 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 73.1%\n",
      "epoch: 70 average loss: 0.729 Epoch Time 9.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\adapt_fine_latest.pth saved!\n",
      "Overall Accuracy : 74.0%\n",
      "Data Saved to adapt_fine.csv\n",
      "Finished Training: \n",
      "Total Time 0.159884 hours\n",
      " Average Time Per Epoch 8.22 seconds\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Bin_state_dict = torch.load('BinaryCifar5_best_acc.pth',map_location= device)\n",
    "\n",
    "bottleneck = autoencoder_adapter(320,200)\n",
    "adapt_fine = resnet18_adapt(num_classes=5)\n",
    "adapt_fine.load_state_dict(Bin_state_dict)\n",
    "adapt_fine.freeze()\n",
    "adapt_fine.add_adapter(after = 'bn2',adapter = bottleneck)\n",
    "\n",
    "adapt_fine_trainer = adapter_Trainer(model = adapt_fine,seed = 123,model_name = 'adapt_fine',project_name='Cifar5',classes = classes,binarise= True)\n",
    "for trainer in [adapt_fine_trainer]:\n",
    "    m = trainer.model\n",
    "    m.to(trainer.device)\n",
    "    for layer in [m.fc,m.bn3,m.bn3]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = True\n",
    "        layer.train()\n",
    "    trainer.lr = 0.01\n",
    "    trainer.batch_size = 128\n",
    "    trainer.epochs =70\n",
    "    trainer.epoch_chkpts = []\n",
    "    trainer.start_epoch = 0\n",
    "    trainer.T_max = 70\n",
    "    # trainer.scheduler.T_max= trainer.T_max\n",
    "    # trainer.optimizer = optim.Adam(trainer.model.parameters(), lr=trainer.lr)\n",
    "    trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max= trainer.epochs)\n",
    "    trainer.train(train59_loader,test59_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b10f70d",
   "metadata": {},
   "source": [
    "## 2 Adapters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "080e9358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start_epoch : 0\n",
      "lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 50\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n",
      "torch.Size([64, 80, 32, 32])\n",
      "torch.Size([64, 160, 16, 16])\n",
      "torch.Size([64, 320, 8, 8])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Cifar_n.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Su/Downloads/SydneyUni/thesis/Thesis/Cifar_n.ipynb#X21sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m trainer\u001b[39m.\u001b[39mT_max \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Su/Downloads/SydneyUni/thesis/Thesis/Cifar_n.ipynb#X21sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m trainer\u001b[39m.\u001b[39mscheduler \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mCosineAnnealingLR(trainer\u001b[39m.\u001b[39moptimizer, T_max\u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mepochs)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/John%20Su/Downloads/SydneyUni/thesis/Thesis/Cifar_n.ipynb#X21sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(train59_loader,test59_loader)\n",
      "File \u001b[1;32mc:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\NN_Thesis\\trainer.py:93\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, trainloader, testloader)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39m#Add chkpt saving\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_epoch,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs):   \n\u001b[1;32m---> 93\u001b[0m     loss,acc\u001b[39m=\u001b[39m  (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_epoch(epoch,trainloader),\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest(testloader))\n\u001b[0;32m     94\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_losses\u001b[39m.\u001b[39mappend((loss,acc))\n\u001b[0;32m     95\u001b[0m     \u001b[39m#Save at checkpoint\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\NN_Thesis\\trainer.py:142\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[1;34m(self, epoch, trainloader)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m--> 142\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m    143\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    145\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39mtime\u001b[39m.\u001b[39mperf_counter()\u001b[39m-\u001b[39m  time_start\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Bin_state_dict = torch.load('BinaryCifar5_best_acc.pth',map_location= device)\n",
    "\n",
    "# bottleneck = autoencoder_adapter(320,200)\n",
    "conv_bn = conv_adapter(80,kernel = 1, padding= 0)\n",
    "\n",
    "adapt_fine2 = resnet18_adapt(num_classes=5)\n",
    "adapt_fine2.load_state_dict(Bin_state_dict)\n",
    "adapt_fine2.freeze()\n",
    "\n",
    "# adapt_fine2.add_adapter(after = 'bn2',adapter = bottleneck)\n",
    "adapt_fine2.add_adapter(after = 'layer1',adapter = conv_bn)\n",
    "\n",
    "adapt_fine2_trainer = adapter_Trainer(model = adapt_fine2,seed = 123,name = 'adapt_fine2',classes = classes,binarise= True)\n",
    "for trainer in [adapt_fine2_trainer]:\n",
    "    m = trainer.model\n",
    "    m.to(trainer.device)\n",
    "    for layer in [m.fc,m.bn3,m.bn3]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = True\n",
    "        layer.train()\n",
    "    trainer.lr = 0.01\n",
    "    trainer.batch_size = 32\n",
    "    trainer.epochs =50\n",
    "    trainer.epoch_chkpts = []\n",
    "    trainer.start_epoch = 0\n",
    "    trainer.T_max = 50\n",
    "    trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max= trainer.epochs)\n",
    "    trainer.train(train59_loader,test59_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df2c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ea3499b",
   "metadata": {},
   "source": [
    "# Weight Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "770e923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_weights(main_model:nn.Module,*models:nn.Module):\n",
    "\n",
    "    main_weights = dict()\n",
    "    for (name, param) in main_model.named_parameters():\n",
    "        main_weights[name] = param\n",
    "\n",
    "    n = len( list(main_model.named_parameters()))\n",
    "    print(n)\n",
    "    \n",
    "    for model in models:\n",
    "        i = 0\n",
    "        for name, param in model.named_parameters():\n",
    "            if name in main_weights.keys():\n",
    "                main_weight = main_weights[name]\n",
    "                if not (torch.all(main_weight == param)):\n",
    "                    print(f'parameters {name} in main_model and other model do not match')\n",
    "            else:\n",
    "                print(f'name {name} does not exist in original model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab905d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "name layer1.2.conv1.weight does not exist in original model\n",
      "name layer1.2.bn1.weight does not exist in original model\n",
      "name layer1.2.bn1.bias does not exist in original model\n",
      "name layer1.2.deconv1.weight does not exist in original model\n",
      "name layer1.2.bn2.weight does not exist in original model\n",
      "name layer1.2.bn2.bias does not exist in original model\n",
      "parameters bn3.weight in main_model and other model do not match\n",
      "parameters bn3.bias in main_model and other model do not match\n",
      "parameters fc.weight in main_model and other model do not match\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.l_in.weight does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.l_in.bias does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.bn1.weight does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.bn1.bias does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.l_out.weight does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.l_out.bias does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.bn2.weight does not exist in original model\n",
      "name adapter_dict.bn2,autoencoder_adapter,0.bn2.bias does not exist in original model\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Bin_state_dict = torch.load('BinaryCifar5_best_acc.pth',map_location= device)\n",
    "fineTune_dict = torch.load('adapt_fine2_best_acc.pth',map_location= device)\n",
    "\n",
    "og_model =  resnet18_adapt(num_classes=5)\n",
    "og_model.load_state_dict(Bin_state_dict)\n",
    "og_model.to(device = 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "finetune = resnet18_adapt(num_classes=5)\n",
    "\n",
    "finetune.to(device = 'cpu')\n",
    "bottleneck = autoencoder_adapter(320,200)\n",
    "conv_bn = conv_bottleneck_adapter(80,40,kernel = 3, padding= 1)\n",
    "finetune.add_adapter(after = 'bn2',adapter = bottleneck)\n",
    "finetune.add_adapter(after = 'layer1',adapter = conv_bn)\n",
    "\n",
    "finetune.load_state_dict(fineTune_dict)\n",
    "\n",
    "# h = resnet18_adapt(num_classes=5)\n",
    "# x = resnet18_adapt(num_classes=5)\n",
    "compare_weights(og_model,finetune)\n",
    "\n",
    "\n",
    "# h = resnet18_adapt(num_classes=5)\n",
    "# x = resnet18_adapt(num_classes=5)\n",
    "\n",
    "# print(torch.all(h.weight == x.weight))\n",
    "\n",
    "# compare_weights(h,x)\n",
    "# print(h.weight)\n",
    "# adapt_fine2.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d27190a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start_epoch : 0\n",
      "lr : 0.01\n",
      "batch_size : 128\n",
      "epochs : 80\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "epoch: 1 average loss: 2.592 Epoch Time 0.89 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 29.9%\n",
      "best_acc.pth saved!\n",
      "epoch: 2 average loss: 1.996 Epoch Time 1.77 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 26.5%\n",
      "epoch: 3 average loss: 1.882 Epoch Time 2.64 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.5%\n",
      "best_acc.pth saved!\n",
      "epoch: 4 average loss: 1.860 Epoch Time 3.52 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 21.6%\n",
      "epoch: 5 average loss: 1.925 Epoch Time 4.40 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 29.8%\n",
      "epoch: 6 average loss: 1.910 Epoch Time 5.28 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 31.1%\n",
      "epoch: 7 average loss: 1.868 Epoch Time 6.16 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 28.4%\n",
      "epoch: 8 average loss: 1.945 Epoch Time 7.04 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 27.6%\n",
      "epoch: 9 average loss: 1.944 Epoch Time 7.92 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 24.7%\n",
      "epoch: 10 average loss: 1.942 Epoch Time 8.80 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 21.9%\n",
      "epoch: 11 average loss: 1.920 Epoch Time 9.68 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 28.0%\n",
      "epoch: 12 average loss: 1.971 Epoch Time 10.56 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 13 average loss: 1.929 Epoch Time 11.44 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.4%\n",
      "best_acc.pth saved!\n",
      "epoch: 14 average loss: 1.915 Epoch Time 12.32 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 31.6%\n",
      "epoch: 15 average loss: 1.915 Epoch Time 13.20 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.5%\n",
      "best_acc.pth saved!\n",
      "epoch: 16 average loss: 1.957 Epoch Time 14.07 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.4%\n",
      "epoch: 17 average loss: 1.851 Epoch Time 14.94 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 18 average loss: 1.826 Epoch Time 15.82 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 19 average loss: 1.834 Epoch Time 16.69 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 31.5%\n",
      "epoch: 20 average loss: 1.870 Epoch Time 17.56 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.8%\n",
      "epoch: 21 average loss: 1.883 Epoch Time 18.43 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.7%\n",
      "epoch: 22 average loss: 1.877 Epoch Time 19.31 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.6%\n",
      "epoch: 23 average loss: 1.884 Epoch Time 20.18 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.9%\n",
      "best_acc.pth saved!\n",
      "epoch: 24 average loss: 1.887 Epoch Time 21.05 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.4%\n",
      "best_acc.pth saved!\n",
      "epoch: 25 average loss: 1.896 Epoch Time 21.92 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.7%\n",
      "epoch: 26 average loss: 1.907 Epoch Time 22.80 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.9%\n",
      "epoch: 27 average loss: 1.880 Epoch Time 23.67 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "best_acc.pth saved!\n",
      "epoch: 28 average loss: 1.895 Epoch Time 24.54 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.6%\n",
      "epoch: 29 average loss: 1.903 Epoch Time 25.41 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 30 average loss: 1.920 Epoch Time 26.28 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.8%\n",
      "epoch: 31 average loss: 1.895 Epoch Time 27.15 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 18.9%\n",
      "epoch: 32 average loss: 1.887 Epoch Time 28.03 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.7%\n",
      "epoch: 33 average loss: 1.907 Epoch Time 28.90 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "best_acc.pth saved!\n",
      "epoch: 34 average loss: 1.873 Epoch Time 29.77 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.1%\n",
      "best_acc.pth saved!\n",
      "epoch: 35 average loss: 1.882 Epoch Time 30.64 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.4%\n",
      "epoch: 36 average loss: 1.868 Epoch Time 31.51 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.9%\n",
      "epoch: 37 average loss: 1.857 Epoch Time 32.38 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.0%\n",
      "epoch: 38 average loss: 1.850 Epoch Time 33.25 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.3%\n",
      "epoch: 39 average loss: 1.849 Epoch Time 34.12 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 40 average loss: 1.878 Epoch Time 34.99 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.5%\n",
      "epoch: 41 average loss: 1.897 Epoch Time 35.86 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.6%\n",
      "epoch: 42 average loss: 1.870 Epoch Time 36.74 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 43 average loss: 1.877 Epoch Time 37.61 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.4%\n",
      "epoch: 44 average loss: 1.880 Epoch Time 38.48 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.2%\n",
      "best_acc.pth saved!\n",
      "epoch: 45 average loss: 1.839 Epoch Time 39.35 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.9%\n",
      "epoch: 46 average loss: 1.836 Epoch Time 40.22 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 23.0%\n",
      "epoch: 47 average loss: 1.909 Epoch Time 41.09 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.3%\n",
      "epoch: 48 average loss: 1.878 Epoch Time 41.96 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 49 average loss: 1.924 Epoch Time 42.83 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.8%\n",
      "epoch: 50 average loss: 1.914 Epoch Time 43.70 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 21.2%\n",
      "epoch: 51 average loss: 1.898 Epoch Time 44.57 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.9%\n",
      "epoch: 52 average loss: 1.885 Epoch Time 45.44 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.3%\n",
      "epoch: 53 average loss: 1.888 Epoch Time 46.31 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.7%\n",
      "epoch: 54 average loss: 1.884 Epoch Time 47.18 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.9%\n",
      "epoch: 55 average loss: 1.901 Epoch Time 48.05 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.3%\n",
      "epoch: 56 average loss: 1.904 Epoch Time 48.92 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.5%\n",
      "epoch: 57 average loss: 1.897 Epoch Time 49.79 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.8%\n",
      "epoch: 58 average loss: 1.940 Epoch Time 50.66 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.5%\n",
      "epoch: 59 average loss: 1.880 Epoch Time 51.53 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.3%\n",
      "epoch: 60 average loss: 1.861 Epoch Time 52.40 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.6%\n",
      "epoch: 61 average loss: 1.859 Epoch Time 53.27 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.5%\n",
      "epoch: 62 average loss: 1.855 Epoch Time 54.14 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 63 average loss: 1.856 Epoch Time 55.02 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.3%\n",
      "best_acc.pth saved!\n",
      "epoch: 64 average loss: 1.855 Epoch Time 55.88 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.4%\n",
      "best_acc.pth saved!\n",
      "epoch: 65 average loss: 1.855 Epoch Time 56.76 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.4%\n",
      "epoch: 66 average loss: 1.839 Epoch Time 57.63 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.2%\n",
      "epoch: 67 average loss: 1.842 Epoch Time 58.50 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.6%\n",
      "best_acc.pth saved!\n",
      "epoch: 68 average loss: 1.839 Epoch Time 59.37 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.0%\n",
      "epoch: 69 average loss: 1.841 Epoch Time 60.24 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.6%\n",
      "epoch: 70 average loss: 1.831 Epoch Time 61.11 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.0%\n",
      "epoch: 71 average loss: 1.831 Epoch Time 61.98 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.3%\n",
      "epoch: 72 average loss: 1.846 Epoch Time 62.85 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.8%\n",
      "epoch: 73 average loss: 1.831 Epoch Time 63.72 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.2%\n",
      "epoch: 74 average loss: 1.829 Epoch Time 64.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.2%\n",
      "epoch: 75 average loss: 1.838 Epoch Time 65.46 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.0%\n",
      "epoch: 76 average loss: 1.862 Epoch Time 66.33 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 17.6%\n",
      "epoch: 77 average loss: 1.992 Epoch Time 67.20 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 29.2%\n",
      "epoch: 78 average loss: 2.011 Epoch Time 68.07 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 29.9%\n",
      "epoch: 79 average loss: 1.915 Epoch Time 68.94 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.7%\n",
      "epoch: 80 average loss: 1.908 Epoch Time 69.81 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\Conv_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.5%\n",
      "0,8099.940979242325,0.2989\n",
      "\n",
      "1,6237.196184396744,0.265\n",
      "\n",
      "2,5879.953437805176,0.3246\n",
      "\n",
      "3,5813.886066913605,0.216\n",
      "\n",
      "4,6017.045122385025,0.2976\n",
      "\n",
      "5,5969.3530440330505,0.311\n",
      "\n",
      "6,5836.442450881004,0.2836\n",
      "\n",
      "7,6077.181616067886,0.2759\n",
      "\n",
      "8,6076.482693910599,0.2471\n",
      "\n",
      "9,6069.883714199066,0.2193\n",
      "\n",
      "10,5999.171329975128,0.2801\n",
      "\n",
      "11,6158.684487938881,0.1\n",
      "\n",
      "12,6029.4378073215485,0.334\n",
      "\n",
      "13,5984.127944946289,0.3162\n",
      "\n",
      "14,5983.590229034424,0.3348\n",
      "\n",
      "15,6117.186181783676,0.3244\n",
      "\n",
      "16,5783.250534415245,0.3532\n",
      "\n",
      "17,5707.166515469551,0.1\n",
      "\n",
      "18,5731.650639533997,0.3154\n",
      "\n",
      "19,5845.213054299355,0.3478\n",
      "\n",
      "20,5885.716653347015,0.3373\n",
      "\n",
      "21,5864.85775744915,0.3464\n",
      "\n",
      "22,5888.944297671318,0.3595\n",
      "\n",
      "23,5897.626473665237,0.3637\n",
      "\n",
      "24,5924.192006111145,0.3268\n",
      "\n",
      "25,5959.27901995182,0.3586\n",
      "\n",
      "26,5876.152055263519,0.3646\n",
      "\n",
      "27,5921.497925400734,0.356\n",
      "\n",
      "28,5946.001384496689,0.1\n",
      "\n",
      "29,6000.746152162552,0.3379\n",
      "\n",
      "30,5923.365646481514,0.1891\n",
      "\n",
      "31,5896.231310606003,0.3469\n",
      "\n",
      "32,5959.00818836689,0.3649\n",
      "\n",
      "33,5852.973301410675,0.371\n",
      "\n",
      "34,5882.13953769207,0.3541\n",
      "\n",
      "35,5837.738756775856,0.3589\n",
      "\n",
      "36,5803.401345491409,0.32\n",
      "\n",
      "37,5780.3156661987305,0.3629\n",
      "\n",
      "38,5779.354523777962,0.1\n",
      "\n",
      "39,5868.924768090248,0.3053\n",
      "\n",
      "40,5926.852863669395,0.3656\n",
      "\n",
      "41,5845.198913693428,0.1\n",
      "\n",
      "42,5864.073205471039,0.3239\n",
      "\n",
      "43,5874.591424465179,0.3722\n",
      "\n",
      "44,5746.118590831757,0.3389\n",
      "\n",
      "45,5736.706527233124,0.2297\n",
      "\n",
      "46,5965.842227220535,0.3035\n",
      "\n",
      "47,5869.5217707157135,0.1\n",
      "\n",
      "48,6010.998265504837,0.3277\n",
      "\n",
      "49,5979.784052729607,0.2125\n",
      "\n",
      "50,5930.023477315903,0.3489\n",
      "\n",
      "51,5889.915028214455,0.343\n",
      "\n",
      "52,5900.942342400551,0.3468\n",
      "\n",
      "53,5887.088482737541,0.3289\n",
      "\n",
      "54,5940.074189782143,0.3528\n",
      "\n",
      "55,5948.972398400307,0.3453\n",
      "\n",
      "56,5928.912617087364,0.348\n",
      "\n",
      "57,6063.025860071182,0.3548\n",
      "\n",
      "58,5874.237913131714,0.3333\n",
      "\n",
      "59,5816.52621281147,0.3664\n",
      "\n",
      "60,5808.114767551422,0.3248\n",
      "\n",
      "61,5797.466562390327,0.3729\n",
      "\n",
      "62,5801.06084215641,0.3732\n",
      "\n",
      "63,5796.374711990356,0.3738\n",
      "\n",
      "64,5798.34011900425,0.3735\n",
      "\n",
      "65,5748.099517226219,0.3724\n",
      "\n",
      "66,5755.917871117592,0.3762\n",
      "\n",
      "67,5747.28307557106,0.3697\n",
      "\n",
      "68,5753.993115663528,0.3759\n",
      "\n",
      "69,5722.7913945913315,0.3002\n",
      "\n",
      "70,5721.40315079689,0.3734\n",
      "\n",
      "71,5769.376770377159,0.3481\n",
      "\n",
      "72,5721.977698922157,0.3723\n",
      "\n",
      "73,5714.555166721344,0.3724\n",
      "\n",
      "74,5742.844411492348,0.3398\n",
      "\n",
      "75,5818.116864085197,0.1762\n",
      "\n",
      "76,6226.110817313194,0.2924\n",
      "\n",
      "77,6282.881877183914,0.2994\n",
      "\n",
      "78,5985.552012562752,0.3368\n",
      "\n",
      "79,5962.420366883278,0.3051\n",
      "\n",
      "Data Saved to Conv_BNN2.csv\n",
      "Finished Training: \n",
      "Total Time 1.163545 hours\n",
      " Average Time Per Epoch 52.36 seconds\n",
      "start\n",
      "start_epoch : 0\n",
      "lr : 0.01\n",
      "batch_size : 128\n",
      "epochs : 80\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "epoch: 1 average loss: 2.589 Epoch Time 0.94 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.1%\n",
      "best_acc.pth saved!\n",
      "epoch: 2 average loss: 1.838 Epoch Time 1.89 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 3 average loss: 1.857 Epoch Time 2.83 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.6%\n",
      "best_acc.pth saved!\n",
      "epoch: 4 average loss: 1.896 Epoch Time 3.78 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 5 average loss: 1.828 Epoch Time 4.72 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "best_acc.pth saved!\n",
      "epoch: 6 average loss: 1.825 Epoch Time 5.67 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 7 average loss: 1.856 Epoch Time 6.62 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.1%\n",
      "epoch: 8 average loss: 1.870 Epoch Time 7.56 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.9%\n",
      "epoch: 9 average loss: 1.893 Epoch Time 8.51 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.7%\n",
      "epoch: 10 average loss: 1.796 Epoch Time 9.46 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.8%\n",
      "epoch: 11 average loss: 1.813 Epoch Time 10.41 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.0%\n",
      "best_acc.pth saved!\n",
      "epoch: 12 average loss: 1.805 Epoch Time 11.35 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 13 average loss: 1.781 Epoch Time 12.31 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 14 average loss: 1.769 Epoch Time 13.25 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.1%\n",
      "epoch: 15 average loss: 1.834 Epoch Time 14.20 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.3%\n",
      "epoch: 16 average loss: 1.767 Epoch Time 15.15 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 27.6%\n",
      "epoch: 17 average loss: 1.741 Epoch Time 16.10 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.9%\n",
      "epoch: 18 average loss: 1.747 Epoch Time 17.04 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.6%\n",
      "epoch: 19 average loss: 1.803 Epoch Time 17.99 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "epoch: 20 average loss: 1.809 Epoch Time 18.94 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 21.4%\n",
      "epoch: 21 average loss: 1.800 Epoch Time 19.89 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 22 average loss: 1.804 Epoch Time 20.84 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.5%\n",
      "epoch: 23 average loss: 1.790 Epoch Time 21.78 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.1%\n",
      "epoch: 24 average loss: 1.826 Epoch Time 22.73 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 25 average loss: 1.807 Epoch Time 23.68 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.1%\n",
      "epoch: 26 average loss: 1.821 Epoch Time 24.63 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.2%\n",
      "epoch: 27 average loss: 1.804 Epoch Time 25.58 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.9%\n",
      "epoch: 28 average loss: 1.764 Epoch Time 26.52 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.4%\n",
      "epoch: 29 average loss: 1.776 Epoch Time 27.47 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 32.6%\n",
      "epoch: 30 average loss: 1.749 Epoch Time 28.42 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 31 average loss: 1.751 Epoch Time 29.37 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 29.2%\n",
      "epoch: 32 average loss: 1.771 Epoch Time 30.32 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 33 average loss: 1.790 Epoch Time 31.27 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.2%\n",
      "epoch: 34 average loss: 1.747 Epoch Time 32.21 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 35 average loss: 1.770 Epoch Time 33.16 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 28.9%\n",
      "epoch: 36 average loss: 1.747 Epoch Time 34.11 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 37 average loss: 1.752 Epoch Time 35.06 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.1%\n",
      "epoch: 38 average loss: 1.761 Epoch Time 36.00 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.2%\n",
      "epoch: 39 average loss: 1.762 Epoch Time 36.95 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 40 average loss: 1.758 Epoch Time 37.90 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.8%\n",
      "epoch: 41 average loss: 1.756 Epoch Time 38.85 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 23.5%\n",
      "epoch: 42 average loss: 1.783 Epoch Time 39.80 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.6%\n",
      "epoch: 43 average loss: 1.777 Epoch Time 40.74 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.8%\n",
      "epoch: 44 average loss: 1.772 Epoch Time 41.69 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 45 average loss: 1.772 Epoch Time 42.64 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.0%\n",
      "epoch: 46 average loss: 1.769 Epoch Time 43.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.2%\n",
      "epoch: 47 average loss: 1.732 Epoch Time 44.53 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.8%\n",
      "epoch: 48 average loss: 1.774 Epoch Time 45.48 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 34.7%\n",
      "epoch: 49 average loss: 1.789 Epoch Time 46.43 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.5%\n",
      "epoch: 50 average loss: 1.783 Epoch Time 47.38 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.3%\n",
      "epoch: 51 average loss: 1.771 Epoch Time 48.33 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.7%\n",
      "epoch: 52 average loss: 1.758 Epoch Time 49.27 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 33.5%\n",
      "epoch: 53 average loss: 1.736 Epoch Time 50.22 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.1%\n",
      "epoch: 54 average loss: 1.750 Epoch Time 51.17 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.7%\n",
      "epoch: 55 average loss: 1.752 Epoch Time 52.12 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.0%\n",
      "epoch: 56 average loss: 1.746 Epoch Time 53.07 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.2%\n",
      "epoch: 57 average loss: 1.735 Epoch Time 54.01 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.4%\n",
      "epoch: 58 average loss: 1.757 Epoch Time 54.96 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.5%\n",
      "epoch: 59 average loss: 1.725 Epoch Time 55.91 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.4%\n",
      "epoch: 60 average loss: 1.708 Epoch Time 56.86 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 27.7%\n",
      "epoch: 61 average loss: 1.717 Epoch Time 57.80 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "epoch: 62 average loss: 1.719 Epoch Time 58.75 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 63 average loss: 1.722 Epoch Time 59.70 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 64 average loss: 1.727 Epoch Time 60.65 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 30.4%\n",
      "epoch: 65 average loss: 1.739 Epoch Time 61.59 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 10.0%\n",
      "epoch: 66 average loss: 1.740 Epoch Time 62.54 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.3%\n",
      "epoch: 67 average loss: 1.717 Epoch Time 63.49 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "epoch: 68 average loss: 1.722 Epoch Time 64.44 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.6%\n",
      "epoch: 69 average loss: 1.733 Epoch Time 65.38 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 37.0%\n",
      "best_acc.pth saved!\n",
      "epoch: 70 average loss: 1.717 Epoch Time 66.33 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.1%\n",
      "epoch: 71 average loss: 1.702 Epoch Time 67.28 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.3%\n",
      "epoch: 72 average loss: 1.707 Epoch Time 68.23 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.4%\n",
      "epoch: 73 average loss: 1.718 Epoch Time 69.18 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.4%\n",
      "epoch: 74 average loss: 1.741 Epoch Time 70.12 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.0%\n",
      "epoch: 75 average loss: 1.767 Epoch Time 71.07 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.6%\n",
      "epoch: 76 average loss: 1.716 Epoch Time 72.02 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.3%\n",
      "epoch: 77 average loss: 1.761 Epoch Time 72.97 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "epoch: 78 average loss: 1.738 Epoch Time 73.92 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.1%\n",
      "epoch: 79 average loss: 1.755 Epoch Time 74.86 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 35.6%\n",
      "epoch: 80 average loss: 1.724 Epoch Time 75.81 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\ConvBN_BNN2_latest.pth saved!\n",
      "Overall Accuracy : 36.5%\n",
      "0,8090.045108914375,0.3406\n",
      "\n",
      "1,5744.079199790955,0.1\n",
      "\n",
      "2,5803.732268214226,0.356\n",
      "\n",
      "3,5924.422278046608,0.1\n",
      "\n",
      "4,5712.627169132233,0.3646\n",
      "\n",
      "5,5703.643463611603,0.1\n",
      "\n",
      "6,5800.083121538162,0.3314\n",
      "\n",
      "7,5843.463107466698,0.3488\n",
      "\n",
      "8,5916.790301680565,0.3473\n",
      "\n",
      "9,5611.466279864311,0.3576\n",
      "\n",
      "10,5665.3035036325455,0.3696\n",
      "\n",
      "11,5639.972053408623,0.1\n",
      "\n",
      "12,5565.110634684563,0.1\n",
      "\n",
      "13,5529.023782968521,0.3014\n",
      "\n",
      "14,5729.736257195473,0.3333\n",
      "\n",
      "15,5523.338476061821,0.2756\n",
      "\n",
      "16,5439.97814977169,0.3689\n",
      "\n",
      "17,5460.107109308243,0.3662\n",
      "\n",
      "18,5634.898241281509,0.3653\n",
      "\n",
      "19,5651.863823533058,0.2136\n",
      "\n",
      "20,5624.1750375032425,0.1\n",
      "\n",
      "21,5637.9680832624435,0.3447\n",
      "\n",
      "22,5594.580346941948,0.3506\n",
      "\n",
      "23,5707.296412944794,0.1\n",
      "\n",
      "24,5648.300881147385,0.3607\n",
      "\n",
      "25,5690.181461453438,0.3516\n",
      "\n",
      "26,5637.855673789978,0.3689\n",
      "\n",
      "27,5513.164198517799,0.3544\n",
      "\n",
      "28,5549.68645632267,0.3263\n",
      "\n",
      "29,5466.688217997551,0.1\n",
      "\n",
      "30,5471.597128510475,0.2925\n",
      "\n",
      "31,5532.820133924484,0.1\n",
      "\n",
      "32,5592.819152832031,0.3616\n",
      "\n",
      "33,5458.608039140701,0.1\n",
      "\n",
      "34,5529.745078325272,0.2893\n",
      "\n",
      "35,5458.006286859512,0.1\n",
      "\n",
      "36,5473.929146409035,0.3305\n",
      "\n",
      "37,5503.10265994072,0.352\n",
      "\n",
      "38,5507.019405007362,0.1\n",
      "\n",
      "39,5493.107804059982,0.308\n",
      "\n",
      "40,5487.285251617432,0.2348\n",
      "\n",
      "41,5571.946670532227,0.3357\n",
      "\n",
      "42,5552.931448936462,0.3484\n",
      "\n",
      "43,5536.606554508209,0.1\n",
      "\n",
      "44,5538.198343634605,0.3598\n",
      "\n",
      "45,5529.61530995369,0.3423\n",
      "\n",
      "46,5412.885029435158,0.3583\n",
      "\n",
      "47,5543.503016471863,0.347\n",
      "\n",
      "48,5590.957150816917,0.3555\n",
      "\n",
      "49,5573.319034337997,0.3534\n",
      "\n",
      "50,5533.50147151947,0.357\n",
      "\n",
      "51,5494.279057621956,0.3347\n",
      "\n",
      "52,5425.19837141037,0.3009\n",
      "\n",
      "53,5470.206729650497,0.3572\n",
      "\n",
      "54,5475.071274995804,0.3602\n",
      "\n",
      "55,5455.507556080818,0.3519\n",
      "\n",
      "56,5422.673845171928,0.3545\n",
      "\n",
      "57,5490.635876297951,0.3549\n",
      "\n",
      "58,5390.933984160423,0.3644\n",
      "\n",
      "59,5337.682922840118,0.2774\n",
      "\n",
      "60,5364.75077188015,0.3655\n",
      "\n",
      "61,5372.103421330452,0.1\n",
      "\n",
      "62,5381.836247205734,0.1\n",
      "\n",
      "63,5397.231115102768,0.3038\n",
      "\n",
      "64,5434.606628894806,0.1\n",
      "\n",
      "65,5438.863090991974,0.3632\n",
      "\n",
      "66,5365.0239174366,0.3655\n",
      "\n",
      "67,5381.173480629921,0.3658\n",
      "\n",
      "68,5415.449820995331,0.37\n",
      "\n",
      "69,5366.66263127327,0.3615\n",
      "\n",
      "70,5318.368523001671,0.3628\n",
      "\n",
      "71,5333.096682906151,0.3645\n",
      "\n",
      "72,5370.250630021095,0.3643\n",
      "\n",
      "73,5439.1297389268875,0.3502\n",
      "\n",
      "74,5522.361746668816,0.3659\n",
      "\n",
      "75,5361.294143199921,0.3633\n",
      "\n",
      "76,5503.716962218285,0.3654\n",
      "\n",
      "77,5431.796422958374,0.3606\n",
      "\n",
      "78,5485.211228251457,0.3564\n",
      "\n",
      "79,5388.070419073105,0.3648\n",
      "\n",
      "Data Saved to ConvBN_BNN2.csv\n",
      "Finished Training: \n",
      "Total Time 1.263516 hours\n",
      " Average Time Per Epoch 56.86 seconds\n"
     ]
    }
   ],
   "source": [
    "# from NN_Thesis.models.binarized_modules import BinarizeConv2d\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Bin_state_dict = torch.load('test_best_acc.pth',map_location= device)\n",
    "\n",
    "bt_model = resnet18_adapt()\n",
    "bt_model.load_state_dict(Bin_state_dict)\n",
    "\n",
    "conv_model = resnet18_adapt()\n",
    "conv_model.load_state_dict(Bin_state_dict)\n",
    "\n",
    "conv_bt_model = resnet18_adapt()\n",
    "conv_bt_model.load_state_dict(Bin_state_dict)\n",
    "\n",
    "\n",
    "\n",
    "adapters = [\n",
    "    (bottleneck_adapter((80,32,32),5),bottleneck_adapter((160,16,16),5),bottleneck_adapter((320,8,8),5)),\n",
    "    (conv_adapter(80,kernel= 3,padding = 1),conv_adapter(160,kernel= 3,padding = 1),conv_adapter(320,kernel=1)),\n",
    "    (conv_bottleneck_adapter(80,80,kernel=3,padding=1),conv_bottleneck_adapter(160,80,kernel=3,padding=1),conv_bottleneck_adapter(320,160,kernel=3,padding=1))\n",
    "]\n",
    "\n",
    "\n",
    "#Set all layer requires grad to false and set to eval mode()\n",
    "for m,adpts in zip([bt_model,conv_model,conv_bt_model],adapters):\n",
    "    m.freeze()\n",
    "    m.add_adapter(after = 'layer1',adapter =adpts[0])\n",
    "    m.add_adapter(after = 'layer2',adapter =adpts[1])\n",
    "    m.add_adapter(after = 'layer3',adapter =adpts[2])\n",
    "\n",
    "\n",
    "# bottle_trainer = adapter_Trainer(model = bt_model,seed = 123,name = 'Bottleneck_BNN2',classes = classes,binarise= True)\n",
    "conv_trainer = adapter_Trainer(model = conv_model,seed = 123,name = 'Conv_BNN2',classes = classes,binarise= True)\n",
    "conv_bt_trainer = adapter_Trainer(model = conv_bt_model,seed = 123,name = 'ConvBN_BNN2',classes = classes,binarise= True)\n",
    "# trainer.load('test_150.pth',map_location= device,load_model= True)\n",
    "for trainer in [conv_trainer,conv_bt_trainer]:\n",
    "    m = trainer.model\n",
    "    m.to(trainer.device)\n",
    "    for layer in [m.fc,m.bn3,m.bn3]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = True\n",
    "        layer.train()\n",
    "    trainer.lr = 0.01\n",
    "    trainer.batch_size = 128\n",
    "    trainer.epochs =80\n",
    "    trainer.epoch_chkpts = []\n",
    "    trainer.start_epoch = 0\n",
    "    trainer.T_max = 80\n",
    "    # trainer.scheduler.T_max= trainer.T_max\n",
    "    trainer.optimizer = optim.Adam(trainer.model.parameters(), lr=trainer.lr)\n",
    "    trainer.scheduler = optim.lr_scheduler.ExponentialLR(trainer.optimizer, gamma=0.95)\n",
    "    trainer.train(trainloader,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f6c44",
   "metadata": {},
   "source": [
    "# DEBUGGING TIME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e50802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start_epoch : 0\n",
      "lr : 0.01\n",
      "batch_size : 128\n",
      "epochs : 10\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "epoch: 1 average loss: 0.448 Epoch Time 0.49 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.7%\n",
      "best_acc.pth saved!\n",
      "epoch: 2 average loss: 0.447 Epoch Time 0.98 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.7%\n",
      "best_acc.pth saved!\n",
      "epoch: 3 average loss: 0.445 Epoch Time 1.47 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 4 average loss: 0.448 Epoch Time 1.97 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 5 average loss: 0.450 Epoch Time 2.46 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 6 average loss: 0.445 Epoch Time 2.96 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.8%\n",
      "best_acc.pth saved!\n",
      "epoch: 7 average loss: 0.453 Epoch Time 3.46 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 8 average loss: 0.446 Epoch Time 3.96 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.9%\n",
      "best_acc.pth saved!\n",
      "epoch: 9 average loss: 0.448 Epoch Time 4.45 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.7%\n",
      "epoch: 10 average loss: 0.445 Epoch Time 4.94 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\debug_latest.pth saved!\n",
      "Overall Accuracy : 83.8%\n",
      "0,1399.2995592085645,0.8365\n",
      "\n",
      "1,1397.314375732094,0.8372\n",
      "\n",
      "2,1389.4603708926588,0.836\n",
      "\n",
      "3,1399.6776360534132,0.836\n",
      "\n",
      "4,1404.7952956985682,0.8361\n",
      "\n",
      "5,1391.060079159215,0.8377\n",
      "\n",
      "6,1415.2307629678398,0.8357\n",
      "\n",
      "7,1393.2362602110952,0.8392\n",
      "\n",
      "8,1400.529228085652,0.8371\n",
      "\n",
      "9,1389.1054652705789,0.8381\n",
      "\n",
      "Data Saved to debug.csv\n",
      "Finished Training: \n",
      "Total Time 0.082292 hours\n",
      " Average Time Per Epoch 29.63 seconds\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Bin_state_dict = torch.load('test_best_acc.pth',map_location= device)\n",
    "\n",
    "debug = resnet18_adapt()\n",
    "debug.load_state_dict(Bin_state_dict)\n",
    "debug.freeze()\n",
    "debug.add_adapter(after = 'layer3',adapter = identity_adapter())\n",
    "\n",
    "debug_trainer = adapter_Trainer(model = debug,seed = 123,name = 'debug',classes = classes,binarise= True)\n",
    "for trainer in [debug_trainer]:\n",
    "    m = trainer.model\n",
    "    m.to(trainer.device)\n",
    "    for layer in [m.fc,m.bn3,m.bn3]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = True\n",
    "        layer.train()\n",
    "    trainer.lr = 0.01\n",
    "    trainer.batch_size = 128\n",
    "    trainer.epochs =10\n",
    "    trainer.epoch_chkpts = []\n",
    "    trainer.start_epoch = 0\n",
    "    trainer.T_max = 80\n",
    "    # trainer.scheduler.T_max= trainer.T_max\n",
    "    trainer.optimizer = optim.Adam(trainer.model.parameters(), lr=trainer.lr)\n",
    "    trainer.scheduler = optim.lr_scheduler.ExponentialLR(trainer.optimizer, gamma=0.95)\n",
    "    trainer.train(trainloader,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9f9eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start_epoch : 0\n",
      "lr : 0.01\n",
      "batch_size : 128\n",
      "epochs : 10\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "epoch: 1 average loss: 0.447 Epoch Time 0.56 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "best_acc.pth saved!\n",
      "epoch: 2 average loss: 0.447 Epoch Time 1.12 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.7%\n",
      "best_acc.pth saved!\n",
      "epoch: 3 average loss: 0.444 Epoch Time 1.69 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 4 average loss: 0.448 Epoch Time 2.25 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.3%\n",
      "epoch: 5 average loss: 0.449 Epoch Time 2.81 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 6 average loss: 0.445 Epoch Time 3.37 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 7 average loss: 0.453 Epoch Time 3.93 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.5%\n",
      "epoch: 8 average loss: 0.446 Epoch Time 4.49 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 84.0%\n",
      "best_acc.pth saved!\n",
      "epoch: 9 average loss: 0.448 Epoch Time 5.06 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.6%\n",
      "epoch: 10 average loss: 0.444 Epoch Time 5.65 mins\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_best_loss.pth saved!\n",
      "c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\mini_adapt_latest.pth saved!\n",
      "Overall Accuracy : 83.8%\n",
      "0,1398.4110385291278,0.8363\n",
      "\n",
      "1,1396.523651432246,0.837\n",
      "\n",
      "2,1387.8463219068944,0.8363\n",
      "\n",
      "3,1398.9699801634997,0.8331\n",
      "\n",
      "4,1404.590050060302,0.8364\n",
      "\n",
      "5,1391.5139812212437,0.8361\n",
      "\n",
      "6,1416.2695680838078,0.8347\n",
      "\n",
      "7,1392.584654616192,0.8401\n",
      "\n",
      "8,1401.0626330338418,0.8356\n",
      "\n",
      "9,1387.0222478583455,0.8377\n",
      "\n",
      "Data Saved to mini_adapt.csv\n",
      "Finished Training: \n",
      "Total Time 0.094159 hours\n",
      " Average Time Per Epoch 33.90 seconds\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Bin_state_dict = torch.load('test_best_acc.pth',map_location= device)\n",
    "\n",
    "adapter = mini_bottleneck_adapter()\n",
    "\n",
    "mini_adapt_model = resnet18_adapt()\n",
    "mini_adapt_model.load_state_dict(Bin_state_dict)\n",
    "mini_adapt_model.freeze()\n",
    "mini_adapt_model.add_adapter(after = 'layer3',adapter = adapter)\n",
    "\n",
    "mini_adapt_trainer = adapter_Trainer(model = mini_adapt_model,seed = 123,name = 'mini_adapt',classes = classes,binarise= True)\n",
    "for trainer in [mini_adapt_trainer]:\n",
    "    m = trainer.model\n",
    "    m.to(trainer.device)\n",
    "    for layer in [m.fc,m.bn3,m.bn3]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = True\n",
    "        layer.train()\n",
    "    trainer.lr = 0.01\n",
    "    trainer.batch_size = 128\n",
    "    trainer.epochs =10\n",
    "    trainer.epoch_chkpts = []\n",
    "    trainer.start_epoch = 0\n",
    "    trainer.T_max = 80\n",
    "    # trainer.scheduler.T_max= trainer.T_max\n",
    "    trainer.optimizer = optim.Adam(trainer.model.parameters(), lr=trainer.lr)\n",
    "    trainer.scheduler = optim.lr_scheduler.ExponentialLR(trainer.optimizer, gamma=0.95)\n",
    "    trainer.train(trainloader,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0dd6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe717efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5daaeb58",
   "metadata": {},
   "source": [
    "# Adapter Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2c84ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adp_only layer1 80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3259f3sh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">firm-hill-17</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/3259f3sh\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/3259f3sh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221024_171937-3259f3sh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3259f3sh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f16a88e7a114f038ad2a208274dd17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221024_172040-uto79r8e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/uto79r8e\" target=\"_blank\">light-grass-18</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name adp_layer1_adp_only \n",
      "\n",
      "\n",
      "Run Start : 2022-10-24 17-20-40\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 64\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4347980\n",
      "Initial accuracy:\n",
      "Test Accuracy : 5.5%, Test Loss: 32.37134543497851\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 5.5%, Test Loss: 31.217803835868835\n",
      "best_acc.pth saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John Su\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 average loss: 1.960\n",
      "Test Accuracy : 56.0%, Test Loss: 1.3767718933522701\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 6.05 seconds\n",
      "epoch: 2 average loss: 1.382\n",
      "Test Accuracy : 60.1%, Test Loss: 1.2578732501715422\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 6.06 seconds\n",
      "epoch: 3 average loss: 1.337\n",
      "Test Accuracy : 60.9%, Test Loss: 1.206426814198494\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 6.10 seconds\n",
      "epoch: 4 average loss: 1.295\n",
      "Test Accuracy : 62.3%, Test Loss: 1.1919167339801788\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 6.10 seconds\n",
      "epoch: 5 average loss: 1.260\n",
      "Test Accuracy : 61.7%, Test Loss: 1.1416980437934399\n",
      "Epoch Time (Training + Test) = 6.04 seconds\n",
      "epoch: 6 average loss: 1.251\n",
      "Test Accuracy : 60.0%, Test Loss: 1.2305712662637234\n",
      "Epoch Time (Training + Test) = 6.02 seconds\n",
      "epoch: 7 average loss: 1.259\n",
      "Test Accuracy : 61.3%, Test Loss: 1.1821174323558807\n",
      "Epoch Time (Training + Test) = 6.01 seconds\n",
      "epoch: 8 average loss: 1.243\n",
      "Test Accuracy : 61.1%, Test Loss: 1.1629335712641478\n",
      "Epoch Time (Training + Test) = 6.04 seconds\n",
      "epoch: 9 average loss: 1.235\n",
      "Test Accuracy : 62.5%, Test Loss: 1.134758798405528\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 6.07 seconds\n",
      "epoch: 10 average loss: 1.240\n",
      "Test Accuracy : 62.1%, Test Loss: 1.1694358345121145\n",
      "Epoch Time (Training + Test) = 6.01 seconds\n",
      "epoch: 11 average loss: 1.222\n",
      "Test Accuracy : 61.9%, Test Loss: 1.1718231849372387\n",
      "Epoch Time (Training + Test) = 6.02 seconds\n",
      "epoch: 12 average loss: 1.230\n",
      "Test Accuracy : 61.7%, Test Loss: 1.1740288231521845\n",
      "Epoch Time (Training + Test) = 5.95 seconds\n",
      "epoch: 13 average loss: 1.218\n",
      "Test Accuracy : 62.5%, Test Loss: 1.1907210499048233\n",
      "Epoch Time (Training + Test) = 5.98 seconds\n",
      "epoch: 14 average loss: 1.220\n",
      "Test Accuracy : 61.0%, Test Loss: 1.1950853746384382\n",
      "Epoch Time (Training + Test) = 5.96 seconds\n",
      "epoch: 15 average loss: 1.212\n",
      "Test Accuracy : 61.0%, Test Loss: 1.185189737007022\n",
      "Epoch Time (Training + Test) = 6.16 seconds\n",
      "epoch: 16 average loss: 1.214\n",
      "Test Accuracy : 62.3%, Test Loss: 1.1788327936083078\n",
      "Epoch Time (Training + Test) = 6.32 seconds\n",
      "epoch: 17 average loss: 1.214\n",
      "Test Accuracy : 61.3%, Test Loss: 1.1606171410530806\n",
      "Epoch Time (Training + Test) = 6.17 seconds\n",
      "epoch: 18 average loss: 1.206\n",
      "Test Accuracy : 62.0%, Test Loss: 1.1614250466227531\n",
      "Epoch Time (Training + Test) = 6.07 seconds\n",
      "epoch: 19 average loss: 1.189\n",
      "Test Accuracy : 62.8%, Test Loss: 1.1786490958184004\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 6.21 seconds\n",
      "epoch: 20 average loss: 1.201\n",
      "Test Accuracy : 62.2%, Test Loss: 1.160730343312025\n",
      "Epoch Time (Training + Test) = 6.09 seconds\n",
      "epoch: 21 average loss: 1.193\n",
      "Test Accuracy : 61.5%, Test Loss: 1.1620791796594858\n",
      "Epoch Time (Training + Test) = 6.10 seconds\n",
      "epoch: 22 average loss: 1.202\n",
      "Test Accuracy : 62.9%, Test Loss: 1.1405563931912184\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 6.07 seconds\n",
      "epoch: 23 average loss: 1.198\n",
      "Test Accuracy : 62.9%, Test Loss: 1.1400812976062298\n",
      "Epoch Time (Training + Test) = 6.05 seconds\n",
      "epoch: 24 average loss: 1.188\n",
      "Test Accuracy : 63.1%, Test Loss: 1.1187576577067375\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 6.13 seconds\n",
      "epoch: 25 average loss: 1.183\n",
      "Test Accuracy : 63.9%, Test Loss: 1.1356878262013197\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 6.09 seconds\n",
      "epoch: 26 average loss: 1.191\n",
      "Test Accuracy : 62.8%, Test Loss: 1.1458899825811386\n",
      "Epoch Time (Training + Test) = 6.09 seconds\n",
      "epoch: 27 average loss: 1.177\n",
      "Test Accuracy : 62.8%, Test Loss: 1.1504557598382235\n",
      "Epoch Time (Training + Test) = 6.17 seconds\n",
      "epoch: 28 average loss: 1.177\n",
      "Test Accuracy : 62.6%, Test Loss: 1.14779007807374\n",
      "Epoch Time (Training + Test) = 6.05 seconds\n",
      "epoch: 29 average loss: 1.164\n",
      "Test Accuracy : 62.5%, Test Loss: 1.1489695087075233\n",
      "Epoch Time (Training + Test) = 6.12 seconds\n",
      "epoch: 30 average loss: 1.178\n",
      "Test Accuracy : 62.7%, Test Loss: 1.13573526032269\n",
      "Epoch Time (Training + Test) = 6.14 seconds\n",
      "epoch: 31 average loss: 1.172\n",
      "Test Accuracy : 63.2%, Test Loss: 1.1557179801166058\n",
      "Epoch Time (Training + Test) = 6.23 seconds\n",
      "epoch: 32 average loss: 1.171\n",
      "Test Accuracy : 61.6%, Test Loss: 1.1456810534000397\n",
      "Epoch Time (Training + Test) = 6.31 seconds\n",
      "epoch: 33 average loss: 1.159\n",
      "Test Accuracy : 62.8%, Test Loss: 1.1637308169156313\n",
      "Epoch Time (Training + Test) = 6.55 seconds\n",
      "epoch: 34 average loss: 1.180\n",
      "Test Accuracy : 63.5%, Test Loss: 1.1077264863997698\n",
      "Epoch Time (Training + Test) = 6.41 seconds\n",
      "epoch: 35 average loss: 1.160\n",
      "Test Accuracy : 61.7%, Test Loss: 1.1660478580743074\n",
      "Epoch Time (Training + Test) = 6.36 seconds\n",
      "epoch: 36 average loss: 1.169\n",
      "Test Accuracy : 62.9%, Test Loss: 1.1425634063780308\n",
      "Epoch Time (Training + Test) = 6.38 seconds\n",
      "epoch: 37 average loss: 1.166\n",
      "Test Accuracy : 62.7%, Test Loss: 1.1395890023559332\n",
      "Epoch Time (Training + Test) = 6.38 seconds\n",
      "epoch: 38 average loss: 1.182\n",
      "Test Accuracy : 62.0%, Test Loss: 1.1570953652262688\n",
      "Epoch Time (Training + Test) = 6.37 seconds\n",
      "epoch: 39 average loss: 1.167\n",
      "Test Accuracy : 64.6%, Test Loss: 1.1400655582547188\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 6.38 seconds\n",
      "epoch: 40 average loss: 1.168\n",
      "Test Accuracy : 61.8%, Test Loss: 1.1560840532183647\n",
      "Epoch Time (Training + Test) = 6.43 seconds\n",
      "epoch: 41 average loss: 1.167\n",
      "Test Accuracy : 61.8%, Test Loss: 1.1481928285211325\n",
      "Epoch Time (Training + Test) = 6.45 seconds\n",
      "epoch: 42 average loss: 1.158\n",
      "Test Accuracy : 63.2%, Test Loss: 1.111240029335022\n",
      "Epoch Time (Training + Test) = 6.36 seconds\n",
      "epoch: 43 average loss: 1.169\n",
      "Test Accuracy : 63.3%, Test Loss: 1.1162524074316025\n",
      "Epoch Time (Training + Test) = 6.40 seconds\n",
      "epoch: 44 average loss: 1.158\n",
      "Test Accuracy : 62.3%, Test Loss: 1.1458809673786163\n",
      "Epoch Time (Training + Test) = 6.35 seconds\n",
      "epoch: 45 average loss: 1.151\n",
      "Test Accuracy : 62.1%, Test Loss: 1.1441153921186924\n",
      "Epoch Time (Training + Test) = 6.44 seconds\n",
      "epoch: 46 average loss: 1.148\n",
      "Test Accuracy : 64.5%, Test Loss: 1.1049156710505486\n",
      "Epoch Time (Training + Test) = 6.21 seconds\n",
      "epoch: 47 average loss: 1.167\n",
      "Test Accuracy : 62.4%, Test Loss: 1.1517187859863043\n",
      "Epoch Time (Training + Test) = 6.09 seconds\n",
      "epoch: 48 average loss: 1.162\n",
      "Test Accuracy : 63.1%, Test Loss: 1.1453726775944233\n",
      "Epoch Time (Training + Test) = 6.18 seconds\n",
      "epoch: 49 average loss: 1.155\n",
      "Test Accuracy : 62.1%, Test Loss: 1.131897695362568\n",
      "Epoch Time (Training + Test) = 6.10 seconds\n",
      "epoch: 50 average loss: 1.162\n",
      "Test Accuracy : 62.4%, Test Loss: 1.1339614037424326\n",
      "Epoch Time (Training + Test) = 6.03 seconds\n",
      "epoch: 51 average loss: 1.155\n",
      "Test Accuracy : 63.6%, Test Loss: 1.1310419775545597\n",
      "Epoch Time (Training + Test) = 6.05 seconds\n",
      "epoch: 52 average loss: 1.164\n",
      "Test Accuracy : 63.2%, Test Loss: 1.137441910803318\n",
      "Epoch Time (Training + Test) = 6.04 seconds\n",
      "epoch: 53 average loss: 1.165\n",
      "Test Accuracy : 62.7%, Test Loss: 1.1238069161772728\n",
      "Epoch Time (Training + Test) = 6.21 seconds\n",
      "epoch: 54 average loss: 1.140\n",
      "Test Accuracy : 61.1%, Test Loss: 1.1932110451161861\n",
      "Epoch Time (Training + Test) = 6.20 seconds\n",
      "epoch: 55 average loss: 1.150\n",
      "Test Accuracy : 61.1%, Test Loss: 1.174200439825654\n",
      "Epoch Time (Training + Test) = 6.40 seconds\n",
      "epoch: 56 average loss: 1.147\n",
      "Test Accuracy : 62.9%, Test Loss: 1.1630664747208357\n",
      "Epoch Time (Training + Test) = 6.08 seconds\n",
      "epoch: 57 average loss: 1.153\n",
      "Test Accuracy : 62.5%, Test Loss: 1.1241704151034355\n",
      "Epoch Time (Training + Test) = 6.09 seconds\n",
      "epoch: 58 average loss: 1.150\n",
      "Test Accuracy : 61.9%, Test Loss: 1.1701424662023783\n",
      "Epoch Time (Training + Test) = 6.08 seconds\n",
      "epoch: 59 average loss: 1.146\n",
      "Test Accuracy : 63.4%, Test Loss: 1.129914054647088\n",
      "Epoch Time (Training + Test) = 6.09 seconds\n",
      "epoch: 60 average loss: 1.146\n",
      "Test Accuracy : 63.7%, Test Loss: 1.1303064916282892\n",
      "Epoch Time (Training + Test) = 6.08 seconds\n",
      "epoch: 61 average loss: 1.160\n",
      "Test Accuracy : 62.9%, Test Loss: 1.132786724716425\n",
      "Epoch Time (Training + Test) = 6.08 seconds\n",
      "epoch: 62 average loss: 1.141\n",
      "Test Accuracy : 62.7%, Test Loss: 1.1418841872364283\n",
      "Epoch Time (Training + Test) = 6.07 seconds\n",
      "epoch: 63 average loss: 1.152\n",
      "Test Accuracy : 64.1%, Test Loss: 1.1194476466625929\n",
      "Epoch Time (Training + Test) = 6.08 seconds\n",
      "epoch: 64 average loss: 1.153\n",
      "Test Accuracy : 62.4%, Test Loss: 1.132907249033451\n",
      "Epoch Time (Training + Test) = 6.08 seconds\n",
      "epoch: 65 average loss: 1.153\n",
      "Test Accuracy : 62.2%, Test Loss: 1.1410148292779922\n",
      "Epoch Time (Training + Test) = 6.10 seconds\n",
      "epoch: 66 average loss: 1.147\n",
      "Test Accuracy : 63.1%, Test Loss: 1.1159884613007307\n",
      "Epoch Time (Training + Test) = 6.09 seconds\n",
      "epoch: 67 average loss: 1.143\n",
      "Test Accuracy : 62.8%, Test Loss: 1.16659839078784\n",
      "Epoch Time (Training + Test) = 6.09 seconds\n",
      "epoch: 68 average loss: 1.148\n",
      "Test Accuracy : 63.4%, Test Loss: 1.1561784818768501\n",
      "Epoch Time (Training + Test) = 6.08 seconds\n",
      "epoch: 69 average loss: 1.146\n",
      "Test Accuracy : 63.0%, Test Loss: 1.169819651171565\n",
      "Epoch Time (Training + Test) = 6.08 seconds\n",
      "epoch: 70 average loss: 1.154\n",
      "Test Accuracy : 63.4%, Test Loss: 1.1338318474590778\n",
      "Epoch Time (Training + Test) = 6.09 seconds\n",
      "epoch: 71 average loss: 1.149\n",
      "Test Accuracy : 63.9%, Test Loss: 1.1121582631021738\n",
      "Epoch Time (Training + Test) = 6.09 seconds\n",
      "epoch: 72 average loss: 1.147\n",
      "Test Accuracy : 63.3%, Test Loss: 1.1313415989279747\n",
      "Epoch Time (Training + Test) = 6.08 seconds\n",
      "epoch: 73 average loss: 1.143\n",
      "Test Accuracy : 63.9%, Test Loss: 1.113809434697032\n",
      "Epoch Time (Training + Test) = 6.08 seconds\n",
      "epoch: 74 average loss: 1.133\n",
      "Test Accuracy : 64.3%, Test Loss: 1.1133211180567741\n",
      "Epoch Time (Training + Test) = 6.11 seconds\n",
      "epoch: 75 average loss: 1.131\n",
      "Test Accuracy : 63.3%, Test Loss: 1.14283518306911\n",
      "Epoch Time (Training + Test) = 6.11 seconds\n",
      "epoch: 76 average loss: 1.124\n",
      "Test Accuracy : 63.0%, Test Loss: 1.1354087814688683\n",
      "Epoch Time (Training + Test) = 6.30 seconds\n",
      "epoch: 77 average loss: 1.125\n",
      "Test Accuracy : 63.3%, Test Loss: 1.1288876049220562\n",
      "Epoch Time (Training + Test) = 6.54 seconds\n",
      "epoch: 78 average loss: 1.159\n",
      "Test Accuracy : 62.7%, Test Loss: 1.1497195065021515\n",
      "Epoch Time (Training + Test) = 6.60 seconds\n",
      "epoch: 79 average loss: 1.149\n",
      "Test Accuracy : 62.6%, Test Loss: 1.1211062781512737\n",
      "Epoch Time (Training + Test) = 6.60 seconds\n",
      "epoch: 80 average loss: 1.129\n",
      "Test Accuracy : 62.6%, Test Loss: 1.1338076032698154\n",
      "Epoch Time (Training + Test) = 6.57 seconds\n",
      "epoch: 81 average loss: 1.138\n",
      "Test Accuracy : 63.3%, Test Loss: 1.136319849640131\n",
      "Epoch Time (Training + Test) = 6.56 seconds\n",
      "epoch: 82 average loss: 1.129\n",
      "Test Accuracy : 64.1%, Test Loss: 1.1150473318994045\n",
      "Epoch Time (Training + Test) = 6.57 seconds\n",
      "epoch: 83 average loss: 1.154\n",
      "Test Accuracy : 63.5%, Test Loss: 1.1121070142835379\n",
      "Epoch Time (Training + Test) = 6.57 seconds\n",
      "epoch: 84 average loss: 1.145\n",
      "Test Accuracy : 62.5%, Test Loss: 1.1517895236611366\n",
      "Epoch Time (Training + Test) = 6.57 seconds\n",
      "epoch: 85 average loss: 1.144\n",
      "Test Accuracy : 62.3%, Test Loss: 1.1550551988184452\n",
      "Epoch Time (Training + Test) = 6.58 seconds\n",
      "epoch: 86 average loss: 1.136\n",
      "Test Accuracy : 64.4%, Test Loss: 1.1146044433116913\n",
      "Epoch Time (Training + Test) = 6.57 seconds\n",
      "epoch: 87 average loss: 1.136\n",
      "Test Accuracy : 62.5%, Test Loss: 1.151738753542304\n",
      "Epoch Time (Training + Test) = 6.59 seconds\n",
      "epoch: 88 average loss: 1.147\n",
      "Test Accuracy : 63.5%, Test Loss: 1.1051182188093662\n",
      "Epoch Time (Training + Test) = 6.58 seconds\n",
      "epoch: 89 average loss: 1.146\n",
      "Test Accuracy : 63.1%, Test Loss: 1.1226958874613047\n",
      "Epoch Time (Training + Test) = 6.57 seconds\n",
      "epoch: 90 average loss: 1.132\n",
      "Test Accuracy : 64.2%, Test Loss: 1.1039911583065987\n",
      "Epoch Time (Training + Test) = 6.60 seconds\n",
      "epoch: 91 average loss: 1.135\n",
      "Test Accuracy : 63.1%, Test Loss: 1.1454000938683748\n",
      "Epoch Time (Training + Test) = 6.59 seconds\n",
      "epoch: 92 average loss: 1.128\n",
      "Test Accuracy : 62.9%, Test Loss: 1.1325966846197844\n",
      "Epoch Time (Training + Test) = 6.56 seconds\n",
      "epoch: 93 average loss: 1.148\n",
      "Test Accuracy : 64.4%, Test Loss: 1.0983320716768503\n",
      "Epoch Time (Training + Test) = 6.57 seconds\n",
      "epoch: 94 average loss: 1.154\n",
      "Test Accuracy : 63.0%, Test Loss: 1.1035743094980717\n",
      "Epoch Time (Training + Test) = 6.53 seconds\n",
      "epoch: 95 average loss: 1.130\n",
      "Test Accuracy : 63.7%, Test Loss: 1.1356156542897224\n",
      "Epoch Time (Training + Test) = 6.29 seconds\n",
      "epoch: 96 average loss: 1.140\n",
      "Test Accuracy : 63.0%, Test Loss: 1.1450913604348898\n",
      "Epoch Time (Training + Test) = 6.19 seconds\n",
      "epoch: 97 average loss: 1.114\n",
      "Test Accuracy : 64.1%, Test Loss: 1.1552731171250343\n",
      "Epoch Time (Training + Test) = 6.24 seconds\n",
      "epoch: 98 average loss: 1.145\n",
      "Test Accuracy : 64.8%, Test Loss: 1.1149601321667433\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 6.28 seconds\n",
      "epoch: 99 average loss: 1.129\n",
      "Test Accuracy : 64.1%, Test Loss: 1.1136719603091478\n",
      "Epoch Time (Training + Test) = 6.22 seconds\n",
      "epoch: 100 average loss: 1.126\n",
      "Test Accuracy : 63.5%, Test Loss: 1.129666792228818\n",
      "Epoch Time (Training + Test) = 6.19 seconds\n",
      "Data Saved to adp_layer1_adp_only.csv\n",
      "Finished Training: \n",
      "Total Time 0.346400 hours\n",
      " Average Time Per Epoch 12.47 seconds\n",
      "full_ft layer1 80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:uto79r8e) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch time (s)</td><td>â–â–‡â–†â–†â–†â–†â–‡â–‡â–‡â–†â–‡â–†â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡</td></tr><tr><td>lr</td><td>â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–‚â–â–â–â–‚â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–„â–ƒâ–‚â–â–â–‚â–‚â–„â–…â–‡â–‡â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–‚â–â–</td></tr><tr><td>test_accuracy</td><td>â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>test_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>training_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.648</td></tr><tr><td>Current Best Acc</td><td>0.648</td></tr><tr><td>Total Time (hours)</td><td>0.3464</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>6.19315</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>test_accuracy</td><td>0.6355</td></tr><tr><td>test_loss</td><td>1.12967</td></tr><tr><td>training_loss</td><td>1.12607</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">light-grass-18</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/uto79r8e\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/uto79r8e</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221024_172040-uto79r8e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:uto79r8e). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdad0107dc3f42049fbe34ce7ccef8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221024_173118-3i1cm4vw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/3i1cm4vw\" target=\"_blank\">restful-grass-19</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name adp_layer1_full_ft \n",
      "\n",
      "\n",
      "Run Start : 2022-10-24 17-31-18\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 64\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4347980\n",
      "Initial accuracy:\n",
      "Test Accuracy : 5.5%, Test Loss: 32.37134543497851\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 5.5%, Test Loss: 31.217803835868835\n",
      "best_acc.pth saved!\n",
      "epoch: 1 average loss: 1.919\n",
      "Test Accuracy : 57.3%, Test Loss: 1.3560853190720081\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.15 seconds\n",
      "epoch: 2 average loss: 1.370\n",
      "Test Accuracy : 57.4%, Test Loss: 1.3036790266633034\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.29 seconds\n",
      "epoch: 3 average loss: 1.315\n",
      "Test Accuracy : 61.4%, Test Loss: 1.2154109198600054\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.23 seconds\n",
      "epoch: 4 average loss: 1.264\n",
      "Test Accuracy : 62.8%, Test Loss: 1.1821346580982208\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.11 seconds\n",
      "epoch: 5 average loss: 1.234\n",
      "Test Accuracy : 62.4%, Test Loss: 1.1852927524596453\n",
      "Epoch Time (Training + Test) = 9.15 seconds\n",
      "epoch: 6 average loss: 1.224\n",
      "Test Accuracy : 62.2%, Test Loss: 1.1917186118662357\n",
      "Epoch Time (Training + Test) = 9.32 seconds\n",
      "epoch: 7 average loss: 1.226\n",
      "Test Accuracy : 62.3%, Test Loss: 1.1788742057979107\n",
      "Epoch Time (Training + Test) = 9.10 seconds\n",
      "epoch: 8 average loss: 1.187\n",
      "Test Accuracy : 62.5%, Test Loss: 1.154352456331253\n",
      "Epoch Time (Training + Test) = 9.12 seconds\n",
      "epoch: 9 average loss: 1.184\n",
      "Test Accuracy : 63.3%, Test Loss: 1.1204126626253128\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.11 seconds\n",
      "epoch: 10 average loss: 1.187\n",
      "Test Accuracy : 63.0%, Test Loss: 1.1300137117505074\n",
      "Epoch Time (Training + Test) = 9.33 seconds\n",
      "epoch: 11 average loss: 1.168\n",
      "Test Accuracy : 64.6%, Test Loss: 1.119816740974784\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.12 seconds\n",
      "epoch: 12 average loss: 1.181\n",
      "Test Accuracy : 61.7%, Test Loss: 1.1998218297958374\n",
      "Epoch Time (Training + Test) = 9.12 seconds\n",
      "epoch: 13 average loss: 1.151\n",
      "Test Accuracy : 61.2%, Test Loss: 1.1705033890902996\n",
      "Epoch Time (Training + Test) = 9.44 seconds\n",
      "epoch: 14 average loss: 1.153\n",
      "Test Accuracy : 63.8%, Test Loss: 1.1273410990834236\n",
      "Epoch Time (Training + Test) = 9.34 seconds\n",
      "epoch: 15 average loss: 1.148\n",
      "Test Accuracy : 62.9%, Test Loss: 1.1455110311508179\n",
      "Epoch Time (Training + Test) = 9.43 seconds\n",
      "epoch: 16 average loss: 1.133\n",
      "Test Accuracy : 62.9%, Test Loss: 1.144417505711317\n",
      "Epoch Time (Training + Test) = 9.14 seconds\n",
      "epoch: 17 average loss: 1.151\n",
      "Test Accuracy : 63.3%, Test Loss: 1.1516198851168156\n",
      "Epoch Time (Training + Test) = 9.23 seconds\n",
      "epoch: 18 average loss: 1.143\n",
      "Test Accuracy : 62.2%, Test Loss: 1.1561156548559666\n",
      "Epoch Time (Training + Test) = 9.14 seconds\n",
      "epoch: 19 average loss: 1.138\n",
      "Test Accuracy : 63.1%, Test Loss: 1.1314155235886574\n",
      "Epoch Time (Training + Test) = 9.08 seconds\n",
      "epoch: 20 average loss: 1.141\n",
      "Test Accuracy : 62.9%, Test Loss: 1.153684239834547\n",
      "Epoch Time (Training + Test) = 9.62 seconds\n",
      "epoch: 21 average loss: 1.113\n",
      "Test Accuracy : 62.8%, Test Loss: 1.1413359679281712\n",
      "Epoch Time (Training + Test) = 9.61 seconds\n",
      "epoch: 22 average loss: 1.129\n",
      "Test Accuracy : 63.3%, Test Loss: 1.1272463221102953\n",
      "Epoch Time (Training + Test) = 9.35 seconds\n",
      "epoch: 23 average loss: 1.131\n",
      "Test Accuracy : 62.0%, Test Loss: 1.1634275149554014\n",
      "Epoch Time (Training + Test) = 9.51 seconds\n",
      "epoch: 24 average loss: 1.133\n",
      "Test Accuracy : 63.7%, Test Loss: 1.126836620271206\n",
      "Epoch Time (Training + Test) = 9.27 seconds\n",
      "epoch: 25 average loss: 1.108\n",
      "Test Accuracy : 63.7%, Test Loss: 1.1280772425234318\n",
      "Epoch Time (Training + Test) = 9.11 seconds\n",
      "epoch: 26 average loss: 1.121\n",
      "Test Accuracy : 61.3%, Test Loss: 1.1804461181163788\n",
      "Epoch Time (Training + Test) = 9.08 seconds\n",
      "epoch: 27 average loss: 1.115\n",
      "Test Accuracy : 61.0%, Test Loss: 1.2074449565261602\n",
      "Epoch Time (Training + Test) = 9.03 seconds\n",
      "epoch: 28 average loss: 1.110\n",
      "Test Accuracy : 62.5%, Test Loss: 1.1535347197204828\n",
      "Epoch Time (Training + Test) = 9.14 seconds\n",
      "epoch: 29 average loss: 1.111\n",
      "Test Accuracy : 63.9%, Test Loss: 1.1409078780561686\n",
      "Epoch Time (Training + Test) = 9.32 seconds\n",
      "epoch: 30 average loss: 1.122\n",
      "Test Accuracy : 64.1%, Test Loss: 1.1349417231976986\n",
      "Epoch Time (Training + Test) = 9.08 seconds\n",
      "epoch: 31 average loss: 1.113\n",
      "Test Accuracy : 63.9%, Test Loss: 1.1316216941922903\n",
      "Epoch Time (Training + Test) = 9.26 seconds\n",
      "epoch: 32 average loss: 1.113\n",
      "Test Accuracy : 62.9%, Test Loss: 1.1291131172329187\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 33 average loss: 1.115\n",
      "Test Accuracy : 63.5%, Test Loss: 1.1362462136894464\n",
      "Epoch Time (Training + Test) = 9.11 seconds\n",
      "epoch: 34 average loss: 1.134\n",
      "Test Accuracy : 62.8%, Test Loss: 1.145998453721404\n",
      "Epoch Time (Training + Test) = 9.37 seconds\n",
      "epoch: 35 average loss: 1.103\n",
      "Test Accuracy : 63.7%, Test Loss: 1.1337268389761448\n",
      "Epoch Time (Training + Test) = 9.31 seconds\n",
      "epoch: 36 average loss: 1.108\n",
      "Test Accuracy : 62.2%, Test Loss: 1.1504455357789993\n",
      "Epoch Time (Training + Test) = 9.19 seconds\n",
      "epoch: 37 average loss: 1.111\n",
      "Test Accuracy : 62.5%, Test Loss: 1.1650846507400274\n",
      "Epoch Time (Training + Test) = 9.52 seconds\n",
      "epoch: 38 average loss: 1.104\n",
      "Test Accuracy : 61.1%, Test Loss: 1.1590002663433552\n",
      "Epoch Time (Training + Test) = 9.33 seconds\n",
      "epoch: 39 average loss: 1.108\n",
      "Test Accuracy : 61.0%, Test Loss: 1.1672935113310814\n",
      "Epoch Time (Training + Test) = 9.40 seconds\n",
      "epoch: 40 average loss: 1.118\n",
      "Test Accuracy : 63.4%, Test Loss: 1.1381919384002686\n",
      "Epoch Time (Training + Test) = 9.31 seconds\n",
      "epoch: 41 average loss: 1.123\n",
      "Test Accuracy : 63.2%, Test Loss: 1.1351720411330462\n",
      "Epoch Time (Training + Test) = 9.23 seconds\n",
      "epoch: 42 average loss: 1.104\n",
      "Test Accuracy : 61.6%, Test Loss: 1.1992368642240763\n",
      "Epoch Time (Training + Test) = 9.43 seconds\n",
      "epoch: 43 average loss: 1.115\n",
      "Test Accuracy : 62.3%, Test Loss: 1.1750925909727812\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 44 average loss: 1.125\n",
      "Test Accuracy : 61.3%, Test Loss: 1.1997218299657106\n",
      "Epoch Time (Training + Test) = 9.25 seconds\n",
      "epoch: 45 average loss: 1.113\n",
      "Test Accuracy : 59.0%, Test Loss: 1.2801196873188019\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 46 average loss: 1.113\n",
      "Test Accuracy : 63.6%, Test Loss: 1.1407850589603186\n",
      "Epoch Time (Training + Test) = 9.20 seconds\n",
      "epoch: 47 average loss: 1.114\n",
      "Test Accuracy : 62.3%, Test Loss: 1.143650220707059\n",
      "Epoch Time (Training + Test) = 9.09 seconds\n",
      "epoch: 48 average loss: 1.116\n",
      "Test Accuracy : 62.7%, Test Loss: 1.1432367712259293\n",
      "Epoch Time (Training + Test) = 8.90 seconds\n",
      "epoch: 49 average loss: 1.108\n",
      "Test Accuracy : 63.0%, Test Loss: 1.1499832887202501\n",
      "Epoch Time (Training + Test) = 8.74 seconds\n",
      "epoch: 50 average loss: 1.119\n",
      "Test Accuracy : 62.3%, Test Loss: 1.15483264811337\n",
      "Epoch Time (Training + Test) = 8.89 seconds\n",
      "epoch: 51 average loss: 1.108\n",
      "Test Accuracy : 64.5%, Test Loss: 1.1059574000537395\n",
      "Epoch Time (Training + Test) = 9.09 seconds\n",
      "epoch: 52 average loss: 1.115\n",
      "Test Accuracy : 61.7%, Test Loss: 1.2028623949736357\n",
      "Epoch Time (Training + Test) = 9.04 seconds\n",
      "epoch: 53 average loss: 1.112\n",
      "Test Accuracy : 60.8%, Test Loss: 1.1821348164230585\n",
      "Epoch Time (Training + Test) = 9.17 seconds\n",
      "epoch: 54 average loss: 1.119\n",
      "Test Accuracy : 61.4%, Test Loss: 1.201749699190259\n",
      "Epoch Time (Training + Test) = 8.87 seconds\n",
      "epoch: 55 average loss: 1.102\n",
      "Test Accuracy : 62.0%, Test Loss: 1.1851142942905426\n",
      "Epoch Time (Training + Test) = 9.26 seconds\n",
      "epoch: 56 average loss: 1.125\n",
      "Test Accuracy : 63.7%, Test Loss: 1.1493807975202799\n",
      "Epoch Time (Training + Test) = 8.97 seconds\n",
      "epoch: 57 average loss: 1.107\n",
      "Test Accuracy : 63.3%, Test Loss: 1.1391551122069359\n",
      "Epoch Time (Training + Test) = 9.16 seconds\n",
      "epoch: 58 average loss: 1.108\n",
      "Test Accuracy : 61.0%, Test Loss: 1.2227379102259874\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 59 average loss: 1.109\n",
      "Test Accuracy : 61.6%, Test Loss: 1.1736201383173466\n",
      "Epoch Time (Training + Test) = 9.40 seconds\n",
      "epoch: 60 average loss: 1.127\n",
      "Test Accuracy : 58.1%, Test Loss: 1.2992778327316046\n",
      "Epoch Time (Training + Test) = 9.16 seconds\n",
      "epoch: 61 average loss: 1.111\n",
      "Test Accuracy : 63.1%, Test Loss: 1.1486405972391367\n",
      "Epoch Time (Training + Test) = 9.42 seconds\n",
      "epoch: 62 average loss: 1.099\n",
      "Test Accuracy : 61.3%, Test Loss: 1.1733701974153519\n",
      "Epoch Time (Training + Test) = 9.77 seconds\n",
      "epoch: 63 average loss: 1.108\n",
      "Test Accuracy : 62.9%, Test Loss: 1.1494985483586788\n",
      "Epoch Time (Training + Test) = 9.43 seconds\n",
      "epoch: 64 average loss: 1.112\n",
      "Test Accuracy : 61.9%, Test Loss: 1.1789722982794046\n",
      "Epoch Time (Training + Test) = 9.35 seconds\n",
      "epoch: 65 average loss: 1.124\n",
      "Test Accuracy : 62.5%, Test Loss: 1.17854867503047\n",
      "Epoch Time (Training + Test) = 9.32 seconds\n",
      "epoch: 66 average loss: 1.126\n",
      "Test Accuracy : 59.8%, Test Loss: 1.2537889741361141\n",
      "Epoch Time (Training + Test) = 9.47 seconds\n",
      "epoch: 67 average loss: 1.117\n",
      "Test Accuracy : 59.9%, Test Loss: 1.2578486893326044\n",
      "Epoch Time (Training + Test) = 9.41 seconds\n",
      "epoch: 68 average loss: 1.123\n",
      "Test Accuracy : 63.1%, Test Loss: 1.1717537604272366\n",
      "Epoch Time (Training + Test) = 9.38 seconds\n",
      "epoch: 69 average loss: 1.128\n",
      "Test Accuracy : 61.6%, Test Loss: 1.1726138424128294\n",
      "Epoch Time (Training + Test) = 9.44 seconds\n",
      "epoch: 70 average loss: 1.113\n",
      "Test Accuracy : 61.9%, Test Loss: 1.2064591608941555\n",
      "Epoch Time (Training + Test) = 9.35 seconds\n",
      "epoch: 71 average loss: 1.120\n",
      "Test Accuracy : 60.8%, Test Loss: 1.19227241165936\n",
      "Epoch Time (Training + Test) = 9.37 seconds\n",
      "epoch: 72 average loss: 1.124\n",
      "Test Accuracy : 61.7%, Test Loss: 1.1735840942710638\n",
      "Epoch Time (Training + Test) = 9.37 seconds\n",
      "epoch: 73 average loss: 1.139\n",
      "Test Accuracy : 60.0%, Test Loss: 1.2444705963134766\n",
      "Epoch Time (Training + Test) = 9.36 seconds\n",
      "epoch: 74 average loss: 1.119\n",
      "Test Accuracy : 60.9%, Test Loss: 1.2568485289812088\n",
      "Epoch Time (Training + Test) = 9.39 seconds\n",
      "epoch: 75 average loss: 1.104\n",
      "Test Accuracy : 62.7%, Test Loss: 1.1923534236848354\n",
      "Epoch Time (Training + Test) = 9.44 seconds\n",
      "epoch: 76 average loss: 1.120\n",
      "Test Accuracy : 64.6%, Test Loss: 1.1254419293254614\n",
      "Epoch Time (Training + Test) = 9.35 seconds\n",
      "epoch: 77 average loss: 1.118\n",
      "Test Accuracy : 61.0%, Test Loss: 1.2066063042730093\n",
      "Epoch Time (Training + Test) = 9.38 seconds\n",
      "epoch: 78 average loss: 1.115\n",
      "Test Accuracy : 63.5%, Test Loss: 1.1357182413339615\n",
      "Epoch Time (Training + Test) = 9.39 seconds\n",
      "epoch: 79 average loss: 1.112\n",
      "Test Accuracy : 63.2%, Test Loss: 1.1259047631174326\n",
      "Epoch Time (Training + Test) = 9.46 seconds\n",
      "epoch: 80 average loss: 1.104\n",
      "Test Accuracy : 63.0%, Test Loss: 1.1479577478021383\n",
      "Epoch Time (Training + Test) = 9.41 seconds\n",
      "epoch: 81 average loss: 1.114\n",
      "Test Accuracy : 61.9%, Test Loss: 1.2040570564568043\n",
      "Epoch Time (Training + Test) = 9.38 seconds\n",
      "epoch: 82 average loss: 1.110\n",
      "Test Accuracy : 61.7%, Test Loss: 1.2170730996876955\n",
      "Epoch Time (Training + Test) = 9.37 seconds\n",
      "epoch: 83 average loss: 1.118\n",
      "Test Accuracy : 60.8%, Test Loss: 1.2247935719788074\n",
      "Epoch Time (Training + Test) = 9.41 seconds\n",
      "epoch: 84 average loss: 1.120\n",
      "Test Accuracy : 61.2%, Test Loss: 1.170736650004983\n",
      "Epoch Time (Training + Test) = 9.41 seconds\n",
      "epoch: 85 average loss: 1.109\n",
      "Test Accuracy : 61.3%, Test Loss: 1.1865637972950935\n",
      "Epoch Time (Training + Test) = 9.41 seconds\n",
      "epoch: 86 average loss: 1.110\n",
      "Test Accuracy : 61.9%, Test Loss: 1.1516122836619616\n",
      "Epoch Time (Training + Test) = 9.43 seconds\n",
      "epoch: 87 average loss: 1.112\n",
      "Test Accuracy : 61.8%, Test Loss: 1.2032196838408709\n",
      "Epoch Time (Training + Test) = 9.46 seconds\n",
      "epoch: 88 average loss: 1.119\n",
      "Test Accuracy : 61.5%, Test Loss: 1.2276031915098429\n",
      "Epoch Time (Training + Test) = 9.46 seconds\n",
      "epoch: 89 average loss: 1.117\n",
      "Test Accuracy : 59.3%, Test Loss: 1.2735439147800207\n",
      "Epoch Time (Training + Test) = 9.32 seconds\n",
      "epoch: 90 average loss: 1.122\n",
      "Test Accuracy : 58.9%, Test Loss: 1.287984736263752\n",
      "Epoch Time (Training + Test) = 9.43 seconds\n",
      "epoch: 91 average loss: 1.104\n",
      "Test Accuracy : 62.5%, Test Loss: 1.1791241969913244\n",
      "Epoch Time (Training + Test) = 9.46 seconds\n",
      "epoch: 92 average loss: 1.107\n",
      "Test Accuracy : 61.5%, Test Loss: 1.2142326813191175\n",
      "Epoch Time (Training + Test) = 9.46 seconds\n",
      "epoch: 93 average loss: 1.112\n",
      "Test Accuracy : 61.4%, Test Loss: 1.2108088042587042\n",
      "Epoch Time (Training + Test) = 9.45 seconds\n",
      "epoch: 94 average loss: 1.127\n",
      "Test Accuracy : 61.4%, Test Loss: 1.2232964355498552\n",
      "Epoch Time (Training + Test) = 9.46 seconds\n",
      "epoch: 95 average loss: 1.109\n",
      "Test Accuracy : 61.0%, Test Loss: 1.1428579166531563\n",
      "Epoch Time (Training + Test) = 9.41 seconds\n",
      "epoch: 96 average loss: 1.108\n",
      "Test Accuracy : 63.4%, Test Loss: 1.149312200024724\n",
      "Epoch Time (Training + Test) = 9.38 seconds\n",
      "epoch: 97 average loss: 1.120\n",
      "Test Accuracy : 61.0%, Test Loss: 1.2497687097638845\n",
      "Epoch Time (Training + Test) = 9.40 seconds\n",
      "epoch: 98 average loss: 1.131\n",
      "Test Accuracy : 59.2%, Test Loss: 1.2598665859550238\n",
      "Epoch Time (Training + Test) = 9.47 seconds\n",
      "epoch: 99 average loss: 1.120\n",
      "Test Accuracy : 63.3%, Test Loss: 1.1424420475959778\n",
      "Epoch Time (Training + Test) = 9.52 seconds\n",
      "epoch: 100 average loss: 1.114\n",
      "Test Accuracy : 62.9%, Test Loss: 1.193633621558547\n",
      "Epoch Time (Training + Test) = 9.48 seconds\n",
      "Data Saved to adp_layer1_full_ft.csv\n",
      "Finished Training: \n",
      "Total Time 0.516387 hours\n",
      " Average Time Per Epoch 18.59 seconds\n",
      "adp_only layer2 160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3i1cm4vw) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch time (s)</td><td>â–â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>lr</td><td>â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–‚â–â–â–â–‚â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–„â–ƒâ–‚â–â–â–‚â–‚â–„â–…â–‡â–‡â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–‚â–â–</td></tr><tr><td>test_accuracy</td><td>â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>test_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>training_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.6465</td></tr><tr><td>Current Best Acc</td><td>0.6465</td></tr><tr><td>Total Time (hours)</td><td>0.51639</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>9.47637</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>test_accuracy</td><td>0.6295</td></tr><tr><td>test_loss</td><td>1.19363</td></tr><tr><td>training_loss</td><td>1.11371</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">restful-grass-19</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/3i1cm4vw\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/3i1cm4vw</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221024_173118-3i1cm4vw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3i1cm4vw). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44891ee9fe845e0958b13ed35877701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221024_174707-2m1y6nnh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/2m1y6nnh\" target=\"_blank\">sleek-dust-20</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name adp_layer2_adp_only \n",
      "\n",
      "\n",
      "Run Start : 2022-10-24 17-47-07\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 64\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4367500\n",
      "Initial accuracy:\n",
      "Test Accuracy : 6.0%, Test Loss: 30.396828305189775\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 6.2%, Test Loss: 29.410422146320343\n",
      "best_acc.pth saved!\n",
      "epoch: 1 average loss: 1.964\n",
      "Test Accuracy : 53.1%, Test Loss: 1.466644898056984\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.81 seconds\n",
      "epoch: 2 average loss: 1.449\n",
      "Test Accuracy : 57.5%, Test Loss: 1.3200827836990356\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.83 seconds\n",
      "epoch: 3 average loss: 1.324\n",
      "Test Accuracy : 60.2%, Test Loss: 1.2232899777591228\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.83 seconds\n",
      "epoch: 4 average loss: 1.255\n",
      "Test Accuracy : 62.1%, Test Loss: 1.1843558326363564\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.81 seconds\n",
      "epoch: 5 average loss: 1.205\n",
      "Test Accuracy : 63.8%, Test Loss: 1.1427107471972704\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.81 seconds\n",
      "epoch: 6 average loss: 1.180\n",
      "Test Accuracy : 63.0%, Test Loss: 1.1494932044297457\n",
      "Epoch Time (Training + Test) = 4.80 seconds\n",
      "epoch: 7 average loss: 1.176\n",
      "Test Accuracy : 63.2%, Test Loss: 1.14714259468019\n",
      "Epoch Time (Training + Test) = 4.81 seconds\n",
      "epoch: 8 average loss: 1.151\n",
      "Test Accuracy : 63.7%, Test Loss: 1.1120618991553783\n",
      "Epoch Time (Training + Test) = 4.81 seconds\n",
      "epoch: 9 average loss: 1.142\n",
      "Test Accuracy : 63.7%, Test Loss: 1.1103031858801842\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 10 average loss: 1.129\n",
      "Test Accuracy : 63.4%, Test Loss: 1.1416408512741327\n",
      "Epoch Time (Training + Test) = 4.80 seconds\n",
      "epoch: 11 average loss: 1.122\n",
      "Test Accuracy : 65.0%, Test Loss: 1.064806506037712\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.81 seconds\n",
      "epoch: 12 average loss: 1.098\n",
      "Test Accuracy : 64.8%, Test Loss: 1.0928302649408579\n",
      "Epoch Time (Training + Test) = 4.82 seconds\n",
      "epoch: 13 average loss: 1.089\n",
      "Test Accuracy : 64.7%, Test Loss: 1.0829048566520214\n",
      "Epoch Time (Training + Test) = 4.80 seconds\n",
      "epoch: 14 average loss: 1.081\n",
      "Test Accuracy : 65.5%, Test Loss: 1.0686936788260937\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.82 seconds\n",
      "epoch: 15 average loss: 1.078\n",
      "Test Accuracy : 64.6%, Test Loss: 1.0873613078147173\n",
      "Epoch Time (Training + Test) = 4.80 seconds\n",
      "epoch: 16 average loss: 1.081\n",
      "Test Accuracy : 65.0%, Test Loss: 1.092307997867465\n",
      "Epoch Time (Training + Test) = 4.76 seconds\n",
      "epoch: 17 average loss: 1.076\n",
      "Test Accuracy : 64.8%, Test Loss: 1.1162329893559217\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 18 average loss: 1.066\n",
      "Test Accuracy : 62.9%, Test Loss: 1.1370212156325579\n",
      "Epoch Time (Training + Test) = 4.80 seconds\n",
      "epoch: 19 average loss: 1.052\n",
      "Test Accuracy : 64.2%, Test Loss: 1.0816532904282212\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 20 average loss: 1.061\n",
      "Test Accuracy : 65.0%, Test Loss: 1.0903789792209864\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 21 average loss: 1.045\n",
      "Test Accuracy : 66.0%, Test Loss: 1.076036810874939\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.82 seconds\n",
      "epoch: 22 average loss: 1.042\n",
      "Test Accuracy : 65.3%, Test Loss: 1.0842307657003403\n",
      "Epoch Time (Training + Test) = 4.79 seconds\n",
      "epoch: 23 average loss: 1.044\n",
      "Test Accuracy : 66.9%, Test Loss: 1.0899739917367697\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.79 seconds\n",
      "epoch: 24 average loss: 1.051\n",
      "Test Accuracy : 67.1%, Test Loss: 1.0377461984753609\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 25 average loss: 1.035\n",
      "Test Accuracy : 65.9%, Test Loss: 1.0747304428368807\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 26 average loss: 1.032\n",
      "Test Accuracy : 66.1%, Test Loss: 1.0863790847361088\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 27 average loss: 1.029\n",
      "Test Accuracy : 66.0%, Test Loss: 1.0505975056439638\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 28 average loss: 1.016\n",
      "Test Accuracy : 63.8%, Test Loss: 1.083431364968419\n",
      "Epoch Time (Training + Test) = 4.79 seconds\n",
      "epoch: 29 average loss: 0.995\n",
      "Test Accuracy : 66.8%, Test Loss: 1.0567044485360384\n",
      "Epoch Time (Training + Test) = 4.80 seconds\n",
      "epoch: 30 average loss: 1.013\n",
      "Test Accuracy : 67.5%, Test Loss: 1.0124899987131357\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 31 average loss: 1.003\n",
      "Test Accuracy : 66.3%, Test Loss: 1.046188347041607\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 32 average loss: 1.009\n",
      "Test Accuracy : 68.6%, Test Loss: 1.0078675784170628\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.80 seconds\n",
      "epoch: 33 average loss: 0.997\n",
      "Test Accuracy : 66.3%, Test Loss: 1.0629366766661406\n",
      "Epoch Time (Training + Test) = 4.76 seconds\n",
      "epoch: 34 average loss: 1.008\n",
      "Test Accuracy : 65.8%, Test Loss: 1.0626249443739653\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 35 average loss: 0.992\n",
      "Test Accuracy : 69.1%, Test Loss: 1.019830284640193\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.83 seconds\n",
      "epoch: 36 average loss: 0.987\n",
      "Test Accuracy : 66.2%, Test Loss: 1.056697055697441\n",
      "Epoch Time (Training + Test) = 4.81 seconds\n",
      "epoch: 37 average loss: 0.986\n",
      "Test Accuracy : 65.3%, Test Loss: 1.0732058268040419\n",
      "Epoch Time (Training + Test) = 4.79 seconds\n",
      "epoch: 38 average loss: 0.970\n",
      "Test Accuracy : 65.6%, Test Loss: 1.0868612956255674\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 39 average loss: 0.983\n",
      "Test Accuracy : 65.5%, Test Loss: 1.066014640033245\n",
      "Epoch Time (Training + Test) = 4.74 seconds\n",
      "epoch: 40 average loss: 0.974\n",
      "Test Accuracy : 67.1%, Test Loss: 1.0407799817621708\n",
      "Epoch Time (Training + Test) = 4.76 seconds\n",
      "epoch: 41 average loss: 0.986\n",
      "Test Accuracy : 67.7%, Test Loss: 1.0198266711086035\n",
      "Epoch Time (Training + Test) = 4.74 seconds\n",
      "epoch: 42 average loss: 0.976\n",
      "Test Accuracy : 67.1%, Test Loss: 1.0619772654026747\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 43 average loss: 0.984\n",
      "Test Accuracy : 66.0%, Test Loss: 1.0579858031123877\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 44 average loss: 0.975\n",
      "Test Accuracy : 66.0%, Test Loss: 1.0570619981735945\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 45 average loss: 0.972\n",
      "Test Accuracy : 67.9%, Test Loss: 1.0359208658337593\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 46 average loss: 0.967\n",
      "Test Accuracy : 67.2%, Test Loss: 1.0352395735681057\n",
      "Epoch Time (Training + Test) = 4.79 seconds\n",
      "epoch: 47 average loss: 0.971\n",
      "Test Accuracy : 66.4%, Test Loss: 1.070016896352172\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 48 average loss: 0.946\n",
      "Test Accuracy : 64.5%, Test Loss: 1.1097009237855673\n",
      "Epoch Time (Training + Test) = 4.81 seconds\n",
      "epoch: 49 average loss: 0.957\n",
      "Test Accuracy : 67.3%, Test Loss: 1.0618986897170544\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 50 average loss: 0.976\n",
      "Test Accuracy : 67.8%, Test Loss: 1.06104576587677\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 51 average loss: 0.955\n",
      "Test Accuracy : 66.6%, Test Loss: 1.060968765988946\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 52 average loss: 0.964\n",
      "Test Accuracy : 66.4%, Test Loss: 1.0696243979036808\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 53 average loss: 0.970\n",
      "Test Accuracy : 65.5%, Test Loss: 1.0666071455925703\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 54 average loss: 0.949\n",
      "Test Accuracy : 65.8%, Test Loss: 1.0547538921236992\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 55 average loss: 0.949\n",
      "Test Accuracy : 65.8%, Test Loss: 1.0798951238393784\n",
      "Epoch Time (Training + Test) = 4.76 seconds\n",
      "epoch: 56 average loss: 0.948\n",
      "Test Accuracy : 68.2%, Test Loss: 1.0325832143425941\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 57 average loss: 0.948\n",
      "Test Accuracy : 66.2%, Test Loss: 1.0504885483533144\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 58 average loss: 0.948\n",
      "Test Accuracy : 67.2%, Test Loss: 1.0429238881915808\n",
      "Epoch Time (Training + Test) = 4.76 seconds\n",
      "epoch: 59 average loss: 0.935\n",
      "Test Accuracy : 65.9%, Test Loss: 1.0606921818107367\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 60 average loss: 0.945\n",
      "Test Accuracy : 66.8%, Test Loss: 1.0318839885294437\n",
      "Epoch Time (Training + Test) = 4.74 seconds\n",
      "epoch: 61 average loss: 0.952\n",
      "Test Accuracy : 67.5%, Test Loss: 1.0195783469825983\n",
      "Epoch Time (Training + Test) = 4.76 seconds\n",
      "epoch: 62 average loss: 0.943\n",
      "Test Accuracy : 66.4%, Test Loss: 1.0556088890880346\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 63 average loss: 0.938\n",
      "Test Accuracy : 66.6%, Test Loss: 1.047036550939083\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 64 average loss: 0.926\n",
      "Test Accuracy : 67.6%, Test Loss: 1.0241751708090305\n",
      "Epoch Time (Training + Test) = 4.81 seconds\n",
      "epoch: 65 average loss: 0.946\n",
      "Test Accuracy : 66.1%, Test Loss: 1.047588374465704\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 66 average loss: 0.929\n",
      "Test Accuracy : 67.0%, Test Loss: 1.0192860085517168\n",
      "Epoch Time (Training + Test) = 4.76 seconds\n",
      "epoch: 67 average loss: 0.933\n",
      "Test Accuracy : 65.8%, Test Loss: 1.092508053407073\n",
      "Epoch Time (Training + Test) = 4.79 seconds\n",
      "epoch: 68 average loss: 0.929\n",
      "Test Accuracy : 66.1%, Test Loss: 1.060032805427909\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 69 average loss: 0.940\n",
      "Test Accuracy : 67.3%, Test Loss: 1.046355701982975\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 70 average loss: 0.918\n",
      "Test Accuracy : 66.5%, Test Loss: 1.051204226911068\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 71 average loss: 0.922\n",
      "Test Accuracy : 66.4%, Test Loss: 1.0498147811740637\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 72 average loss: 0.921\n",
      "Test Accuracy : 66.2%, Test Loss: 1.084621213376522\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 73 average loss: 0.936\n",
      "Test Accuracy : 67.7%, Test Loss: 1.05566830560565\n",
      "Epoch Time (Training + Test) = 4.73 seconds\n",
      "epoch: 74 average loss: 0.928\n",
      "Test Accuracy : 66.3%, Test Loss: 1.0682671982795\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 75 average loss: 0.923\n",
      "Test Accuracy : 67.6%, Test Loss: 1.0455526039004326\n",
      "Epoch Time (Training + Test) = 4.76 seconds\n",
      "epoch: 76 average loss: 0.920\n",
      "Test Accuracy : 66.4%, Test Loss: 1.054544847458601\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 77 average loss: 0.922\n",
      "Test Accuracy : 67.1%, Test Loss: 1.061981212347746\n",
      "Epoch Time (Training + Test) = 4.76 seconds\n",
      "epoch: 78 average loss: 0.918\n",
      "Test Accuracy : 67.2%, Test Loss: 1.0177924428135157\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 79 average loss: 0.916\n",
      "Test Accuracy : 66.8%, Test Loss: 1.038148682564497\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 80 average loss: 0.921\n",
      "Test Accuracy : 67.2%, Test Loss: 1.0250024609267712\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 81 average loss: 0.920\n",
      "Test Accuracy : 66.5%, Test Loss: 1.0842146649956703\n",
      "Epoch Time (Training + Test) = 4.74 seconds\n",
      "epoch: 82 average loss: 0.904\n",
      "Test Accuracy : 67.7%, Test Loss: 1.0456060152500868\n",
      "Epoch Time (Training + Test) = 4.79 seconds\n",
      "epoch: 83 average loss: 0.912\n",
      "Test Accuracy : 67.3%, Test Loss: 1.0426952261477709\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 84 average loss: 0.913\n",
      "Test Accuracy : 67.0%, Test Loss: 1.0349289197474718\n",
      "Epoch Time (Training + Test) = 4.74 seconds\n",
      "epoch: 85 average loss: 0.909\n",
      "Test Accuracy : 66.8%, Test Loss: 1.055177815258503\n",
      "Epoch Time (Training + Test) = 4.76 seconds\n",
      "epoch: 86 average loss: 0.902\n",
      "Test Accuracy : 66.2%, Test Loss: 1.0915422458201647\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 87 average loss: 0.900\n",
      "Test Accuracy : 67.6%, Test Loss: 1.0482840966433287\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 88 average loss: 0.900\n",
      "Test Accuracy : 65.6%, Test Loss: 1.061772981658578\n",
      "Epoch Time (Training + Test) = 4.79 seconds\n",
      "epoch: 89 average loss: 0.903\n",
      "Test Accuracy : 67.0%, Test Loss: 1.0750940144062042\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 90 average loss: 0.916\n",
      "Test Accuracy : 66.0%, Test Loss: 1.072963709011674\n",
      "Epoch Time (Training + Test) = 4.76 seconds\n",
      "epoch: 91 average loss: 0.901\n",
      "Test Accuracy : 66.7%, Test Loss: 1.033557130023837\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 92 average loss: 0.899\n",
      "Test Accuracy : 66.7%, Test Loss: 1.0611606566235423\n",
      "Epoch Time (Training + Test) = 4.77 seconds\n",
      "epoch: 93 average loss: 0.880\n",
      "Test Accuracy : 66.5%, Test Loss: 1.059608243405819\n",
      "Epoch Time (Training + Test) = 4.78 seconds\n",
      "epoch: 94 average loss: 0.919\n",
      "Test Accuracy : 67.4%, Test Loss: 1.0044147735461593\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 95 average loss: 0.899\n",
      "Test Accuracy : 67.0%, Test Loss: 1.0085268896073103\n",
      "Epoch Time (Training + Test) = 4.74 seconds\n",
      "epoch: 96 average loss: 0.905\n",
      "Test Accuracy : 67.3%, Test Loss: 1.0588361099362373\n",
      "Epoch Time (Training + Test) = 4.75 seconds\n",
      "epoch: 97 average loss: 0.887\n",
      "Test Accuracy : 65.9%, Test Loss: 1.0846298672258854\n",
      "Epoch Time (Training + Test) = 4.74 seconds\n",
      "epoch: 98 average loss: 0.919\n",
      "Test Accuracy : 68.2%, Test Loss: 1.021412381902337\n",
      "Epoch Time (Training + Test) = 4.74 seconds\n",
      "epoch: 99 average loss: 0.896\n",
      "Test Accuracy : 68.2%, Test Loss: 1.0238120798021555\n",
      "Epoch Time (Training + Test) = 4.73 seconds\n",
      "epoch: 100 average loss: 0.898\n",
      "Test Accuracy : 65.8%, Test Loss: 1.0648948717862368\n",
      "Epoch Time (Training + Test) = 4.74 seconds\n",
      "Data Saved to adp_layer2_adp_only.csv\n",
      "Finished Training: \n",
      "Total Time 0.265213 hours\n",
      " Average Time Per Epoch 9.55 seconds\n",
      "full_ft layer2 160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2m1y6nnh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch time (s)</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡</td></tr><tr><td>lr</td><td>â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–‚â–â–â–â–‚â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–„â–ƒâ–‚â–â–â–‚â–‚â–„â–…â–‡â–‡â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–‚â–â–</td></tr><tr><td>test_accuracy</td><td>â–â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>test_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>training_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.691</td></tr><tr><td>Current Best Acc</td><td>0.691</td></tr><tr><td>Total Time (hours)</td><td>0.26521</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>4.73929</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>test_accuracy</td><td>0.6575</td></tr><tr><td>test_loss</td><td>1.06489</td></tr><tr><td>training_loss</td><td>0.89759</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sleek-dust-20</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/2m1y6nnh\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/2m1y6nnh</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221024_174707-2m1y6nnh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2m1y6nnh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f500b0e58844ce6bfb57beeb86fd040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221024_175523-3mcpnplt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/3mcpnplt\" target=\"_blank\">glamorous-salad-21</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name adp_layer2_full_ft \n",
      "\n",
      "\n",
      "Run Start : 2022-10-24 17-55-23\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 64\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4367500\n",
      "Initial accuracy:\n",
      "Test Accuracy : 6.0%, Test Loss: 30.396828305189775\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 6.2%, Test Loss: 29.410422146320343\n",
      "best_acc.pth saved!\n",
      "epoch: 1 average loss: 1.944\n",
      "Test Accuracy : 50.8%, Test Loss: 1.5309335365891457\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.15 seconds\n",
      "epoch: 2 average loss: 1.438\n",
      "Test Accuracy : 56.2%, Test Loss: 1.3122505135834217\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.14 seconds\n",
      "epoch: 3 average loss: 1.315\n",
      "Test Accuracy : 59.5%, Test Loss: 1.2340384647250175\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.11 seconds\n",
      "epoch: 4 average loss: 1.248\n",
      "Test Accuracy : 62.6%, Test Loss: 1.1912023518234491\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.18 seconds\n",
      "epoch: 5 average loss: 1.202\n",
      "Test Accuracy : 64.0%, Test Loss: 1.1252236030995846\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 6 average loss: 1.161\n",
      "Test Accuracy : 62.8%, Test Loss: 1.1599712762981653\n",
      "Epoch Time (Training + Test) = 9.23 seconds\n",
      "epoch: 7 average loss: 1.156\n",
      "Test Accuracy : 63.7%, Test Loss: 1.1108357980847359\n",
      "Epoch Time (Training + Test) = 9.20 seconds\n",
      "epoch: 8 average loss: 1.128\n",
      "Test Accuracy : 64.4%, Test Loss: 1.109866563230753\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.20 seconds\n",
      "epoch: 9 average loss: 1.107\n",
      "Test Accuracy : 64.5%, Test Loss: 1.0939866472035646\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.11 seconds\n",
      "epoch: 10 average loss: 1.091\n",
      "Test Accuracy : 64.6%, Test Loss: 1.1176731660962105\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 11 average loss: 1.092\n",
      "Test Accuracy : 66.1%, Test Loss: 1.0398364439606667\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.19 seconds\n",
      "epoch: 12 average loss: 1.068\n",
      "Test Accuracy : 63.7%, Test Loss: 1.1209249719977379\n",
      "Epoch Time (Training + Test) = 9.36 seconds\n",
      "epoch: 13 average loss: 1.054\n",
      "Test Accuracy : 63.7%, Test Loss: 1.1208578329533339\n",
      "Epoch Time (Training + Test) = 9.38 seconds\n",
      "epoch: 14 average loss: 1.054\n",
      "Test Accuracy : 64.0%, Test Loss: 1.0992885120213032\n",
      "Epoch Time (Training + Test) = 9.15 seconds\n",
      "epoch: 15 average loss: 1.042\n",
      "Test Accuracy : 65.8%, Test Loss: 1.0725262109190226\n",
      "Epoch Time (Training + Test) = 9.20 seconds\n",
      "epoch: 16 average loss: 1.036\n",
      "Test Accuracy : 65.6%, Test Loss: 1.0840127021074295\n",
      "Epoch Time (Training + Test) = 9.21 seconds\n",
      "epoch: 17 average loss: 1.037\n",
      "Test Accuracy : 66.8%, Test Loss: 1.059636052697897\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.15 seconds\n",
      "epoch: 18 average loss: 1.022\n",
      "Test Accuracy : 65.2%, Test Loss: 1.0662143155932426\n",
      "Epoch Time (Training + Test) = 9.36 seconds\n",
      "epoch: 19 average loss: 1.007\n",
      "Test Accuracy : 65.2%, Test Loss: 1.0816863626241684\n",
      "Epoch Time (Training + Test) = 9.29 seconds\n",
      "epoch: 20 average loss: 1.007\n",
      "Test Accuracy : 64.6%, Test Loss: 1.0877621937543154\n",
      "Epoch Time (Training + Test) = 9.37 seconds\n",
      "epoch: 21 average loss: 1.007\n",
      "Test Accuracy : 65.6%, Test Loss: 1.0911428984254599\n",
      "Epoch Time (Training + Test) = 9.34 seconds\n",
      "epoch: 22 average loss: 1.004\n",
      "Test Accuracy : 66.6%, Test Loss: 1.029051212593913\n",
      "Epoch Time (Training + Test) = 9.30 seconds\n",
      "epoch: 23 average loss: 0.990\n",
      "Test Accuracy : 65.5%, Test Loss: 1.110828410834074\n",
      "Epoch Time (Training + Test) = 9.21 seconds\n",
      "epoch: 24 average loss: 0.995\n",
      "Test Accuracy : 66.1%, Test Loss: 1.0708323903381824\n",
      "Epoch Time (Training + Test) = 9.23 seconds\n",
      "epoch: 25 average loss: 0.993\n",
      "Test Accuracy : 67.3%, Test Loss: 1.0167255159467459\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.14 seconds\n",
      "epoch: 26 average loss: 0.983\n",
      "Test Accuracy : 66.2%, Test Loss: 1.0676099602133036\n",
      "Epoch Time (Training + Test) = 9.23 seconds\n",
      "epoch: 27 average loss: 0.973\n",
      "Test Accuracy : 66.6%, Test Loss: 1.0415632911026478\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 28 average loss: 0.964\n",
      "Test Accuracy : 65.4%, Test Loss: 1.0703386571258307\n",
      "Epoch Time (Training + Test) = 9.39 seconds\n",
      "epoch: 29 average loss: 0.935\n",
      "Test Accuracy : 65.0%, Test Loss: 1.0983009710907936\n",
      "Epoch Time (Training + Test) = 9.38 seconds\n",
      "epoch: 30 average loss: 0.971\n",
      "Test Accuracy : 66.0%, Test Loss: 1.0871895011514425\n",
      "Epoch Time (Training + Test) = 9.46 seconds\n",
      "epoch: 31 average loss: 0.961\n",
      "Test Accuracy : 63.9%, Test Loss: 1.1469415128231049\n",
      "Epoch Time (Training + Test) = 9.19 seconds\n",
      "epoch: 32 average loss: 0.965\n",
      "Test Accuracy : 66.5%, Test Loss: 1.0563823152333498\n",
      "Epoch Time (Training + Test) = 9.23 seconds\n",
      "epoch: 33 average loss: 0.956\n",
      "Test Accuracy : 67.1%, Test Loss: 1.0447526220232248\n",
      "Epoch Time (Training + Test) = 9.13 seconds\n",
      "epoch: 34 average loss: 0.964\n",
      "Test Accuracy : 67.0%, Test Loss: 1.0370341651141644\n",
      "Epoch Time (Training + Test) = 9.33 seconds\n",
      "epoch: 35 average loss: 0.949\n",
      "Test Accuracy : 66.8%, Test Loss: 1.0405462104827166\n",
      "Epoch Time (Training + Test) = 9.39 seconds\n",
      "epoch: 36 average loss: 0.951\n",
      "Test Accuracy : 66.1%, Test Loss: 1.073747193440795\n",
      "Epoch Time (Training + Test) = 9.36 seconds\n",
      "epoch: 37 average loss: 0.946\n",
      "Test Accuracy : 66.0%, Test Loss: 1.054433697834611\n",
      "Epoch Time (Training + Test) = 9.40 seconds\n",
      "epoch: 38 average loss: 0.936\n",
      "Test Accuracy : 65.3%, Test Loss: 1.096725145354867\n",
      "Epoch Time (Training + Test) = 9.35 seconds\n",
      "epoch: 39 average loss: 0.934\n",
      "Test Accuracy : 66.0%, Test Loss: 1.0640146993100643\n",
      "Epoch Time (Training + Test) = 9.49 seconds\n",
      "epoch: 40 average loss: 0.934\n",
      "Test Accuracy : 67.7%, Test Loss: 1.0464187171310186\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.22 seconds\n",
      "epoch: 41 average loss: 0.930\n",
      "Test Accuracy : 66.8%, Test Loss: 1.0492970012128353\n",
      "Epoch Time (Training + Test) = 9.27 seconds\n",
      "epoch: 42 average loss: 0.924\n",
      "Test Accuracy : 67.7%, Test Loss: 1.0398717671632767\n",
      "Epoch Time (Training + Test) = 9.36 seconds\n",
      "epoch: 43 average loss: 0.936\n",
      "Test Accuracy : 67.5%, Test Loss: 1.0543519034981728\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 44 average loss: 0.934\n",
      "Test Accuracy : 67.0%, Test Loss: 1.0263806134462357\n",
      "Epoch Time (Training + Test) = 9.13 seconds\n",
      "epoch: 45 average loss: 0.917\n",
      "Test Accuracy : 66.5%, Test Loss: 1.0625426191836596\n",
      "Epoch Time (Training + Test) = 9.32 seconds\n",
      "epoch: 46 average loss: 0.925\n",
      "Test Accuracy : 67.3%, Test Loss: 1.0413101967424154\n",
      "Epoch Time (Training + Test) = 9.27 seconds\n",
      "epoch: 47 average loss: 0.928\n",
      "Test Accuracy : 65.4%, Test Loss: 1.099765233695507\n",
      "Epoch Time (Training + Test) = 9.35 seconds\n",
      "epoch: 48 average loss: 0.918\n",
      "Test Accuracy : 65.5%, Test Loss: 1.0896398853510618\n",
      "Epoch Time (Training + Test) = 9.44 seconds\n",
      "epoch: 49 average loss: 0.925\n",
      "Test Accuracy : 67.8%, Test Loss: 1.0335490871220827\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.39 seconds\n",
      "epoch: 50 average loss: 0.917\n",
      "Test Accuracy : 68.0%, Test Loss: 1.0487698353827\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.46 seconds\n",
      "epoch: 51 average loss: 0.924\n",
      "Test Accuracy : 66.2%, Test Loss: 1.078955750912428\n",
      "Epoch Time (Training + Test) = 9.19 seconds\n",
      "epoch: 52 average loss: 0.919\n",
      "Test Accuracy : 67.5%, Test Loss: 1.0553963240236044\n",
      "Epoch Time (Training + Test) = 9.19 seconds\n",
      "epoch: 53 average loss: 0.926\n",
      "Test Accuracy : 67.3%, Test Loss: 1.0196852330118418\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 54 average loss: 0.898\n",
      "Test Accuracy : 65.2%, Test Loss: 1.0910960640758276\n",
      "Epoch Time (Training + Test) = 9.30 seconds\n",
      "epoch: 55 average loss: 0.913\n",
      "Test Accuracy : 66.1%, Test Loss: 1.0863447654992342\n",
      "Epoch Time (Training + Test) = 9.18 seconds\n",
      "epoch: 56 average loss: 0.908\n",
      "Test Accuracy : 66.3%, Test Loss: 1.0895583666861057\n",
      "Epoch Time (Training + Test) = 9.38 seconds\n",
      "epoch: 57 average loss: 0.911\n",
      "Test Accuracy : 68.1%, Test Loss: 1.039747366681695\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.28 seconds\n",
      "epoch: 58 average loss: 0.897\n",
      "Test Accuracy : 68.1%, Test Loss: 1.0327446032315493\n",
      "Epoch Time (Training + Test) = 9.46 seconds\n",
      "epoch: 59 average loss: 0.917\n",
      "Test Accuracy : 66.5%, Test Loss: 1.090807856991887\n",
      "Epoch Time (Training + Test) = 9.56 seconds\n",
      "epoch: 60 average loss: 0.913\n",
      "Test Accuracy : 66.6%, Test Loss: 1.0637640859931707\n",
      "Epoch Time (Training + Test) = 9.48 seconds\n",
      "epoch: 61 average loss: 0.909\n",
      "Test Accuracy : 67.0%, Test Loss: 1.029106603935361\n",
      "Epoch Time (Training + Test) = 9.40 seconds\n",
      "epoch: 62 average loss: 0.890\n",
      "Test Accuracy : 66.9%, Test Loss: 1.0416198316961527\n",
      "Epoch Time (Training + Test) = 9.23 seconds\n",
      "epoch: 63 average loss: 0.907\n",
      "Test Accuracy : 65.7%, Test Loss: 1.0847955718636513\n",
      "Epoch Time (Training + Test) = 9.23 seconds\n",
      "epoch: 64 average loss: 0.905\n",
      "Test Accuracy : 65.5%, Test Loss: 1.1013850402086973\n",
      "Epoch Time (Training + Test) = 9.29 seconds\n",
      "epoch: 65 average loss: 0.920\n",
      "Test Accuracy : 66.3%, Test Loss: 1.071694863960147\n",
      "Epoch Time (Training + Test) = 9.22 seconds\n",
      "epoch: 66 average loss: 0.911\n",
      "Test Accuracy : 65.5%, Test Loss: 1.0846379268914461\n",
      "Epoch Time (Training + Test) = 9.31 seconds\n",
      "epoch: 67 average loss: 0.904\n",
      "Test Accuracy : 67.2%, Test Loss: 1.0477722100913525\n",
      "Epoch Time (Training + Test) = 9.30 seconds\n",
      "epoch: 68 average loss: 0.910\n",
      "Test Accuracy : 65.8%, Test Loss: 1.119973661378026\n",
      "Epoch Time (Training + Test) = 9.26 seconds\n",
      "epoch: 69 average loss: 0.905\n",
      "Test Accuracy : 68.8%, Test Loss: 1.035247914493084\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.19 seconds\n",
      "epoch: 70 average loss: 0.899\n",
      "Test Accuracy : 66.9%, Test Loss: 1.0411835759878159\n",
      "Epoch Time (Training + Test) = 9.27 seconds\n",
      "epoch: 71 average loss: 0.900\n",
      "Test Accuracy : 65.6%, Test Loss: 1.1243451200425625\n",
      "Epoch Time (Training + Test) = 9.36 seconds\n",
      "epoch: 72 average loss: 0.900\n",
      "Test Accuracy : 65.2%, Test Loss: 1.0648669134825468\n",
      "Epoch Time (Training + Test) = 9.36 seconds\n",
      "epoch: 73 average loss: 0.902\n",
      "Test Accuracy : 67.4%, Test Loss: 1.0557796452194452\n",
      "Epoch Time (Training + Test) = 9.41 seconds\n",
      "epoch: 74 average loss: 0.901\n",
      "Test Accuracy : 65.8%, Test Loss: 1.1453278306871653\n",
      "Epoch Time (Training + Test) = 9.50 seconds\n",
      "epoch: 75 average loss: 0.882\n",
      "Test Accuracy : 65.4%, Test Loss: 1.0794288124889135\n",
      "Epoch Time (Training + Test) = 9.37 seconds\n",
      "epoch: 76 average loss: 0.897\n",
      "Test Accuracy : 65.5%, Test Loss: 1.1050684470683336\n",
      "Epoch Time (Training + Test) = 9.28 seconds\n",
      "epoch: 77 average loss: 0.890\n",
      "Test Accuracy : 65.5%, Test Loss: 1.1052585393190384\n",
      "Epoch Time (Training + Test) = 9.29 seconds\n",
      "epoch: 78 average loss: 0.895\n",
      "Test Accuracy : 66.5%, Test Loss: 1.0731805358082056\n",
      "Epoch Time (Training + Test) = 9.23 seconds\n",
      "epoch: 79 average loss: 0.893\n",
      "Test Accuracy : 68.0%, Test Loss: 1.0086973458528519\n",
      "Epoch Time (Training + Test) = 9.21 seconds\n",
      "epoch: 80 average loss: 0.890\n",
      "Test Accuracy : 67.9%, Test Loss: 0.9861902464181185\n",
      "Epoch Time (Training + Test) = 9.39 seconds\n",
      "epoch: 81 average loss: 0.892\n",
      "Test Accuracy : 67.2%, Test Loss: 1.0627708323299885\n",
      "Epoch Time (Training + Test) = 9.34 seconds\n",
      "epoch: 82 average loss: 0.872\n",
      "Test Accuracy : 67.6%, Test Loss: 1.100947929546237\n",
      "Epoch Time (Training + Test) = 9.41 seconds\n",
      "epoch: 83 average loss: 0.865\n",
      "Test Accuracy : 67.5%, Test Loss: 1.0607372261583805\n",
      "Epoch Time (Training + Test) = 9.27 seconds\n",
      "epoch: 84 average loss: 0.894\n",
      "Test Accuracy : 66.6%, Test Loss: 1.0757637452334166\n",
      "Epoch Time (Training + Test) = 9.23 seconds\n",
      "epoch: 85 average loss: 0.879\n",
      "Test Accuracy : 67.3%, Test Loss: 1.049766568467021\n",
      "Epoch Time (Training + Test) = 9.21 seconds\n",
      "epoch: 86 average loss: 0.879\n",
      "Test Accuracy : 68.3%, Test Loss: 1.0310138445347548\n",
      "Epoch Time (Training + Test) = 9.08 seconds\n",
      "epoch: 87 average loss: 0.889\n",
      "Test Accuracy : 65.2%, Test Loss: 1.1101605519652367\n",
      "Epoch Time (Training + Test) = 9.09 seconds\n",
      "epoch: 88 average loss: 0.888\n",
      "Test Accuracy : 66.2%, Test Loss: 1.0762976557016373\n",
      "Epoch Time (Training + Test) = 9.14 seconds\n",
      "epoch: 89 average loss: 0.904\n",
      "Test Accuracy : 65.4%, Test Loss: 1.0981478914618492\n",
      "Epoch Time (Training + Test) = 9.21 seconds\n",
      "epoch: 90 average loss: 0.896\n",
      "Test Accuracy : 67.3%, Test Loss: 1.057285139337182\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 91 average loss: 0.874\n",
      "Test Accuracy : 68.0%, Test Loss: 1.0481714401394129\n",
      "Epoch Time (Training + Test) = 9.11 seconds\n",
      "epoch: 92 average loss: 0.884\n",
      "Test Accuracy : 67.5%, Test Loss: 1.0607666857540607\n",
      "Epoch Time (Training + Test) = 9.06 seconds\n",
      "epoch: 93 average loss: 0.883\n",
      "Test Accuracy : 67.2%, Test Loss: 1.0678791403770447\n",
      "Epoch Time (Training + Test) = 9.10 seconds\n",
      "epoch: 94 average loss: 0.877\n",
      "Test Accuracy : 66.0%, Test Loss: 1.0614567948505282\n",
      "Epoch Time (Training + Test) = 9.23 seconds\n",
      "epoch: 95 average loss: 0.872\n",
      "Test Accuracy : 66.9%, Test Loss: 1.0907131843268871\n",
      "Epoch Time (Training + Test) = 9.17 seconds\n",
      "epoch: 96 average loss: 0.882\n",
      "Test Accuracy : 64.8%, Test Loss: 1.1345267295837402\n",
      "Epoch Time (Training + Test) = 9.18 seconds\n",
      "epoch: 97 average loss: 0.878\n",
      "Test Accuracy : 68.2%, Test Loss: 1.0913784392178059\n",
      "Epoch Time (Training + Test) = 9.07 seconds\n",
      "epoch: 98 average loss: 0.881\n",
      "Test Accuracy : 66.8%, Test Loss: 1.0646339859813452\n",
      "Epoch Time (Training + Test) = 9.12 seconds\n",
      "epoch: 99 average loss: 0.876\n",
      "Test Accuracy : 66.6%, Test Loss: 1.0938845239579678\n",
      "Epoch Time (Training + Test) = 9.11 seconds\n",
      "epoch: 100 average loss: 0.887\n",
      "Test Accuracy : 63.5%, Test Loss: 1.1340234987437725\n",
      "Epoch Time (Training + Test) = 9.12 seconds\n",
      "Data Saved to adp_layer2_full_ft.csv\n",
      "Finished Training: \n",
      "Total Time 0.514724 hours\n",
      " Average Time Per Epoch 18.53 seconds\n",
      "adp_only layer3 320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3mcpnplt) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch time (s)</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆ</td></tr><tr><td>lr</td><td>â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–‚â–â–â–â–‚â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–„â–ƒâ–‚â–â–â–‚â–‚â–„â–…â–‡â–‡â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–‚â–â–</td></tr><tr><td>test_accuracy</td><td>â–â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡</td></tr><tr><td>test_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>training_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.6875</td></tr><tr><td>Current Best Acc</td><td>0.6875</td></tr><tr><td>Total Time (hours)</td><td>0.51472</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>9.12072</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>test_accuracy</td><td>0.635</td></tr><tr><td>test_loss</td><td>1.13402</td></tr><tr><td>training_loss</td><td>0.88729</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glamorous-salad-21</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/3mcpnplt\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/3mcpnplt</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221024_175523-3mcpnplt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3mcpnplt). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356d73b69c8e49949fa576b2a4dd28e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221024_181109-19gub1zj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/19gub1zj\" target=\"_blank\">magic-glade-22</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name adp_layer3_adp_only \n",
      "\n",
      "\n",
      "Run Start : 2022-10-24 18-11-09\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 64\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4444940\n",
      "Initial accuracy:\n",
      "Test Accuracy : 5.0%, Test Loss: 27.6664420692784\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 5.0%, Test Loss: 27.637647092342377\n",
      "epoch: 1 average loss: 2.917\n",
      "Test Accuracy : 12.4%, Test Loss: 2.84285144507885\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.31 seconds\n",
      "epoch: 2 average loss: 2.922\n",
      "Test Accuracy : 8.5%, Test Loss: 2.9565192982554436\n",
      "Epoch Time (Training + Test) = 4.29 seconds\n",
      "epoch: 3 average loss: 2.962\n",
      "Test Accuracy : 6.0%, Test Loss: 2.982088565826416\n",
      "Epoch Time (Training + Test) = 4.35 seconds\n",
      "epoch: 4 average loss: 2.954\n",
      "Test Accuracy : 9.8%, Test Loss: 2.902385078370571\n",
      "Epoch Time (Training + Test) = 4.25 seconds\n",
      "epoch: 5 average loss: 2.950\n",
      "Test Accuracy : 8.0%, Test Loss: 3.5554082691669464\n",
      "Epoch Time (Training + Test) = 4.27 seconds\n",
      "epoch: 6 average loss: 2.922\n",
      "Test Accuracy : 8.7%, Test Loss: 2.958217293024063\n",
      "Epoch Time (Training + Test) = 4.24 seconds\n",
      "epoch: 7 average loss: 2.936\n",
      "Test Accuracy : 7.2%, Test Loss: 2.8921084851026535\n",
      "Epoch Time (Training + Test) = 4.29 seconds\n",
      "epoch: 8 average loss: 2.889\n",
      "Test Accuracy : 6.6%, Test Loss: 3.08050923794508\n",
      "Epoch Time (Training + Test) = 4.27 seconds\n",
      "epoch: 9 average loss: 2.989\n",
      "Test Accuracy : 7.2%, Test Loss: 2.9521890357136726\n",
      "Epoch Time (Training + Test) = 4.25 seconds\n",
      "epoch: 10 average loss: 2.965\n",
      "Test Accuracy : 7.8%, Test Loss: 2.9688054099678993\n",
      "Epoch Time (Training + Test) = 4.27 seconds\n",
      "epoch: 11 average loss: 2.961\n",
      "Test Accuracy : 5.6%, Test Loss: 2.9920294359326363\n",
      "Epoch Time (Training + Test) = 4.32 seconds\n",
      "epoch: 12 average loss: 2.983\n",
      "Test Accuracy : 7.1%, Test Loss: 2.9796382263302803\n",
      "Epoch Time (Training + Test) = 4.25 seconds\n",
      "epoch: 13 average loss: 2.985\n",
      "Test Accuracy : 6.2%, Test Loss: 2.9931556582450867\n",
      "Epoch Time (Training + Test) = 4.25 seconds\n",
      "epoch: 14 average loss: 2.967\n",
      "Test Accuracy : 9.3%, Test Loss: 2.9426788985729218\n",
      "Epoch Time (Training + Test) = 4.23 seconds\n",
      "epoch: 15 average loss: 2.970\n",
      "Test Accuracy : 5.0%, Test Loss: 5.175459548830986\n",
      "Epoch Time (Training + Test) = 4.25 seconds\n",
      "epoch: 16 average loss: 2.951\n",
      "Test Accuracy : 5.5%, Test Loss: 3.143231689929962\n",
      "Epoch Time (Training + Test) = 4.29 seconds\n",
      "epoch: 17 average loss: 2.919\n",
      "Test Accuracy : 10.4%, Test Loss: 2.8884531259536743\n",
      "Epoch Time (Training + Test) = 4.27 seconds\n",
      "epoch: 18 average loss: 2.904\n",
      "Test Accuracy : 11.6%, Test Loss: 2.8530229702591896\n",
      "Epoch Time (Training + Test) = 4.30 seconds\n",
      "epoch: 19 average loss: 2.890\n",
      "Test Accuracy : 11.8%, Test Loss: 2.8539411574602127\n",
      "Epoch Time (Training + Test) = 4.29 seconds\n",
      "epoch: 20 average loss: 2.881\n",
      "Test Accuracy : 10.8%, Test Loss: 2.8414295613765717\n",
      "Epoch Time (Training + Test) = 4.30 seconds\n",
      "epoch: 21 average loss: 2.905\n",
      "Test Accuracy : 10.2%, Test Loss: 2.8603395745158195\n",
      "Epoch Time (Training + Test) = 4.33 seconds\n",
      "epoch: 22 average loss: 2.921\n",
      "Test Accuracy : 9.9%, Test Loss: 2.889620967209339\n",
      "Epoch Time (Training + Test) = 4.26 seconds\n",
      "epoch: 23 average loss: 2.952\n",
      "Test Accuracy : 4.8%, Test Loss: 2.9642129465937614\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 24 average loss: 2.958\n",
      "Test Accuracy : 7.0%, Test Loss: 2.9525029584765434\n",
      "Epoch Time (Training + Test) = 4.26 seconds\n",
      "epoch: 25 average loss: 2.939\n",
      "Test Accuracy : 10.1%, Test Loss: 2.9158439338207245\n",
      "Epoch Time (Training + Test) = 4.29 seconds\n",
      "epoch: 26 average loss: 2.878\n",
      "Test Accuracy : 12.9%, Test Loss: 2.84253890812397\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.34 seconds\n",
      "epoch: 27 average loss: 2.863\n",
      "Test Accuracy : 13.2%, Test Loss: 2.8696700781583786\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.33 seconds\n",
      "epoch: 28 average loss: 2.886\n",
      "Test Accuracy : 11.2%, Test Loss: 2.8961552903056145\n",
      "Epoch Time (Training + Test) = 4.27 seconds\n",
      "epoch: 29 average loss: 2.938\n",
      "Test Accuracy : 7.4%, Test Loss: 3.084123872220516\n",
      "Epoch Time (Training + Test) = 4.27 seconds\n",
      "epoch: 30 average loss: 2.904\n",
      "Test Accuracy : 11.4%, Test Loss: 2.7382602468132973\n",
      "Epoch Time (Training + Test) = 4.27 seconds\n",
      "epoch: 31 average loss: 2.758\n",
      "Test Accuracy : 10.9%, Test Loss: 2.746113069355488\n",
      "Epoch Time (Training + Test) = 4.31 seconds\n",
      "epoch: 32 average loss: 2.734\n",
      "Test Accuracy : 14.6%, Test Loss: 2.711122862994671\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.35 seconds\n",
      "epoch: 33 average loss: 2.702\n",
      "Test Accuracy : 11.9%, Test Loss: 2.7672017365694046\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 34 average loss: 2.676\n",
      "Test Accuracy : 10.5%, Test Loss: 2.698793515563011\n",
      "Epoch Time (Training + Test) = 4.29 seconds\n",
      "epoch: 35 average loss: 2.659\n",
      "Test Accuracy : 15.0%, Test Loss: 2.6293682977557182\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.30 seconds\n",
      "epoch: 36 average loss: 2.636\n",
      "Test Accuracy : 16.0%, Test Loss: 2.5862249583005905\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.34 seconds\n",
      "epoch: 37 average loss: 2.629\n",
      "Test Accuracy : 16.4%, Test Loss: 2.5918703600764275\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.32 seconds\n",
      "epoch: 38 average loss: 2.617\n",
      "Test Accuracy : 13.8%, Test Loss: 2.663009837269783\n",
      "Epoch Time (Training + Test) = 4.27 seconds\n",
      "epoch: 39 average loss: 2.649\n",
      "Test Accuracy : 16.0%, Test Loss: 2.6151397079229355\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 40 average loss: 2.630\n",
      "Test Accuracy : 16.4%, Test Loss: 2.608116202056408\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 41 average loss: 2.598\n",
      "Test Accuracy : 18.1%, Test Loss: 2.557397574186325\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.38 seconds\n",
      "epoch: 42 average loss: 2.553\n",
      "Test Accuracy : 20.4%, Test Loss: 2.4770422130823135\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.35 seconds\n",
      "epoch: 43 average loss: 2.529\n",
      "Test Accuracy : 19.0%, Test Loss: 2.4969398379325867\n",
      "Epoch Time (Training + Test) = 4.33 seconds\n",
      "epoch: 44 average loss: 2.505\n",
      "Test Accuracy : 21.4%, Test Loss: 2.445832744240761\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.39 seconds\n",
      "epoch: 45 average loss: 2.485\n",
      "Test Accuracy : 21.1%, Test Loss: 2.4273923859000206\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 46 average loss: 2.473\n",
      "Test Accuracy : 22.1%, Test Loss: 2.40083247423172\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.32 seconds\n",
      "epoch: 47 average loss: 2.455\n",
      "Test Accuracy : 23.0%, Test Loss: 2.4596214964985847\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.32 seconds\n",
      "epoch: 48 average loss: 2.438\n",
      "Test Accuracy : 19.8%, Test Loss: 2.4129096046090126\n",
      "Epoch Time (Training + Test) = 4.31 seconds\n",
      "epoch: 49 average loss: 2.424\n",
      "Test Accuracy : 21.5%, Test Loss: 2.3454186990857124\n",
      "Epoch Time (Training + Test) = 4.29 seconds\n",
      "epoch: 50 average loss: 2.402\n",
      "Test Accuracy : 23.3%, Test Loss: 2.3248178400099277\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.38 seconds\n",
      "epoch: 51 average loss: 2.381\n",
      "Test Accuracy : 22.9%, Test Loss: 2.289909213781357\n",
      "Epoch Time (Training + Test) = 4.29 seconds\n",
      "epoch: 52 average loss: 2.365\n",
      "Test Accuracy : 25.1%, Test Loss: 2.2576427310705185\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 53 average loss: 2.347\n",
      "Test Accuracy : 22.0%, Test Loss: 2.392585225403309\n",
      "Epoch Time (Training + Test) = 4.29 seconds\n",
      "epoch: 54 average loss: 2.334\n",
      "Test Accuracy : 23.9%, Test Loss: 2.311246372759342\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 55 average loss: 2.329\n",
      "Test Accuracy : 23.1%, Test Loss: 2.360031560063362\n",
      "Epoch Time (Training + Test) = 4.34 seconds\n",
      "epoch: 56 average loss: 2.346\n",
      "Test Accuracy : 24.0%, Test Loss: 2.2829654291272163\n",
      "Epoch Time (Training + Test) = 4.26 seconds\n",
      "epoch: 57 average loss: 2.329\n",
      "Test Accuracy : 23.7%, Test Loss: 2.275113984942436\n",
      "Epoch Time (Training + Test) = 4.32 seconds\n",
      "epoch: 58 average loss: 2.295\n",
      "Test Accuracy : 27.4%, Test Loss: 2.2896854132413864\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.37 seconds\n",
      "epoch: 59 average loss: 2.287\n",
      "Test Accuracy : 24.1%, Test Loss: 2.2859322875738144\n",
      "Epoch Time (Training + Test) = 4.33 seconds\n",
      "epoch: 60 average loss: 2.292\n",
      "Test Accuracy : 25.5%, Test Loss: 2.2268999591469765\n",
      "Epoch Time (Training + Test) = 4.29 seconds\n",
      "epoch: 61 average loss: 2.273\n",
      "Test Accuracy : 28.1%, Test Loss: 2.22311032935977\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.36 seconds\n",
      "epoch: 62 average loss: 2.251\n",
      "Test Accuracy : 26.2%, Test Loss: 2.2682512253522873\n",
      "Epoch Time (Training + Test) = 4.37 seconds\n",
      "epoch: 63 average loss: 2.235\n",
      "Test Accuracy : 28.2%, Test Loss: 2.1697761565446854\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.33 seconds\n",
      "epoch: 64 average loss: 2.233\n",
      "Test Accuracy : 26.8%, Test Loss: 2.1633818782866\n",
      "Epoch Time (Training + Test) = 4.30 seconds\n",
      "epoch: 65 average loss: 2.230\n",
      "Test Accuracy : 28.1%, Test Loss: 2.195249069482088\n",
      "Epoch Time (Training + Test) = 4.30 seconds\n",
      "epoch: 66 average loss: 2.204\n",
      "Test Accuracy : 29.0%, Test Loss: 2.2079982720315456\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.31 seconds\n",
      "epoch: 67 average loss: 2.197\n",
      "Test Accuracy : 26.6%, Test Loss: 2.199896812438965\n",
      "Epoch Time (Training + Test) = 4.31 seconds\n",
      "epoch: 68 average loss: 2.177\n",
      "Test Accuracy : 29.2%, Test Loss: 2.0999158695340157\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.32 seconds\n",
      "epoch: 69 average loss: 2.191\n",
      "Test Accuracy : 30.8%, Test Loss: 2.124718278646469\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 70 average loss: 2.168\n",
      "Test Accuracy : 32.0%, Test Loss: 2.0586099587380886\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.33 seconds\n",
      "epoch: 71 average loss: 2.167\n",
      "Test Accuracy : 31.0%, Test Loss: 2.117775835096836\n",
      "Epoch Time (Training + Test) = 4.32 seconds\n",
      "epoch: 72 average loss: 2.150\n",
      "Test Accuracy : 31.4%, Test Loss: 2.0922286100685596\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 73 average loss: 2.174\n",
      "Test Accuracy : 30.2%, Test Loss: 2.118465691804886\n",
      "Epoch Time (Training + Test) = 4.25 seconds\n",
      "epoch: 74 average loss: 2.162\n",
      "Test Accuracy : 28.0%, Test Loss: 2.1125278659164906\n",
      "Epoch Time (Training + Test) = 4.23 seconds\n",
      "epoch: 75 average loss: 2.153\n",
      "Test Accuracy : 29.3%, Test Loss: 2.110040098428726\n",
      "Epoch Time (Training + Test) = 4.26 seconds\n",
      "epoch: 76 average loss: 2.144\n",
      "Test Accuracy : 29.4%, Test Loss: 2.1077906116843224\n",
      "Epoch Time (Training + Test) = 4.27 seconds\n",
      "epoch: 77 average loss: 2.126\n",
      "Test Accuracy : 29.3%, Test Loss: 2.1237053386867046\n",
      "Epoch Time (Training + Test) = 4.27 seconds\n",
      "epoch: 78 average loss: 2.130\n",
      "Test Accuracy : 33.9%, Test Loss: 2.0560614354908466\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 79 average loss: 2.133\n",
      "Test Accuracy : 31.9%, Test Loss: 2.0477032251656055\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 80 average loss: 2.138\n",
      "Test Accuracy : 32.6%, Test Loss: 2.0190401896834373\n",
      "Epoch Time (Training + Test) = 4.29 seconds\n",
      "epoch: 81 average loss: 2.142\n",
      "Test Accuracy : 28.1%, Test Loss: 2.1764324344694614\n",
      "Epoch Time (Training + Test) = 4.31 seconds\n",
      "epoch: 82 average loss: 2.138\n",
      "Test Accuracy : 31.4%, Test Loss: 2.068353660404682\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 83 average loss: 2.133\n",
      "Test Accuracy : 29.0%, Test Loss: 2.102498784661293\n",
      "Epoch Time (Training + Test) = 4.30 seconds\n",
      "epoch: 84 average loss: 2.127\n",
      "Test Accuracy : 31.9%, Test Loss: 2.084219105541706\n",
      "Epoch Time (Training + Test) = 4.32 seconds\n",
      "epoch: 85 average loss: 2.133\n",
      "Test Accuracy : 31.9%, Test Loss: 2.0726976953446865\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 86 average loss: 2.120\n",
      "Test Accuracy : 28.3%, Test Loss: 2.1470380537211895\n",
      "Epoch Time (Training + Test) = 4.30 seconds\n",
      "epoch: 87 average loss: 2.120\n",
      "Test Accuracy : 30.4%, Test Loss: 2.0593983493745327\n",
      "Epoch Time (Training + Test) = 4.27 seconds\n",
      "epoch: 88 average loss: 2.124\n",
      "Test Accuracy : 30.3%, Test Loss: 2.0693271420896053\n",
      "Epoch Time (Training + Test) = 4.28 seconds\n",
      "epoch: 89 average loss: 2.106\n",
      "Test Accuracy : 32.2%, Test Loss: 2.0193510949611664\n",
      "Epoch Time (Training + Test) = 4.33 seconds\n",
      "epoch: 90 average loss: 2.113\n",
      "Test Accuracy : 33.2%, Test Loss: 2.0681329518556595\n",
      "Epoch Time (Training + Test) = 4.27 seconds\n",
      "epoch: 91 average loss: 2.105\n",
      "Test Accuracy : 31.7%, Test Loss: 2.1465406380593777\n",
      "Epoch Time (Training + Test) = 4.33 seconds\n",
      "epoch: 92 average loss: 2.108\n",
      "Test Accuracy : 33.4%, Test Loss: 2.048382915556431\n",
      "Epoch Time (Training + Test) = 4.27 seconds\n",
      "epoch: 93 average loss: 2.106\n",
      "Test Accuracy : 30.2%, Test Loss: 2.0357113890349865\n",
      "Epoch Time (Training + Test) = 4.31 seconds\n",
      "epoch: 94 average loss: 2.114\n",
      "Test Accuracy : 33.6%, Test Loss: 2.0140205547213554\n",
      "Epoch Time (Training + Test) = 4.31 seconds\n",
      "epoch: 95 average loss: 2.104\n",
      "Test Accuracy : 34.3%, Test Loss: 2.0378383025527\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 4.36 seconds\n",
      "epoch: 96 average loss: 2.092\n",
      "Test Accuracy : 32.5%, Test Loss: 2.0659011900424957\n",
      "Epoch Time (Training + Test) = 4.32 seconds\n",
      "epoch: 97 average loss: 2.097\n",
      "Test Accuracy : 33.1%, Test Loss: 2.046760194003582\n",
      "Epoch Time (Training + Test) = 4.35 seconds\n",
      "epoch: 98 average loss: 2.114\n",
      "Test Accuracy : 33.3%, Test Loss: 2.031256288290024\n",
      "Epoch Time (Training + Test) = 4.30 seconds\n",
      "epoch: 99 average loss: 2.112\n",
      "Test Accuracy : 33.0%, Test Loss: 2.0297679267823696\n",
      "Epoch Time (Training + Test) = 4.32 seconds\n",
      "epoch: 100 average loss: 2.100\n",
      "Test Accuracy : 32.1%, Test Loss: 2.0591596998274326\n",
      "Epoch Time (Training + Test) = 4.32 seconds\n",
      "Data Saved to adp_layer3_adp_only.csv\n",
      "Finished Training: \n",
      "Total Time 0.238830 hours\n",
      " Average Time Per Epoch 8.60 seconds\n",
      "full_ft layer3 320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:19gub1zj) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch time (s)</td><td>â–â–…â–…â–…â–…â–„â–„â–…â–†â–…â–…â–…â–…â–…â–†â–…â–ˆâ–†â–†â–†â–…â–…â–„â–‡â–‡â–†â–†â–…â–†â–„â–…â–…â–…â–†â–…â–‡â–…â–†â–‡â–†</td></tr><tr><td>lr</td><td>â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–‚â–â–â–â–‚â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–„â–ƒâ–‚â–â–â–‚â–‚â–„â–…â–‡â–‡â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–‚â–â–</td></tr><tr><td>test_accuracy</td><td>â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>test_loss</td><td>â–ˆâ–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>training_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.343</td></tr><tr><td>Current Best Acc</td><td>0.343</td></tr><tr><td>Total Time (hours)</td><td>0.23883</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>4.32242</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>test_accuracy</td><td>0.3215</td></tr><tr><td>test_loss</td><td>2.05916</td></tr><tr><td>training_loss</td><td>2.09986</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">magic-glade-22</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/19gub1zj\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/19gub1zj</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221024_181109-19gub1zj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:19gub1zj). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4966d123687949a49a835f781a156440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666414434, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221024_181837-2f7rrjh9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/2f7rrjh9\" target=\"_blank\">noble-eon-23</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar80-20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar80-20, Run Name adp_layer3_full_ft \n",
      "\n",
      "\n",
      "Run Start : 2022-10-24 18-18-37\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 64\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4444940\n",
      "Initial accuracy:\n",
      "Test Accuracy : 5.0%, Test Loss: 27.6664420692784\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 5.0%, Test Loss: 27.637647092342377\n",
      "epoch: 1 average loss: 2.914\n",
      "Test Accuracy : 10.2%, Test Loss: 2.853027567267418\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.11 seconds\n",
      "epoch: 2 average loss: 2.916\n",
      "Test Accuracy : 8.5%, Test Loss: 2.942184194922447\n",
      "Epoch Time (Training + Test) = 9.04 seconds\n",
      "epoch: 3 average loss: 2.973\n",
      "Test Accuracy : 5.5%, Test Loss: 3.2366816326975822\n",
      "Epoch Time (Training + Test) = 9.01 seconds\n",
      "epoch: 4 average loss: 2.977\n",
      "Test Accuracy : 5.7%, Test Loss: 3.0073725134134293\n",
      "Epoch Time (Training + Test) = 9.07 seconds\n",
      "epoch: 5 average loss: 2.949\n",
      "Test Accuracy : 8.1%, Test Loss: 2.9587967470288277\n",
      "Epoch Time (Training + Test) = 9.05 seconds\n",
      "epoch: 6 average loss: 2.937\n",
      "Test Accuracy : 8.7%, Test Loss: 2.914878062903881\n",
      "Epoch Time (Training + Test) = 9.07 seconds\n",
      "epoch: 7 average loss: 2.917\n",
      "Test Accuracy : 11.0%, Test Loss: 2.8750638589262962\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.19 seconds\n",
      "epoch: 8 average loss: 2.889\n",
      "Test Accuracy : 10.5%, Test Loss: 2.8810610696673393\n",
      "Epoch Time (Training + Test) = 9.15 seconds\n",
      "epoch: 9 average loss: 2.935\n",
      "Test Accuracy : 4.0%, Test Loss: 2.9957251474261284\n",
      "Epoch Time (Training + Test) = 9.02 seconds\n",
      "epoch: 10 average loss: 2.987\n",
      "Test Accuracy : 6.3%, Test Loss: 2.971958339214325\n",
      "Epoch Time (Training + Test) = 9.09 seconds\n",
      "epoch: 11 average loss: 2.957\n",
      "Test Accuracy : 11.5%, Test Loss: 2.8735899701714516\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.07 seconds\n",
      "epoch: 12 average loss: 2.850\n",
      "Test Accuracy : 14.6%, Test Loss: 2.7544397488236427\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.22 seconds\n",
      "epoch: 13 average loss: 2.799\n",
      "Test Accuracy : 13.2%, Test Loss: 2.7974080368876457\n",
      "Epoch Time (Training + Test) = 9.22 seconds\n",
      "epoch: 14 average loss: 2.801\n",
      "Test Accuracy : 14.0%, Test Loss: 2.760447219014168\n",
      "Epoch Time (Training + Test) = 9.09 seconds\n",
      "epoch: 15 average loss: 2.774\n",
      "Test Accuracy : 13.4%, Test Loss: 2.7527361065149307\n",
      "Epoch Time (Training + Test) = 9.12 seconds\n",
      "epoch: 16 average loss: 2.791\n",
      "Test Accuracy : 12.3%, Test Loss: 2.7415100559592247\n",
      "Epoch Time (Training + Test) = 9.11 seconds\n",
      "epoch: 17 average loss: 2.802\n",
      "Test Accuracy : 15.0%, Test Loss: 2.755347318947315\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.16 seconds\n",
      "epoch: 18 average loss: 2.801\n",
      "Test Accuracy : 12.7%, Test Loss: 2.767316520214081\n",
      "Epoch Time (Training + Test) = 9.14 seconds\n",
      "epoch: 19 average loss: 2.795\n",
      "Test Accuracy : 10.4%, Test Loss: 2.8318781182169914\n",
      "Epoch Time (Training + Test) = 9.04 seconds\n",
      "epoch: 20 average loss: 2.798\n",
      "Test Accuracy : 14.1%, Test Loss: 2.732659585773945\n",
      "Epoch Time (Training + Test) = 9.18 seconds\n",
      "epoch: 21 average loss: 2.789\n",
      "Test Accuracy : 10.1%, Test Loss: 2.829168885946274\n",
      "Epoch Time (Training + Test) = 9.15 seconds\n",
      "epoch: 22 average loss: 2.798\n",
      "Test Accuracy : 9.2%, Test Loss: 2.7957373186945915\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 23 average loss: 2.760\n",
      "Test Accuracy : 15.9%, Test Loss: 2.711135357618332\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.38 seconds\n",
      "epoch: 24 average loss: 2.726\n",
      "Test Accuracy : 13.6%, Test Loss: 2.7135845348238945\n",
      "Epoch Time (Training + Test) = 9.34 seconds\n",
      "epoch: 25 average loss: 2.688\n",
      "Test Accuracy : 16.1%, Test Loss: 2.6561635732650757\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.37 seconds\n",
      "epoch: 26 average loss: 2.657\n",
      "Test Accuracy : 16.4%, Test Loss: 2.583309441804886\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.18 seconds\n",
      "epoch: 27 average loss: 2.623\n",
      "Test Accuracy : 16.1%, Test Loss: 2.6212571933865547\n",
      "Epoch Time (Training + Test) = 9.19 seconds\n",
      "epoch: 28 average loss: 2.611\n",
      "Test Accuracy : 17.8%, Test Loss: 2.5681128576397896\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.26 seconds\n",
      "epoch: 29 average loss: 2.588\n",
      "Test Accuracy : 17.4%, Test Loss: 2.5616866424679756\n",
      "Epoch Time (Training + Test) = 9.07 seconds\n",
      "epoch: 30 average loss: 2.581\n",
      "Test Accuracy : 19.2%, Test Loss: 2.5412667617201805\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.37 seconds\n",
      "epoch: 31 average loss: 2.567\n",
      "Test Accuracy : 20.2%, Test Loss: 2.5170444324612617\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.34 seconds\n",
      "epoch: 32 average loss: 2.564\n",
      "Test Accuracy : 18.2%, Test Loss: 2.5320121124386787\n",
      "Epoch Time (Training + Test) = 9.35 seconds\n",
      "epoch: 33 average loss: 2.548\n",
      "Test Accuracy : 18.4%, Test Loss: 2.5497636646032333\n",
      "Epoch Time (Training + Test) = 9.50 seconds\n",
      "epoch: 34 average loss: 2.543\n",
      "Test Accuracy : 20.7%, Test Loss: 2.490756742656231\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.71 seconds\n",
      "epoch: 35 average loss: 2.543\n",
      "Test Accuracy : 20.6%, Test Loss: 2.5051189810037613\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 36 average loss: 2.511\n",
      "Test Accuracy : 21.9%, Test Loss: 2.4515972584486008\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.21 seconds\n",
      "epoch: 37 average loss: 2.507\n",
      "Test Accuracy : 20.0%, Test Loss: 2.4739388525485992\n",
      "Epoch Time (Training + Test) = 9.17 seconds\n",
      "epoch: 38 average loss: 2.491\n",
      "Test Accuracy : 19.7%, Test Loss: 2.4846662133932114\n",
      "Epoch Time (Training + Test) = 9.22 seconds\n",
      "epoch: 39 average loss: 2.483\n",
      "Test Accuracy : 22.8%, Test Loss: 2.4517232328653336\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.32 seconds\n",
      "epoch: 40 average loss: 2.470\n",
      "Test Accuracy : 21.1%, Test Loss: 2.4808339178562164\n",
      "Epoch Time (Training + Test) = 9.18 seconds\n",
      "epoch: 41 average loss: 2.461\n",
      "Test Accuracy : 19.6%, Test Loss: 2.4745144844055176\n",
      "Epoch Time (Training + Test) = 9.21 seconds\n",
      "epoch: 42 average loss: 2.434\n",
      "Test Accuracy : 20.5%, Test Loss: 2.466185748577118\n",
      "Epoch Time (Training + Test) = 9.50 seconds\n",
      "epoch: 43 average loss: 2.443\n",
      "Test Accuracy : 20.9%, Test Loss: 2.427054889500141\n",
      "Epoch Time (Training + Test) = 9.41 seconds\n",
      "epoch: 44 average loss: 2.450\n",
      "Test Accuracy : 22.7%, Test Loss: 2.465539872646332\n",
      "Epoch Time (Training + Test) = 9.33 seconds\n",
      "epoch: 45 average loss: 2.432\n",
      "Test Accuracy : 22.9%, Test Loss: 2.4587376043200493\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.70 seconds\n",
      "epoch: 46 average loss: 2.408\n",
      "Test Accuracy : 22.6%, Test Loss: 2.4178892746567726\n",
      "Epoch Time (Training + Test) = 9.67 seconds\n",
      "epoch: 47 average loss: 2.413\n",
      "Test Accuracy : 22.8%, Test Loss: 2.4569836780428886\n",
      "Epoch Time (Training + Test) = 9.12 seconds\n",
      "epoch: 48 average loss: 2.405\n",
      "Test Accuracy : 21.4%, Test Loss: 2.492908962070942\n",
      "Epoch Time (Training + Test) = 9.17 seconds\n",
      "epoch: 49 average loss: 2.403\n",
      "Test Accuracy : 23.5%, Test Loss: 2.4694492518901825\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.30 seconds\n",
      "epoch: 50 average loss: 2.397\n",
      "Test Accuracy : 23.2%, Test Loss: 2.415533646941185\n",
      "Epoch Time (Training + Test) = 9.35 seconds\n",
      "epoch: 51 average loss: 2.394\n",
      "Test Accuracy : 25.5%, Test Loss: 2.4245244041085243\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.34 seconds\n",
      "epoch: 52 average loss: 2.385\n",
      "Test Accuracy : 22.9%, Test Loss: 2.4286562874913216\n",
      "Epoch Time (Training + Test) = 9.14 seconds\n",
      "epoch: 53 average loss: 2.368\n",
      "Test Accuracy : 23.9%, Test Loss: 2.4621478766202927\n",
      "Epoch Time (Training + Test) = 9.17 seconds\n",
      "epoch: 54 average loss: 2.371\n",
      "Test Accuracy : 23.4%, Test Loss: 2.4479221403598785\n",
      "Epoch Time (Training + Test) = 9.22 seconds\n",
      "epoch: 55 average loss: 2.364\n",
      "Test Accuracy : 25.9%, Test Loss: 2.329133130609989\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.53 seconds\n",
      "epoch: 56 average loss: 2.341\n",
      "Test Accuracy : 23.9%, Test Loss: 2.3472515493631363\n",
      "Epoch Time (Training + Test) = 9.70 seconds\n",
      "epoch: 57 average loss: 2.324\n",
      "Test Accuracy : 25.0%, Test Loss: 2.3383654057979584\n",
      "Epoch Time (Training + Test) = 9.98 seconds\n",
      "epoch: 58 average loss: 2.330\n",
      "Test Accuracy : 25.6%, Test Loss: 2.35884802788496\n",
      "Epoch Time (Training + Test) = 9.84 seconds\n",
      "epoch: 59 average loss: 2.306\n",
      "Test Accuracy : 28.3%, Test Loss: 2.2825540117919445\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.29 seconds\n",
      "epoch: 60 average loss: 2.296\n",
      "Test Accuracy : 26.8%, Test Loss: 2.260903399437666\n",
      "Epoch Time (Training + Test) = 9.29 seconds\n",
      "epoch: 61 average loss: 2.296\n",
      "Test Accuracy : 26.2%, Test Loss: 2.3220188207924366\n",
      "Epoch Time (Training + Test) = 9.28 seconds\n",
      "epoch: 62 average loss: 2.286\n",
      "Test Accuracy : 28.1%, Test Loss: 2.270177122205496\n",
      "Epoch Time (Training + Test) = 9.13 seconds\n",
      "epoch: 63 average loss: 2.278\n",
      "Test Accuracy : 25.6%, Test Loss: 2.366622745990753\n",
      "Epoch Time (Training + Test) = 9.42 seconds\n",
      "epoch: 64 average loss: 2.279\n",
      "Test Accuracy : 25.4%, Test Loss: 2.2840002179145813\n",
      "Epoch Time (Training + Test) = 9.57 seconds\n",
      "epoch: 65 average loss: 2.260\n",
      "Test Accuracy : 28.3%, Test Loss: 2.211716655641794\n",
      "Epoch Time (Training + Test) = 9.72 seconds\n",
      "epoch: 66 average loss: 2.250\n",
      "Test Accuracy : 26.2%, Test Loss: 2.3008052706718445\n",
      "Epoch Time (Training + Test) = 9.88 seconds\n",
      "epoch: 67 average loss: 2.245\n",
      "Test Accuracy : 25.9%, Test Loss: 2.3328834287822247\n",
      "Epoch Time (Training + Test) = 9.69 seconds\n",
      "epoch: 68 average loss: 2.233\n",
      "Test Accuracy : 27.6%, Test Loss: 2.2856790348887444\n",
      "Epoch Time (Training + Test) = 9.41 seconds\n",
      "epoch: 69 average loss: 2.236\n",
      "Test Accuracy : 23.3%, Test Loss: 2.3318610712885857\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 70 average loss: 2.239\n",
      "Test Accuracy : 28.6%, Test Loss: 2.2217825949192047\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 71 average loss: 2.213\n",
      "Test Accuracy : 27.7%, Test Loss: 2.24143385887146\n",
      "Epoch Time (Training + Test) = 9.26 seconds\n",
      "epoch: 72 average loss: 2.225\n",
      "Test Accuracy : 28.1%, Test Loss: 2.193086925894022\n",
      "Epoch Time (Training + Test) = 9.28 seconds\n",
      "epoch: 73 average loss: 2.211\n",
      "Test Accuracy : 28.5%, Test Loss: 2.2052149176597595\n",
      "Epoch Time (Training + Test) = 9.36 seconds\n",
      "epoch: 74 average loss: 2.207\n",
      "Test Accuracy : 24.1%, Test Loss: 2.3583152145147324\n",
      "Epoch Time (Training + Test) = 9.64 seconds\n",
      "epoch: 75 average loss: 2.211\n",
      "Test Accuracy : 28.2%, Test Loss: 2.212717220187187\n",
      "Epoch Time (Training + Test) = 9.54 seconds\n",
      "epoch: 76 average loss: 2.203\n",
      "Test Accuracy : 27.4%, Test Loss: 2.244249291718006\n",
      "Epoch Time (Training + Test) = 9.61 seconds\n",
      "epoch: 77 average loss: 2.196\n",
      "Test Accuracy : 28.5%, Test Loss: 2.228097964078188\n",
      "Epoch Time (Training + Test) = 9.26 seconds\n",
      "epoch: 78 average loss: 2.197\n",
      "Test Accuracy : 28.1%, Test Loss: 2.210590999573469\n",
      "Epoch Time (Training + Test) = 9.09 seconds\n",
      "epoch: 79 average loss: 2.192\n",
      "Test Accuracy : 30.8%, Test Loss: 2.187028970569372\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.37 seconds\n",
      "epoch: 80 average loss: 2.191\n",
      "Test Accuracy : 31.3%, Test Loss: 2.168311085551977\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.30 seconds\n",
      "epoch: 81 average loss: 2.180\n",
      "Test Accuracy : 27.7%, Test Loss: 2.240348231047392\n",
      "Epoch Time (Training + Test) = 9.44 seconds\n",
      "epoch: 82 average loss: 2.160\n",
      "Test Accuracy : 27.7%, Test Loss: 2.304042913019657\n",
      "Epoch Time (Training + Test) = 9.50 seconds\n",
      "epoch: 83 average loss: 2.165\n",
      "Test Accuracy : 29.0%, Test Loss: 2.173546176403761\n",
      "Epoch Time (Training + Test) = 9.61 seconds\n",
      "epoch: 84 average loss: 2.159\n",
      "Test Accuracy : 28.2%, Test Loss: 2.3284000642597675\n",
      "Epoch Time (Training + Test) = 9.86 seconds\n",
      "epoch: 85 average loss: 2.150\n",
      "Test Accuracy : 28.8%, Test Loss: 2.2067770063877106\n",
      "Epoch Time (Training + Test) = 10.16 seconds\n",
      "epoch: 86 average loss: 2.141\n",
      "Test Accuracy : 29.5%, Test Loss: 2.1814291290938854\n",
      "Epoch Time (Training + Test) = 9.44 seconds\n",
      "epoch: 87 average loss: 2.136\n",
      "Test Accuracy : 30.8%, Test Loss: 2.13038482144475\n",
      "Epoch Time (Training + Test) = 9.32 seconds\n",
      "epoch: 88 average loss: 2.132\n",
      "Test Accuracy : 31.3%, Test Loss: 2.1447534561157227\n",
      "Epoch Time (Training + Test) = 9.33 seconds\n",
      "epoch: 89 average loss: 2.125\n",
      "Test Accuracy : 31.8%, Test Loss: 2.1123679764568806\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.34 seconds\n",
      "epoch: 90 average loss: 2.132\n",
      "Test Accuracy : 29.8%, Test Loss: 2.1501139737665653\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 91 average loss: 2.107\n",
      "Test Accuracy : 32.9%, Test Loss: 2.1246433295309544\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.99 seconds\n",
      "epoch: 92 average loss: 2.114\n",
      "Test Accuracy : 29.2%, Test Loss: 2.10260159522295\n",
      "Epoch Time (Training + Test) = 9.95 seconds\n",
      "epoch: 93 average loss: 2.106\n",
      "Test Accuracy : 29.2%, Test Loss: 2.2255085557699203\n",
      "Epoch Time (Training + Test) = 9.71 seconds\n",
      "epoch: 94 average loss: 2.117\n",
      "Test Accuracy : 25.5%, Test Loss: 2.3323116078972816\n",
      "Epoch Time (Training + Test) = 9.82 seconds\n",
      "epoch: 95 average loss: 2.099\n",
      "Test Accuracy : 32.2%, Test Loss: 2.1337302774190903\n",
      "Epoch Time (Training + Test) = 9.76 seconds\n",
      "epoch: 96 average loss: 2.099\n",
      "Test Accuracy : 32.0%, Test Loss: 2.104001570492983\n",
      "Epoch Time (Training + Test) = 9.31 seconds\n",
      "epoch: 97 average loss: 2.096\n",
      "Test Accuracy : 31.9%, Test Loss: 2.1198404505848885\n",
      "Epoch Time (Training + Test) = 9.27 seconds\n",
      "epoch: 98 average loss: 2.101\n",
      "Test Accuracy : 30.3%, Test Loss: 2.128119468688965\n",
      "Epoch Time (Training + Test) = 9.29 seconds\n",
      "epoch: 99 average loss: 2.076\n",
      "Test Accuracy : 34.6%, Test Loss: 2.058044947683811\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 9.24 seconds\n",
      "epoch: 100 average loss: 2.084\n",
      "Test Accuracy : 31.7%, Test Loss: 2.1389814727008343\n",
      "Epoch Time (Training + Test) = 9.57 seconds\n",
      "Data Saved to adp_layer3_full_ft.csv\n",
      "Finished Training: \n",
      "Total Time 0.519804 hours\n",
      " Average Time Per Epoch 18.71 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "PATH = '.\\SavedModels\\Cifar80-20\\Baseline_BNN_Resnet18_inflate_5_2022-10-23 14-35-04\\Baseline_BNN_Resnet18_inflate_5_best_acc.pth'\n",
    "BinCifar5_state_dict = torch.load(PATH,map_location= device)\n",
    "\n",
    "\n",
    "layers = ['layer1','layer2','layer3']\n",
    "channels = [80,160,320]\n",
    "\n",
    "\n",
    "for layer,channel in zip(layers,channels):\n",
    "    for t in ['adp_only','full_ft']:\n",
    "        print(t,layer,channel)\n",
    "        torch.manual_seed(42)\n",
    "        adapter_model = resnet18_adapt(num_classes=80)\n",
    "        adapter_model.load_state_dict(BinCifar5_state_dict)\n",
    "        adapter_model.fc = BinarizeLinear(64*5,20)\n",
    "        adapter_model.bn3 = nn.BatchNorm1d(20)\n",
    "        if t == 'adp_only':\n",
    "            adapter_model.freeze()\n",
    "        conv_adp = conv_adapter(channel,kernel = 1, padding= 0)\n",
    "        adapter_model.add_adapter(after = layer,adapter = conv_adp)\n",
    "        trainer = adapter_Trainer(model = adapter_model,seed = 123,model_name = f'adp_{layer}_{t}',project_name = 'Cifar80-20',classes = classes,binarise= True)\n",
    "        m = trainer.model\n",
    "        m.to(trainer.device)\n",
    "        for head in [m.fc,m.bn2,m.bn3]:\n",
    "            for p in head.parameters():\n",
    "                p.requires_grad = True\n",
    "            head.train()\n",
    "        trainer.lr = 0.01\n",
    "        trainer.batch_size = 64\n",
    "        trainer.epochs =100\n",
    "        trainer.epoch_chkpts = []\n",
    "        trainer.start_epoch = 0\n",
    "        # trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max= trainer.epochs)\n",
    "        trainer.tags = ['finetune',f'Training: {t}',f'Adpater Location {layer}']\n",
    "        trainer.train(train20_loader,test20_loader,group = 'Adapter Location Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a140d433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c03a52b9f0405c83677feae72e2472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch time (s)</td><td>â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆ</td></tr><tr><td>lr</td><td>â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–‚â–â–â–â–‚â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–„â–ƒâ–‚â–â–â–‚â–‚â–„â–…â–‡â–‡â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–‚â–â–</td></tr><tr><td>test_accuracy</td><td>â–â–‚â–‚â–ƒâ–â–„â–ƒâ–„â–ƒâ–„â–„â–„â–…â–„â–…â–…â–…â–…â–†â–…â–†â–†â–†â–†â–‡â–†â–‡â–†â–‡â–†â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–†â–ˆâ–ˆ</td></tr><tr><td>test_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>training_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.346</td></tr><tr><td>Current Best Acc</td><td>0.346</td></tr><tr><td>Total Time (hours)</td><td>0.5198</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>9.56599</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>test_accuracy</td><td>0.317</td></tr><tr><td>test_loss</td><td>2.13898</td></tr><tr><td>training_loss</td><td>2.08443</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">noble-eon-23</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar80-20/runs/2f7rrjh9\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar80-20/runs/2f7rrjh9</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221024_181837-2f7rrjh9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0252f580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.1048, -10.0902, -42.1078,  -0.1369,  -2.0739]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = resnet18_adapt(num_classes=5)\n",
    "\n",
    "b.eval()\n",
    "x = torch.rand((1,3,32,32))\n",
    "\n",
    "b(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1600d878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): BinarizeConv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (tanh1): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "    (conv2): BinarizeConv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (tanh2): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "    (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): BinarizeConv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (tanh1): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "    (conv2): BinarizeConv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (tanh2): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)\n",
       "    (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.layer1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73a11b",
   "metadata": {},
   "source": [
    "# Adapters with init at zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8600fe1d",
   "metadata": {},
   "source": [
    "## Adp Only Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "PATH = '.\\SavedModels\\Cifar5\\Baseline_BNN_Resnet18_2022_10_21_10_47_20\\Baseline_BNN_Resnet18_best_acc.pth'\n",
    "BinCifar5_state_dict = torch.load(PATH,map_location= device)\n",
    "\n",
    "\n",
    "layers = ['layer1','layer2','layer3']\n",
    "channels = [80,160,320]\n",
    "\n",
    "\n",
    "for layer,channel in zip(layers,channels):\n",
    "    for t in ['adp_only']:\n",
    "        print(t,layer,channel)\n",
    "        torch.manual_seed(42)\n",
    "        adapter_model = resnet18_adapt(num_classes=5)\n",
    "        adapter_model.load_state_dict(BinCifar5_state_dict)\n",
    "        \n",
    "        if t == 'adp_only':\n",
    "            adapter_model.freeze()\n",
    "        conv_adp = conv_adapter(channel,kernel = 1, padding= 0)\n",
    "        conv_adp.init_weight_zeros()\n",
    "\n",
    "        adapter_model.add_adapter(after = layer,adapter = conv_adp)\n",
    "        trainer = adapter_Trainer(model = adapter_model,seed = 123,model_name = f'adp_{layer}_{t}',project_name = 'Cifar5',classes = classes,binarise= True)\n",
    "        m = trainer.model\n",
    "        m.to(trainer.device)\n",
    "        for head in [m.fc,m.bn3,m.bn3]:\n",
    "            for p in head.parameters():\n",
    "                p.requires_grad = True\n",
    "            head.train()\n",
    "        trainer.lr = 0.01\n",
    "        trainer.batch_size = 32\n",
    "        trainer.epochs =100\n",
    "        trainer.epoch_chkpts = []\n",
    "        trainer.start_epoch = 0\n",
    "        # trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max= trainer.epochs)\n",
    "        trainer.tags = ['finetune',f'Training: {t}',f'Adpater Location {layer}']\n",
    "        trainer.train(train59_loader,test59_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eff35e",
   "metadata": {},
   "source": [
    "## Adp = FullFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b87f695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_ft layer1 80\n",
      "Scheduler Set {'T_max': 10, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnny_suu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221022_110118-1zn2a2fd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/1zn2a2fd\" target=\"_blank\">major-sound-29</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name adp_layer1_full_ft \n",
      "\n",
      "\n",
      "Run Start : 2022-10-22 11-01-15\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4343135\n",
      "Initial accuracy:\n",
      "Test Accuracy : 20.0%, Test Loss: 3.4470722077752622\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 20.0%, Test Loss: 3.447869495967465\n",
      "epoch: 1 average loss: 1.141\n",
      "Test Accuracy : 60.0%, Test Loss: 0.9797220431325381\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 43.38 seconds\n",
      "epoch: 2 average loss: 0.953\n",
      "Test Accuracy : 66.2%, Test Loss: 0.8494304965828996\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 43.26 seconds\n",
      "epoch: 3 average loss: 0.871\n",
      "Test Accuracy : 67.8%, Test Loss: 0.817934007290989\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 43.13 seconds\n",
      "epoch: 4 average loss: 0.824\n",
      "Test Accuracy : 70.7%, Test Loss: 0.7592351189659684\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 43.93 seconds\n",
      "epoch: 5 average loss: 0.798\n",
      "Test Accuracy : 69.8%, Test Loss: 0.7710752542061574\n",
      "Epoch Time (Training + Test) = 41.45 seconds\n",
      "epoch: 6 average loss: 0.771\n",
      "Test Accuracy : 73.1%, Test Loss: 0.7033898546872541\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 42.34 seconds\n",
      "epoch: 7 average loss: 0.764\n",
      "Test Accuracy : 73.1%, Test Loss: 0.7055718950603319\n",
      "Epoch Time (Training + Test) = 42.17 seconds\n",
      "epoch: 8 average loss: 0.750\n",
      "Test Accuracy : 73.7%, Test Loss: 0.689567197238088\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 42.16 seconds\n",
      "epoch: 9 average loss: 0.727\n",
      "Test Accuracy : 73.6%, Test Loss: 0.6864552039776921\n",
      "Epoch Time (Training + Test) = 42.81 seconds\n",
      "epoch: 10 average loss: 0.737\n",
      "Test Accuracy : 73.9%, Test Loss: 0.6821067937652169\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 41.60 seconds\n",
      "epoch: 11 average loss: 0.732\n",
      "Test Accuracy : 73.9%, Test Loss: 0.6819104419644836\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 42.50 seconds\n",
      "epoch: 12 average loss: 0.735\n",
      "Test Accuracy : 73.7%, Test Loss: 0.6926155402074994\n",
      "Epoch Time (Training + Test) = 42.65 seconds\n",
      "epoch: 13 average loss: 0.731\n",
      "Test Accuracy : 74.3%, Test Loss: 0.6776013782109751\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 44.89 seconds\n",
      "epoch: 14 average loss: 0.730\n",
      "Test Accuracy : 74.4%, Test Loss: 0.6779771685752722\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 44.28 seconds\n",
      "epoch: 15 average loss: 0.736\n",
      "Test Accuracy : 74.8%, Test Loss: 0.666006154492688\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 41.67 seconds\n",
      "epoch: 16 average loss: 0.742\n",
      "Test Accuracy : 72.2%, Test Loss: 0.7074006306545814\n",
      "Epoch Time (Training + Test) = 42.07 seconds\n",
      "epoch: 17 average loss: 0.733\n",
      "Test Accuracy : 72.3%, Test Loss: 0.7153244837165793\n",
      "Epoch Time (Training + Test) = 45.63 seconds\n",
      "epoch: 18 average loss: 0.730\n",
      "Test Accuracy : 71.8%, Test Loss: 0.722078366352774\n",
      "Epoch Time (Training + Test) = 44.90 seconds\n",
      "epoch: 19 average loss: 0.727\n",
      "Test Accuracy : 74.7%, Test Loss: 0.667474450586397\n",
      "Epoch Time (Training + Test) = 42.68 seconds\n",
      "epoch: 20 average loss: 0.731\n",
      "Test Accuracy : 73.9%, Test Loss: 0.6941582337974588\n",
      "Epoch Time (Training + Test) = 41.75 seconds\n",
      "epoch: 21 average loss: 0.728\n",
      "Test Accuracy : 75.9%, Test Loss: 0.6447687373136926\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 42.47 seconds\n",
      "epoch: 22 average loss: 0.731\n",
      "Test Accuracy : 74.3%, Test Loss: 0.6822717265247384\n",
      "Epoch Time (Training + Test) = 42.29 seconds\n",
      "epoch: 23 average loss: 0.735\n",
      "Test Accuracy : 67.3%, Test Loss: 0.949659354851374\n",
      "Epoch Time (Training + Test) = 43.16 seconds\n",
      "epoch: 24 average loss: 0.717\n",
      "Test Accuracy : 69.9%, Test Loss: 0.802374400141294\n",
      "Epoch Time (Training + Test) = 43.09 seconds\n",
      "epoch: 25 average loss: 0.702\n",
      "Test Accuracy : 75.2%, Test Loss: 0.659483465849591\n",
      "Epoch Time (Training + Test) = 42.88 seconds\n",
      "epoch: 26 average loss: 0.698\n",
      "Test Accuracy : 75.7%, Test Loss: 0.6545855486027116\n",
      "Epoch Time (Training + Test) = 42.31 seconds\n",
      "epoch: 27 average loss: 0.685\n",
      "Test Accuracy : 76.6%, Test Loss: 0.6198382087223365\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 42.97 seconds\n",
      "epoch: 28 average loss: 0.685\n",
      "Test Accuracy : 75.4%, Test Loss: 0.6508847502491358\n",
      "Epoch Time (Training + Test) = 43.33 seconds\n",
      "epoch: 29 average loss: 0.674\n",
      "Test Accuracy : 74.3%, Test Loss: 0.6874965180826309\n",
      "Epoch Time (Training + Test) = 43.65 seconds\n",
      "epoch: 30 average loss: 0.670\n",
      "Test Accuracy : 70.9%, Test Loss: 0.7675002131925519\n",
      "Epoch Time (Training + Test) = 42.72 seconds\n",
      "epoch: 31 average loss: 0.678\n",
      "Test Accuracy : 76.4%, Test Loss: 0.6196239169906167\n",
      "Epoch Time (Training + Test) = 43.38 seconds\n",
      "epoch: 32 average loss: 0.672\n",
      "Test Accuracy : 66.8%, Test Loss: 0.8854620436878156\n",
      "Epoch Time (Training + Test) = 43.67 seconds\n",
      "epoch: 33 average loss: 0.679\n",
      "Test Accuracy : 71.8%, Test Loss: 0.7585855525015565\n",
      "Epoch Time (Training + Test) = 43.15 seconds\n",
      "epoch: 34 average loss: 0.673\n",
      "Test Accuracy : 75.2%, Test Loss: 0.6597185594498959\n",
      "Epoch Time (Training + Test) = 43.63 seconds\n",
      "epoch: 35 average loss: 0.678\n",
      "Test Accuracy : 70.1%, Test Loss: 0.8039166474586252\n",
      "Epoch Time (Training + Test) = 42.34 seconds\n",
      "epoch: 36 average loss: 0.686\n",
      "Test Accuracy : 75.7%, Test Loss: 0.6400489434409324\n",
      "Epoch Time (Training + Test) = 43.15 seconds\n",
      "epoch: 37 average loss: 0.689\n",
      "Test Accuracy : 74.3%, Test Loss: 0.6675808962501223\n",
      "Epoch Time (Training + Test) = 42.19 seconds\n",
      "epoch: 38 average loss: 0.688\n",
      "Test Accuracy : 73.0%, Test Loss: 0.72301864974639\n",
      "Epoch Time (Training + Test) = 42.00 seconds\n",
      "epoch: 39 average loss: 0.689\n",
      "Test Accuracy : 73.1%, Test Loss: 0.7115032466323784\n",
      "Epoch Time (Training + Test) = 42.50 seconds\n",
      "epoch: 40 average loss: 0.691\n",
      "Test Accuracy : 64.7%, Test Loss: 0.9713802945888256\n",
      "Epoch Time (Training + Test) = 42.29 seconds\n",
      "epoch: 41 average loss: 0.677\n",
      "Test Accuracy : 71.4%, Test Loss: 0.7736101433291764\n",
      "Epoch Time (Training + Test) = 43.37 seconds\n",
      "epoch: 42 average loss: 0.691\n",
      "Test Accuracy : 75.8%, Test Loss: 0.6370388363175989\n",
      "Epoch Time (Training + Test) = 42.99 seconds\n",
      "epoch: 43 average loss: 0.677\n",
      "Test Accuracy : 74.0%, Test Loss: 0.7002902128507414\n",
      "Epoch Time (Training + Test) = 43.15 seconds\n",
      "epoch: 44 average loss: 0.677\n",
      "Test Accuracy : 72.7%, Test Loss: 0.7349908226896125\n",
      "Epoch Time (Training + Test) = 44.02 seconds\n",
      "epoch: 45 average loss: 0.663\n",
      "Test Accuracy : 75.0%, Test Loss: 0.6764023404597016\n",
      "Epoch Time (Training + Test) = 43.44 seconds\n",
      "epoch: 46 average loss: 0.664\n",
      "Test Accuracy : 75.1%, Test Loss: 0.6714050682152019\n",
      "Epoch Time (Training + Test) = 43.82 seconds\n",
      "epoch: 47 average loss: 0.658\n",
      "Test Accuracy : 76.4%, Test Loss: 0.6334294684402778\n",
      "Epoch Time (Training + Test) = 44.22 seconds\n",
      "epoch: 48 average loss: 0.652\n",
      "Test Accuracy : 72.2%, Test Loss: 0.7388172443870389\n",
      "Epoch Time (Training + Test) = 43.59 seconds\n",
      "epoch: 49 average loss: 0.653\n",
      "Test Accuracy : 75.5%, Test Loss: 0.6662671514179396\n",
      "Epoch Time (Training + Test) = 44.67 seconds\n",
      "epoch: 50 average loss: 0.648\n",
      "Test Accuracy : 76.3%, Test Loss: 0.6569515600076417\n",
      "Epoch Time (Training + Test) = 45.73 seconds\n",
      "epoch: 51 average loss: 0.650\n",
      "Test Accuracy : 78.6%, Test Loss: 0.5798017737048361\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 44.34 seconds\n",
      "epoch: 52 average loss: 0.637\n",
      "Test Accuracy : 77.9%, Test Loss: 0.593519253117959\n",
      "Epoch Time (Training + Test) = 43.60 seconds\n",
      "epoch: 53 average loss: 0.645\n",
      "Test Accuracy : 76.3%, Test Loss: 0.6330771903552668\n",
      "Epoch Time (Training + Test) = 44.00 seconds\n",
      "epoch: 54 average loss: 0.650\n",
      "Test Accuracy : 77.1%, Test Loss: 0.6202415805643476\n",
      "Epoch Time (Training + Test) = 45.58 seconds\n",
      "epoch: 55 average loss: 0.655\n",
      "Test Accuracy : 73.9%, Test Loss: 0.7007920700113487\n",
      "Epoch Time (Training + Test) = 45.70 seconds\n",
      "epoch: 56 average loss: 0.668\n",
      "Test Accuracy : 77.1%, Test Loss: 0.6252354009986838\n",
      "Epoch Time (Training + Test) = 45.16 seconds\n",
      "epoch: 57 average loss: 0.676\n",
      "Test Accuracy : 72.1%, Test Loss: 0.750788888434315\n",
      "Epoch Time (Training + Test) = 44.12 seconds\n",
      "epoch: 58 average loss: 0.674\n",
      "Test Accuracy : 75.9%, Test Loss: 0.645004177794737\n",
      "Epoch Time (Training + Test) = 43.81 seconds\n",
      "epoch: 59 average loss: 0.671\n",
      "Test Accuracy : 76.3%, Test Loss: 0.6302368171379694\n",
      "Epoch Time (Training + Test) = 44.50 seconds\n",
      "epoch: 60 average loss: 0.679\n",
      "Test Accuracy : 75.7%, Test Loss: 0.654377823824163\n",
      "Epoch Time (Training + Test) = 45.21 seconds\n",
      "epoch: 61 average loss: 0.664\n",
      "Test Accuracy : 72.1%, Test Loss: 0.7516379544649587\n",
      "Epoch Time (Training + Test) = 44.76 seconds\n",
      "epoch: 62 average loss: 0.665\n",
      "Test Accuracy : 57.9%, Test Loss: 1.1752790663858204\n",
      "Epoch Time (Training + Test) = 42.86 seconds\n",
      "epoch: 63 average loss: 0.670\n",
      "Test Accuracy : 68.0%, Test Loss: 0.859788920644604\n",
      "Epoch Time (Training + Test) = 42.97 seconds\n",
      "epoch: 64 average loss: 0.679\n",
      "Test Accuracy : 71.9%, Test Loss: 0.7505883688816939\n",
      "Epoch Time (Training + Test) = 44.11 seconds\n",
      "epoch: 65 average loss: 0.675\n",
      "Test Accuracy : 72.2%, Test Loss: 0.7571672864277345\n",
      "Epoch Time (Training + Test) = 45.18 seconds\n",
      "epoch: 66 average loss: 0.658\n",
      "Test Accuracy : 75.0%, Test Loss: 0.6878328635869428\n",
      "Epoch Time (Training + Test) = 44.31 seconds\n",
      "epoch: 67 average loss: 0.651\n",
      "Test Accuracy : 70.8%, Test Loss: 0.8104519568898184\n",
      "Epoch Time (Training + Test) = 43.61 seconds\n",
      "epoch: 68 average loss: 0.650\n",
      "Test Accuracy : 76.3%, Test Loss: 0.6480403445718234\n",
      "Epoch Time (Training + Test) = 43.21 seconds\n",
      "epoch: 69 average loss: 0.650\n",
      "Test Accuracy : 76.0%, Test Loss: 0.6453861158217311\n",
      "Epoch Time (Training + Test) = 43.11 seconds\n",
      "epoch: 70 average loss: 0.641\n",
      "Test Accuracy : 76.0%, Test Loss: 0.6426589375414202\n",
      "Epoch Time (Training + Test) = 42.43 seconds\n",
      "epoch: 71 average loss: 0.639\n",
      "Test Accuracy : 76.1%, Test Loss: 0.643975232034693\n",
      "Epoch Time (Training + Test) = 42.86 seconds\n",
      "epoch: 72 average loss: 0.638\n",
      "Test Accuracy : 72.3%, Test Loss: 0.7452826826163875\n",
      "Epoch Time (Training + Test) = 42.63 seconds\n",
      "epoch: 73 average loss: 0.634\n",
      "Test Accuracy : 72.7%, Test Loss: 0.7263195307358451\n",
      "Epoch Time (Training + Test) = 42.96 seconds\n",
      "epoch: 74 average loss: 0.642\n",
      "Test Accuracy : 71.5%, Test Loss: 0.7756693117758807\n",
      "Epoch Time (Training + Test) = 43.71 seconds\n",
      "epoch: 75 average loss: 0.661\n",
      "Test Accuracy : 71.6%, Test Loss: 0.7478178160269852\n",
      "Epoch Time (Training + Test) = 43.64 seconds\n",
      "epoch: 76 average loss: 0.657\n",
      "Test Accuracy : 68.9%, Test Loss: 0.8359276147754601\n",
      "Epoch Time (Training + Test) = 44.29 seconds\n",
      "epoch: 77 average loss: 0.674\n",
      "Test Accuracy : 67.2%, Test Loss: 0.8941286764181483\n",
      "Epoch Time (Training + Test) = 43.59 seconds\n",
      "epoch: 78 average loss: 0.671\n",
      "Test Accuracy : 72.6%, Test Loss: 0.6898305437448994\n",
      "Epoch Time (Training + Test) = 43.77 seconds\n",
      "epoch: 79 average loss: 0.680\n",
      "Test Accuracy : 64.4%, Test Loss: 0.8824624360522346\n",
      "Epoch Time (Training + Test) = 43.35 seconds\n",
      "epoch: 80 average loss: 0.677\n",
      "Test Accuracy : 73.7%, Test Loss: 0.7231308173035722\n",
      "Epoch Time (Training + Test) = 43.90 seconds\n",
      "epoch: 81 average loss: 0.676\n",
      "Test Accuracy : 70.3%, Test Loss: 0.790227885441402\n",
      "Epoch Time (Training + Test) = 42.97 seconds\n",
      "epoch: 82 average loss: 0.677\n",
      "Test Accuracy : 77.4%, Test Loss: 0.6032066227072646\n",
      "Epoch Time (Training + Test) = 44.08 seconds\n",
      "epoch: 83 average loss: 0.671\n",
      "Test Accuracy : 73.3%, Test Loss: 0.7409182212999105\n",
      "Epoch Time (Training + Test) = 35.54 seconds\n",
      "epoch: 84 average loss: 0.680\n",
      "Test Accuracy : 74.1%, Test Loss: 0.6911926902925877\n",
      "Epoch Time (Training + Test) = 41.72 seconds\n",
      "epoch: 85 average loss: 0.674\n",
      "Test Accuracy : 66.2%, Test Loss: 0.9202501493341783\n",
      "Epoch Time (Training + Test) = 41.15 seconds\n",
      "epoch: 86 average loss: 0.664\n",
      "Test Accuracy : 73.4%, Test Loss: 0.7258697975322109\n",
      "Epoch Time (Training + Test) = 41.28 seconds\n",
      "epoch: 87 average loss: 0.661\n",
      "Test Accuracy : 77.3%, Test Loss: 0.6080783856341906\n",
      "Epoch Time (Training + Test) = 40.26 seconds\n",
      "epoch: 88 average loss: 0.663\n",
      "Test Accuracy : 75.7%, Test Loss: 0.6619959304399807\n",
      "Epoch Time (Training + Test) = 39.16 seconds\n",
      "epoch: 89 average loss: 0.648\n",
      "Test Accuracy : 75.9%, Test Loss: 0.643468465494073\n",
      "Epoch Time (Training + Test) = 39.32 seconds\n",
      "epoch: 90 average loss: 0.645\n",
      "Test Accuracy : 77.5%, Test Loss: 0.6165492180973062\n",
      "Epoch Time (Training + Test) = 38.98 seconds\n",
      "epoch: 91 average loss: 0.649\n",
      "Test Accuracy : 76.4%, Test Loss: 0.6481567139515791\n",
      "Epoch Time (Training + Test) = 40.03 seconds\n",
      "epoch: 92 average loss: 0.658\n",
      "Test Accuracy : 72.8%, Test Loss: 0.7345370606083395\n",
      "Epoch Time (Training + Test) = 40.46 seconds\n",
      "epoch: 93 average loss: 0.651\n",
      "Test Accuracy : 70.4%, Test Loss: 0.78716341164106\n",
      "Epoch Time (Training + Test) = 39.33 seconds\n",
      "epoch: 94 average loss: 0.666\n",
      "Test Accuracy : 77.7%, Test Loss: 0.5989183320871094\n",
      "Epoch Time (Training + Test) = 39.03 seconds\n",
      "epoch: 95 average loss: 0.655\n",
      "Test Accuracy : 72.8%, Test Loss: 0.7241301265976313\n",
      "Epoch Time (Training + Test) = 38.89 seconds\n",
      "epoch: 96 average loss: 0.662\n",
      "Test Accuracy : 75.3%, Test Loss: 0.6530256673807988\n",
      "Epoch Time (Training + Test) = 38.87 seconds\n",
      "epoch: 97 average loss: 0.670\n",
      "Test Accuracy : 73.2%, Test Loss: 0.7534217189644914\n",
      "Epoch Time (Training + Test) = 38.88 seconds\n",
      "epoch: 98 average loss: 0.676\n",
      "Test Accuracy : 73.6%, Test Loss: 0.7085547283329927\n",
      "Epoch Time (Training + Test) = 38.83 seconds\n",
      "epoch: 99 average loss: 0.687\n",
      "Test Accuracy : 68.2%, Test Loss: 0.9818193385058351\n",
      "Epoch Time (Training + Test) = 38.94 seconds\n",
      "epoch: 100 average loss: 0.693\n",
      "Test Accuracy : 71.5%, Test Loss: 0.7787427047024602\n",
      "Epoch Time (Training + Test) = 39.04 seconds\n",
      "Data Saved to adp_layer1_full_ft.csv\n",
      "Finished Training: \n",
      "Total Time 2.371914 hours\n",
      " Average Time Per Epoch 85.39 seconds\n",
      "full_ft layer2 160\n",
      "Scheduler Set {'T_max': 10, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1zn2a2fd) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>â–â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch time (s)</td><td>â–â–‡â–†â–‡â–†â–‡â–†â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–†â–…â–…â–…</td></tr><tr><td>lr</td><td>â–ˆâ–‡â–…â–‚â–â–‚â–…â–‡â–ˆâ–‡â–…â–‚â–â–‚â–…â–‡â–ˆâ–‡â–ƒâ–‚â–â–‚â–†â–‡â–ˆâ–†â–ƒâ–â–â–ƒâ–†â–ˆâ–‡â–†â–‚â–â–‚â–ƒâ–‡â–ˆ</td></tr><tr><td>test_accuracy</td><td>â–â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡</td></tr><tr><td>test_loss</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–</td></tr><tr><td>training_loss</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.7858</td></tr><tr><td>Current Best Acc</td><td>0.7858</td></tr><tr><td>Total Time (hours)</td><td>2.37191</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>39.03697</td></tr><tr><td>lr</td><td>0.1</td></tr><tr><td>test_accuracy</td><td>0.71536</td></tr><tr><td>test_loss</td><td>0.77874</td></tr><tr><td>training_loss</td><td>0.69345</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">major-sound-29</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/1zn2a2fd\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar5/runs/1zn2a2fd</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221022_110118-1zn2a2fd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1zn2a2fd). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4522a45fd2ef42d29371faf7c53aba39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333357344, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221022_121259-3fqr98om</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/3fqr98om\" target=\"_blank\">warm-tree-31</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name adp_layer2_full_ft \n",
      "\n",
      "\n",
      "Run Start : 2022-10-22 12-12-59\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4362655\n",
      "Initial accuracy:\n",
      "Test Accuracy : 20.0%, Test Loss: 3.993683311335571\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 20.0%, Test Loss: 3.9929843113550443\n",
      "epoch: 1 average loss: 1.046\n",
      "Test Accuracy : 61.1%, Test Loss: 0.9781214172577919\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.58 seconds\n",
      "epoch: 2 average loss: 0.885\n",
      "Test Accuracy : 65.7%, Test Loss: 0.8972264279794815\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.83 seconds\n",
      "epoch: 3 average loss: 0.851\n",
      "Test Accuracy : 60.5%, Test Loss: 1.0736043549254728\n",
      "Epoch Time (Training + Test) = 38.64 seconds\n",
      "epoch: 4 average loss: 0.811\n",
      "Test Accuracy : 67.5%, Test Loss: 0.8402391516644022\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.52 seconds\n",
      "epoch: 5 average loss: 0.804\n",
      "Test Accuracy : 72.1%, Test Loss: 0.7358404968095862\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.75 seconds\n",
      "epoch: 6 average loss: 0.740\n",
      "Test Accuracy : 73.3%, Test Loss: 0.7083923257982639\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.55 seconds\n",
      "epoch: 7 average loss: 0.729\n",
      "Test Accuracy : 74.4%, Test Loss: 0.6883392665544739\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.75 seconds\n",
      "epoch: 8 average loss: 0.719\n",
      "Test Accuracy : 68.8%, Test Loss: 0.8693330776508507\n",
      "Epoch Time (Training + Test) = 38.75 seconds\n",
      "epoch: 9 average loss: 0.704\n",
      "Test Accuracy : 75.4%, Test Loss: 0.6611982493296914\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.67 seconds\n",
      "epoch: 10 average loss: 0.699\n",
      "Test Accuracy : 74.3%, Test Loss: 0.6897854936854614\n",
      "Epoch Time (Training + Test) = 39.34 seconds\n",
      "epoch: 11 average loss: 0.697\n",
      "Test Accuracy : 73.0%, Test Loss: 0.7290918125825769\n",
      "Epoch Time (Training + Test) = 40.26 seconds\n",
      "epoch: 12 average loss: 0.695\n",
      "Test Accuracy : 73.8%, Test Loss: 0.7063579096666077\n",
      "Epoch Time (Training + Test) = 40.34 seconds\n",
      "epoch: 13 average loss: 0.698\n",
      "Test Accuracy : 74.2%, Test Loss: 0.6947123765792993\n",
      "Epoch Time (Training + Test) = 39.52 seconds\n",
      "epoch: 14 average loss: 0.693\n",
      "Test Accuracy : 71.7%, Test Loss: 0.765331728684018\n",
      "Epoch Time (Training + Test) = 38.74 seconds\n",
      "epoch: 15 average loss: 0.702\n",
      "Test Accuracy : 75.7%, Test Loss: 0.6583505567077481\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.74 seconds\n",
      "epoch: 16 average loss: 0.709\n",
      "Test Accuracy : 74.2%, Test Loss: 0.6935619285801793\n",
      "Epoch Time (Training + Test) = 38.89 seconds\n",
      "epoch: 17 average loss: 0.718\n",
      "Test Accuracy : 64.4%, Test Loss: 1.026004981811699\n",
      "Epoch Time (Training + Test) = 38.44 seconds\n",
      "epoch: 18 average loss: 0.720\n",
      "Test Accuracy : 65.9%, Test Loss: 0.9268099403442325\n",
      "Epoch Time (Training + Test) = 38.96 seconds\n",
      "epoch: 19 average loss: 0.728\n",
      "Test Accuracy : 67.0%, Test Loss: 0.908205540131425\n",
      "Epoch Time (Training + Test) = 38.78 seconds\n",
      "epoch: 20 average loss: 0.719\n",
      "Test Accuracy : 69.3%, Test Loss: 0.8304747397180103\n",
      "Epoch Time (Training + Test) = 38.74 seconds\n",
      "epoch: 21 average loss: 0.720\n",
      "Test Accuracy : 66.3%, Test Loss: 1.04302647168679\n",
      "Epoch Time (Training + Test) = 38.64 seconds\n",
      "epoch: 22 average loss: 0.738\n",
      "Test Accuracy : 71.3%, Test Loss: 0.7766292913795432\n",
      "Epoch Time (Training + Test) = 38.66 seconds\n",
      "epoch: 23 average loss: 0.716\n",
      "Test Accuracy : 57.4%, Test Loss: 1.245190014467215\n",
      "Epoch Time (Training + Test) = 38.72 seconds\n",
      "epoch: 24 average loss: 0.699\n",
      "Test Accuracy : 65.8%, Test Loss: 0.9822959084340068\n",
      "Epoch Time (Training + Test) = 38.63 seconds\n",
      "epoch: 25 average loss: 0.688\n",
      "Test Accuracy : 73.8%, Test Loss: 0.7134925024131374\n",
      "Epoch Time (Training + Test) = 38.70 seconds\n",
      "epoch: 26 average loss: 0.685\n",
      "Test Accuracy : 75.7%, Test Loss: 0.6581566352825945\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.72 seconds\n",
      "epoch: 27 average loss: 0.665\n",
      "Test Accuracy : 76.1%, Test Loss: 0.6372614405344209\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.69 seconds\n",
      "epoch: 28 average loss: 0.651\n",
      "Test Accuracy : 76.0%, Test Loss: 0.6404556439965582\n",
      "Epoch Time (Training + Test) = 38.66 seconds\n",
      "epoch: 29 average loss: 0.645\n",
      "Test Accuracy : 75.2%, Test Loss: 0.6740560915768908\n",
      "Epoch Time (Training + Test) = 38.86 seconds\n",
      "epoch: 30 average loss: 0.643\n",
      "Test Accuracy : 77.1%, Test Loss: 0.6324832840724979\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.79 seconds\n",
      "epoch: 31 average loss: 0.664\n",
      "Test Accuracy : 72.7%, Test Loss: 0.778345673590365\n",
      "Epoch Time (Training + Test) = 38.98 seconds\n",
      "epoch: 32 average loss: 0.642\n",
      "Test Accuracy : 76.1%, Test Loss: 0.6578053650648698\n",
      "Epoch Time (Training + Test) = 38.83 seconds\n",
      "epoch: 33 average loss: 0.647\n",
      "Test Accuracy : 77.1%, Test Loss: 0.6125905640289911\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.54 seconds\n",
      "epoch: 34 average loss: 0.639\n",
      "Test Accuracy : 72.6%, Test Loss: 0.7247882405357897\n",
      "Epoch Time (Training + Test) = 38.81 seconds\n",
      "epoch: 35 average loss: 0.647\n",
      "Test Accuracy : 77.6%, Test Loss: 0.6078407653914694\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 38.59 seconds\n",
      "epoch: 36 average loss: 0.664\n",
      "Test Accuracy : 67.0%, Test Loss: 0.9577317678410074\n",
      "Epoch Time (Training + Test) = 38.68 seconds\n",
      "epoch: 37 average loss: 0.697\n",
      "Test Accuracy : 60.1%, Test Loss: 1.2937241408526134\n",
      "Epoch Time (Training + Test) = 38.57 seconds\n",
      "epoch: 38 average loss: 0.688\n",
      "Test Accuracy : 72.1%, Test Loss: 0.7542890727215106\n",
      "Epoch Time (Training + Test) = 38.64 seconds\n",
      "epoch: 39 average loss: 0.689\n",
      "Test Accuracy : 70.2%, Test Loss: 0.819651074497901\n",
      "Epoch Time (Training + Test) = 39.08 seconds\n",
      "epoch: 40 average loss: 0.719\n",
      "Test Accuracy : 68.2%, Test Loss: 0.83909550583576\n",
      "Epoch Time (Training + Test) = 39.72 seconds\n",
      "epoch: 41 average loss: 0.701\n",
      "Test Accuracy : 66.6%, Test Loss: 0.9160777729795412\n",
      "Epoch Time (Training + Test) = 41.29 seconds\n",
      "epoch: 42 average loss: 0.730\n",
      "Test Accuracy : 58.4%, Test Loss: 1.2015427379961818\n",
      "Epoch Time (Training + Test) = 40.66 seconds\n",
      "epoch: 43 average loss: 0.725\n",
      "Test Accuracy : 68.3%, Test Loss: 0.8428987238718115\n",
      "Epoch Time (Training + Test) = 40.75 seconds\n",
      "epoch: 44 average loss: 0.713\n",
      "Test Accuracy : 75.7%, Test Loss: 0.6463866819201223\n",
      "Epoch Time (Training + Test) = 41.27 seconds\n",
      "epoch: 45 average loss: 0.706\n",
      "Test Accuracy : 73.2%, Test Loss: 0.7577545496508898\n",
      "Epoch Time (Training + Test) = 39.72 seconds\n",
      "epoch: 46 average loss: 0.681\n",
      "Test Accuracy : 75.5%, Test Loss: 0.670187520401557\n",
      "Epoch Time (Training + Test) = 40.12 seconds\n",
      "epoch: 47 average loss: 0.657\n",
      "Test Accuracy : 71.5%, Test Loss: 0.764506186823101\n",
      "Epoch Time (Training + Test) = 41.09 seconds\n",
      "epoch: 48 average loss: 0.650\n",
      "Test Accuracy : 71.4%, Test Loss: 0.7947796920833685\n",
      "Epoch Time (Training + Test) = 40.62 seconds\n",
      "epoch: 49 average loss: 0.633\n",
      "Test Accuracy : 74.6%, Test Loss: 0.6858070574300673\n",
      "Epoch Time (Training + Test) = 40.93 seconds\n",
      "epoch: 50 average loss: 0.638\n",
      "Test Accuracy : 73.2%, Test Loss: 0.7313976148357781\n",
      "Epoch Time (Training + Test) = 40.96 seconds\n",
      "epoch: 51 average loss: 0.624\n",
      "Test Accuracy : 70.6%, Test Loss: 0.8163814437206444\n",
      "Epoch Time (Training + Test) = 41.38 seconds\n",
      "epoch: 52 average loss: 0.627\n",
      "Test Accuracy : 74.4%, Test Loss: 0.6821386778293668\n",
      "Epoch Time (Training + Test) = 41.64 seconds\n",
      "epoch: 53 average loss: 0.630\n",
      "Test Accuracy : 69.0%, Test Loss: 0.8888790576964083\n",
      "Epoch Time (Training + Test) = 40.71 seconds\n",
      "epoch: 54 average loss: 0.640\n",
      "Test Accuracy : 72.1%, Test Loss: 0.773876051235077\n",
      "Epoch Time (Training + Test) = 40.81 seconds\n",
      "epoch: 55 average loss: 0.640\n",
      "Test Accuracy : 71.0%, Test Loss: 0.8137498927848114\n",
      "Epoch Time (Training + Test) = 40.94 seconds\n",
      "epoch: 56 average loss: 0.661\n",
      "Test Accuracy : 68.5%, Test Loss: 0.8621985645550291\n",
      "Epoch Time (Training + Test) = 34.85 seconds\n",
      "epoch: 57 average loss: 0.658\n",
      "Test Accuracy : 64.6%, Test Loss: 0.9969241218188839\n",
      "Epoch Time (Training + Test) = 39.74 seconds\n",
      "epoch: 58 average loss: 0.674\n",
      "Test Accuracy : 74.1%, Test Loss: 0.7097543567952598\n",
      "Epoch Time (Training + Test) = 40.70 seconds\n",
      "epoch: 59 average loss: 0.682\n",
      "Test Accuracy : 72.0%, Test Loss: 0.7466892568808993\n",
      "Epoch Time (Training + Test) = 40.67 seconds\n",
      "epoch: 60 average loss: 0.684\n",
      "Test Accuracy : 71.2%, Test Loss: 0.7220462873921065\n",
      "Epoch Time (Training + Test) = 40.21 seconds\n",
      "epoch: 61 average loss: 0.709\n",
      "Test Accuracy : 69.0%, Test Loss: 0.7870047641227312\n",
      "Epoch Time (Training + Test) = 41.08 seconds\n",
      "epoch: 62 average loss: 0.720\n",
      "Test Accuracy : 75.2%, Test Loss: 0.6592070250712392\n",
      "Epoch Time (Training + Test) = 39.45 seconds\n",
      "epoch: 63 average loss: 0.694\n",
      "Test Accuracy : 56.9%, Test Loss: 1.1631481850238712\n",
      "Epoch Time (Training + Test) = 40.24 seconds\n",
      "epoch: 64 average loss: 0.687\n",
      "Test Accuracy : 69.7%, Test Loss: 0.8450805190426615\n",
      "Epoch Time (Training + Test) = 39.96 seconds\n",
      "epoch: 65 average loss: 0.678\n",
      "Test Accuracy : 73.4%, Test Loss: 0.7303931535509847\n",
      "Epoch Time (Training + Test) = 40.01 seconds\n",
      "epoch: 66 average loss: 0.662\n",
      "Test Accuracy : 77.6%, Test Loss: 0.6043967475824039\n",
      "Epoch Time (Training + Test) = 40.08 seconds\n",
      "epoch: 67 average loss: 0.652\n",
      "Test Accuracy : 75.8%, Test Loss: 0.6530747454032264\n",
      "Epoch Time (Training + Test) = 40.11 seconds\n",
      "epoch: 68 average loss: 0.651\n",
      "Test Accuracy : 70.2%, Test Loss: 0.8228139548045595\n",
      "Epoch Time (Training + Test) = 40.43 seconds\n",
      "epoch: 69 average loss: 0.643\n",
      "Test Accuracy : 70.6%, Test Loss: 0.8480745932025373\n",
      "Epoch Time (Training + Test) = 40.10 seconds\n",
      "epoch: 70 average loss: 0.634\n",
      "Test Accuracy : 75.1%, Test Loss: 0.6741574955413409\n",
      "Epoch Time (Training + Test) = 40.83 seconds\n",
      "epoch: 71 average loss: 0.627\n",
      "Test Accuracy : 74.7%, Test Loss: 0.6789570572736013\n",
      "Epoch Time (Training + Test) = 40.07 seconds\n",
      "epoch: 72 average loss: 0.635\n",
      "Test Accuracy : 73.7%, Test Loss: 0.7300794756473483\n",
      "Epoch Time (Training + Test) = 40.27 seconds\n",
      "epoch: 73 average loss: 0.639\n",
      "Test Accuracy : 71.7%, Test Loss: 0.8034884684226092\n",
      "Epoch Time (Training + Test) = 39.99 seconds\n",
      "epoch: 74 average loss: 0.645\n",
      "Test Accuracy : 74.3%, Test Loss: 0.6813043836894852\n",
      "Epoch Time (Training + Test) = 39.80 seconds\n",
      "epoch: 75 average loss: 0.658\n",
      "Test Accuracy : 77.1%, Test Loss: 0.6173556595659622\n",
      "Epoch Time (Training + Test) = 40.30 seconds\n",
      "epoch: 76 average loss: 0.663\n",
      "Test Accuracy : 69.2%, Test Loss: 0.8410716328931891\n",
      "Epoch Time (Training + Test) = 40.11 seconds\n",
      "epoch: 77 average loss: 0.692\n",
      "Test Accuracy : 53.4%, Test Loss: 1.5256106609578632\n",
      "Epoch Time (Training + Test) = 40.16 seconds\n",
      "epoch: 78 average loss: 0.692\n",
      "Test Accuracy : 58.2%, Test Loss: 1.2559176035549329\n",
      "Epoch Time (Training + Test) = 38.74 seconds\n",
      "epoch: 79 average loss: 0.686\n",
      "Test Accuracy : 52.2%, Test Loss: 1.8078932429823424\n",
      "Epoch Time (Training + Test) = 38.03 seconds\n",
      "epoch: 80 average loss: 0.697\n",
      "Test Accuracy : 71.3%, Test Loss: 0.7751172370160632\n",
      "Epoch Time (Training + Test) = 37.37 seconds\n",
      "epoch: 81 average loss: 0.698\n",
      "Test Accuracy : 61.5%, Test Loss: 1.0267020058448968\n",
      "Epoch Time (Training + Test) = 37.73 seconds\n",
      "epoch: 82 average loss: 0.691\n",
      "Test Accuracy : 64.3%, Test Loss: 0.976080213056501\n",
      "Epoch Time (Training + Test) = 37.89 seconds\n",
      "epoch: 83 average loss: 0.682\n",
      "Test Accuracy : 64.4%, Test Loss: 0.9912579529120794\n",
      "Epoch Time (Training + Test) = 37.62 seconds\n",
      "epoch: 84 average loss: 0.698\n",
      "Test Accuracy : 48.5%, Test Loss: 1.7001107431128812\n",
      "Epoch Time (Training + Test) = 38.01 seconds\n",
      "epoch: 85 average loss: 0.690\n",
      "Test Accuracy : 73.5%, Test Loss: 0.7400028799348475\n",
      "Epoch Time (Training + Test) = 37.09 seconds\n",
      "epoch: 86 average loss: 0.682\n",
      "Test Accuracy : 69.6%, Test Loss: 0.8835780699082347\n",
      "Epoch Time (Training + Test) = 38.05 seconds\n",
      "epoch: 87 average loss: 0.677\n",
      "Test Accuracy : 72.7%, Test Loss: 0.7465196781603577\n",
      "Epoch Time (Training + Test) = 37.59 seconds\n",
      "epoch: 88 average loss: 0.658\n",
      "Test Accuracy : 64.0%, Test Loss: 1.1172261634446166\n",
      "Epoch Time (Training + Test) = 37.57 seconds\n",
      "epoch: 89 average loss: 0.650\n",
      "Test Accuracy : 72.7%, Test Loss: 0.7892400917342252\n",
      "Epoch Time (Training + Test) = 37.90 seconds\n",
      "epoch: 90 average loss: 0.635\n",
      "Test Accuracy : 67.8%, Test Loss: 0.9385611658815838\n",
      "Epoch Time (Training + Test) = 37.39 seconds\n",
      "epoch: 91 average loss: 0.641\n",
      "Test Accuracy : 63.4%, Test Loss: 1.0470720875598585\n",
      "Epoch Time (Training + Test) = 38.26 seconds\n",
      "epoch: 92 average loss: 0.654\n",
      "Test Accuracy : 71.1%, Test Loss: 0.847153892297574\n",
      "Epoch Time (Training + Test) = 37.16 seconds\n",
      "epoch: 93 average loss: 0.642\n",
      "Test Accuracy : 66.6%, Test Loss: 0.9834427489039234\n",
      "Epoch Time (Training + Test) = 37.90 seconds\n",
      "epoch: 94 average loss: 0.651\n",
      "Test Accuracy : 71.3%, Test Loss: 0.8188836013569551\n",
      "Epoch Time (Training + Test) = 37.62 seconds\n",
      "epoch: 95 average loss: 0.653\n",
      "Test Accuracy : 69.9%, Test Loss: 0.8591130876632602\n",
      "Epoch Time (Training + Test) = 37.77 seconds\n",
      "epoch: 96 average loss: 0.668\n",
      "Test Accuracy : 72.0%, Test Loss: 0.8018909832248298\n",
      "Epoch Time (Training + Test) = 37.89 seconds\n",
      "epoch: 97 average loss: 0.656\n",
      "Test Accuracy : 75.4%, Test Loss: 0.6604872208726985\n",
      "Epoch Time (Training + Test) = 37.17 seconds\n",
      "epoch: 98 average loss: 0.682\n",
      "Test Accuracy : 73.6%, Test Loss: 0.7155674396420989\n",
      "Epoch Time (Training + Test) = 38.40 seconds\n",
      "epoch: 99 average loss: 0.707\n",
      "Test Accuracy : 66.9%, Test Loss: 0.9151833376006397\n",
      "Epoch Time (Training + Test) = 37.22 seconds\n",
      "epoch: 100 average loss: 0.714\n",
      "Test Accuracy : 65.0%, Test Loss: 0.950030455199044\n",
      "Epoch Time (Training + Test) = 37.76 seconds\n",
      "Data Saved to adp_layer2_full_ft.csv\n",
      "Finished Training: \n",
      "Total Time 2.174725 hours\n",
      " Average Time Per Epoch 78.29 seconds\n",
      "full_ft layer3 320\n",
      "Scheduler Set {'T_max': 10, 'eta_min': 0, 'base_lrs': [0.1], 'last_epoch': 0, '_step_count': 1, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [0.1]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3fqr98om) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Current Best Acc</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch time (s)</td><td>â–â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡</td></tr><tr><td>lr</td><td>â–ˆâ–‡â–…â–‚â–â–‚â–…â–‡â–ˆâ–‡â–…â–‚â–â–‚â–…â–‡â–ˆâ–‡â–ƒâ–‚â–â–‚â–†â–‡â–ˆâ–†â–ƒâ–â–â–ƒâ–†â–ˆâ–‡â–†â–‚â–â–‚â–ƒâ–‡â–ˆ</td></tr><tr><td>test_accuracy</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–…â–†â–„â–‡â–‡â–‡â–‡â–ˆâ–†</td></tr><tr><td>test_loss</td><td>â–ˆâ–‚â–â–â–â–â–â–‚â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–‚â–â–â–â–â–‚â–â–â–â–ƒâ–‚â–ƒâ–â–â–‚â–â–â–‚</td></tr><tr><td>training_loss</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Accuracy</td><td>0.776</td></tr><tr><td>Current Best Acc</td><td>0.776</td></tr><tr><td>Total Time (hours)</td><td>2.17472</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>epoch time (s)</td><td>37.75997</td></tr><tr><td>lr</td><td>0.1</td></tr><tr><td>test_accuracy</td><td>0.65008</td></tr><tr><td>test_loss</td><td>0.95003</td></tr><tr><td>training_loss</td><td>0.7141</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">warm-tree-31</strong>: <a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/3fqr98om\" target=\"_blank\">https://wandb.ai/johnny_suu/Cifar5/runs/3fqr98om</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221022_121259-3fqr98om\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3fqr98om). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a1bfcd237942b391d93be6ed4b9889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333327028, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\John Su\\Downloads\\SydneyUni\\thesis\\Thesis\\wandb\\run-20221022_131847-3ejge5bu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny_suu/Cifar5/runs/3ejge5bu\" target=\"_blank\">iconic-universe-33</a></strong> to <a href=\"https://wandb.ai/johnny_suu/Cifar5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Project Name: Cifar5, Run Name adp_layer3_full_ft \n",
      "\n",
      "\n",
      "Run Start : 2022-10-22 13-18-47\n",
      "start_epoch : 0\n",
      "initial_lr : 0.01\n",
      "batch_size : 32\n",
      "epochs : 100\n",
      "epoch_chkpts : []\n",
      "device : cuda:0\n",
      "criterion : CrossEntropyLoss()\n",
      "optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "seed : 123\n",
      "model_architecture : <class 'NN_Thesis.nn_classes.resnet18_adapt'>\n",
      "binerised_training : True\n",
      "Number of Elements : 4440095\n",
      "Initial accuracy:\n",
      "Test Accuracy : 20.0%, Test Loss: 2.556679776867332\n",
      "best_acc.pth saved!\n",
      "Test Accuracy : 20.0%, Test Loss: 2.5566383127666192\n",
      "epoch: 1 average loss: 1.266\n",
      "Test Accuracy : 48.2%, Test Loss: 1.0762298646790291\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.72 seconds\n",
      "epoch: 2 average loss: 1.105\n",
      "Test Accuracy : 60.0%, Test Loss: 1.0136027793445246\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.67 seconds\n",
      "epoch: 3 average loss: 1.061\n",
      "Test Accuracy : 55.1%, Test Loss: 1.0187291911495922\n",
      "Epoch Time (Training + Test) = 37.64 seconds\n",
      "epoch: 4 average loss: 1.064\n",
      "Test Accuracy : 59.1%, Test Loss: 0.9844172200583436\n",
      "Epoch Time (Training + Test) = 36.65 seconds\n",
      "epoch: 5 average loss: 1.010\n",
      "Test Accuracy : 59.6%, Test Loss: 0.9803640604628931\n",
      "Epoch Time (Training + Test) = 37.09 seconds\n",
      "epoch: 6 average loss: 0.998\n",
      "Test Accuracy : 60.4%, Test Loss: 0.9682744442654387\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.22 seconds\n",
      "epoch: 7 average loss: 0.988\n",
      "Test Accuracy : 60.0%, Test Loss: 0.9595957715493029\n",
      "Epoch Time (Training + Test) = 36.69 seconds\n",
      "epoch: 8 average loss: 0.978\n",
      "Test Accuracy : 60.8%, Test Loss: 0.9988373632321272\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.52 seconds\n",
      "epoch: 9 average loss: 0.979\n",
      "Test Accuracy : 57.7%, Test Loss: 1.0227516851461758\n",
      "Epoch Time (Training + Test) = 36.41 seconds\n",
      "epoch: 10 average loss: 0.981\n",
      "Test Accuracy : 59.0%, Test Loss: 0.9699182717696481\n",
      "Epoch Time (Training + Test) = 37.34 seconds\n",
      "epoch: 11 average loss: 0.994\n",
      "Test Accuracy : 60.5%, Test Loss: 0.9400618872069337\n",
      "Epoch Time (Training + Test) = 36.93 seconds\n",
      "epoch: 12 average loss: 0.978\n",
      "Test Accuracy : 59.8%, Test Loss: 0.9488474586430717\n",
      "Epoch Time (Training + Test) = 36.91 seconds\n",
      "epoch: 13 average loss: 0.975\n",
      "Test Accuracy : 61.5%, Test Loss: 0.9428622611343404\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.32 seconds\n",
      "epoch: 14 average loss: 0.967\n",
      "Test Accuracy : 61.1%, Test Loss: 0.9214370198871779\n",
      "Epoch Time (Training + Test) = 36.59 seconds\n",
      "epoch: 15 average loss: 0.960\n",
      "Test Accuracy : 58.6%, Test Loss: 0.9786877697690979\n",
      "Epoch Time (Training + Test) = 37.74 seconds\n",
      "epoch: 16 average loss: 0.979\n",
      "Test Accuracy : 61.8%, Test Loss: 0.9236655491392326\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 36.68 seconds\n",
      "epoch: 17 average loss: 0.963\n",
      "Test Accuracy : 63.5%, Test Loss: 0.9768321209246545\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.06 seconds\n",
      "epoch: 18 average loss: 0.969\n",
      "Test Accuracy : 66.5%, Test Loss: 0.9370936771183063\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.11 seconds\n",
      "epoch: 19 average loss: 0.954\n",
      "Test Accuracy : 60.8%, Test Loss: 0.9303021979758807\n",
      "Epoch Time (Training + Test) = 36.51 seconds\n",
      "epoch: 20 average loss: 0.934\n",
      "Test Accuracy : 66.5%, Test Loss: 0.919821251993594\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.71 seconds\n",
      "epoch: 21 average loss: 0.908\n",
      "Test Accuracy : 63.3%, Test Loss: 0.9518410848534625\n",
      "Epoch Time (Training + Test) = 36.57 seconds\n",
      "epoch: 22 average loss: 0.899\n",
      "Test Accuracy : 68.3%, Test Loss: 0.840920811418987\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 37.40 seconds\n",
      "epoch: 23 average loss: 0.884\n",
      "Test Accuracy : 68.3%, Test Loss: 0.905271961408503\n",
      "Epoch Time (Training + Test) = 36.93 seconds\n",
      "epoch: 24 average loss: 0.872\n",
      "Test Accuracy : 66.4%, Test Loss: 0.991802728084652\n",
      "Epoch Time (Training + Test) = 36.93 seconds\n",
      "epoch: 25 average loss: 0.855\n",
      "Test Accuracy : 59.0%, Test Loss: 1.0386236505130368\n",
      "Epoch Time (Training + Test) = 36.79 seconds\n",
      "epoch: 26 average loss: 0.847\n",
      "Test Accuracy : 63.9%, Test Loss: 0.9606992558140279\n",
      "Epoch Time (Training + Test) = 25.80 seconds\n",
      "epoch: 27 average loss: 0.837\n",
      "Test Accuracy : 62.7%, Test Loss: 0.9295965100798156\n",
      "Epoch Time (Training + Test) = 25.97 seconds\n",
      "epoch: 28 average loss: 0.841\n",
      "Test Accuracy : 72.9%, Test Loss: 0.7583939937679359\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 25.83 seconds\n",
      "epoch: 29 average loss: 0.827\n",
      "Test Accuracy : 63.1%, Test Loss: 0.9298535367412031\n",
      "Epoch Time (Training + Test) = 25.83 seconds\n",
      "epoch: 30 average loss: 0.814\n",
      "Test Accuracy : 68.2%, Test Loss: 0.850497757763509\n",
      "Epoch Time (Training + Test) = 25.79 seconds\n",
      "epoch: 31 average loss: 0.822\n",
      "Test Accuracy : 71.0%, Test Loss: 0.7571870484925292\n",
      "Epoch Time (Training + Test) = 25.77 seconds\n",
      "epoch: 32 average loss: 0.817\n",
      "Test Accuracy : 68.3%, Test Loss: 0.8640158696247794\n",
      "Epoch Time (Training + Test) = 25.83 seconds\n",
      "epoch: 33 average loss: 0.838\n",
      "Test Accuracy : 67.6%, Test Loss: 0.8668046864249822\n",
      "Epoch Time (Training + Test) = 25.74 seconds\n",
      "epoch: 34 average loss: 0.841\n",
      "Test Accuracy : 70.7%, Test Loss: 0.7733961906274567\n",
      "Epoch Time (Training + Test) = 25.79 seconds\n",
      "epoch: 35 average loss: 0.846\n",
      "Test Accuracy : 66.7%, Test Loss: 0.9173213177934632\n",
      "Epoch Time (Training + Test) = 25.74 seconds\n",
      "epoch: 36 average loss: 0.844\n",
      "Test Accuracy : 69.5%, Test Loss: 0.8445350315869616\n",
      "Epoch Time (Training + Test) = 25.77 seconds\n",
      "epoch: 37 average loss: 0.858\n",
      "Test Accuracy : 46.0%, Test Loss: 1.452539008291786\n",
      "Epoch Time (Training + Test) = 25.77 seconds\n",
      "epoch: 38 average loss: 0.839\n",
      "Test Accuracy : 58.9%, Test Loss: 1.079690835664949\n",
      "Epoch Time (Training + Test) = 25.78 seconds\n",
      "epoch: 39 average loss: 0.822\n",
      "Test Accuracy : 70.1%, Test Loss: 0.7724662133494912\n",
      "Epoch Time (Training + Test) = 25.79 seconds\n",
      "epoch: 40 average loss: 0.810\n",
      "Test Accuracy : 49.9%, Test Loss: 1.263344482082845\n",
      "Epoch Time (Training + Test) = 25.82 seconds\n",
      "epoch: 41 average loss: 0.801\n",
      "Test Accuracy : 64.7%, Test Loss: 0.9841141854710591\n",
      "Epoch Time (Training + Test) = 25.81 seconds\n",
      "epoch: 42 average loss: 0.804\n",
      "Test Accuracy : 62.0%, Test Loss: 1.078617384366672\n",
      "Epoch Time (Training + Test) = 25.74 seconds\n",
      "epoch: 43 average loss: 0.791\n",
      "Test Accuracy : 71.8%, Test Loss: 0.7715657819110109\n",
      "Epoch Time (Training + Test) = 25.83 seconds\n",
      "epoch: 44 average loss: 0.796\n",
      "Test Accuracy : 70.7%, Test Loss: 0.7809324275197276\n",
      "Epoch Time (Training + Test) = 25.73 seconds\n",
      "epoch: 45 average loss: 0.778\n",
      "Test Accuracy : 70.7%, Test Loss: 0.766459953525792\n",
      "Epoch Time (Training + Test) = 25.85 seconds\n",
      "epoch: 46 average loss: 0.780\n",
      "Test Accuracy : 67.7%, Test Loss: 0.8367115326244813\n",
      "Epoch Time (Training + Test) = 25.72 seconds\n",
      "epoch: 47 average loss: 0.770\n",
      "Test Accuracy : 67.3%, Test Loss: 0.86210234573735\n",
      "Epoch Time (Training + Test) = 25.83 seconds\n",
      "epoch: 48 average loss: 0.765\n",
      "Test Accuracy : 71.6%, Test Loss: 0.7487729312208913\n",
      "Epoch Time (Training + Test) = 25.81 seconds\n",
      "epoch: 49 average loss: 0.758\n",
      "Test Accuracy : 68.3%, Test Loss: 0.8349678243517571\n",
      "Epoch Time (Training + Test) = 25.79 seconds\n",
      "epoch: 50 average loss: 0.746\n",
      "Test Accuracy : 69.8%, Test Loss: 0.8288329447931646\n",
      "Epoch Time (Training + Test) = 25.81 seconds\n",
      "epoch: 51 average loss: 0.742\n",
      "Test Accuracy : 72.3%, Test Loss: 0.7383457457318026\n",
      "Epoch Time (Training + Test) = 25.78 seconds\n",
      "epoch: 52 average loss: 0.750\n",
      "Test Accuracy : 75.5%, Test Loss: 0.6822442519847695\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 25.77 seconds\n",
      "epoch: 53 average loss: 0.765\n",
      "Test Accuracy : 70.2%, Test Loss: 0.7968806686151363\n",
      "Epoch Time (Training + Test) = 25.72 seconds\n",
      "epoch: 54 average loss: 0.765\n",
      "Test Accuracy : 65.9%, Test Loss: 0.8847169415725161\n",
      "Epoch Time (Training + Test) = 25.77 seconds\n",
      "epoch: 55 average loss: 0.770\n",
      "Test Accuracy : 74.4%, Test Loss: 0.7275275645201164\n",
      "Epoch Time (Training + Test) = 25.83 seconds\n",
      "epoch: 56 average loss: 0.772\n",
      "Test Accuracy : 71.0%, Test Loss: 0.782760046860751\n",
      "Epoch Time (Training + Test) = 25.71 seconds\n",
      "epoch: 57 average loss: 0.770\n",
      "Test Accuracy : 63.3%, Test Loss: 0.9542626968735014\n",
      "Epoch Time (Training + Test) = 25.78 seconds\n",
      "epoch: 58 average loss: 0.779\n",
      "Test Accuracy : 71.3%, Test Loss: 0.7788697764696673\n",
      "Epoch Time (Training + Test) = 25.71 seconds\n",
      "epoch: 59 average loss: 0.764\n",
      "Test Accuracy : 65.2%, Test Loss: 0.8749914170835938\n",
      "Epoch Time (Training + Test) = 25.73 seconds\n",
      "epoch: 60 average loss: 0.751\n",
      "Test Accuracy : 65.4%, Test Loss: 0.9683889839655299\n",
      "Epoch Time (Training + Test) = 25.72 seconds\n",
      "epoch: 61 average loss: 0.756\n",
      "Test Accuracy : 71.0%, Test Loss: 0.797741898795223\n",
      "Epoch Time (Training + Test) = 25.73 seconds\n",
      "epoch: 62 average loss: 0.755\n",
      "Test Accuracy : 62.0%, Test Loss: 1.0842812154299157\n",
      "Epoch Time (Training + Test) = 25.71 seconds\n",
      "epoch: 63 average loss: 0.755\n",
      "Test Accuracy : 70.2%, Test Loss: 0.8127693837256078\n",
      "Epoch Time (Training + Test) = 25.77 seconds\n",
      "epoch: 64 average loss: 0.745\n",
      "Test Accuracy : 66.5%, Test Loss: 0.9823727837913786\n",
      "Epoch Time (Training + Test) = 25.74 seconds\n",
      "epoch: 65 average loss: 0.732\n",
      "Test Accuracy : 59.8%, Test Loss: 1.1964415173091547\n",
      "Epoch Time (Training + Test) = 25.79 seconds\n",
      "epoch: 66 average loss: 0.734\n",
      "Test Accuracy : 68.0%, Test Loss: 0.9162469689193589\n",
      "Epoch Time (Training + Test) = 25.75 seconds\n",
      "epoch: 67 average loss: 0.725\n",
      "Test Accuracy : 70.7%, Test Loss: 0.8031512359371575\n",
      "Epoch Time (Training + Test) = 25.79 seconds\n",
      "epoch: 68 average loss: 0.719\n",
      "Test Accuracy : 73.0%, Test Loss: 0.7570357735809463\n",
      "Epoch Time (Training + Test) = 25.78 seconds\n",
      "epoch: 69 average loss: 0.714\n",
      "Test Accuracy : 72.2%, Test Loss: 0.7656960389803132\n",
      "Epoch Time (Training + Test) = 25.79 seconds\n",
      "epoch: 70 average loss: 0.697\n",
      "Test Accuracy : 70.5%, Test Loss: 0.8365573428780831\n",
      "Epoch Time (Training + Test) = 25.82 seconds\n",
      "epoch: 71 average loss: 0.686\n",
      "Test Accuracy : 76.3%, Test Loss: 0.639060970310055\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 25.84 seconds\n",
      "epoch: 72 average loss: 0.703\n",
      "Test Accuracy : 71.0%, Test Loss: 0.7827235394731507\n",
      "Epoch Time (Training + Test) = 25.75 seconds\n",
      "epoch: 73 average loss: 0.717\n",
      "Test Accuracy : 74.9%, Test Loss: 0.6700127169756633\n",
      "Epoch Time (Training + Test) = 25.76 seconds\n",
      "epoch: 74 average loss: 0.721\n",
      "Test Accuracy : 71.9%, Test Loss: 0.7544843452360929\n",
      "Epoch Time (Training + Test) = 25.72 seconds\n",
      "epoch: 75 average loss: 0.728\n",
      "Test Accuracy : 70.1%, Test Loss: 0.7541948812239615\n",
      "Epoch Time (Training + Test) = 25.74 seconds\n",
      "epoch: 76 average loss: 0.728\n",
      "Test Accuracy : 68.5%, Test Loss: 0.8479089200344232\n",
      "Epoch Time (Training + Test) = 25.79 seconds\n",
      "epoch: 77 average loss: 0.731\n",
      "Test Accuracy : 72.2%, Test Loss: 0.7659741553961469\n",
      "Epoch Time (Training + Test) = 25.78 seconds\n",
      "epoch: 78 average loss: 0.727\n",
      "Test Accuracy : 74.1%, Test Loss: 0.7182813865296981\n",
      "Epoch Time (Training + Test) = 25.78 seconds\n",
      "epoch: 79 average loss: 0.740\n",
      "Test Accuracy : 68.4%, Test Loss: 0.8100550478071813\n",
      "Epoch Time (Training + Test) = 25.80 seconds\n",
      "epoch: 80 average loss: 0.724\n",
      "Test Accuracy : 62.2%, Test Loss: 1.059336196278672\n",
      "Epoch Time (Training + Test) = 25.75 seconds\n",
      "epoch: 81 average loss: 0.735\n",
      "Test Accuracy : 73.2%, Test Loss: 0.7441425321199705\n",
      "Epoch Time (Training + Test) = 25.74 seconds\n",
      "epoch: 82 average loss: 0.734\n",
      "Test Accuracy : 72.6%, Test Loss: 0.7372830763954641\n",
      "Epoch Time (Training + Test) = 25.75 seconds\n",
      "epoch: 83 average loss: 0.725\n",
      "Test Accuracy : 71.4%, Test Loss: 0.7938518881645349\n",
      "Epoch Time (Training + Test) = 25.74 seconds\n",
      "epoch: 84 average loss: 0.723\n",
      "Test Accuracy : 71.0%, Test Loss: 0.7300544407056726\n",
      "Epoch Time (Training + Test) = 25.78 seconds\n",
      "epoch: 85 average loss: 0.721\n",
      "Test Accuracy : 57.9%, Test Loss: 1.1464650277286539\n",
      "Epoch Time (Training + Test) = 25.73 seconds\n",
      "epoch: 86 average loss: 0.716\n",
      "Test Accuracy : 62.2%, Test Loss: 1.071842488120584\n",
      "Epoch Time (Training + Test) = 25.78 seconds\n",
      "epoch: 87 average loss: 0.712\n",
      "Test Accuracy : 62.0%, Test Loss: 1.0211303583191484\n",
      "Epoch Time (Training + Test) = 25.78 seconds\n",
      "epoch: 88 average loss: 0.702\n",
      "Test Accuracy : 71.9%, Test Loss: 0.7615259355291382\n",
      "Epoch Time (Training + Test) = 25.79 seconds\n",
      "epoch: 89 average loss: 0.693\n",
      "Test Accuracy : 63.3%, Test Loss: 1.0360106568202339\n",
      "Epoch Time (Training + Test) = 25.77 seconds\n",
      "epoch: 90 average loss: 0.687\n",
      "Test Accuracy : 77.2%, Test Loss: 0.6372556997382123\n",
      "best_acc.pth saved!\n",
      "Epoch Time (Training + Test) = 25.78 seconds\n",
      "epoch: 91 average loss: 0.665\n",
      "Test Accuracy : 77.1%, Test Loss: 0.6222857200276212\n",
      "Epoch Time (Training + Test) = 25.83 seconds\n",
      "epoch: 92 average loss: 0.699\n",
      "Test Accuracy : 73.7%, Test Loss: 0.703890531492965\n",
      "Epoch Time (Training + Test) = 25.74 seconds\n",
      "epoch: 93 average loss: 0.694\n",
      "Test Accuracy : 70.1%, Test Loss: 0.8426924213728941\n",
      "Epoch Time (Training + Test) = 25.81 seconds\n",
      "epoch: 94 average loss: 0.716\n",
      "Test Accuracy : 66.7%, Test Loss: 0.9224279856742801\n",
      "Epoch Time (Training + Test) = 25.81 seconds\n",
      "epoch: 95 average loss: 0.716\n",
      "Test Accuracy : 76.0%, Test Loss: 0.6487921728654895\n",
      "Epoch Time (Training + Test) = 25.74 seconds\n",
      "epoch: 96 average loss: 0.714\n",
      "Test Accuracy : 41.2%, Test Loss: 1.9701608260879127\n",
      "Epoch Time (Training + Test) = 25.79 seconds\n",
      "epoch: 97 average loss: 0.713\n",
      "Test Accuracy : 74.8%, Test Loss: 0.6735351087949465\n",
      "Epoch Time (Training + Test) = 25.77 seconds\n",
      "epoch: 98 average loss: 0.722\n",
      "Test Accuracy : 61.1%, Test Loss: 1.2342821835252025\n",
      "Epoch Time (Training + Test) = 25.76 seconds\n",
      "epoch: 99 average loss: 0.727\n",
      "Test Accuracy : 67.0%, Test Loss: 0.8302274112353849\n",
      "Epoch Time (Training + Test) = 25.76 seconds\n",
      "epoch: 100 average loss: 0.732\n",
      "Test Accuracy : 63.6%, Test Loss: 1.0220439130692835\n",
      "Epoch Time (Training + Test) = 25.77 seconds\n",
      "Data Saved to adp_layer3_full_ft.csv\n",
      "Finished Training: \n",
      "Total Time 1.588529 hours\n",
      " Average Time Per Epoch 57.19 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "PATH = '.\\SavedModels\\Cifar5\\Baseline_BNN_Resnet18_2022_10_21_10_47_20\\Baseline_BNN_Resnet18_best_acc.pth'\n",
    "BinCifar5_state_dict = torch.load(PATH,map_location= device)\n",
    "\n",
    "\n",
    "layers = ['layer1','layer2','layer3']\n",
    "channels = [80,160,320]\n",
    "\n",
    "\n",
    "for layer,channel in zip(layers,channels):\n",
    "    for t in ['full_ft']:\n",
    "        print(t,layer,channel)\n",
    "        torch.manual_seed(42)\n",
    "        adapter_model = resnet18_adapt(num_classes=5)\n",
    "        adapter_model.load_state_dict(BinCifar5_state_dict)\n",
    "        \n",
    "        if t == 'adp_only':\n",
    "            adapter_model.freeze()\n",
    "        conv_adp = conv_adapter(channel,kernel = 1, padding= 0)\n",
    "        conv_adp.init_weight_zeros()\n",
    "        adapter_model.add_adapter(after = layer,adapter = conv_adp)\n",
    "        trainer = adapter_Trainer(model = adapter_model,seed = 123,model_name = f'adp_{layer}_{t}',project_name = 'Cifar5',classes = classes,binarise= True)\n",
    "        m = trainer.model\n",
    "        m.to(trainer.device)\n",
    "        for head in [m.fc,m.bn3,m.bn3]:\n",
    "            for p in head.parameters():\n",
    "                p.requires_grad = True\n",
    "            head.train()\n",
    "        trainer.lr = 0.01\n",
    "        trainer.batch_size = 32\n",
    "        trainer.epochs =100\n",
    "        trainer.epoch_chkpts = []\n",
    "        trainer.start_epoch = 0\n",
    "        # trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max= trainer.epochs)\n",
    "        trainer.tags = ['finetune',f'Training: {t}',f'Adpater Location {layer}','Init_weight: {} ']\n",
    "        trainer.train(train59_loader,test59_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

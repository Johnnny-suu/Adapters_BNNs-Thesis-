{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2caf320",
   "metadata": {
    "id": "b2caf320"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c4810",
   "metadata": {
    "id": "249c4810"
   },
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc17541",
   "metadata": {
    "id": "fbc17541"
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\\\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\\\n",
    "                              transforms.ConvertImageDtype(dtype = torch.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f698b356",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "f4416d1859d44a118ad7946153bf2bac",
      "74c29808cdb34667a54c8b722d86e719",
      "26600127cf084e28a68bca5ed34ca624",
      "138a97b37c514d6588b50e0f861a0e40",
      "99a1c669ee7b45bc81603a67fafd357f",
      "7cefe456d5f94a16bc2cf61f6d0285c4",
      "222018cf695f4631ac3ede377f9e374c",
      "a5d353baeecb4426bb561ec2861b6552",
      "98d06e6c238e4e49aea789b184401398",
      "67b039e916ce40a2a59b9faed6a3ea54",
      "db5a55b00b4e4978ac73e64cd6d64a1d"
     ]
    },
    "id": "f698b356",
    "outputId": "a89ca9f2-85f0-4abc-b9df-6f1b948e118a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4416d1859d44a118ad7946153bf2bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "train = torchvision.datasets.CIFAR10(root ='./data',train = True, download = True,transform = transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2019f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3a2019f",
    "outputId": "244ee5d8-c927-46b4-bde9-4c1071f7a982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train,batch_size = batch_size,shuffle= True, num_workers = 0)\n",
    "os.listdir('./data')\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e7fc1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0e7fc1b",
    "outputId": "3a42856f-2a5d-498f-8feb-01b701e97a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'torch.Tensor'>, <class 'torch.Tensor'>]\n",
      "tensor([0, 0, 6, 3]) torch.Size([4, 3, 32, 32])\n",
      "tensor([0, 0, 6, 3])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "for i in iter(trainloader):\n",
    "    print([type(k) for k in i])\n",
    "    print(i[1],i[0].size())\n",
    "    print(i[1])\n",
    "    imgs = i[0]\n",
    "    img = i[0][0]\n",
    "    print(img.dtype)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe37050",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "fbe37050",
    "outputId": "91eb7035-1abf-425a-9287-8cfb25d59dd2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img.to(torch.float32)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17dd7cf",
   "metadata": {
    "id": "b17dd7cf"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "#         self.type = self.conv1.weight.dtype\n",
    "        \n",
    "    def forward(self,x):\n",
    "#         x = x.type(self.conv1.weight.dtype)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "#         x = F.softmax(x,dim = -1 )\n",
    "        return x\n",
    "\n",
    "#Create Models\n",
    "\n",
    "Model1 = MyNN()\n",
    "Model2 = MyNN().bfloat16()\n",
    "\n",
    "#Test forward function\n",
    "y = Model1.forward(imgs)\n",
    "# torch.sum(y,dim= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc87bc5",
   "metadata": {
    "id": "0bc87bc5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "def training(model,epochs,batch_size,train_set,device):\n",
    "    #Set Optimisers\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    trainloader = torch.utils.data.DataLoader(train_set,batch_size = batch_size,shuffle= True, num_workers = 0)\n",
    "    \n",
    "    time_start = time.perf_counter()\n",
    "    print('hi')\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        running_loss = 0\n",
    "        for i,data in enumerate(iter(trainloader)):\n",
    "            images, labels = data[0].to(device),data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "    total_time =time.perf_counter()-  time_start \n",
    "    \n",
    "    print(f'Finished Training \\nTotal Time {total_time}\\n Average Time Per Epoch {(total_time)/epochs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f9df8",
   "metadata": {
    "id": "857f9df8"
   },
   "outputs": [],
   "source": [
    "#Save Model\n",
    "def saveModel(filename):\n",
    "    PATH = f'./{filename}.pth'\n",
    "    torch.save(Model1.state_dict(), PATH)\n",
    "    print(f'{filename}.pth saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ff495",
   "metadata": {
    "id": "0a5ff495"
   },
   "outputs": [],
   "source": [
    "\n",
    "def test(model,testset,device):\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    correct_class = {classname: 0 for classname in classes}\n",
    "    total_class = {classname: 0 for classname in classes}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(testloader):\n",
    "  \n",
    "            images, labels = data[0].to(device),data[1].to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _,predict = torch.max(outputs.data,-1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predict == labels).sum().item()\n",
    "            for label, prediction in zip(labels, predict):\n",
    "                if label == prediction:\n",
    "                    correct_class[classes[label]] += 1\n",
    "                total_class[classes[label]] += 1\n",
    "            \n",
    "    # print accuracy for each class\n",
    "    for classname, correct_count in correct_class.items():\n",
    "        accuracy = 100 * float(correct_count) / total_class[classname]\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "    #Overall Accuracy\n",
    "    print(f'Overall Accuracy : {correct/total*100:.1f}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905eb3af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "905eb3af",
    "outputId": "94a76569-b5e9-4c72-e089-4ff52aa4396b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "hi\n",
      "[1,  3125] loss: 3.188\n",
      "[2,  3125] loss: 2.442\n",
      "[3,  3125] loss: 2.140\n",
      "[4,  3125] loss: 1.979\n",
      "[5,  3125] loss: 1.864\n",
      "[6,  3125] loss: 1.766\n",
      "[7,  3125] loss: 1.682\n",
      "[8,  3125] loss: 1.604\n",
      "[9,  3125] loss: 1.536\n",
      "[10,  3125] loss: 1.473\n",
      "[11,  3125] loss: 1.415\n",
      "[12,  3125] loss: 1.360\n",
      "[13,  3125] loss: 1.312\n",
      "[14,  3125] loss: 1.265\n",
      "[15,  3125] loss: 1.220\n",
      "[16,  3125] loss: 1.179\n",
      "[17,  3125] loss: 1.132\n",
      "[18,  3125] loss: 1.092\n",
      "[19,  3125] loss: 1.055\n",
      "[20,  3125] loss: 1.020\n",
      "Finished Training \n",
      "Total Time 337.878234401\n",
      " Average Time Per Epoch 16.89391172005\n",
      "Model1.pth saved!\n",
      "Accuracy for class: plane is 66.8 %\n",
      "Accuracy for class: car   is 77.7 %\n",
      "Accuracy for class: bird  is 47.5 %\n",
      "Accuracy for class: cat   is 47.2 %\n",
      "Accuracy for class: deer  is 55.5 %\n",
      "Accuracy for class: dog   is 61.0 %\n",
      "Accuracy for class: frog  is 66.9 %\n",
      "Accuracy for class: horse is 63.0 %\n",
      "Accuracy for class: ship  is 76.3 %\n",
      "Accuracy for class: truck is 69.9 %\n",
      "Overall Accuracy : 63.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(123)\n",
    "random.seed(123)\n",
    "transform = transforms.Compose([transforms.ToTensor(),\\\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\\\n",
    "                              transforms.ConvertImageDtype(dtype = torch.float32)])\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "train = torchvision.datasets.CIFAR10(root ='./data',train = True, download = True,transform = transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "Model1 = MyNN().to(device)\n",
    "\n",
    "training(Model1,epochs = 20,batch_size = 16,train_set = train,device = device)\n",
    "saveModel('Model1')\n",
    "test(Model1,testset,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a83608",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 814
    },
    "id": "49a83608",
    "outputId": "0d9cbb16-bf4e-49ba-ba21-5d0ca956afae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "hi\n",
      "[1,  3125] loss: 3.488\n",
      "[2,  3125] loss: 2.687\n",
      "[3,  3125] loss: 2.262\n",
      "[4,  3125] loss: 2.056\n",
      "[5,  3125] loss: 1.929\n",
      "[6,  3125] loss: 1.825\n",
      "[7,  3125] loss: 1.741\n",
      "[8,  3125] loss: 1.661\n",
      "[9,  3125] loss: 1.596\n",
      "[10,  3125] loss: 1.533\n",
      "[11,  3125] loss: 1.473\n",
      "[12,  3125] loss: 1.423\n",
      "[13,  3125] loss: 1.374\n",
      "[14,  3125] loss: 1.324\n",
      "[15,  3125] loss: 1.280\n",
      "[16,  3125] loss: 1.244\n",
      "[17,  3125] loss: 1.198\n",
      "[18,  3125] loss: 1.161\n",
      "[19,  3125] loss: 1.124\n",
      "[20,  3125] loss: 1.083\n",
      "Finished Training \n",
      "Total Time 353.5931467290002\n",
      " Average Time Per Epoch 17.67965733645001\n",
      "Model2.pth saved!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d07bc67b9dbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msaveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-ffd3833735b2>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, testset, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "random.seed(123)\n",
    "transform = transforms.Compose([transforms.ToTensor(),\\\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\\\n",
    "                              transforms.ConvertImageDtype(dtype = torch.half)])\n",
    "\n",
    "train = torchvision.datasets.CIFAR10(root ='./data',train = True, download = True,transform = transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "Model2 = MyNN().to(device=device,dtype = torch.float16)\n",
    "training(Model2,epochs = 20,batch_size = 16,train_set = train,device = device)\n",
    "saveModel('Model2')\n",
    "test(Model2,testset,device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7HQJzLWzjQoQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7HQJzLWzjQoQ",
    "outputId": "8f031e50-3ce2-475f-b283-d9f06ba1ffe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 71.2 %\n",
      "Accuracy for class: car   is 81.7 %\n",
      "Accuracy for class: bird  is 50.2 %\n",
      "Accuracy for class: cat   is 47.8 %\n",
      "Accuracy for class: deer  is 50.9 %\n",
      "Accuracy for class: dog   is 54.2 %\n",
      "Accuracy for class: frog  is 74.9 %\n",
      "Accuracy for class: horse is 67.5 %\n",
      "Accuracy for class: ship  is 79.4 %\n",
      "Accuracy for class: truck is 70.2 %\n",
      "Overall Accuracy : 64.8\n"
     ]
    }
   ],
   "source": [
    "test(Model2,testset,device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1jDQtpGobgy5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "id": "1jDQtpGobgy5",
    "outputId": "a85b7f43-89c1-433a-bd3c-34edd8baf4ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "hi\n",
      "[1,  3125] loss: 3.598\n",
      "[2,  3125] loss: 3.595\n",
      "[3,  3125] loss: 3.596\n",
      "[4,  3125] loss: 3.596\n",
      "[5,  3125] loss: 3.596\n",
      "[6,  3125] loss: 3.596\n",
      "[7,  3125] loss: 3.595\n",
      "[8,  3125] loss: 3.595\n",
      "[9,  3125] loss: 3.595\n",
      "[10,  3125] loss: 3.595\n",
      "[11,  3125] loss: 3.595\n",
      "[12,  3125] loss: 3.594\n",
      "[13,  3125] loss: 3.595\n",
      "[14,  3125] loss: 3.595\n",
      "[15,  3125] loss: 3.595\n",
      "[16,  3125] loss: 3.595\n",
      "[17,  3125] loss: 3.595\n",
      "[18,  3125] loss: 3.595\n",
      "[19,  3125] loss: 3.596\n",
      "[20,  3125] loss: 3.594\n",
      "Finished Training \n",
      "Total Time 432.3703728520002\n",
      " Average Time Per Epoch 21.61851864260001\n",
      "Model2.pth saved!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f60a09313057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msaveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-40e301be372e>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, testloader, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6e71700d813e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         x = x.type(self.conv1.weight.dtype)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected bias to have type Float but got BFloat16"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "random.seed(123)\n",
    "transform = transforms.Compose([transforms.ToTensor(),\\\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\\\n",
    "                              transforms.ConvertImageDtype(dtype = torch.bfloat16)])\n",
    "\n",
    "train = torchvision.datasets.CIFAR10(root ='./data',train = True, download = True,transform = transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "Model3 = MyNN().to(device = device,dtype = torch.bfloat16)\n",
    "training(Model3,epochs = 20,batch_size = 16,train_set = train,device = device)\n",
    "saveModel('Model3')\n",
    "test(Model3,testset,device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NZ6p-JyThQto",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NZ6p-JyThQto",
    "outputId": "2289a492-9900-4edb-8ff0-ed7f680d8604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 0.0 %\n",
      "Accuracy for class: car   is 10.7 %\n",
      "Accuracy for class: bird  is 0.0 %\n",
      "Accuracy for class: cat   is 0.0 %\n",
      "Accuracy for class: deer  is 60.2 %\n",
      "Accuracy for class: dog   is 0.9 %\n",
      "Accuracy for class: frog  is 0.1 %\n",
      "Accuracy for class: horse is 0.0 %\n",
      "Accuracy for class: ship  is 73.2 %\n",
      "Accuracy for class: truck is 0.0 %\n",
      "Overall Accuracy : 14.5\n"
     ]
    }
   ],
   "source": [
    "test(Model3,testset,device = device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Comparison.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "138a97b37c514d6588b50e0f861a0e40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67b039e916ce40a2a59b9faed6a3ea54",
      "placeholder": "​",
      "style": "IPY_MODEL_db5a55b00b4e4978ac73e64cd6d64a1d",
      "value": " 170498071/170498071 [00:02&lt;00:00, 94507531.72it/s]"
     }
    },
    "222018cf695f4631ac3ede377f9e374c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26600127cf084e28a68bca5ed34ca624": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5d353baeecb4426bb561ec2861b6552",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_98d06e6c238e4e49aea789b184401398",
      "value": 170498071
     }
    },
    "67b039e916ce40a2a59b9faed6a3ea54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74c29808cdb34667a54c8b722d86e719": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cefe456d5f94a16bc2cf61f6d0285c4",
      "placeholder": "​",
      "style": "IPY_MODEL_222018cf695f4631ac3ede377f9e374c",
      "value": "100%"
     }
    },
    "7cefe456d5f94a16bc2cf61f6d0285c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98d06e6c238e4e49aea789b184401398": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "99a1c669ee7b45bc81603a67fafd357f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5d353baeecb4426bb561ec2861b6552": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db5a55b00b4e4978ac73e64cd6d64a1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4416d1859d44a118ad7946153bf2bac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_74c29808cdb34667a54c8b722d86e719",
       "IPY_MODEL_26600127cf084e28a68bca5ed34ca624",
       "IPY_MODEL_138a97b37c514d6588b50e0f861a0e40"
      ],
      "layout": "IPY_MODEL_99a1c669ee7b45bc81603a67fafd357f"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

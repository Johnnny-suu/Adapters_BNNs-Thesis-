{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "676032d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_Thesis.nn_classes import *\n",
    "from NN_Thesis.trainer import *\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eef694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39df9150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\\\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\\\n",
    "                              transforms.ConvertImageDtype(dtype = torch.float32)])\n",
    "train = torchvision.datasets.CIFAR10(root ='./data',train = True, download = True,transform = transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train,batch_size = batch_size,shuffle= True, num_workers = 0)\n",
    "os.listdir('./data')\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a752ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = MyNN()\n",
    "\n",
    "# trainer = Trainer(model1,classes = classes)\n",
    "\n",
    "# #Set Training Params\n",
    "# trainer.batch_size = 16\n",
    "# trainer.epochs = 2\n",
    "# # \n",
    "# trainer.training(trainloader,testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efb13b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff8b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a custom module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7436df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class scalarLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.k = nn.Parameter(torch.tensor([-5.0]))\n",
    "    def forward(self,x,toBin):\n",
    "        \n",
    "        \n",
    "        if toBin:\n",
    "            temp = self.k.data.clone()\n",
    "\n",
    "            print(self.k.data)\n",
    "\n",
    "            self.k.data = torch.sign(self.k.data)\n",
    "            out = self.k*x\n",
    "            self.k.data = temp\n",
    "            print('\\n\\n')\n",
    "        \n",
    "        else:\n",
    "            out = self.k*x\n",
    "        \n",
    "        return out\n",
    "#         return (self.k*x)\n",
    "        \n",
    "        \n",
    "\n",
    "m = scalarLayer()\n",
    "loss_F = F.mse_loss\n",
    "# opt = optim.SGD(m.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8258ea65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([-17.]) Parameter containing:\n",
      "tensor([-5.], requires_grad=True)\n",
      "\n",
      "tensor([-25.]) Parameter containing:\n",
      "tensor([-5.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = scalarLayer()\n",
    "m2 = scalarLayer()\n",
    "loss_F = F.mse_loss\n",
    "loss_F2 = F.mse_loss\n",
    "# print(m.k.item())\n",
    "# x= torch.tensor([2.0])\n",
    "x = torch.ones(2,1)\n",
    "\n",
    "# print(x.shape)\n",
    "out = m(x,toBin = True)\n",
    "out2 = m2(x,toBin = False)\n",
    "\n",
    "# print(out)\n",
    "pred = torch.unsqueeze(torch.tensor([10.0,5.0]),1)\n",
    "\n",
    "# print(pred.shape)\n",
    "loss = loss_F(out,pred)\n",
    "loss2 = loss_F2(out2,pred)\n",
    "loss.backward()\n",
    "loss2.backward()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for p,q in zip(m.parameters(),m2.parameters()):\n",
    "        print(p.grad,p,end = '\\n\\n')\n",
    "        \n",
    "        print(q.grad,q)\n",
    "        p-= p.grad*0.0001\n",
    "#         print(p)\n",
    "        m.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25f9737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3])\n",
      "<bound method binarise_layer.<locals>.binary_layer.forward of binary_layer(3, 1, kernel_size=(3, 3), stride=(1, 1))>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def binarise_layer(layer,*args,**kwargs):\n",
    "    #Takes in a module and binarises the forward pass\n",
    "    class binary_layer(layer):\n",
    "        def __init__(self,*args,**kwargs):\n",
    "            #Recreate the layer properties\n",
    "            super().__init__(*args,**kwargs)\n",
    "            \n",
    "            #We need the original forward function\n",
    "            self.org_forward = super().forward\n",
    "            \n",
    "            self.has_weight = False\n",
    "            self.has_bias = False \n",
    "            \n",
    "                        \n",
    "            if hasattr(self,'weight'):\n",
    "                self.org_weight_data = self.weight.data\n",
    "                self.has_weight = True\n",
    "            if hasattr(self,'bias'):\n",
    "                self.org_bias_data = self.bias.data\n",
    "                self.has_bias = True\n",
    "        def forward(self,x):\n",
    "            #Can replace with for loop over layer.parameters()?\n",
    "            #Replace the weights and biases with binarisation and then return them to orig after\n",
    "#             if self.has_weight:\n",
    "            self.org_weight_data = self.weight.data\n",
    "            self.weight.data = torch.sign(self.weight.data)\n",
    "#             if self.has_bias:\n",
    "            self.org_bias_data = self.bias.data\n",
    "            self.bias.data = torch.sign(self.bias.data)\n",
    "            out = self.org_forward(x)\n",
    "#             print(self.org_forward)\n",
    "            #Replace the weights with original weights\n",
    "            self.weight.data = self.org_weight_data\n",
    "            self.bias.data = self.org_bias_data\n",
    "            return out\n",
    "    return binary_layer(*args,**kwargs)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "m = nn.Conv2d\n",
    "\n",
    "b = binarise_layer(m,3,1,3)\n",
    "x = torch.randn(1,3,3,3)\n",
    "print(x.shape)\n",
    "# for p in b.parameters():\n",
    "#     print(p.data) \n",
    "b(x)\n",
    "print(b.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34c186f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = nn.BatchNorm2d(3)\n",
    "l = nn.Conv2d(3,3,3)\n",
    "\n",
    "\n",
    "s = nn.Sequential(l,k)\n",
    "\n",
    "isinstance(l,nn.Conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d2f1128",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'clone'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrently only accepts conv2d and linear layers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m n \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m \u001b[43mconvert_to_binary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mvars\u001b[39m(n)\n",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36mconvert_to_binary\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m     26\u001b[0m     module\u001b[38;5;241m.\u001b[39morg_weight_data \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m     27\u001b[0m     module\u001b[38;5;241m.\u001b[39morg_bias_data \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m---> 28\u001b[0m     module\u001b[38;5;241m.\u001b[39mforward \u001b[38;5;241m=\u001b[39m \u001b[43mbinary_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrently only accepts conv2d and linear layers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36mconvert_to_binary.<locals>.binary_forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbinary_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morg_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m()\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(x):\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morg_weight_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'clone'"
     ]
    }
   ],
   "source": [
    "def convert_to_binary(module):\n",
    "    \n",
    "    \n",
    "    def binary_forward(self):\n",
    "        \n",
    "        def forward(x):\n",
    "            self.org_weight_data = self.weight.data\n",
    "            self.weight.data = torch.sign(self.weight.data)\n",
    "    #             if self.has_bias:\n",
    "            self.org_bias_data = self.bias.data\n",
    "            self.bias.data = torch.sign(self.bias.data)\n",
    "\n",
    "            out = self.org_forward(x)\n",
    "            print(self.org_forward)\n",
    "            #Replace the weights with original weights\n",
    "            self.weight.data = self.org_weight_data\n",
    "            self.bias.data = self.org_bias_data\n",
    "            return out\n",
    "        return forward\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    if isinstance(module,(nn.Conv2d,nn.Linear)):\n",
    "        module.org_weight_data = module.weight.data\n",
    "        module.org_bias_data = module.bias.data\n",
    "        module.org_forward = self.forward\n",
    "        module.forward = binary_forward(module)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Currently only accepts conv2d and linear layers')\n",
    "        \n",
    "\n",
    "n = nn.Conv2d(3,3,3)\n",
    "\n",
    "convert_to_binary(n)\n",
    "\n",
    "x = torch.ones(1,3,3,3)\n",
    "\n",
    "vars(n)\n",
    "n(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
